// Merged header file - auto-generated by python3 ./merge_headers.py ./inc/aclnnop

// Begin content from: acl/error_codes/ge_error_codes.h
/* Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 * ===================================================================================================================*/

#ifndef INC_EXTERNAL_GE_GE_ERROR_CODES_H_
#define INC_EXTERNAL_GE_GE_ERROR_CODES_H_

#if defined(_MSC_VER)
#ifdef FUNC_VISIBILITY
#define GE_FUNC_VISIBILITY _declspec(dllexport)
#else
#define GE_FUNC_VISIBILITY
#endif
#else
#ifdef FUNC_VISIBILITY
#define GE_FUNC_VISIBILITY __attribute__((visibility("default")))
#else
#define GE_FUNC_VISIBILITY
#endif
#endif

#include <stddef.h>
#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif
static const uint32_t ACL_ERROR_GE_PARAM_INVALID = 145000U;
static const uint32_t ACL_ERROR_GE_EXEC_NOT_INIT = 145001U;
static const uint32_t ACL_ERROR_GE_EXEC_MODEL_PATH_INVALID = 145002U;
static const uint32_t ACL_ERROR_GE_EXEC_MODEL_ID_INVALID = 145003U;
static const uint32_t ACL_ERROR_GE_EXEC_MODEL_DATA_SIZE_INVALID = 145006U;
static const uint32_t ACL_ERROR_GE_EXEC_MODEL_ADDR_INVALID = 145007U;
static const uint32_t ACL_ERROR_GE_EXEC_MODEL_QUEUE_ID_INVALID = 145008U;
static const uint32_t ACL_ERROR_GE_EXEC_LOAD_MODEL_REPEATED = 145009U;
static const uint32_t ACL_ERROR_GE_DYNAMIC_INPUT_ADDR_INVALID = 145011U;
static const uint32_t ACL_ERROR_GE_DYNAMIC_INPUT_LENGTH_INVALID = 145012U;
static const uint32_t ACL_ERROR_GE_DYNAMIC_BATCH_SIZE_INVALID = 145013U;
static const uint32_t ACL_ERROR_GE_AIPP_BATCH_EMPTY = 145014U;
static const uint32_t ACL_ERROR_GE_AIPP_NOT_EXIST = 145015U;
static const uint32_t ACL_ERROR_GE_AIPP_MODE_INVALID = 145016U;
static const uint32_t ACL_ERROR_GE_OP_TASK_TYPE_INVALID = 145017U;
static const uint32_t ACL_ERROR_GE_OP_KERNEL_TYPE_INVALID = 145018U;
static const uint32_t ACL_ERROR_GE_PLGMGR_PATH_INVALID = 145019U;
static const uint32_t ACL_ERROR_GE_FORMAT_INVALID = 145020U;
static const uint32_t ACL_ERROR_GE_SHAPE_INVALID = 145021U;
static const uint32_t ACL_ERROR_GE_DATATYPE_INVALID = 145022U;
static const uint32_t ACL_ERROR_GE_MEMORY_ALLOCATION = 245000U;
static const uint32_t ACL_ERROR_GE_MEMORY_OPERATE_FAILED = 245001U;
static const uint32_t ACL_ERROR_GE_DEVICE_MEMORY_OPERATE_FAILED = 245002U;
static const uint32_t ACL_ERROR_GE_SUBHEALTHY = 345102U;
static const uint32_t ACL_ERROR_GE_USER_RAISE_EXCEPTION = 345103U;
static const uint32_t ACL_ERROR_GE_DATA_NOT_ALIGNED = 345104U;
static const uint32_t ACL_ERROR_GE_INTERNAL_ERROR = 545000U;
static const uint32_t ACL_ERROR_GE_LOAD_MODEL = 545001U;
static const uint32_t ACL_ERROR_GE_EXEC_LOAD_MODEL_PARTITION_FAILED = 545002U;
static const uint32_t ACL_ERROR_GE_EXEC_LOAD_WEIGHT_PARTITION_FAILED = 545003U;
static const uint32_t ACL_ERROR_GE_EXEC_LOAD_TASK_PARTITION_FAILED = 545004U;
static const uint32_t ACL_ERROR_GE_EXEC_LOAD_KERNEL_PARTITION_FAILED = 545005U;
static const uint32_t ACL_ERROR_GE_EXEC_RELEASE_MODEL_DATA = 545006U;
static const uint32_t ACL_ERROR_GE_COMMAND_HANDLE = 545007U;
static const uint32_t ACL_ERROR_GE_GET_TENSOR_INFO = 545008U;
static const uint32_t ACL_ERROR_GE_UNLOAD_MODEL = 545009U;
static const uint32_t ACL_ERROR_GE_MODEL_EXECUTE_TIMEOUT = 545601U;
static const uint32_t ACL_ERROR_GE_REDEPLOYING = 545602U;

#ifdef __cplusplus
}  // namespace ge
#endif
#endif  // INC_EXTERNAL_GE_GE_ERROR_CODES_H_
// End content from: acl/error_codes/ge_error_codes.h

// Begin content from: acl/error_codes/rt_error_codes.h
/**
* @file rt_error_codes.h
*
* Copyright (C) Huawei Technologies Co., Ltd. 2019-2020. All Rights Reserved.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
*/

#ifndef __INC_EXTERNEL_RT_ERROR_CODES_H__
#define __INC_EXTERNEL_RT_ERROR_CODES_H__

#include <stddef.h>

#ifdef __cplusplus
extern "C" {
#endif

#define  ACL_RT_SUCCESS    0                               // success
#define  ACL_ERROR_RT_PARAM_INVALID              107000 // param invalid
#define  ACL_ERROR_RT_INVALID_DEVICEID           107001 // invalid device id
#define  ACL_ERROR_RT_CONTEXT_NULL               107002 // current context null
#define  ACL_ERROR_RT_STREAM_CONTEXT             107003 // stream not in current context
#define  ACL_ERROR_RT_MODEL_CONTEXT              107004 // model not in current context
#define  ACL_ERROR_RT_STREAM_MODEL               107005 // stream not in model
#define  ACL_ERROR_RT_EVENT_TIMESTAMP_INVALID    107006 // event timestamp invalid
#define  ACL_ERROR_RT_EVENT_TIMESTAMP_REVERSAL   107007 // event timestamp reversal
#define  ACL_ERROR_RT_ADDR_UNALIGNED             107008 // memory address unaligned
#define  ACL_ERROR_RT_FILE_OPEN                  107009 // open file failed
#define  ACL_ERROR_RT_FILE_WRITE                 107010 // write file failed
#define  ACL_ERROR_RT_STREAM_SUBSCRIBE           107011 // error subscribe stream
#define  ACL_ERROR_RT_THREAD_SUBSCRIBE           107012 // error subscribe thread
#define  ACL_ERROR_RT_GROUP_NOT_SET              107013 // group not set
#define  ACL_ERROR_RT_GROUP_NOT_CREATE           107014 // group not create
#define  ACL_ERROR_RT_STREAM_NO_CB_REG           107015 // callback not register to stream
#define  ACL_ERROR_RT_INVALID_MEMORY_TYPE        107016 // invalid memory type
#define  ACL_ERROR_RT_INVALID_HANDLE             107017 // invalid handle
#define  ACL_ERROR_RT_INVALID_MALLOC_TYPE        107018 // invalid malloc type
#define  ACL_ERROR_RT_WAIT_TIMEOUT               107019 // wait timeout
#define  ACL_ERROR_RT_TASK_TIMEOUT               107020 // task timeout
#define  ACL_ERROR_RT_SYSPARAMOPT_NOT_SET        107021 // not set sysparamopt
#define  ACL_ERROR_RT_DEVICE_TASK_ABORT          107022 // device task aborting
#define  ACL_ERROR_RT_STREAM_ABORT               107023 // stream aborting

#define  ACL_ERROR_RT_FEATURE_NOT_SUPPORT        207000 // feature not support
#define  ACL_ERROR_RT_MEMORY_ALLOCATION          207001 // memory allocation error
#define  ACL_ERROR_RT_MEMORY_FREE                207002 // memory free error
#define  ACL_ERROR_RT_AICORE_OVER_FLOW           207003 // aicore over flow
#define  ACL_ERROR_RT_NO_DEVICE                  207004 // no device
#define  ACL_ERROR_RT_RESOURCE_ALLOC_FAIL        207005 // resource alloc fail
#define  ACL_ERROR_RT_NO_PERMISSION              207006 // no permission
#define  ACL_ERROR_RT_NO_EVENT_RESOURCE          207007 // no event resource
#define  ACL_ERROR_RT_NO_STREAM_RESOURCE         207008 // no stream resource
#define  ACL_ERROR_RT_NO_NOTIFY_RESOURCE         207009 // no notify resource
#define  ACL_ERROR_RT_NO_MODEL_RESOURCE          207010 // no model resource
#define  ACL_ERROR_RT_NO_CDQ_RESOURCE            207011 // no cdq resource
#define  ACL_ERROR_RT_OVER_LIMIT                 207012 // over limit
#define  ACL_ERROR_RT_QUEUE_EMPTY                207013 // queue is empty
#define  ACL_ERROR_RT_QUEUE_FULL                 207014 // queue is full
#define  ACL_ERROR_RT_REPEATED_INIT              207015 // repeated init
#define  ACL_ERROR_RT_AIVEC_OVER_FLOW            207016 // aivec over flow
#define  ACL_ERROR_RT_OVER_FLOW                  207017 // common over flow
#define  ACL_ERROR_RT_DEVICE_OOM                 207018 // device oom

#define  ACL_ERROR_RT_INTERNAL_ERROR             507000 // runtime internal error
#define  ACL_ERROR_RT_TS_ERROR                   507001 // ts internel error
#define  ACL_ERROR_RT_STREAM_TASK_FULL           507002 // task full in stream
#define  ACL_ERROR_RT_STREAM_TASK_EMPTY          507003 // task empty in stream
#define  ACL_ERROR_RT_STREAM_NOT_COMPLETE        507004 // stream not complete
#define  ACL_ERROR_RT_END_OF_SEQUENCE            507005 // end of sequence
#define  ACL_ERROR_RT_EVENT_NOT_COMPLETE         507006 // event not complete
#define  ACL_ERROR_RT_CONTEXT_RELEASE_ERROR      507007 // context release error
#define  ACL_ERROR_RT_SOC_VERSION                507008 // soc version error
#define  ACL_ERROR_RT_TASK_TYPE_NOT_SUPPORT      507009 // task type not support
#define  ACL_ERROR_RT_LOST_HEARTBEAT             507010 // ts lost heartbeat
#define  ACL_ERROR_RT_MODEL_EXECUTE              507011 // model execute failed
#define  ACL_ERROR_RT_REPORT_TIMEOUT             507012 // report timeout
#define  ACL_ERROR_RT_SYS_DMA                    507013 // sys dma error
#define  ACL_ERROR_RT_AICORE_TIMEOUT             507014 // aicore timeout
#define  ACL_ERROR_RT_AICORE_EXCEPTION           507015 // aicore exception
#define  ACL_ERROR_RT_AICORE_TRAP_EXCEPTION      507016 // aicore trap exception
#define  ACL_ERROR_RT_AICPU_TIMEOUT              507017 // aicpu timeout
#define  ACL_ERROR_RT_AICPU_EXCEPTION            507018 // aicpu exception
#define  ACL_ERROR_RT_AICPU_DATADUMP_RSP_ERR     507019 // aicpu datadump response error
#define  ACL_ERROR_RT_AICPU_MODEL_RSP_ERR        507020 // aicpu model operate response error
#define  ACL_ERROR_RT_PROFILING_ERROR            507021 // profiling error
#define  ACL_ERROR_RT_IPC_ERROR                  507022 // ipc error
#define  ACL_ERROR_RT_MODEL_ABORT_NORMAL         507023 // model abort normal
#define  ACL_ERROR_RT_KERNEL_UNREGISTERING       507024 // kernel unregistering
#define  ACL_ERROR_RT_RINGBUFFER_NOT_INIT        507025 // ringbuffer not init
#define  ACL_ERROR_RT_RINGBUFFER_NO_DATA         507026 // ringbuffer no data
#define  ACL_ERROR_RT_KERNEL_LOOKUP              507027 // kernel lookup error
#define  ACL_ERROR_RT_KERNEL_DUPLICATE           507028 // kernel register duplicate
#define  ACL_ERROR_RT_DEBUG_REGISTER_FAIL        507029 // debug register failed
#define  ACL_ERROR_RT_DEBUG_UNREGISTER_FAIL      507030 // debug unregister failed
#define  ACL_ERROR_RT_LABEL_CONTEXT              507031 // label not in current context
#define  ACL_ERROR_RT_PROGRAM_USE_OUT            507032 // program register num use out
#define  ACL_ERROR_RT_DEV_SETUP_ERROR            507033 // device setup error
#define  ACL_ERROR_RT_VECTOR_CORE_TIMEOUT        507034 // vector core timeout
#define  ACL_ERROR_RT_VECTOR_CORE_EXCEPTION      507035 // vector core exception
#define  ACL_ERROR_RT_VECTOR_CORE_TRAP_EXCEPTION 507036 // vector core trap exception
#define  ACL_ERROR_RT_CDQ_BATCH_ABNORMAL         507037 // cdq alloc batch abnormal
#define  ACL_ERROR_RT_DIE_MODE_CHANGE_ERROR      507038 // can not change die mode
#define  ACL_ERROR_RT_DIE_SET_ERROR              507039 // single die mode can not set die
#define  ACL_ERROR_RT_INVALID_DIEID              507040 // invalid die id
#define  ACL_ERROR_RT_DIE_MODE_NOT_SET           507041 // die mode not set
#define  ACL_ERROR_RT_AICORE_TRAP_READ_OVERFLOW       507042 // aic trap read overflow
#define  ACL_ERROR_RT_AICORE_TRAP_WRITE_OVERFLOW      507043 // aic trap write overflow
#define  ACL_ERROR_RT_VECTOR_CORE_TRAP_READ_OVERFLOW  507044 // aiv trap read overflow
#define  ACL_ERROR_RT_VECTOR_CORE_TRAP_WRITE_OVERFLOW 507045 // aiv trap write overflow
#define  ACL_ERROR_RT_STREAM_SYNC_TIMEOUT        507046 // stream sync time out
#define  ACL_ERROR_RT_EVENT_SYNC_TIMEOUT         507047 // event sync time out
#define  ACL_ERROR_RT_FFTS_PLUS_TIMEOUT          507048 // ffts+ timeout
#define  ACL_ERROR_RT_FFTS_PLUS_EXCEPTION        507049 // ffts+ exception
#define  ACL_ERROR_RT_FFTS_PLUS_TRAP_EXCEPTION   507050 // ffts+ trap exception
#define  ACL_ERROR_RT_SEND_MSG                   507051 // hdc send msg fail
#define  ACL_ERROR_RT_COPY_DATA                  507052 // copy data fail
#define  ACL_ERROR_RT_DEVICE_MEM_ERROR           507053 // device MEM ERROR
#define  ACL_ERROR_RT_DRV_INTERNAL_ERROR         507899 // drv internal error
#define  ACL_ERROR_RT_AICPU_INTERNAL_ERROR       507900 // aicpu internal error
#define  ACL_ERROR_RT_SOCKET_CLOSE               507901 // hdc disconnect
#define  ACL_ERROR_RT_AICPU_INFO_LOAD_RSP_ERR    507902 // aicpu info load response error

#ifdef __cplusplus
}
#endif
#endif // __INC_EXTERNEL_RT_ERROR_CODES_H__
// End content from: acl/error_codes/rt_error_codes.h

// Begin content from: acl/acl_base.h
/**
* @file acl_base.h
*
* Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
*/

#ifndef INC_EXTERNAL_ACL_ACL_BASE_H_
#define INC_EXTERNAL_ACL_ACL_BASE_H_

#include <stdint.h>
#include <stddef.h>
// #include "error_codes/rt_error_codes.h"
// #include "error_codes/ge_error_codes.h"

#ifdef __cplusplus
extern "C" {
#endif

#if defined(_MSC_VER)
#ifdef FUNC_VISIBILITY
#define ACL_FUNC_VISIBILITY _declspec(dllexport)
#else
#define ACL_FUNC_VISIBILITY
#endif
#else
#ifdef FUNC_VISIBILITY
#define ACL_FUNC_VISIBILITY __attribute__((visibility("default")))
#else
#define ACL_FUNC_VISIBILITY
#endif
#endif

#ifdef __GNUC__
#define ACL_DEPRECATED __attribute__((deprecated))
#define ACL_DEPRECATED_MESSAGE(message) __attribute__((deprecated(message)))
#elif defined(_MSC_VER)
#define ACL_DEPRECATED __declspec(deprecated)
#define ACL_DEPRECATED_MESSAGE(message) __declspec(deprecated(message))
#else
#define ACL_DEPRECATED
#define ACL_DEPRECATED_MESSAGE(message)
#endif

typedef void *aclrtStream;
typedef void *aclrtEvent;
typedef void *aclrtContext;
typedef int aclError;
typedef uint16_t aclFloat16;
typedef struct aclDataBuffer aclDataBuffer;
typedef struct aclTensorDesc aclTensorDesc;
typedef void *aclrtAllocatorDesc;
typedef void *aclrtAllocator;
typedef void *aclrtAllocatorBlock;
typedef void *aclrtAllocatorAddr;

static const int ACL_ERROR_NONE = 0;
static const int ACL_SUCCESS = 0;

static const int ACL_ERROR_INVALID_PARAM = 100000;
static const int ACL_ERROR_UNINITIALIZE = 100001;
static const int ACL_ERROR_REPEAT_INITIALIZE = 100002;
static const int ACL_ERROR_INVALID_FILE = 100003;
static const int ACL_ERROR_WRITE_FILE = 100004;
static const int ACL_ERROR_INVALID_FILE_SIZE = 100005;
static const int ACL_ERROR_PARSE_FILE = 100006;
static const int ACL_ERROR_FILE_MISSING_ATTR = 100007;
static const int ACL_ERROR_FILE_ATTR_INVALID = 100008;
static const int ACL_ERROR_INVALID_DUMP_CONFIG = 100009;
static const int ACL_ERROR_INVALID_PROFILING_CONFIG = 100010;
static const int ACL_ERROR_INVALID_MODEL_ID = 100011;
static const int ACL_ERROR_DESERIALIZE_MODEL = 100012;
static const int ACL_ERROR_PARSE_MODEL = 100013;
static const int ACL_ERROR_READ_MODEL_FAILURE = 100014;
static const int ACL_ERROR_MODEL_SIZE_INVALID = 100015;
static const int ACL_ERROR_MODEL_MISSING_ATTR = 100016;
static const int ACL_ERROR_MODEL_INPUT_NOT_MATCH = 100017;
static const int ACL_ERROR_MODEL_OUTPUT_NOT_MATCH = 100018;
static const int ACL_ERROR_MODEL_NOT_DYNAMIC = 100019;
static const int ACL_ERROR_OP_TYPE_NOT_MATCH = 100020;
static const int ACL_ERROR_OP_INPUT_NOT_MATCH = 100021;
static const int ACL_ERROR_OP_OUTPUT_NOT_MATCH = 100022;
static const int ACL_ERROR_OP_ATTR_NOT_MATCH = 100023;
static const int ACL_ERROR_OP_NOT_FOUND = 100024;
static const int ACL_ERROR_OP_LOAD_FAILED = 100025;
static const int ACL_ERROR_UNSUPPORTED_DATA_TYPE = 100026;
static const int ACL_ERROR_FORMAT_NOT_MATCH = 100027;
static const int ACL_ERROR_BIN_SELECTOR_NOT_REGISTERED = 100028;
static const int ACL_ERROR_KERNEL_NOT_FOUND = 100029;
static const int ACL_ERROR_BIN_SELECTOR_ALREADY_REGISTERED = 100030;
static const int ACL_ERROR_KERNEL_ALREADY_REGISTERED = 100031;
static const int ACL_ERROR_INVALID_QUEUE_ID = 100032;
static const int ACL_ERROR_REPEAT_SUBSCRIBE = 100033;
static const int ACL_ERROR_STREAM_NOT_SUBSCRIBE = 100034;
static const int ACL_ERROR_THREAD_NOT_SUBSCRIBE = 100035;
static const int ACL_ERROR_WAIT_CALLBACK_TIMEOUT = 100036;
static const int ACL_ERROR_REPEAT_FINALIZE = 100037;
static const int ACL_ERROR_NOT_STATIC_AIPP = 100038;
static const int ACL_ERROR_COMPILING_STUB_MODE = 100039;
static const int ACL_ERROR_GROUP_NOT_SET = 100040;
static const int ACL_ERROR_GROUP_NOT_CREATE = 100041;
static const int ACL_ERROR_PROF_ALREADY_RUN = 100042;
static const int ACL_ERROR_PROF_NOT_RUN = 100043;
static const int ACL_ERROR_DUMP_ALREADY_RUN = 100044;
static const int ACL_ERROR_DUMP_NOT_RUN = 100045;
static const int ACL_ERROR_PROF_REPEAT_SUBSCRIBE = 148046;
static const int ACL_ERROR_PROF_API_CONFLICT = 148047;
static const int ACL_ERROR_INVALID_MAX_OPQUEUE_NUM_CONFIG = 148048;
static const int ACL_ERROR_INVALID_OPP_PATH = 148049;
static const int ACL_ERROR_OP_UNSUPPORTED_DYNAMIC = 148050;
static const int ACL_ERROR_RELATIVE_RESOURCE_NOT_CLEARED = 148051;
static const int ACL_ERROR_UNSUPPORTED_JPEG = 148052;
static const int ACL_ERROR_INVALID_BUNDLE_MODEL_ID = 148053;

static const int ACL_ERROR_BAD_ALLOC = 200000;
static const int ACL_ERROR_API_NOT_SUPPORT = 200001;
static const int ACL_ERROR_INVALID_DEVICE = 200002;
static const int ACL_ERROR_MEMORY_ADDRESS_UNALIGNED = 200003;
static const int ACL_ERROR_RESOURCE_NOT_MATCH = 200004;
static const int ACL_ERROR_INVALID_RESOURCE_HANDLE = 200005;
static const int ACL_ERROR_FEATURE_UNSUPPORTED = 200006;
static const int ACL_ERROR_PROF_MODULES_UNSUPPORTED = 200007;

static const int ACL_ERROR_STORAGE_OVER_LIMIT = 300000;

static const int ACL_ERROR_INTERNAL_ERROR = 500000;
static const int ACL_ERROR_FAILURE = 500001;
static const int ACL_ERROR_GE_FAILURE = 500002;
static const int ACL_ERROR_RT_FAILURE = 500003;
static const int ACL_ERROR_DRV_FAILURE = 500004;
static const int ACL_ERROR_PROFILING_FAILURE = 500005;

#define ACL_TENSOR_SHAPE_RANGE_NUM 2
#define ACL_TENSOR_VALUE_RANGE_NUM 2
#define ACL_UNKNOWN_RANK 0xFFFFFFFFFFFFFFFE

typedef enum {
    ACL_DT_UNDEFINED = -1,
    ACL_FLOAT = 0,
    ACL_FLOAT16 = 1,
    ACL_INT8 = 2,
    ACL_INT32 = 3,
    ACL_UINT8 = 4,
    ACL_INT16 = 6,
    ACL_UINT16 = 7,
    ACL_UINT32 = 8,
    ACL_INT64 = 9,
    ACL_UINT64 = 10,
    ACL_DOUBLE = 11,
    ACL_BOOL = 12,
    ACL_STRING = 13,
    ACL_COMPLEX64 = 16,
    ACL_COMPLEX128 = 17,
    ACL_BF16 = 27,
    ACL_INT4 = 29,
    ACL_UINT1 = 30,
    ACL_COMPLEX32 = 33,
} aclDataType;

typedef enum {
    ACL_FORMAT_UNDEFINED = -1,
    ACL_FORMAT_NCHW = 0,
    ACL_FORMAT_NHWC = 1,
    ACL_FORMAT_ND = 2,
    ACL_FORMAT_NC1HWC0 = 3,
    ACL_FORMAT_FRACTAL_Z = 4,
    ACL_FORMAT_NC1HWC0_C04 = 12,
    ACL_FORMAT_HWCN = 16,
    ACL_FORMAT_NDHWC = 27,
    ACL_FORMAT_FRACTAL_NZ = 29,
    ACL_FORMAT_NCDHW = 30,
    ACL_FORMAT_NDC1HWC0 = 32,
    ACL_FRACTAL_Z_3D = 33,
    ACL_FORMAT_NC = 35,
    ACL_FORMAT_NCL = 47,
} aclFormat;

typedef enum {
    ACL_DEBUG = 0,
    ACL_INFO = 1,
    ACL_WARNING = 2,
    ACL_ERROR = 3,
} aclLogLevel;

typedef enum {
    ACL_MEMTYPE_DEVICE = 0,
    ACL_MEMTYPE_HOST = 1,
    ACL_MEMTYPE_HOST_COMPILE_INDEPENDENT = 2
} aclMemType;

typedef enum {
    ACL_OPT_DETERMINISTIC = 0,
    ACL_OPT_ENABLE_DEBUG_KERNEL = 1
} aclSysParamOpt;

typedef enum {
    ACL_CANN_ATTR_UNDEFINED = -1,
    ACL_CANN_ATTR_INF_NAN = 0,
    ACL_CANN_ATTR_BF16 = 1,
    ACL_CANN_ATTR_JIT_COMPILE = 2
} aclCannAttr;

typedef enum {
    ACL_DEVICE_INFO_UNDEFINED = -1,
    ACL_DEVICE_INFO_AI_CORE_NUM = 0,
    ACL_DEVICE_INFO_VECTOR_CORE_NUM = 1,
    ACL_DEVICE_INFO_L2_SIZE = 2
} aclDeviceInfo;

/**
 * @ingroup AscendCL
 * @brief Converts data of type aclFloat16 to data of type float
 *
 * @param value [IN]   Data to be converted
 *
 * @retval Transformed data
 */
ACL_FUNC_VISIBILITY float aclFloat16ToFloat(aclFloat16 value);

/**
 * @ingroup AscendCL
 * @brief Converts data of type float to data of type aclFloat16
 *
 * @param value [IN]   Data to be converted
 *
 * @retval Transformed data
 */
ACL_FUNC_VISIBILITY aclFloat16 aclFloatToFloat16(float value);

/**
 * @ingroup AscendCL
 * @brief create data of aclDataBuffer
 *
 * @param data [IN]    pointer to data
 * @li Need to be managed by the user,
 *  call aclrtMalloc interface to apply for memory,
 *  call aclrtFree interface to release memory
 *
 * @param size [IN]    size of data in bytes
 *
 * @retval pointer to created instance. nullptr if run out of memory
 *
 * @see aclrtMalloc | aclrtFree
 */
ACL_FUNC_VISIBILITY aclDataBuffer *aclCreateDataBuffer(void *data, size_t size);

/**
 * @ingroup AscendCL
 * @brief destroy data of aclDataBuffer
 *
 * @par Function
 *  Only the aclDataBuffer type data is destroyed here.
 *  The memory of the data passed in when the aclDataDataBuffer interface
 *  is called to create aclDataBuffer type data must be released by the user
 *
 * @param  dataBuffer [IN]   pointer to the aclDataBuffer
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclCreateDataBuffer
 */
ACL_FUNC_VISIBILITY aclError aclDestroyDataBuffer(const aclDataBuffer *dataBuffer);

/**
 * @ingroup AscendCL
 * @brief update new data of aclDataBuffer
 *
 * @param dataBuffer [OUT]    pointer to aclDataBuffer
 * @li The old data need to be released by the user, otherwise it may occur memory leak leakage
 *  call aclGetDataBufferAddr interface to get old data address
 *  call aclrtFree interface to release memory
 *
 * @param data [IN]    pointer to new data
 * @li Need to be managed by the user,
 *  call aclrtMalloc interface to apply for memory,
 *  call aclrtFree interface to release memory
 *
 * @param size [IN]    size of data in bytes
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtMalloc | aclrtFree | aclGetDataBufferAddr
 */
ACL_FUNC_VISIBILITY aclError aclUpdateDataBuffer(aclDataBuffer *dataBuffer, void *data, size_t size);

/**
 * @ingroup AscendCL
 * @brief get data address from aclDataBuffer
 *
 * @param dataBuffer [IN]    pointer to the data of aclDataBuffer
 *
 * @retval data address
 */
ACL_FUNC_VISIBILITY void *aclGetDataBufferAddr(const aclDataBuffer *dataBuffer);

/**
 * @ingroup AscendCL
 * @brief get data size of aclDataBuffer
 *
 * @param  dataBuffer [IN]    pointer to the data of aclDataBuffer
 *
 * @retval data size
 */
ACL_DEPRECATED_MESSAGE("aclGetDataBufferSize is deprecated, use aclGetDataBufferSizeV2 instead")
ACL_FUNC_VISIBILITY uint32_t aclGetDataBufferSize(const aclDataBuffer *dataBuffer);

/**
 * @ingroup AscendCL
 * @brief get data size of aclDataBuffer to replace aclGetDataBufferSize
 *
 * @param  dataBuffer [IN]    pointer to the data of aclDataBuffer
 *
 * @retval data size
 */
ACL_FUNC_VISIBILITY size_t aclGetDataBufferSizeV2(const aclDataBuffer *dataBuffer);

/**
 * @ingroup AscendCL
 * @brief get size of aclDataType
 *
 * @param  dataType [IN]    aclDataType data the size to get
 *
 * @retval size of the aclDataType
 */
ACL_FUNC_VISIBILITY size_t aclDataTypeSize(aclDataType dataType);

// interfaces of tensor desc
/**
 * @ingroup AscendCL
 * @brief create data aclTensorDesc
 *
 * @param  dataType [IN]    Data types described by tensor
 * @param  numDims [IN]     the number of dimensions of the shape
 * @param  dims [IN]        the size of the specified dimension
 * @param  format [IN]      tensor format
 *
 * @retval aclTensorDesc pointer.
 * @retval nullptr if param is invalid or run out of memory
 */
ACL_FUNC_VISIBILITY aclTensorDesc *aclCreateTensorDesc(aclDataType dataType,
                                                       int numDims,
                                                       const int64_t *dims,
                                                       aclFormat format);

/**
 * @ingroup AscendCL
 * @brief destroy data aclTensorDesc
 *
 * @param desc [IN]     pointer to the data of aclTensorDesc to destroy
 */
ACL_FUNC_VISIBILITY void aclDestroyTensorDesc(const aclTensorDesc *desc);

/**
 * @ingroup AscendCL
 * @brief set tensor shape range for aclTensorDesc
 *
 * @param  desc [OUT]     pointer to the data of aclTensorDesc
 * @param  dimsCount [IN]     the number of dimensions of the shape
 * @param  dimsRange [IN]     the range of dimensions of the shape
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorShapeRange(aclTensorDesc* desc,
                                                    size_t dimsCount,
                                                    int64_t dimsRange[][ACL_TENSOR_SHAPE_RANGE_NUM]);

/**
 * @ingroup AscendCL
 * @brief set value range for aclTensorDesc
 *
 * @param  desc [OUT]     pointer to the data of aclTensorDesc
 * @param  valueCount [IN]     the number of value
 * @param  valueRange [IN]     the range of value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorValueRange(aclTensorDesc* desc,
                                                    size_t valueCount,
                                                    int64_t valueRange[][ACL_TENSOR_VALUE_RANGE_NUM]);
/**
 * @ingroup AscendCL
 * @brief get data type specified by the tensor description
 *
 * @param desc [IN]        pointer to the instance of aclTensorDesc
 *
 * @retval data type specified by the tensor description.
 * @retval ACL_DT_UNDEFINED if description is null
 */
ACL_FUNC_VISIBILITY aclDataType aclGetTensorDescType(const aclTensorDesc *desc);

/**
 * @ingroup AscendCL
 * @brief get data format specified by the tensor description
 *
 * @param  desc [IN]        pointer to the instance of aclTensorDesc
 *
 * @retval data format specified by the tensor description.
 * @retval ACL_FORMAT_UNDEFINED if description is null
 */
ACL_FUNC_VISIBILITY aclFormat aclGetTensorDescFormat(const aclTensorDesc *desc);

/**
 * @ingroup AscendCL
 * @brief get tensor size specified by the tensor description
 *
 * @param  desc [IN]        pointer to the instance of aclTensorDesc
 *
 * @retval data size specified by the tensor description.
 * @retval 0 if description is null
 */
ACL_FUNC_VISIBILITY size_t aclGetTensorDescSize(const aclTensorDesc *desc);

/**
 * @ingroup AscendCL
 * @brief get element count specified by the tensor description
 *
 * @param  desc [IN]        pointer to the instance of aclTensorDesc
 *
 * @retval element count specified by the tensor description.
 * @retval 0 if description is null
 */
ACL_FUNC_VISIBILITY size_t aclGetTensorDescElementCount(const aclTensorDesc *desc);

/**
 * @ingroup AscendCL
 * @brief get number of dims specified by the tensor description
 *
 * @param  desc [IN]        pointer to the instance of aclTensorDesc
 *
 * @retval number of dims specified by the tensor description.
 * @retval 0 if description is null
 * @retval ACL_UNKNOWN_RANK if the tensor dim is -2
 */
ACL_FUNC_VISIBILITY size_t aclGetTensorDescNumDims(const aclTensorDesc *desc);

/**
 * @ingroup AscendCL
 * @brief Get the size of the specified dim in the tensor description
 *
 * @param  desc [IN]        pointer to the instance of aclTensorDesc
 * @param  index [IN]       index of dims, start from 0.
 *
 * @retval dim specified by the tensor description and index.
 * @retval -1 if description or index is invalid
 */
ACL_DEPRECATED_MESSAGE("aclGetTensorDescDim is deprecated, use aclGetTensorDescDimV2 instead")
ACL_FUNC_VISIBILITY int64_t aclGetTensorDescDim(const aclTensorDesc *desc, size_t index);

/**
 * @ingroup AscendCL
 * @brief Get the size of the specified dim in the tensor description
 *
 * @param  desc [IN]        pointer to the instance of aclTensorDesc
 * @param  index [IN]       index of dims, start from 0.
 * @param  dimSize [OUT]    size of the specified dim.
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclGetTensorDescDimV2(const aclTensorDesc *desc, size_t index, int64_t *dimSize);

/**
 * @ingroup AscendCL
 * @brief Get the range of the specified dim in the tensor description
 *
 * @param  desc [IN]        pointer to the instance of aclTensorDesc
 * @param  index [IN]       index of dims, start from 0.
 * @param  dimRangeNum [IN]     number of dimRange.
 * @param  dimRange [OUT]       range of the specified dim.
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclGetTensorDescDimRange(const aclTensorDesc *desc,
                                                      size_t index,
                                                      size_t dimRangeNum,
                                                      int64_t *dimRange);

/**
 * @ingroup AscendCL
 * @brief set tensor description name
 *
 * @param desc [OUT]       pointer to the instance of aclTensorDesc
 * @param name [IN]        tensor description name
 */
ACL_FUNC_VISIBILITY void aclSetTensorDescName(aclTensorDesc *desc, const char *name);

/**
 * @ingroup AscendCL
 * @brief get tensor description name
 *
 * @param  desc [IN]        pointer to the instance of aclTensorDesc
 *
 * @retval tensor description name.
 * @retval empty string if description is null
 */
ACL_FUNC_VISIBILITY const char *aclGetTensorDescName(aclTensorDesc *desc);

/**
 * @ingroup AscendCL
 * @brief Convert the format in the source aclTensorDesc according to
 * the specified dstFormat to generate a new target aclTensorDesc.
 * The format in the source aclTensorDesc remains unchanged.
 *
 * @param  srcDesc [IN]     pointer to the source tensor desc
 * @param  dstFormat [IN]   destination format
 * @param  dstDesc [OUT]    pointer to the pointer to the destination tensor desc
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclTransTensorDescFormat(const aclTensorDesc *srcDesc, aclFormat dstFormat,
    aclTensorDesc **dstDesc);

/**
 * @ingroup AscendCL
 * @brief Set the storage format specified by the tensor description
 *
 * @param  desc [OUT]     pointer to the instance of aclTensorDesc
 * @param  format [IN]    the storage format
 *
 * @retval ACL_SUCCESS    The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_DEPRECATED_MESSAGE("aclSetTensorStorageFormat is deprecated, use aclSetTensorFormat instead")
ACL_FUNC_VISIBILITY aclError aclSetTensorStorageFormat(aclTensorDesc *desc, aclFormat format);

/**
 * @ingroup AscendCL
 * @brief Set the storage shape specified by the tensor description
 *
 * @param  desc [OUT]      pointer to the instance of aclTensorDesc
 * @param  numDims [IN]    the number of dimensions of the shape
 * @param  dims [IN]       the size of the specified dimension
 *
 * @retval ACL_SUCCESS     The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_DEPRECATED_MESSAGE("aclSetTensorStorageShape is deprecated, use aclSetTensorShape instead")
ACL_FUNC_VISIBILITY aclError aclSetTensorStorageShape(aclTensorDesc *desc, int numDims, const int64_t *dims);

/**
 * @ingroup AscendCL
 * @brief Set the format specified by the tensor description
 *
 * @param  desc [OUT]     pointer to the instance of aclTensorDesc
 * @param  format [IN]    the storage format
 *
 * @retval ACL_SUCCESS    The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorFormat(aclTensorDesc *desc, aclFormat format);

/**
 * @ingroup AscendCL
 * @brief Set the shape specified by the tensor description
 *
 * @param  desc [OUT]      pointer to the instance of aclTensorDesc
 * @param  numDims [IN]    the number of dimensions of the shape
 * @param  dims [IN]       the size of the specified dimension
 *
 * @retval ACL_SUCCESS     The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorShape(aclTensorDesc *desc, int numDims, const int64_t *dims);

/**
 * @ingroup AscendCL
 * @brief Set the original format specified by the tensor description
 *
 * @param  desc [OUT]     pointer to the instance of aclTensorDesc
 * @param  format [IN]    the storage format
 *
 * @retval ACL_SUCCESS    The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorOriginFormat(aclTensorDesc *desc, aclFormat format);

/**
 * @ingroup AscendCL
 * @brief Set the original shape specified by the tensor description
 *
 * @param  desc [OUT]      pointer to the instance of aclTensorDesc
 * @param  numDims [IN]    the number of dimensions of the shape
 * @param  dims [IN]       the size of the specified dimension
 *
 * @retval ACL_SUCCESS     The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorOriginShape(aclTensorDesc *desc, int numDims, const int64_t *dims);

/**
 * @ingroup AscendCL
 * @brief get op description info
 *
 * @param desc [IN]     pointer to tensor description
 * @param index [IN]    index of tensor
 *
 * @retval null for failed.
 * @retval OtherValues success.
*/
ACL_FUNC_VISIBILITY aclTensorDesc *aclGetTensorDescByIndex(aclTensorDesc *desc, size_t index);

/**
 * @ingroup AscendCL
 * @brief get address of tensor
 *
 * @param desc [IN]    pointer to tensor description
 *
 * @retval null for failed
 * @retval OtherValues success
*/
ACL_FUNC_VISIBILITY void *aclGetTensorDescAddress(const aclTensorDesc *desc);

/**
 * @ingroup AscendCL
 * @brief Set the dynamic input name specified by the tensor description
 *
 * @param  desc [OUT]      pointer to the instance of aclTensorDesc
 * @param  dynamicInputName [IN]       pointer to the dynamic input name
 *
 * @retval ACL_SUCCESS     The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorDynamicInput(aclTensorDesc *desc, const char *dynamicInputName);

/**
 * @ingroup AscendCL
 * @brief Set const data specified by the tensor description
 *
 * @param  desc [OUT]      pointer to the instance of aclTensorDesc
 * @param  dataBuffer [IN]       pointer to the const databuffer
 * @param  length [IN]       the length of const databuffer
 *
 * @retval ACL_SUCCESS     The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorConst(aclTensorDesc *desc, void *dataBuffer, size_t length);

/**
 * @ingroup AscendCL
 * @brief Set tensor memory type specified by the tensor description
 *
 * @param  desc [OUT]      pointer to the instance of aclTensorDesc
 * @param  memType [IN]       ACL_MEMTYPE_DEVICE means device, ACL_MEMTYPE_HOST or
 * ACL_MEMTYPE_HOST_COMPILE_INDEPENDENT means host
 *
 * @retval ACL_SUCCESS     The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetTensorPlaceMent(aclTensorDesc *desc, aclMemType memType);

/**
 * @ingroup AscendCL
 * @brief an interface for users to output  APP logs
 *
 * @param logLevel [IN]    the level of current log
 * @param func [IN]        the function where the log is located
 * @param file [IN]        the file where the log is located
 * @param line [IN]        Number of source lines where the log is located
 * @param fmt [IN]         the format of current log
 * @param ... [IN]         the value of current log
 */
ACL_FUNC_VISIBILITY void aclAppLog(aclLogLevel logLevel, const char *func, const char *file, uint32_t line,
    const char *fmt, ...);

/**
 * @ingroup AscendCL
 * @brief get soc name
 *
 * @retval null for failed
 * @retval OtherValues success
*/
ACL_FUNC_VISIBILITY const char *aclrtGetSocName();

#define ACL_APP_LOG(level, fmt, ...) \
    aclAppLog(level, __FUNCTION__, __FILE__, __LINE__, fmt, ##__VA_ARGS__)

/**
 * @ingroup AscendCL
 * @brief Get a list of the available CANN attributes in current environment
 *
 * @param  cannAttrList [OUT]  list of the available CANN attributes
 * @param  num [OUT]  the number of the available CANN attributes
 *
 * @retval ACL_SUCCESS  The function is successfully executed.
 * @retval OtherValues  Failure
 */
ACL_FUNC_VISIBILITY aclError aclGetCannAttributeList(const aclCannAttr **cannAttrList, size_t *num);

/**
 * @ingroup AscendCL
 * @brief Check whether the specified CANN attribute is available in current
 * environment
 *
 * @param  cannAttr [IN]  CANN attributes to query
 * @param  num [OUT]  0/1: 0 represents unavailable , 1 available
 *
 * @retval ACL_SUCCESS  The function is successfully executed.
 * @retval OtherValues  Failure
 */
ACL_FUNC_VISIBILITY aclError aclGetCannAttribute(aclCannAttr cannAttr, int32_t *value);

/**
 * @ingroup AscendCL
 * @brief Get capability value of the specified device
 *
 * @param  deviceId [IN]  device id
 * @param  deviceInfo [IN]  device capability to query
 * @param  value [OUT]    returned device capability value
 *
 * @retval ACL_SUCCESS  The function is successfully executed.
 * @retval OtherValues  Failure
 */
ACL_FUNC_VISIBILITY aclError aclGetDeviceCapability(uint32_t deviceId, aclDeviceInfo deviceInfo, int64_t *value);

#ifdef __cplusplus
}
#endif

#endif // INC_EXTERNAL_ACL_ACL_BASE_H_
// End content from: acl/acl_base.h

// Begin content from: acl/acl_rt.h
/**
* @file acl_rt.h
*
* Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
*/

#ifndef INC_EXTERNAL_ACL_ACL_RT_H_
#define INC_EXTERNAL_ACL_ACL_RT_H_

#include <stdint.h>
#include <stddef.h>
// #include "acl_base.h"

#ifdef __cplusplus
extern "C" {
#endif

#define ACL_EVENT_SYNC                    0x00000001u
#define ACL_EVENT_CAPTURE_STREAM_PROGRESS 0x00000002u
#define ACL_EVENT_TIME_LINE               0x00000008u

#define ACL_STREAM_FAST_LAUNCH 0x00000001u
#define ACL_STREAM_FAST_SYNC   0x00000002u

#define ACL_CONTINUE_ON_FAILURE 0x00000000u
#define ACL_STOP_ON_FAILURE     0x00000001u

typedef enum aclrtRunMode {
    ACL_DEVICE,
    ACL_HOST,
} aclrtRunMode;

typedef enum aclrtTsId {
    ACL_TS_ID_AICORE   = 0,
    ACL_TS_ID_AIVECTOR = 1,
    ACL_TS_ID_RESERVED = 2,
} aclrtTsId;

typedef enum aclrtEventStatus {
    ACL_EVENT_STATUS_COMPLETE  = 0,
    ACL_EVENT_STATUS_NOT_READY = 1,
    ACL_EVENT_STATUS_RESERVED  = 2,
} aclrtEventStatus;

typedef enum aclrtEventRecordedStatus {
    ACL_EVENT_RECORDED_STATUS_NOT_READY = 0,
    ACL_EVENT_RECORDED_STATUS_COMPLETE = 1,
} aclrtEventRecordedStatus;

typedef enum aclrtEventWaitStatus {
    ACL_EVENT_WAIT_STATUS_COMPLETE  = 0,
    ACL_EVENT_WAIT_STATUS_NOT_READY = 1,
    ACL_EVENT_WAIT_STATUS_RESERVED  = 0xFFFF,
} aclrtEventWaitStatus;

typedef enum aclrtStreamStatus {
    ACL_STREAM_STATUS_COMPLETE  = 0,
    ACL_STREAM_STATUS_NOT_READY = 1,
    ACL_STREAM_STATUS_RESERVED  = 0xFFFF,
} aclrtStreamStatus;

typedef enum aclrtCallbackBlockType {
    ACL_CALLBACK_NO_BLOCK,
    ACL_CALLBACK_BLOCK,
} aclrtCallbackBlockType;

typedef enum aclrtMemcpyKind {
    ACL_MEMCPY_HOST_TO_HOST,
    ACL_MEMCPY_HOST_TO_DEVICE,
    ACL_MEMCPY_DEVICE_TO_HOST,
    ACL_MEMCPY_DEVICE_TO_DEVICE,
    ACL_MEMCPY_DEFAULT,
} aclrtMemcpyKind;

typedef enum aclrtMemMallocPolicy {
    ACL_MEM_MALLOC_HUGE_FIRST,
    ACL_MEM_MALLOC_HUGE_ONLY,
    ACL_MEM_MALLOC_NORMAL_ONLY,
    ACL_MEM_MALLOC_HUGE_FIRST_P2P,
    ACL_MEM_MALLOC_HUGE_ONLY_P2P,
    ACL_MEM_MALLOC_NORMAL_ONLY_P2P,
    ACL_MEM_TYPE_LOW_BAND_WIDTH   = 0x0100,
    ACL_MEM_TYPE_HIGH_BAND_WIDTH  = 0x1000,
} aclrtMemMallocPolicy;

typedef enum aclrtMemAttr {
    ACL_DDR_MEM,
    ACL_HBM_MEM,
    ACL_DDR_MEM_HUGE,
    ACL_DDR_MEM_NORMAL,
    ACL_HBM_MEM_HUGE,
    ACL_HBM_MEM_NORMAL,
    ACL_DDR_MEM_P2P_HUGE,
    ACL_DDR_MEM_P2P_NORMAL,
    ACL_HBM_MEM_P2P_HUGE,
    ACL_HBM_MEM_P2P_NORMAL,
} aclrtMemAttr;

typedef enum aclrtGroupAttr {
    ACL_GROUP_AICORE_INT,
    ACL_GROUP_AIV_INT,
    ACL_GROUP_AIC_INT,
    ACL_GROUP_SDMANUM_INT,
    ACL_GROUP_ASQNUM_INT,
    ACL_GROUP_GROUPID_INT
} aclrtGroupAttr;

typedef enum aclrtFloatOverflowMode {
    ACL_RT_OVERFLOW_MODE_SATURATION = 0,
    ACL_RT_OVERFLOW_MODE_INFNAN,
    ACL_RT_OVERFLOW_MODE_UNDEF,
} aclrtFloatOverflowMode;

typedef enum {
    ACL_RT_STREAM_WORK_ADDR_PTR = 0, /**< pointer to model work addr */
    ACL_RT_STREAM_WORK_SIZE, /**< pointer to model work size */
    ACL_RT_STREAM_FLAG,
    ACL_RT_STREAM_PRIORITY,
} aclrtStreamConfigAttr;

typedef struct aclrtStreamConfigHandle {
    void* workptr;
    size_t workSize;
    size_t flag;
    uint32_t priority;
} aclrtStreamConfigHandle;

typedef struct aclrtUtilizationExtendInfo aclrtUtilizationExtendInfo;

typedef struct aclrtUtilizationInfo {
    int32_t cubeUtilization;
    int32_t vectorUtilization;
    int32_t aicpuUtilization;
    int32_t memoryUtilization;
    aclrtUtilizationExtendInfo *utilizationExtend; /**< reserved parameters, current version needs to be null */
} aclrtUtilizationInfo;

typedef struct tagRtGroupInfo aclrtGroupInfo;

typedef struct rtExceptionInfo aclrtExceptionInfo;

typedef enum aclrtMemLocationType {
    ACL_MEM_LOCATION_TYPE_HOST = 0, /**< reserved enum, current version not support */
    ACL_MEM_LOCATION_TYPE_DEVICE,
} aclrtMemLocationType;

typedef struct aclrtMemLocation {
    uint32_t id;
    aclrtMemLocationType type;
} aclrtMemLocation;

typedef enum aclrtMemAllocationType {
    ACL_MEM_ALLOCATION_TYPE_PINNED = 0,
} aclrtMemAllocationType;

typedef enum aclrtMemHandleType {
    ACL_MEM_HANDLE_TYPE_NONE = 0,
} aclrtMemHandleType;

typedef struct aclrtPhysicalMemProp {
    aclrtMemHandleType handleType;
    aclrtMemAllocationType allocationType;
    aclrtMemAttr memAttr;
    aclrtMemLocation location;
    uint64_t reserve;
} aclrtPhysicalMemProp;

typedef enum aclrtMemGranularityOptions {
    ACL_RT_MEM_ALLOC_GRANULARITY_MINIMUM,
    ACL_RT_MEM_ALLOC_GRANULARITY_RECOMMENDED,
    ACL_RT_MEM_ALLOC_GRANULARITY_UNDEF = 0xFFFF,
} aclrtMemGranularityOptions;

typedef void* aclrtDrvMemHandle;

typedef void (*aclrtCallback)(void *userData);

typedef void (*aclrtExceptionInfoCallback)(aclrtExceptionInfo *exceptionInfo);

typedef enum aclrtDeviceStatus {
    ACL_RT_DEVICE_STATUS_NORMAL = 0,
    ACL_RT_DEVICE_STATUS_ABNORMAL,
    ACL_RT_DEVICE_STATUS_END = 0xFFFF,
} aclrtDeviceStatus;

typedef void* aclrtBinary;
typedef void* aclrtBinHandle;
typedef void* aclrtFuncHandle;

#define MAX_MEM_UCE_INFO_ARRAY_SIZE 128
#define UCE_INFO_RESERVED_SIZE 14

typedef struct aclrtMemUceInfo {
    void* addr;
    size_t len;
    size_t reserved[UCE_INFO_RESERVED_SIZE];
} aclrtMemUceInfo;

typedef enum aclrtCmoType {
    ACL_RT_CMO_TYPE_PREFETCH = 0,
} aclrtCmoType;

typedef enum aclrtLastErrLevel {
    ACL_RT_THREAD_LEVEL = 0,
} aclrtLastErrLevel;

/**
 * @ingroup AscendCL
 * @brief peek at last error by level
 *
 * @param level [IN] error level
 *
 * @retval Runtime error code
 */
ACL_FUNC_VISIBILITY aclError aclrtPeekAtLastError(aclrtLastErrLevel level);

/**
 * @ingroup AscendCL
 * @brief get last error by level
 *
 * @param level [IN] error level
 *
 * @retval Runtime error code
 */
ACL_FUNC_VISIBILITY aclError aclrtGetLastError(aclrtLastErrLevel level);


/**
 * @ingroup AscendCL
 * @brief Set a callback function to handle exception information
 *
 * @param callback [IN] callback function to handle exception information
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSetExceptionInfoCallback(aclrtExceptionInfoCallback callback);

/**
 * @ingroup AscendCL
 * @brief Get task id from exception information
 *
 * @param info [IN]   pointer of exception information
 *
 * @retval The task id from exception information
 * @retval 0xFFFFFFFF if info is null
 */
ACL_FUNC_VISIBILITY uint32_t aclrtGetTaskIdFromExceptionInfo(const aclrtExceptionInfo *info);

/**
 * @ingroup AscendCL
 * @brief Get stream id from exception information
 *
 * @param info [IN]   pointer of exception information
 *
 * @retval The stream id from exception information
 * @retval 0xFFFFFFFF if info is null
 */
ACL_FUNC_VISIBILITY uint32_t aclrtGetStreamIdFromExceptionInfo(const aclrtExceptionInfo *info);

/**
 * @ingroup AscendCL
 * @brief Get thread id from exception information
 *
 * @param info [IN]   pointer of exception information
 *
 * @retval The thread id of fail task
 * @retval 0xFFFFFFFF if info is null
 */
ACL_FUNC_VISIBILITY uint32_t aclrtGetThreadIdFromExceptionInfo(const aclrtExceptionInfo *info);

/**
 * @ingroup AscendCL
 * @brief Get device id from exception information
 *
 * @param info [IN]   pointer of exception information
 *
 * @retval The thread id of fail task
 * @retval 0xFFFFFFFF if info is null
 */
ACL_FUNC_VISIBILITY uint32_t aclrtGetDeviceIdFromExceptionInfo(const aclrtExceptionInfo *info);

/**
 * @ingroup AscendCL
 * @brief Get error code from exception information
 *
 * @param info [IN]   pointer of exception information
 *
 * @retval The error code from exception information
 * @retval 0xFFFFFFFF if info is null
 */
ACL_FUNC_VISIBILITY uint32_t aclrtGetErrorCodeFromExceptionInfo(const aclrtExceptionInfo *info);

/**
 * @ingroup AscendCL
 * @brief The thread that handles the callback function on the Stream
 *
 * @param threadId [IN] thread ID
 * @param stream [IN]   stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSubscribeReport(uint64_t threadId, aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief Add a callback function to be executed on the host
 *        to the task queue of the Stream
 *
 * @param fn [IN]   Specify the callback function to be added
 *                  The function prototype of the callback function is:
 *                  typedef void (*aclrtCallback)(void *userData);
 * @param userData [IN]   User data to be passed to the callback function
 * @param blockType [IN]  callback block type
 * @param stream [IN]     stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtLaunchCallback(aclrtCallback fn, void *userData, aclrtCallbackBlockType blockType,
                                                 aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief After waiting for a specified time, trigger callback processing
 *
 * @par Function
 *  The thread processing callback specified by
 *  the aclrtSubscribeReport interface
 *
 * @param timeout [IN]   timeout value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtSubscribeReport
 */
ACL_FUNC_VISIBILITY aclError aclrtProcessReport(int32_t timeout);

/**
 * @ingroup AscendCL
 * @brief Cancel thread registration,
 *        the callback function on the specified Stream
 *        is no longer processed by the specified thread
 *
 * @param threadId [IN]   thread ID
 * @param stream [IN]     stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtUnSubscribeReport(uint64_t threadId, aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief create context and associates it with the calling thread
 *
 * @par Function
 * The following use cases are supported:
 * @li If you don't call the aclrtCreateContext interface
 * to explicitly create the context,
 * the system will use the default context, which is implicitly created
 * when the aclrtSetDevice interface is called.
 * @li If multiple contexts are created in a process
 * (there is no limit on the number of contexts),
 * the current thread can only use one of them at the same time.
 * It is recommended to explicitly specify the context of the current thread
 * through the aclrtSetCurrentContext interface to increase.
 * the maintainability of the program.
 *
 * @param  context [OUT]    point to the created context
 * @param  deviceId [IN]    device to create context on
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtSetDevice | aclrtSetCurrentContext
 */
ACL_FUNC_VISIBILITY aclError aclrtCreateContext(aclrtContext *context, int32_t deviceId);

/**
 * @ingroup AscendCL
 * @brief destroy context instance
 *
 * @par Function
 * Can only destroy context created through aclrtCreateContext interface
 *
 * @param  context [IN]   the context to destroy
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtCreateContext
 */
ACL_FUNC_VISIBILITY aclError aclrtDestroyContext(aclrtContext context);

/**
 * @ingroup AscendCL
 * @brief set the context of the thread
 *
 * @par Function
 * The following scenarios are supported:
 * @li If the aclrtCreateContext interface is called in a thread to explicitly
 * create a Context (for example: ctx1), the thread's Context can be specified
 * without calling the aclrtSetCurrentContext interface.
 * The system uses ctx1 as the context of thread1 by default.
 * @li If the aclrtCreateContext interface is not explicitly created,
 * the system uses the default context as the context of the thread.
 * At this time, the aclrtDestroyContext interface cannot be used to release
 * the default context.
 * @li If the aclrtSetCurrentContext interface is called multiple times to
 * set the thread's Context, the last one prevails.
 *
 * @par Restriction
 * @li If the cevice corresponding to the context set for the thread
 * has been reset, you cannot set the context as the context of the thread,
 * otherwise a business exception will result.
 * @li It is recommended to use the context created in a thread.
 * If the aclrtCreateContext interface is called in thread A to create a context,
 * and the context is used in thread B,
 * the user must guarantee the execution order of tasks in the same stream
 * under the same context in two threads.
 *
 * @param  context [IN]   the current context of the thread
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtCreateContext | aclrtDestroyContext
 */
ACL_FUNC_VISIBILITY aclError aclrtSetCurrentContext(aclrtContext context);

/**
 * @ingroup AscendCL
 * @brief get the context of the thread
 *
 * @par Function
 * If the user calls the aclrtSetCurrentContext interface
 * multiple times to set the context of the current thread,
 * then the last set context is obtained
 *
 * @param  context [OUT]   the current context of the thread
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtSetCurrentContext
 */
ACL_FUNC_VISIBILITY aclError aclrtGetCurrentContext(aclrtContext *context);

/**
 * @ingroup AscendCL
 * @brief get system param option value in current context
 *
 * @param opt[IN] system option
 * @param value[OUT] value of system option
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclrtCtxGetSysParamOpt(aclSysParamOpt opt, int64_t *value);

/**
 * @ingroup AscendCL
 * @brief set system param option value in current context
 *
 * @param opt[IN] system option
 * @param value[IN] value of system option
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclrtCtxSetSysParamOpt(aclSysParamOpt opt, int64_t value);

/**
 * @ingroup AscendCL
 * @brief get system param option value in current process
 *
 * @param opt[IN] system option
 * @param value[OUT] value of system option
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclrtGetSysParamOpt(aclSysParamOpt opt, int64_t *value);

/**
 * @ingroup AscendCL
 * @brief set system param option value in current process
 *
 * @param opt[IN] system option
 * @param value[IN] value of system option
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclrtSetSysParamOpt(aclSysParamOpt opt, int64_t value);

/**
 * @ingroup AscendCL
 * @brief Specify the device to use for the operation
 * implicitly create the default context and the default stream
 *
 * @par Function
 * The following use cases are supported:
 * @li Device can be specified in the process or thread.
 * If you call the aclrtSetDevice interface multiple
 * times to specify the same device,
 * you only need to call the aclrtResetDevice interface to reset the device.
 * @li The same device can be specified for operation
 *  in different processes or threads.
 * @li Device is specified in a process,
 * and multiple threads in the process can share this device to explicitly
 * create a Context (aclrtCreateContext interface).
 * @li In multi-device scenarios, you can switch to other devices
 * through the aclrtSetDevice interface in the process.
 *
 * @param  deviceId [IN]  the device id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtResetDevice |aclrtCreateContext
 */
ACL_FUNC_VISIBILITY aclError aclrtSetDevice(int32_t deviceId);

/**
 * @ingroup AscendCL
 * @brief Reset the current operating Device and free resources on the device,
 * including the default context, the default stream,
 * and all streams created under the default context,
 * and synchronizes the interface.
 * If the task under the default context or stream has not been completed,
 * the system will wait for the task to complete before releasing it.
 *
 * @par Restriction
 * @li The Context, Stream, and Event that are explicitly created
 * on the device to be reset. Before resetting,
 * it is recommended to follow the following interface calling sequence,
 * otherwise business abnormalities may be caused.
 * @li Interface calling sequence:
 * call aclrtDestroyEvent interface to release Event or
 * call aclrtDestroyStream interface to release explicitly created Stream->
 * call aclrtDestroyContext to release explicitly created Context->
 * call aclrtResetDevice interface
 *
 * @param  deviceId [IN]   the device id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtResetDevice(int32_t deviceId);

/**
 * @ingroup AscendCL
 * @brief Reset the current operating Device and free resources on the device by FORCE,
 * including the default context, the default stream,
 * and all streams created under the default context,
 * and synchronizes the interface.
 * If the task under the default context or stream has not been completed,
 * the system will wait for the task to complete before releasing it.
 * No matter how many times you call aclrtSetDevice for the same device id,
 * you only need to call aclrtResetDeviceForce once for resetting.
 *
 * @par Restriction
 * @li The Context, Stream, and Event that are explicitly created
 * on the device to be reset. Before resetting,
 * it is recommended to follow the following interface calling sequence,
 * otherwise business abnormalities may be caused.
 * @li Interface calling sequence:
 * call aclrtDestroyEvent interface to release Event or
 * call aclrtDestroyStream interface to release explicitly created Stream->
 * call aclrtDestroyContext to release explicitly created Context->
 * call aclrtResetDeviceForce interface
 *
 * @param  deviceId [IN]   the device id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 * 
 * @see aclrtResetDevice
 */
ACL_FUNC_VISIBILITY aclError aclrtResetDeviceForce(int32_t deviceId);

/**
 * @ingroup AscendCL
 * @brief get target device of current thread
 *
 * @param deviceId [OUT]  the device id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetDevice(int32_t *deviceId);

/**
 * @ingroup AscendCL
 * @brief set stream failure mode
 *
 * @param stream [IN]  the stream to set
 * @param mode [IN]  stream failure mode
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSetStreamFailureMode(aclrtStream stream, uint64_t mode);

/**
 * @ingroup AscendCL
 * @brief get target side
 *
 * @param runMode [OUT]    the run mode
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetRunMode(aclrtRunMode *runMode);

/**
 * @ingroup AscendCL
 * @brief Wait for compute device to finish
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSynchronizeDevice(void);

/**
 * @ingroup AscendCL
 * @brief Wait for compute device to finish and set timeout
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSynchronizeDeviceWithTimeout(int32_t timeout);

/**
 * @ingroup AscendCL
 * @brief Set Scheduling TS
 *
 * @param tsId [IN]   the ts id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSetTsDevice(aclrtTsId tsId);

/**
 * @ingroup AscendCL
 * @brief Query the comprehensive usage rate of device
 * @param deviceId [IN] the need query's deviceId
 * @param utilizationInfo [OUT] the usage rate of device
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetDeviceUtilizationRate(int32_t deviceId, aclrtUtilizationInfo *utilizationInfo);

/**
 * @ingroup AscendCL
 * @brief get total device number.
 *
 * @param count [OUT]    the device number
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetDeviceCount(uint32_t *count);

/**
 * @ingroup AscendCL
 * @brief create event instance
 *
 * @param event [OUT]   created event
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtCreateEvent(aclrtEvent *event);

/**
 * @ingroup AscendCL
 * @brief create event instance with flag
 *
 * @param event [OUT]   created event
 * @param flag [IN]     event flag
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtCreateEventWithFlag(aclrtEvent *event, uint32_t flag);

/**
 * @ingroup AscendCL
 * @brief create event instance with flag, event can be reused naturally
 *
 * @param event [OUT]   created event
 * @param flag [IN]     event flag
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtCreateEventExWithFlag(aclrtEvent *event, uint32_t flag);

/**
 * @ingroup AscendCL
 * @brief destroy event instance
 *
 * @par Function
 *  Only events created through the aclrtCreateEvent interface can be
 *  destroyed, synchronous interfaces. When destroying an event,
 *  the user must ensure that the tasks involved in the aclrtSynchronizeEvent
 *  interface or the aclrtStreamWaitEvent interface are completed before
 *  they are destroyed.
 *
 * @param  event [IN]   event to destroy
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtCreateEvent | aclrtSynchronizeEvent | aclrtStreamWaitEvent
 */
ACL_FUNC_VISIBILITY aclError aclrtDestroyEvent(aclrtEvent event);

/**
 * @ingroup AscendCL
 * @brief Record an Event in the Stream
 *
 * @param event [IN]    event to record
 * @param stream [IN]   stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtRecordEvent(aclrtEvent event, aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief Reset an event
 *
 * @par Function
 *  Users need to make sure to wait for the tasks in the Stream
 *  to complete before resetting the Event
 *
 * @param event [IN]    event to reset
 * @param stream [IN]   stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtResetEvent(aclrtEvent event, aclrtStream stream);

 /**
 * @ingroup AscendCL
 * @brief Queries an event's status
 *
 * @param  event [IN]    event to query
 * @param  status [OUT]  event status
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_DEPRECATED_MESSAGE("aclrtQueryEvent is deprecated, use aclrtQueryEventStatus instead")
ACL_FUNC_VISIBILITY aclError aclrtQueryEvent(aclrtEvent event, aclrtEventStatus *status);

/**
 * @ingroup AscendCL
 * @brief Queries an event's status
 *
 * @param  event [IN]    event to query
 * @param  status [OUT]  event recorded status
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtQueryEventStatus(aclrtEvent event, aclrtEventRecordedStatus *status);

/**
* @ingroup AscendCL
* @brief Queries an event's wait-status
*
* @param  event [IN]    event to query
* @param  status [OUT]  event wait-status
*
* @retval ACL_SUCCESS The function is successfully executed.
* @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclrtQueryEventWaitStatus(aclrtEvent event, aclrtEventWaitStatus *status);

/**
 * @ingroup AscendCL
 * @brief Block Host Running, wait event to be complete
 *
 * @param  event [IN]   event to wait
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSynchronizeEvent(aclrtEvent event);

/**
 * @ingroup AscendCL
 * @brief Block Host Running, wait event to be complete
 *
 * @param  event [IN]   event to wait
 * @param  timeout [IN]  timeout value,the unit is milliseconds
 * -1 means waiting indefinitely, 0 means check whether synchronization is immediately completed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSynchronizeEventWithTimeout(aclrtEvent event, int32_t timeout);

/**
 * @ingroup AscendCL
 * @brief computes the elapsed time between events.
 *
 * @param ms [OUT]     time between start and end in ms
 * @param start [IN]   starting event
 * @param end [IN]     ending event
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtCreateEvent | aclrtRecordEvent | aclrtSynchronizeStream
 */
ACL_FUNC_VISIBILITY aclError aclrtEventElapsedTime(float *ms, aclrtEvent startEvent, aclrtEvent endEvent);

/**
 * @ingroup AscendCL
 * @brief alloc memory on device, real alloc size is aligned to 32 bytes and padded with 32 bytes
 *
 * @par Function
 *  alloc for size linear memory on device
 *  and return a pointer to allocated memory by *devPtr
 *
 * @par Restriction
 * @li The memory requested by the aclrtMalloc interface needs to be released
 * through the aclrtFree interface.
 * @li Before calling the media data processing interface,
 * if you need to apply memory on the device to store input or output data,
 * you need to call acldvppMalloc to apply for memory.
 *
 * @param devPtr [OUT]  pointer to pointer to allocated memory on device
 * @param size [IN]     alloc memory size
 * @param policy [IN]   memory alloc policy
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtFree | acldvppMalloc | aclrtMallocCached
 */
ACL_FUNC_VISIBILITY aclError aclrtMalloc(void **devPtr,
                                         size_t size,
                                         aclrtMemMallocPolicy policy);

/**
 * @ingroup AscendCL
 * @brief alloc memory on device, real alloc size is aligned to 32 bytes with no padding
 *
 * @par Function
 *  alloc for size linear memory on device
 *  and return a pointer to allocated memory by *devPtr
 *
 * @par Restriction
 * @li The memory requested by the aclrtMallocAlign32 interface needs to be released
 * through the aclrtFree interface.
 *
 * @param devPtr [OUT]  pointer to pointer to allocated memory on device
 * @param size [IN]     alloc memory size
 * @param policy [IN]   memory alloc policy
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtFree | aclrtMalloc | aclrtMallocCached
 */
ACL_FUNC_VISIBILITY aclError aclrtMallocAlign32(void **devPtr,
                                                size_t size,
                                                aclrtMemMallocPolicy policy);

/**
 * @ingroup AscendCL
 * @brief allocate memory on device with cache
 *
 * @par Function
 *  alloc for size linear memory on device
 *  and return a pointer to allocated memory by *devPtr
 *
 * @par Restriction
 * @li The memory requested by the aclrtMallocCached interface needs to be released
 * through the aclrtFree interface.
 *
 * @param devPtr [OUT]  pointer to pointer to allocated memory on device
 * @param size [IN]     alloc memory size
 * @param policy [IN]   memory alloc policy
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtFree | aclrtMalloc
 */
ACL_FUNC_VISIBILITY aclError aclrtMallocCached(void **devPtr,
                                               size_t size,
                                               aclrtMemMallocPolicy policy);

/**
 * @ingroup AscendCL
 * @brief flush cache data to ddr
 *
 * @param devPtr [IN]  the pointer that flush data to ddr
 * @param size [IN]    flush size
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemFlush(void *devPtr, size_t size);

/**
 * @ingroup AscendCL
 * @brief invalidate cache data
 *
 * @param devPtr [IN]  pointer to invalidate cache data
 * @param size [IN]    invalidate size
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemInvalidate(void *devPtr, size_t size);

/**
 * @ingroup AscendCL
 * @brief free device memory
 *
 * @par Function
 *  can only free memory allocated through the aclrtMalloc interface
 *
 * @param  devPtr [IN]  Pointer to memory to be freed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtMalloc
 */
ACL_FUNC_VISIBILITY aclError aclrtFree(void *devPtr);

/**
 * @ingroup AscendCL
 * @brief alloc memory on host
 *
 * @par Restriction
 * @li The requested memory cannot be used in the Device
 * and needs to be explicitly copied to the Device.
 * @li The memory requested by the aclrtMallocHost interface
 * needs to be released through the aclrtFreeHost interface.
 *
 * @param  hostPtr [OUT] pointer to pointer to allocated memory on the host
 * @param  size [IN]     alloc memory size
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtFreeHost
 */
ACL_FUNC_VISIBILITY aclError aclrtMallocHost(void **hostPtr, size_t size);

/**
 * @ingroup AscendCL
 * @brief free host memory
 *
 * @par Function
 *  can only free memory allocated through the aclrtMallocHost interface
 *
 * @param  hostPtr [IN]   free memory pointer
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtMallocHost
 */
ACL_FUNC_VISIBILITY aclError aclrtFreeHost(void *hostPtr);

/**
 * @ingroup AscendCL
 * @brief synchronous memory replication between host and device
 *
 * @param dst [IN]       destination address pointer
 * @param destMax [IN]   Max length of the destination address memory
 * @param src [IN]       source address pointer
 * @param count [IN]     the length of byte to copy
 * @param kind [IN]      memcpy type
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemcpy(void *dst,
                                         size_t destMax,
                                         const void *src,
                                         size_t count,
                                         aclrtMemcpyKind kind);

/**
 * @ingroup AscendCL
 * @brief Initialize memory and set contents of memory to specified value
 *
 * @par Function
 *  The memory to be initialized is on the Host or device side,
 *  and the system determines whether
 *  it is host or device according to the address
 *
 * @param devPtr [IN]    Starting address of memory
 * @param maxCount [IN]  Max length of destination address memory
 * @param value [IN]     Set value
 * @param count [IN]     The length of memory
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemset(void *devPtr, size_t maxCount, int32_t value, size_t count);

/**
 * @ingroup AscendCL
 * @brief  Asynchronous memory replication between Host and Device
 *
 * @par Function
 *  After calling this interface,
 *  be sure to call the aclrtSynchronizeStream interface to ensure that
 *  the task of memory replication has been completed
 *
 * @par Restriction
 * @li For on-chip Device-to-Device memory copy,
 *     both the source and destination addresses must be 64-byte aligned
 *
 * @param dst [IN]     destination address pointer
 * @param destMax [IN] Max length of destination address memory
 * @param src [IN]     source address pointer
 * @param count [IN]   the number of byte to copy
 * @param kind [IN]    memcpy type
 * @param stream [IN]  asynchronized task stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtSynchronizeStream
 */
ACL_FUNC_VISIBILITY aclError aclrtMemcpyAsync(void *dst,
                                              size_t destMax,
                                              const void *src,
                                              size_t count,
                                              aclrtMemcpyKind kind,
                                              aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief  Asynchronous memory replication between Host and Device, would
 *         be synchronous if memory is not allocated via calling acl or rts api.
 *
 * @par Function
 *  After calling this interface and memory is allocated via calling acl or rts api,
 *  be sure to call the aclrtSynchronizeStream interface to ensure that
 *  the task of memory replication has been completed
 *
 * @par Restriction
 * @li For on-chip Device-to-Device memory copy,
 *     both the source and destination addresses must be 64-byte aligned
 *
 * @param dst [IN]     destination address pointer
 * @param destMax [IN] Max length of destination address memory
 * @param src [IN]     source address pointer
 * @param count [IN]   the number of byte to copy
 * @param kind [IN]    memcpy type
 * @param stream [IN]  asynchronized task stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtSynchronizeStream
 */
ACL_FUNC_VISIBILITY aclError aclrtMemcpyAsyncWithCondition(void *dst,
                                                           size_t destMax,
                                                           const void *src,
                                                           size_t count,
                                                           aclrtMemcpyKind kind,
                                                           aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief synchronous memory replication of two-dimensional matrix between host and device
 *
 * @param dst [IN]       destination address pointer
 * @param dpitch [IN]    pitch of destination memory
 * @param src [IN]       source address pointer
 * @param spitch [IN]    pitch of source memory
 * @param width [IN]     width of matrix transfer
 * @param height [IN]    height of matrix transfer
 * @param kind [IN]      memcpy type
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemcpy2d(void *dst,
                                           size_t dpitch,
                                           const void *src,
                                           size_t spitch,
                                           size_t width,
                                           size_t height,
                                           aclrtMemcpyKind kind);

/**
 * @ingroup AscendCL
 * @brief asynchronous memory replication of two-dimensional matrix between host and device
 *
 * @param dst [IN]       destination address pointer
 * @param dpitch [IN]    pitch of destination memory
 * @param src [IN]       source address pointer
 * @param spitch [IN]    pitch of source memory
 * @param width [IN]     width of matrix transfer
 * @param height [IN]    height of matrix transfer
 * @param kind [IN]      memcpy type
 * @param stream [IN]    asynchronized task stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemcpy2dAsync(void *dst,
                                                size_t dpitch,
                                                const void *src,
                                                size_t spitch,
                                                size_t width,
                                                size_t height,
                                                aclrtMemcpyKind kind,
                                                aclrtStream stream);

/**
* @ingroup AscendCL
* @brief Asynchronous initialize memory
* and set contents of memory to specified value async
*
* @par Function
 *  The memory to be initialized is on the Host or device side,
 *  and the system determines whether
 *  it is host or device according to the address
 *
* @param devPtr [IN]      destination address pointer
* @param maxCount [IN]    Max length of destination address memory
* @param value [IN]       set value
* @param count [IN]       the number of byte to set
* @param stream [IN]      asynchronized task stream
*
* @retval ACL_SUCCESS The function is successfully executed.
* @retval OtherValues Failure
*
* @see aclrtSynchronizeStream
*/
ACL_FUNC_VISIBILITY aclError aclrtMemsetAsync(void *devPtr,
                                              size_t maxCount,
                                              int32_t value,
                                              size_t count,
                                              aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief Allocate an address range reservation
 *
 * @param virPtr [OUT]    Resulting pointer to start of virtual address range allocated
 * @param size [IN]       Size of the reserved virtual address range requested
 * @param alignment [IN]  Alignment of the reserved virtual address range requested
 * @param expectPtr [IN]  Fixed starting address range requested, must be nullptr
 * @param flags [IN]      Flag of page type
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtReleaseMemAddress | aclrtMallocPhysical | aclrtMapMem
 */
ACL_FUNC_VISIBILITY aclError aclrtReserveMemAddress(void **virPtr,
                                                    size_t size,
                                                    size_t alignment,
                                                    void *expectPtr,
                                                    uint64_t flags);

/**
 * @ingroup AscendCL
 * @brief Free an address range reservation
 *
 * @param virPtr [IN]  Starting address of the virtual address range to free
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtReserveMemAddress
 */
ACL_FUNC_VISIBILITY aclError aclrtReleaseMemAddress(void *virPtr);

/**
 * @ingroup AscendCL
 * @brief Create a memory handle representing a memory allocation of a given
 * size described by the given properties
 *
 * @param handle [OUT]  Value of handle returned. All operations on this
 * allocation are to be performed using this handle.
 * @param size [IN]     Size of the allocation requested
 * @param prop [IN]     Properties of the allocation to create
 * @param flags [IN]    Currently unused, must be zero
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtFreePhysical | aclrtReserveMemAddress | aclrtMapMem
 */
ACL_FUNC_VISIBILITY aclError aclrtMallocPhysical(aclrtDrvMemHandle *handle,
                                                 size_t size,
                                                 const aclrtPhysicalMemProp *prop,
                                                 uint64_t flags);

/**
 * @ingroup AscendCL
 * @brief Release a memory handle representing a memory allocation which was
 * previously allocated through aclrtMallocPhysical
 *
 * @param handle [IN]  Value of handle which was returned previously by aclrtMallocPhysical
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtMallocPhysical
 */
ACL_FUNC_VISIBILITY aclError aclrtFreePhysical(aclrtDrvMemHandle handle);

/**
 * @ingroup AscendCL
 * @brief Maps an allocation handle to a reserved virtual address range
 *
 * @param virPtr [IN]  Address where memory will be mapped
 * @param size [IN]    Size of the memory mapping
 * @param offset [IN]  Offset into the memory represented by handle from which to start mapping
 * @param handle [IN]  Handle to a shareable memory
 * @param flags [IN]   Currently unused, must be zero
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtUnmapMem | aclrtReserveMemAddress | aclrtMallocPhysical
 */
ACL_FUNC_VISIBILITY aclError aclrtMapMem(void *virPtr,
                                         size_t size,
                                         size_t offset,
                                         aclrtDrvMemHandle handle,
                                         uint64_t flags);

/**
 * @ingroup AscendCL
 * @brief Unmap the backing memory of a given address range
 *
 * @param virPtr [IN]  Starting address for the virtual address range to unmap
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtMapMem
 */
ACL_FUNC_VISIBILITY aclError aclrtUnmapMem(void *virPtr);

/**
 * @ingroup AscendCL
 * @brief Create config handle of stream
 *
 * @retval the aclrtStreamConfigHandle pointer
 */
ACL_FUNC_VISIBILITY aclrtStreamConfigHandle *aclrtCreateStreamConfigHandle(void);

/**
 * @ingroup AscendCL
 * @brief Destroy config handle of model execute
 *
 * @param  handle [IN]  Pointer to aclrtStreamConfigHandle to be destroyed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtDestroyStreamConfigHandle(aclrtStreamConfigHandle *handle);

/**
 * @ingroup AscendCL
 * @brief set config for stream
 *
 * @param handle [OUT]    pointer to stream config handle
 * @param attr [IN]       config attr in stream config handle to be set
 * @param attrValue [IN]  pointer to stream config value
 * @param valueSize [IN]  memory size of attrValue
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSetStreamConfigOpt(aclrtStreamConfigHandle *handle, aclrtStreamConfigAttr attr,
    const void *attrValue, size_t valueSize);

/**
 * @ingroup AscendCL
 * @brief  create stream instance
 *
 * @param  stream [OUT]   the created stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtCreateStream(aclrtStream *stream);

/**
 * @ingroup AscendCL
 * @brief  create stream instance
 *
 * @param  stream [OUT]   the created stream
 * @param  handle [IN]   the config of stream
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtCreateStreamV2(aclrtStream *stream, const aclrtStreamConfigHandle *handle);

/**
 * @ingroup AscendCL
 * @brief  create stream instance with param
 *
 * @par Function
 * Can create fast streams through the aclrtCreateStreamWithConfig interface
 *
 * @param  stream [OUT]   the created stream
 * @param  priority [IN]   the priority of stream, value range:0~7
 * @param  flag [IN]   indicate the function for stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtCreateStreamWithConfig(aclrtStream *stream, uint32_t priority, uint32_t flag);

/**
 * @ingroup AscendCL
 * @brief destroy stream instance
 *
 * @par Function
 * Can only destroy streams created through the aclrtCreateStream interface
 *
 * @par Restriction
 * Before calling the aclrtDestroyStream interface to destroy
 * the specified Stream, you need to call the aclrtSynchronizeStream interface
 * to ensure that the tasks in the Stream have been completed.
 *
 * @param stream [IN]  the stream to destroy
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtCreateStream | aclrtSynchronizeStream
 */
ACL_FUNC_VISIBILITY aclError aclrtDestroyStream(aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief destroy stream instance by force
 *
 * @par Function
 * Can only destroy streams created through the aclrtCreateStream interface
 *
 * @param stream [IN]  the stream to destroy
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtCreateStream
 */
ACL_FUNC_VISIBILITY aclError aclrtDestroyStreamForce(aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief block the host until all tasks
 * in the specified stream have completed
 *
 * @param  stream [IN]   the stream to wait
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSynchronizeStream(aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief block the host until all tasks
 * in the specified stream have completed
 *
 * @param  stream [IN]   the stream to wait
 * @param  timeout [IN]  timeout value,the unit is milliseconds
 * -1 means waiting indefinitely, 0 means check whether synchronization is complete immediately
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSynchronizeStreamWithTimeout(aclrtStream stream, int32_t timeout);

/**
 * @ingroup AscendCL
 * @brief Query a stream for completion status.
 *
 * @param  stream [IN]   the stream to query
 * @param  status [OUT]  stream status
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtStreamQuery(aclrtStream stream, aclrtStreamStatus *status);

/**
 * @ingroup AscendCL
 * @brief Blocks the operation of the specified Stream until
 * the specified Event is completed.
 * Support for multiple streams waiting for the same event.
 *
 * @param  stream [IN]   the wait stream If using thedefault Stream, set NULL
 * @param  event [IN]    the event to wait
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtStreamWaitEvent(aclrtStream stream, aclrtEvent event);

/**
 * @ingroup AscendCL
 * @brief set group
 *
 * @par Function
 *  set the task to the corresponding group
 *
 * @param groupId [IN]   group id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtGetGroupCount | aclrtGetAllGroupInfo | aclrtGetGroupInfoDetail
 */
ACL_FUNC_VISIBILITY aclError aclrtSetGroup(int32_t groupId);

/**
 * @ingroup AscendCL
 * @brief get the number of group
 *
 * @par Function
 *  get the number of group. if the number of group is zero,
 *  it means that group is not supported or group is not created.
 *
 * @param count [OUT]   the number of group
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 */
ACL_FUNC_VISIBILITY aclError aclrtGetGroupCount(uint32_t *count);

/**
 * @ingroup AscendCL
 * @brief create group information
 *
 * @retval null for failed.
 * @retval OtherValues success.
 *
 * @see aclrtDestroyGroupInfo
 */
ACL_FUNC_VISIBILITY aclrtGroupInfo *aclrtCreateGroupInfo();

/**
 * @ingroup AscendCL
 * @brief destroy group information
 *
 * @param groupInfo [IN]   pointer to group information
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtCreateGroupInfo
 */
ACL_FUNC_VISIBILITY aclError aclrtDestroyGroupInfo(aclrtGroupInfo *groupInfo);

/**
 * @ingroup AscendCL
 * @brief get all group information
 *
 * @param groupInfo [OUT]   pointer to group information
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtGetGroupCount
 */
ACL_FUNC_VISIBILITY aclError aclrtGetAllGroupInfo(aclrtGroupInfo *groupInfo);

/**
 * @ingroup AscendCL
 * @brief get detail information of group
 *
 * @param groupInfo [IN]    pointer to group information
 * @param groupIndex [IN]   group index value
 * @param attr [IN]         group attribute
 * @param attrValue [OUT]   pointer to attribute value
 * @param valueLen [IN]     length of attribute value
 * @param paramRetSize [OUT]   pointer to real length of attribute value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtGetGroupCount | aclrtGetAllGroupInfo
 */
ACL_FUNC_VISIBILITY aclError aclrtGetGroupInfoDetail(const aclrtGroupInfo *groupInfo,
                                                     int32_t groupIndex,
                                                     aclrtGroupAttr attr,
                                                     void *attrValue,
                                                     size_t valueLen,
                                                     size_t *paramRetSize);

/**
 * @ingroup AscendCL
 * @brief checking whether current device and peer device support the p2p feature
 *
 * @param canAccessPeer [OUT]   pointer to save the checking result
 * @param deviceId [IN]         current device id
 * @param peerDeviceId [IN]     peer device id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtDeviceEnablePeerAccess | aclrtDeviceDisablePeerAccess
 */
ACL_FUNC_VISIBILITY aclError aclrtDeviceCanAccessPeer(int32_t *canAccessPeer, int32_t deviceId, int32_t peerDeviceId);

/**
 * @ingroup AscendCL
 * @brief enable the peer device to support the p2p feature
 *
 * @param peerDeviceId [IN]   the peer device id
 * @param flags [IN]   reserved field, now it must be zero
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtDeviceCanAccessPeer | aclrtDeviceDisablePeerAccess
 */
ACL_FUNC_VISIBILITY aclError aclrtDeviceEnablePeerAccess(int32_t peerDeviceId, uint32_t flags);

/**
 * @ingroup AscendCL
 * @brief disable the peer device to support the p2p function
 *
 * @param peerDeviceId [IN]   the peer device id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtDeviceCanAccessPeer | aclrtDeviceEnablePeerAccess
 */
ACL_FUNC_VISIBILITY aclError aclrtDeviceDisablePeerAccess(int32_t peerDeviceId);

/**
 * @ingroup AscendCL
 * @brief Obtain the free memory and total memory of specified attribute.
 * the specified memory include normal memory and huge memory.
 *
 * @param attr [IN]    the memory attribute of specified device
 * @param free [OUT]   the free memory of specified device
 * @param total [OUT]  the total memory of specified device.
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetMemInfo(aclrtMemAttr attr, size_t *free, size_t *total);

/**
 * @ingroup AscendCL
 * @brief Set the timeout interval for waitting of op
 *
 * @param timeout [IN]   op wait timeout
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSetOpWaitTimeout(uint32_t timeout);

/**
 * @ingroup AscendCL
 * @brief Set the timeout interval for op executing
 *
 * @param timeout [IN]   op execute timeout
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSetOpExecuteTimeOut(uint32_t timeout);

/**
 * @ingroup AscendCL
 * @brief enable or disable overflow switch on some stream
 * @param stream [IN]   set overflow switch on this stream
 * @param flag [IN]  0 : disable 1 : enable
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSetStreamOverflowSwitch(aclrtStream stream, uint32_t flag);

/**
 * @ingroup AscendCL
 * @brief get overflow switch on some stream
 * @param stream [IN]   get overflow switch on this stream
 * @param flag [OUT]  current overflow switch, 0 : disable others : enable
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetStreamOverflowSwitch(aclrtStream stream, uint32_t *flag);

/**
 * @ingroup AscendCL
 * @brief set saturation mode
 * @param mode [IN]   target saturation mode
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSetDeviceSatMode(aclrtFloatOverflowMode mode);

/**
 * @ingroup AscendCL
 * @brief get saturation mode
 * @param mode [OUT]   get saturation mode
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetDeviceSatMode(aclrtFloatOverflowMode *mode);

/**
 * @ingroup AscendCL
 * @brief get overflow status asynchronously
 *
 * @par Restriction
 * After calling the aclrtGetOverflowStatus interface,
 * you need to call the aclrtSynchronizeStream interface
 * to ensure that the tasks in the stream have been completed.
 * @param outputAddr [IN/OUT]  output device addr to store overflow status
 * @param outputSize [IN]  output addr size
 * @param outputSize [IN]  stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetOverflowStatus(void *outputAddr, size_t outputSize, aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief reset overflow status asynchronously
 *
 * @par Restriction
 * After calling the aclrtResetOverflowStatus interface,
 * you need to call the aclrtSynchronizeStream interface
 * to ensure that the tasks in the stream have been completed.
 * @param outputSize [IN]  stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtResetOverflowStatus(aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief The thread that handles the hostFunc function on the Stream
 *
 * @param hostFuncThreadId [IN] thread ID
 * @param exeStream        [IN] stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtSubscribeHostFunc(uint64_t hostFuncThreadId, aclrtStream exeStream);

/**
 * @ingroup AscendCL
 * @brief After waiting for a specified time, trigger hostFunc callback function processing
 *
 * @par Function
 *  The thread processing callback specified by the aclrtSubscribeHostFunc interface
 *
 * @param timeout [IN]   timeout value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclrtSubscribeHostFunc
 */
ACL_FUNC_VISIBILITY aclError aclrtProcessHostFunc(int32_t timeout);

/**
 * @ingroup AscendCL
 * @brief Cancel thread registration,
 *        the hostFunc function on the specified Stream
 *        is no longer processed by the specified thread
 *
 * @param hostFuncThreadId [IN]   thread ID
 * @param exeStream        [IN]   stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtUnSubscribeHostFunc(uint64_t hostFuncThreadId, aclrtStream exeStream);

/**
 * @ingroup AscendCL
 * @brief Get device status
 *
 * @param deviceId       [IN]   device ID
 * @param deviceStatus   [OUT]  device status
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtQueryDeviceStatus(int32_t deviceId, aclrtDeviceStatus *deviceStatus);

/**
 * @ingroup AscendCL
 * @brief Create data of type aclrtBinary
 *
 * @param [in] data   binary data
 * @param [in] dataLen   binary length
 *
 * @retval the aclrtBinary
 */
ACL_FUNC_VISIBILITY aclrtBinary aclrtCreateBinary(const void *data, size_t dataLen);

/**
 * @ingroup AscendCL
 * @brief Destroy data of type aclrtBinary
 *
 * @param modelDesc [IN]   aclrtBinary to be destroyed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtDestroyBinary(aclrtBinary binary);


/**
 * @ingroup AscendCL
 * @brief Registers and parses the bin file and loads it to the device.
 *
 * @param [in] binary   device binary description
 * @param [out] binHandle   device binary handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtBinaryLoad(const aclrtBinary binary, aclrtBinHandle *binHandle);


/**
 * @ingroup AscendCL
 * @brief UnLoad binary
 *
 * @param [in] binHandle  binary handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtBinaryUnLoad(aclrtBinHandle binHandle);

/**
 * @ingroup AscendCL
 * @brief Find funcHandle based on binHandle and kernel name
 *
 * @param [in] binHandle  binHandle
 * @param [in] kernelName   kernel name
 * @param [out] funcHandle   funcHandle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtBinaryGetFunction(const aclrtBinHandle binHandle, const char *kernelName,
                                                    aclrtFuncHandle *funcHandle);

/**
 * @ingroup AscendCL
 * @brief Kernel Launch to device
 * @param [in] funcHandle  function handle
 * @param [in] blockDim  block dimentions
 * @param [in] argsData  args data
 * @param [in] argsSize  args size
 * @param [in] stream   stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtLaunchKernel(aclrtFuncHandle funcHandle, uint32_t blockDim,
                                               const void *argsData, size_t argsSize, aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief share the handle that created by the process itself to other process
 * @param [in] handle   mem handle created by aclrtMallocPhysical
 * @param [in] handleType  reserved param, must be MEM_HANDLE_TYPE_NONE
 * @param [in] flags  reserved param, must be 0
 * @param [out] shareableHandle  shareable Handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemExportToShareableHandle(aclrtDrvMemHandle handle,
                                                             aclrtMemHandleType handleType, uint64_t flags,
                                                             uint64_t *shareableHandle);

/**
 * @ingroup AscendCL
 * @brief import a mem allocation from a shareable Handle
 * @param [in] shareableHandle  shareable Handle
 * @param [in] deviceId  used to generate the handle in the specified Device Id
 * @param [out] handle handle in the process
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemImportFromShareableHandle(uint64_t shareableHandle,
                                                               int32_t deviceId, aclrtDrvMemHandle *handle);

/**
 * @ingroup AscendCL
 * @brief set the process whitelist, only the process configured in the whitelist can use this shareableHandle
 * @param [in] shareableHandle  shareable Handle
 * @param [in] deviceId  used to generate the handle in the specified Device Id
 * @param [out] handle handle in the process
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemSetPidToShareableHandle(uint64_t shareableHandle,
                                                             int32_t *pid, size_t pidNum);

/**`
 * @ingroup AscendCL
 * @brief get the mem allocation granularity by the option
 * @param [in] prop  aclrtPhysicalMemProp
 * @param [in] option  mem granularity option
 * @param [out] granularity granularity
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemGetAllocationGranularity(aclrtPhysicalMemProp *prop,
                                                              aclrtMemGranularityOptions option,
                                                              size_t *granularity);

/**
 * @ingroup AscendCL
 * @brief Get the pid for the current process on the physical device
 * @param [out] pid value of pid
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtDeviceGetBareTgid(int32_t *pid);

/**
 * @ingroup AscendCL
 * @brief cache manager operation
 * @param [in] src  device memory address
 * @param [in] size  memory size
 * @param [in] cmoType  type of operation, currently, only ACL_RT_CMO_TYPE_PREFETCH is supported
 * @param [in] stream   stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtCmoAsync(void *src, size_t size, aclrtCmoType cmoType, aclrtStream stream);

/**`
 * @ingroup AscendCL
 * @brief get the mem uce info
 * @param [in] deviceId
 * @param [in/out] memUceInfoArray
 * @param [in] arraySize
 * @param [out] retSize
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetMemUceInfo(int32_t deviceId, aclrtMemUceInfo *memUceInfoArray,
                                                size_t arraySize, size_t *retSize);

/**`
 * @ingroup AscendCL
 * @brief stop the task on specified device
 * @param [in] deviceId
 * @param [in] timeout
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtDeviceTaskAbort(int32_t deviceId, uint32_t timeout);

/**`
 * @ingroup AscendCL
 * @brief repair the mem uce
 * @param [in] deviceId
 * @param [in/out] memUceInfoArray
 * @param [in] arraySize
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtMemUceRepair(int32_t deviceId, aclrtMemUceInfo *memUceInfoArray, size_t arraySize);

/**`
 * @ingroup AscendCL
 * @brief abort unexecuted tasks and pause executing tasks on the stream
 * @param [in] stream  stream to be aborted, cannot be null
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtStreamAbort(aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif // INC_EXTERNAL_ACL_ACL_RT_H_

// End content from: acl/acl_rt.h

// Begin content from: acl/acl_mdl.h
/**
* @file acl_mdl.h
*
* Copyright (c) Huawei Technologies Co., Ltd. 2019-2023. All rights reserved.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
*/

#ifndef INC_EXTERNAL_ACL_ACL_MODEL_H_
#define INC_EXTERNAL_ACL_ACL_MODEL_H_

#include <stddef.h>
#include <stdint.h>

// #include "acl_base.h"
// #include "acl_rt.h"

#ifdef __cplusplus
extern "C" {
#endif

#define ACL_DIM_ENDPOINTS        2
#define ACL_MAX_DIM_CNT          128
#define ACL_MAX_TENSOR_NAME_LEN  128
#define ACL_MAX_BATCH_NUM        128
#define ACL_MAX_HW_NUM           128
#define ACL_MAX_SHAPE_COUNT      128
#define ACL_INVALID_NODE_INDEX   0xFFFFFFFF

#define ACL_MDL_LOAD_FROM_FILE            1
#define ACL_MDL_LOAD_FROM_FILE_WITH_MEM   2
#define ACL_MDL_LOAD_FROM_MEM             3
#define ACL_MDL_LOAD_FROM_MEM_WITH_MEM    4
#define ACL_MDL_LOAD_FROM_FILE_WITH_Q     5
#define ACL_MDL_LOAD_FROM_MEM_WITH_Q      6

#define ACL_DYNAMIC_TENSOR_NAME "ascend_mbatch_shape_data"
#define ACL_DYNAMIC_AIPP_NAME "ascend_dynamic_aipp_data"
#define ACL_ATTR_NAME_DATA_DUMP_ORIGIN_OP_NAMES "_datadump_original_op_names"

/* used for ACL_MDL_WORKSPACE_MEM_OPTIMIZE */
#define ACL_WORKSPACE_MEM_OPTIMIZE_DEFAULT 0
#define ACL_WORKSPACE_MEM_OPTIMIZE_INPUTOUTPUT 1

typedef struct aclmdlDataset aclmdlDataset;
typedef struct aclmdlDesc aclmdlDesc;
typedef struct aclmdlAIPP aclmdlAIPP;
typedef struct aclAippExtendInfo aclAippExtendInfo;
typedef struct aclmdlConfigHandle aclmdlConfigHandle;
typedef struct aclmdlExecConfigHandle aclmdlExecConfigHandle;

typedef enum {
    ACL_YUV420SP_U8 = 1,
    ACL_XRGB8888_U8 = 2,
    ACL_RGB888_U8 = 3,
    ACL_YUV400_U8 = 4,
    ACL_NC1HWC0DI_FP16 = 5,
    ACL_NC1HWC0DI_S8 = 6,
    ACL_ARGB8888_U8 = 7,
    ACL_YUYV_U8 = 8,
    ACL_YUV422SP_U8 = 9,
    ACL_AYUV444_U8 = 10,
    ACL_RAW10 = 11,
    ACL_RAW12 = 12,
    ACL_RAW16 = 13,
    ACL_RAW24 = 14,
    ACL_AIPP_RESERVED = 0xFFFF,
} aclAippInputFormat;

typedef enum {
    ACL_MDL_PRIORITY_INT32 = 0,
    ACL_MDL_LOAD_TYPE_SIZET,
    ACL_MDL_PATH_PTR, /**< pointer to model load path with deep copy */
    ACL_MDL_MEM_ADDR_PTR, /**< pointer to model memory with shallow copy */
    ACL_MDL_MEM_SIZET,
    ACL_MDL_WEIGHT_ADDR_PTR, /**< pointer to weight memory of model with shallow copy */
    ACL_MDL_WEIGHT_SIZET,
    ACL_MDL_WORKSPACE_ADDR_PTR, /**< pointer to worksapce memory of model with shallow copy */
    ACL_MDL_WORKSPACE_SIZET,
    ACL_MDL_INPUTQ_NUM_SIZET,
    ACL_MDL_INPUTQ_ADDR_PTR, /**< pointer to inputQ with shallow copy */
    ACL_MDL_OUTPUTQ_NUM_SIZET,
    ACL_MDL_OUTPUTQ_ADDR_PTR, /**< pointer to outputQ with shallow copy */
    ACL_MDL_WORKSPACE_MEM_OPTIMIZE,
    ACL_MDL_WEIGHT_PATH_PTR, /**< pointer to weight path with deep copy */
    ACL_MDL_MODEL_DESC_PTR, /**< pointer to model desc of model with shallow copy */
    ACL_MDL_MODEL_DESC_SIZET,
    ACL_MDL_KERNEL_PTR, /**< pointer to kernel bin of model with shallow copy */
    ACL_MDL_KERNEL_SIZET,
    ACL_MDL_KERNEL_ARGS_PTR, /**< pointer to kernel args of model with shallow copy */
    ACL_MDL_KERNEL_ARGS_SIZET,
    ACL_MDL_STATIC_TASK_PTR, /**< pointer to static task desc of model with shallow copy */
    ACL_MDL_STATIC_TASK_SIZET,
    ACL_MDL_DYNAMIC_TASK_PTR, /**< pointer to dynamic task desc of model with shallow copy */
    ACL_MDL_DYNAMIC_TASK_SIZET,
    ACL_MDL_MEM_MALLOC_POLICY_SIZET
} aclmdlConfigAttr;

typedef enum {
    ACL_MDL_STREAM_SYNC_TIMEOUT = 0,
    ACL_MDL_EVENT_SYNC_TIMEOUT,
    ACL_MDL_WORK_ADDR_PTR, /**< param */
    ACL_MDL_WORK_SIZET, /**< param */
    ACL_MDL_MPAIMID_SIZET, /**< param reserved */
    ACL_MDL_AICQOS_SIZET, /**< param reserved */
    ACL_MDL_AICOST_SIZET, /**< param reserved */
    ACL_MDL_MEC_TIMETHR_SIZET /**< param reserved */
} aclmdlExecConfigAttr;

typedef enum {
    ACL_DATA_WITHOUT_AIPP = 0,
    ACL_DATA_WITH_STATIC_AIPP,
    ACL_DATA_WITH_DYNAMIC_AIPP,
    ACL_DYNAMIC_AIPP_NODE
} aclmdlInputAippType;

typedef struct aclmdlIODims {
    char name[ACL_MAX_TENSOR_NAME_LEN]; /**< tensor name */
    size_t dimCount; /**< dim array count */
    int64_t dims[ACL_MAX_DIM_CNT]; /**< dim data array */
} aclmdlIODims;

typedef struct aclmdlIODimsRange {
    size_t rangeCount; /**< dim range array count */
    int64_t range[ACL_MAX_DIM_CNT][ACL_DIM_ENDPOINTS]; /**< range data array */
} aclmdlIODimsRange;

typedef struct aclAippDims {
    aclmdlIODims srcDims; /**< input dims before model transform */
    size_t srcSize; /**< input size before model transform */
    aclmdlIODims aippOutdims; /**< aipp output dims */
    size_t aippOutSize; /**< aipp output size */
} aclAippDims;

typedef struct aclmdlBatch {
    size_t batchCount; /**< batch array count */
    uint64_t batch[ACL_MAX_BATCH_NUM]; /**< batch data array */
} aclmdlBatch;

typedef struct aclmdlHW {
    size_t hwCount; /**< height&width array count */
    uint64_t hw[ACL_MAX_HW_NUM][2]; /**< height&width data array */
} aclmdlHW;

typedef struct aclAippInfo {
    aclAippInputFormat inputFormat;
    int32_t srcImageSizeW;
    int32_t srcImageSizeH;
    int8_t cropSwitch;
    int32_t loadStartPosW;
    int32_t loadStartPosH;
    int32_t cropSizeW;
    int32_t cropSizeH;
    int8_t resizeSwitch;
    int32_t resizeOutputW;
    int32_t resizeOutputH;
    int8_t paddingSwitch;
    int32_t leftPaddingSize;
    int32_t rightPaddingSize;
    int32_t topPaddingSize;
    int32_t bottomPaddingSize;
    int8_t cscSwitch;
    int8_t rbuvSwapSwitch;
    int8_t axSwapSwitch;
    int8_t singleLineMode;
    int32_t matrixR0C0;
    int32_t matrixR0C1;
    int32_t matrixR0C2;
    int32_t matrixR1C0;
    int32_t matrixR1C1;
    int32_t matrixR1C2;
    int32_t matrixR2C0;
    int32_t matrixR2C1;
    int32_t matrixR2C2;
    int32_t outputBias0;
    int32_t outputBias1;
    int32_t outputBias2;
    int32_t inputBias0;
    int32_t inputBias1;
    int32_t inputBias2;
    int32_t meanChn0;
    int32_t meanChn1;
    int32_t meanChn2;
    int32_t meanChn3;
    float minChn0;
    float minChn1;
    float minChn2;
    float minChn3;
    float varReciChn0;
    float varReciChn1;
    float varReciChn2;
    float varReciChn3;
    aclFormat srcFormat;
    aclDataType srcDatatype;
    size_t srcDimNum;
    size_t shapeCount;
    aclAippDims outDims[ACL_MAX_SHAPE_COUNT];
    aclAippExtendInfo *aippExtend; /**< reserved parameters, current version needs to be null */
} aclAippInfo;

typedef struct aclmdlExeOMDesc {
  size_t workSize;
  size_t weightSize;
  size_t modelDescSize;
  size_t kernelSize;
  size_t kernelArgsSize;
  size_t staticTaskSize;
  size_t dynamicTaskSize;
  size_t reserved[9];
} aclmdlExeOMDesc;

/**
 * @ingroup AscendCL
 * @brief Create data of type aclmdlDesc
 *
 * @retval the aclmdlDesc pointer
 */
ACL_FUNC_VISIBILITY aclmdlDesc *aclmdlCreateDesc();

/**
 * @ingroup AscendCL
 * @brief destroy data of type aclmdlDesc
 *
 * @param modelDesc [IN]   Pointer to almdldlDesc to be destroyed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlDestroyDesc(aclmdlDesc *modelDesc);

/**
 * @ingroup AscendCL
 * @brief Get aclmdlDesc data of the model according to the model ID
 *
 * @param  modelDesc [OUT]   aclmdlDesc pointer
 * @param  modelId [IN]      model id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetDesc(aclmdlDesc *modelDesc, uint32_t modelId);

/**
 * @ingroup AscendCL
 * @brief Get aclmdlDesc data of the model according to the model path
 *
 * @param  modelDesc [OUT]   aclmdlDesc pointer
 * @param  modelPath [IN]    model path
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetDescFromFile(aclmdlDesc *modelDesc, const char *modelPath);

/**
 * @ingroup AscendCL
 * @brief Get aclmdlDesc data of the model according to the model and modelSize
 *
 * @param  modelDesc [OUT]   aclmdlDesc pointer
 * @param  model [IN]        model pointer
 * @param  modelSize [IN]    model size
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetDescFromMem(aclmdlDesc *modelDesc, const void *model, size_t modelSize);

/**
 * @ingroup AscendCL
 * @brief Get the number of the inputs of
 *        the model according to data of aclmdlDesc
 *
 * @param  modelDesc [IN]   aclmdlDesc pointer
 *
 * @retval input size with aclmdlDesc
 */
ACL_FUNC_VISIBILITY size_t aclmdlGetNumInputs(aclmdlDesc *modelDesc);

/**
 * @ingroup AscendCL
 * @brief Get the number of the output of
 *        the model according to data of aclmdlDesc
 *
 * @param  modelDesc [IN]   aclmdlDesc pointer
 *
 * @retval output size with aclmdlDesc
 */
ACL_FUNC_VISIBILITY size_t aclmdlGetNumOutputs(aclmdlDesc *modelDesc);

/**
 * @ingroup AscendCL
 * @brief Get the size of the specified input according to
 *        the data of type aclmdlDesc
 *
 * @param  modelDesc [IN]  aclmdlDesc pointer
 * @param  index [IN] the size of the number of inputs to be obtained,
 *         the index value starts from 0
 *
 * @retval Specify the size of the input
 */
ACL_FUNC_VISIBILITY size_t aclmdlGetInputSizeByIndex(aclmdlDesc *modelDesc, size_t index);

/**
 * @ingroup AscendCL
 * @brief Get the size of the specified output according to
 *        the data of type aclmdlDesc
 *
 * @param modelDesc [IN]   aclmdlDesc pointer
 * @param index [IN]  the size of the number of outputs to be obtained,
 *        the index value starts from 0
 *
 * @retval Specify the size of the output
 */
ACL_FUNC_VISIBILITY size_t aclmdlGetOutputSizeByIndex(aclmdlDesc *modelDesc, size_t index);

/**
 * @ingroup AscendCL
 * @brief Create config handle of execute
 *
 * @retval the aclmdlCreateExecConfigHandle pointer
 */
ACL_FUNC_VISIBILITY aclmdlExecConfigHandle *aclmdlCreateExecConfigHandle();

/**
 * @ingroup AscendCL
 * @brief Destroy config handle of model execute
 *
 * @param  handle [IN]  Pointer to aclmdlExecConfigHandle to be destroyed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlDestroyExecConfigHandle(const aclmdlExecConfigHandle *handle);

/**
 * @ingroup AscendCL
 * @brief Create data of type aclmdlDataset
 *
 * @retval the aclmdlDataset pointer
 */
ACL_FUNC_VISIBILITY aclmdlDataset *aclmdlCreateDataset();

/**
 * @ingroup AscendCL
 * @brief destroy data of type aclmdlDataset
 *
 * @param  dataset [IN]  Pointer to aclmdlDataset to be destroyed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlDestroyDataset(const aclmdlDataset *dataset);

/**
 * @ingroup AscendCL
 * @brief Add aclDataBuffer to aclmdlDataset
 *
 * @param dataset [OUT]    aclmdlDataset address of aclDataBuffer to be added
 * @param dataBuffer [IN]  aclDataBuffer address to be added
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlAddDatasetBuffer(aclmdlDataset *dataset, aclDataBuffer *dataBuffer);

/**
 * @ingroup AscendCL
 * @brief Set aclTensorDesc to aclmdlDataset
 *
 * @param dataset [OUT]    aclmdlDataset address of aclDataBuffer to be added
 * @param tensorDesc [IN]  aclTensorDesc address to be added
 * @param index [IN]       index of tensorDesc which to be added
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlSetDatasetTensorDesc(aclmdlDataset *dataset,
                                                        aclTensorDesc *tensorDesc,
                                                        size_t index);

/**
 * @ingroup AscendCL
 * @brief Get aclTensorDesc from aclmdlDataset
 *
 * @param dataset [IN]    aclmdlDataset pointer;
 * @param index [IN]      index of tensorDesc
 *
 * @retval Get address of aclTensorDesc when executed successfully.
 * @retval Failure return NULL
 */
ACL_FUNC_VISIBILITY aclTensorDesc *aclmdlGetDatasetTensorDesc(const aclmdlDataset *dataset, size_t index);

/**
 * @ingroup AscendCL
 * @brief Get the number of aclDataBuffer in aclmdlDataset
 *
 * @param dataset [IN]   aclmdlDataset pointer
 *
 * @retval the number of aclDataBuffer
 */
ACL_FUNC_VISIBILITY size_t aclmdlGetDatasetNumBuffers(const aclmdlDataset *dataset);

/**
 * @ingroup AscendCL
 * @brief Get the aclDataBuffer in aclmdlDataset by index
 *
 * @param dataset [IN]   aclmdlDataset pointer
 * @param index [IN]     the index of aclDataBuffer
 *
 * @retval Get successfully, return the address of aclDataBuffer
 * @retval Failure return NULL
 */
ACL_FUNC_VISIBILITY aclDataBuffer *aclmdlGetDatasetBuffer(const aclmdlDataset *dataset, size_t index);

/**
 * @ingroup AscendCL
 * @brief Load offline model data from files
 * and manage memory internally by the system
 *
 * @par Function
 * After the system finishes loading the model,
 * the model ID returned is used as a mark to identify the model
 * during subsequent operations
 *
 * @param modelPath [IN]   Storage path for offline model files
 * @param modelId [OUT]    Model ID generated after
 *        the system finishes loading the model
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlLoadFromFile(const char *modelPath, uint32_t *modelId);

/**
 * @ingroup AscendCL
 * @brief Load offline bundle model data from file
 * and manage memory internally by the system
 *
 * @par Function
 * After the system finishes loading the bundle model,
 * the bundle model ID returned is used as a mark to identify the bundle model
 * during subsequent operations
 *
 * @param modelPath [IN]   Storage path for offline bundle model file
 * @param bundleId [OUT]   Bundle model id generated after
 *        the system finishes loading the bundle model
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlBundleLoadFromFile(const char *modelPath, uint32_t *bundleId);

/**
 * @ingroup AscendCL
 * @brief Load offline bundle model data from memory and manage the memory of
 * model running internally by the system
 *
 * @par Function
 * After the system finishes loading the bundle model,
 * the bundle model ID returned is used as a mark to identify the bundle  model
 * during subsequent operations
 *
 * @param model [IN]      Bundle model data stored in memory
 * @param modelSize [IN]  model data size
 * @param bundleId [OUT]  Bundle model id generated after
 *        the system finishes loading the model
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlBundleLoadFromMem(const void *model,  size_t modelSize, uint32_t *bundleId);

/**
 * @ingroup AscendCL
 * @brief unload bundle model with bundle model id
 *
 * @param  bundleId [IN]   bundle model id to be unloaded
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlBundleUnload(uint32_t bundleId);

/**
 * @ingroup AscendCL
 * @brief get bundle model inner model nums
 *
 * @param bundleId [IN] bundle id acquired by aclmdlBundleLoadFromFile or aclmdlBundleLoadFromMem
 * @param modelNum [OUT]    the pointer to model num
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 */
ACL_FUNC_VISIBILITY aclError aclmdlBundleGetModelNum(uint32_t bundleId, size_t *modelNum);

/**
 * @ingroup AscendCL
 * @brief get inner model id by index
 *
 * @param bundleId [IN] bundle id acquired by aclmdlBundleLoadFromFile or aclmdlBundleLoadFromMem
 * @param index [IN] index of bundle models
 * @param modelId [OUT]    the pointer to inner model id which to be executed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 */
ACL_FUNC_VISIBILITY aclError aclmdlBundleGetModelId(uint32_t bundleId, size_t index, uint32_t *modelId);

/**
 * @ingroup AscendCL
 * @brief Load offline model data from memory and manage the memory of
 * model running internally by the system
 *
 * @par Function
 * After the system finishes loading the model,
 * the model ID returned is used as a mark to identify the model
 * during subsequent operations
 *
 * @param model [IN]      Model data stored in memory
 * @param modelSize [IN]  model data size
 * @param modelId [OUT]   Model ID generated after
 *        the system finishes loading the model
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlLoadFromMem(const void *model,  size_t modelSize, uint32_t *modelId);

/**
 * @ingroup AscendCL
 * @brief Load offline model data from a file,
 * and the user manages the memory of the model run by itself
 *
 * @par Function
 * After the system finishes loading the model,
 * the model ID returned is used as a mark to identify the model
 * during subsequent operations.
 * @param modelPath [IN]   Storage path for offline model files
 * @param modelId [OUT]    Model ID generated after finishes loading the model
 * @param workPtr [IN]     A pointer to the working memory
 *                         required by the model on the Device,can be null
 * @param workSize [IN]    The amount of working memory required by the model
 * @param weightPtr [IN]   Pointer to model weight memory on Device
 * @param weightSize [IN]  The amount of weight memory required by the model
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlLoadFromFileWithMem(const char *modelPath,
                                                       uint32_t *modelId, void *workPtr, size_t workSize,
                                                       void *weightPtr, size_t weightSize);

/**
 * @ingroup AscendCL
 * @brief Load offline model data from memory,
 * and the user can manage the memory of model running
 *
 * @par Function
 * After the system finishes loading the model,
 * the model ID returned is used as a mark to identify the model
 * during subsequent operations
 * @param model [IN]      Model data stored in memory
 * @param modelSize [IN]  model data size
 * @param modelId [OUT]   Model ID generated after finishes loading the model
 * @param workPtr [IN]    A pointer to the working memory
 *                        required by the model on the Device,can be null
 * @param workSize [IN]   work memory size
 * @param weightPtr [IN]  Pointer to model weight memory on Device,can be null
 * @param weightSize [IN] The amount of weight memory required by the model
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlLoadFromMemWithMem(const void *model, size_t modelSize,
                                                      uint32_t *modelId, void *workPtr, size_t workSize,
                                                      void *weightPtr, size_t weightSize);

/**
 * @ingroup AscendCL
 * @brief load model from file with async queue
 *
 * @param modelPath  [IN] model path
 * @param modelId [OUT]   return model id if load success
 * @param inputQ [IN]     input queue pointer
 * @param inputQNum [IN]  input queue num
 * @param outputQ [IN]    output queue pointer
 * @param outputQNum [IN] output queue num
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlLoadFromFileWithQ(const char *modelPath, uint32_t *modelId, const uint32_t *inputQ,
                                                     size_t inputQNum, const uint32_t *outputQ, size_t outputQNum);

/**
 * @ingroup AscendCL
 * @brief load model from memory with async queue
 *
 * @param model [IN]      model memory which user manages
 * @param modelSize [IN]  model size
 * @param modelId [OUT]   return model id if load success
 * @param inputQ [IN]     input queue pointer
 * @param inputQNum [IN]  input queue num
 * @param outputQ [IN]    output queue pointer
 * @param outputQNum [IN] output queue num
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlLoadFromMemWithQ(const void *model, size_t modelSize, uint32_t *modelId,
                                                    const uint32_t *inputQ, size_t inputQNum,
                                                    const uint32_t *outputQ, size_t outputQNum);

/**
 * @ingroup AscendCL
 * @brief Execute model synchronous inference until the inference result is returned
 *
 * @param  modelId [IN]   ID of the model to perform inference
 * @param  input [IN]     Input data for model inference
 * @param  output [OUT]   Output data for model inference
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlExecute(uint32_t modelId, const aclmdlDataset *input, aclmdlDataset *output);

/**
 * @ingroup AscendCL
 * @brief Execute model synchronous inference until the inference result is returned
 *
 * @param  modelId [IN]   ID of the model to perform inference
 * @param  input [IN]     Input data for model inference
 * @param  output [OUT]   Output data for model inference
 * @param  stream [IN]   stream
 * @param  handle [IN]   config of model execute
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlExecuteV2(uint32_t modelId, const aclmdlDataset *input, aclmdlDataset *output,
                                             aclrtStream stream, const aclmdlExecConfigHandle *handle);

/**
 * @ingroup AscendCL
 * @brief Execute model asynchronous inference until the inference result is returned
 *
 * @param  modelId [IN]   ID of the model to perform inference
 * @param  input [IN]     Input data for model inference
 * @param  output [OUT]   Output data for model inference
 * @param  stream [IN]   stream
 * @param  handle [IN]   config of model execute
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY  aclError aclmdlExecuteAsyncV2(uint32_t modelId, const aclmdlDataset *input, aclmdlDataset *output,
                                                   aclrtStream stream, const aclmdlExecConfigHandle *handle);
/**
 * @ingroup AscendCL
 * @brief Execute model asynchronous inference until the inference result is returned
 *
 * @param  modelId [IN]   ID of the model to perform inference
 * @param  input [IN]     Input data for model inference
 * @param  output [OUT]   Output data for model inference
 * @param  stream [IN]    stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlLoadFromFile | aclmdlLoadFromMem | aclmdlLoadFromFileWithMem |
 * aclmdlLoadFromMemWithMem
 */
ACL_FUNC_VISIBILITY aclError aclmdlExecuteAsync(uint32_t modelId, const aclmdlDataset *input,
                                                aclmdlDataset *output, aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief unload model with model id
 *
 * @param  modelId [IN]   model id to be unloaded
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlUnload(uint32_t modelId);

/**
 * @ingroup AscendCL
 * @brief Get the weight memory size and working memory size
 * required for model execution according to the model file
 *
 * @param  fileName [IN]     Model path to get memory information
 * @param  workSize [OUT]    The amount of working memory for model executed
 * @param  weightSize [OUT]  The amount of weight memory for model executed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlQuerySize(const char *fileName, size_t *workSize, size_t *weightSize);

/**
 * @ingroup AscendCL
 * @brief Get the size of each partition and working memory size
 * required for model execution according to the model file
 *
 * @param  fileName [IN]          Model path to get memory information
 * @param  aclmdlExeOMDesc [OUT]  The size of each partition and working memory size
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlQueryExeOMDesc(const char *fileName, aclmdlExeOMDesc *mdlPartitionSize);

/**
 * @ingroup AscendCL
 * @brief Obtain the weights required for
 * model execution according to the model data in memory
 *
 * @par Restriction
 * The execution and weight memory is Device memory,
 * and requires user application and release.
 * @param  model [IN]        model memory which user manages
 * @param  modelSize [IN]    model data size
 * @param  workSize [OUT]    The amount of working memory for model executed
 * @param  weightSize [OUT]  The amount of weight memory for model executed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlQuerySizeFromMem(const void *model, size_t modelSize, size_t *workSize,
                                                    size_t *weightSize);

/**
 * @ingroup AscendCL
 * @brief In dynamic batch scenarios,
 * it is used to set the number of images processed
 * at one time during model inference
 *
 * @param  modelId [IN]     model id
 * @param  dataset [IN|OUT] data for model inference
 * @param  index [IN]       index of dynamic tensor
 * @param  batchSize [IN]   Number of images processed at a time during model
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlLoadFromFile | aclmdlLoadFromMem | aclmdlLoadFromFileWithMem |
 * aclmdlLoadFromMemWithMem | aclmdlGetInputIndexByName
 */
ACL_FUNC_VISIBILITY aclError aclmdlSetDynamicBatchSize(uint32_t modelId, aclmdlDataset *dataset, size_t index,
                                                       uint64_t batchSize);

/**
 * @ingroup AscendCL
 * @brief Sets the H and W of the specified input of the model
 *
 * @param  modelId [IN]     model id
 * @param  dataset [IN|OUT] data for model inference
 * @param  index [IN]       index of dynamic tensor
 * @param  height [IN]      model height
 * @param  width [IN]       model width
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlLoadFromFile | aclmdlLoadFromMem | aclmdlLoadFromFileWithMem |
 * aclmdlLoadFromMemWithMem | aclmdlGetInputIndexByName
 */
ACL_FUNC_VISIBILITY aclError aclmdlSetDynamicHWSize(uint32_t modelId, aclmdlDataset *dataset, size_t index,
                                                    uint64_t height, uint64_t width);

/**
 * @ingroup AscendCL
 * @brief Sets the dynamic dims of the specified input of the model
 *
 * @param  modelId [IN]     model id
 * @param  dataset [IN|OUT] data for model inference
 * @param  index [IN]       index of dynamic dims
 * @param  dims [IN]        value of dynamic dims
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlLoadFromFile | aclmdlLoadFromMem | aclmdlLoadFromFileWithMem |
 * aclmdlLoadFromMemWithMem | aclmdlGetInputIndexByName
 */
ACL_FUNC_VISIBILITY aclError aclmdlSetInputDynamicDims(uint32_t modelId, aclmdlDataset *dataset, size_t index,
                                                       const aclmdlIODims *dims);

/**
 * @ingroup AscendCL
 * @brief get input dims info
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]  input tensor index
 * @param dims [OUT]  dims info
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlGetInputDimsV2
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetInputDims(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims);

/**
 * @ingroup AscendCL
 * @brief get input dims info(version 2), especially for static aipp
 * it is the same with aclmdlGetInputDims while model without static aipp
 *
 * @param modelDesc [IN] model description
 * @param index [IN]     input tensor index
 * @param dims [OUT]     dims info
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlGetInputDims
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetInputDimsV2(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims);

/**
 * @ingroup AscendCL
 * @brief get input dims range info
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]  input tensor index
 * @param dimsRange [OUT]  dims range info
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetInputDimsRange(const aclmdlDesc *modelDesc, size_t index,
                                                     aclmdlIODimsRange *dimsRange);

/**
 * @ingroup AscendCL
 * @brief get output dims info
 *
 * @param modelDesc [IN] model description
 * @param index [IN]     output tensor index
 * @param dims [OUT]     dims info
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetOutputDims(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims);

/**
 * @ingroup AscendCL
 * @brief get current output dims info
 *
 * @par Function
 * The following use cases are supported:
 * @li Get current output shape when model is dynamic and
 * dynamic shape info is set
 * @li Get max output shape when model is dynamic and
 * dynamic shape info is not set
 * @li Get actual output shape when model is static
 *
 * @param modelDesc [IN] model description
 * @param index [IN]     output tensor index
 * @param dims [OUT]     dims info
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetCurOutputDims(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims);

/**
 * @ingroup AscendCL
 * @brief get attr value by op name
 *
 * @param modelDesc [IN]   model description
 * @param opName [IN]      op name
 * @param attr [IN]        attr name
 *
 * @retval the attr value
 */
ACL_FUNC_VISIBILITY const char *aclmdlGetOpAttr(aclmdlDesc *modelDesc, const char *opName, const char *attr);

/**
 * @ingroup AscendCL
 * @brief get input name by index
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]      intput tensor index
 *
 * @retval input tensor name,the same life cycle with modelDesc
 */
ACL_FUNC_VISIBILITY const char *aclmdlGetInputNameByIndex(const aclmdlDesc *modelDesc, size_t index);

/**
 * @ingroup AscendCL
 * @brief get output name by index
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]      output tensor index
 *
 * @retval output tensor name,the same life cycle with modelDesc
 */
ACL_FUNC_VISIBILITY const char *aclmdlGetOutputNameByIndex(const aclmdlDesc *modelDesc, size_t index);

/**
 * @ingroup AscendCL
 * @brief get input format by index
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]      intput tensor index
 *
 * @retval input tensor format
 */
ACL_FUNC_VISIBILITY aclFormat aclmdlGetInputFormat(const aclmdlDesc *modelDesc, size_t index);

/**
 * @ingroup AscendCL
 * @brief get output format by index
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]      output tensor index
 *
 * @retval output tensor format
 */
ACL_FUNC_VISIBILITY aclFormat aclmdlGetOutputFormat(const aclmdlDesc *modelDesc, size_t index);

/**
 * @ingroup AscendCL
 * @brief get input data type by index
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]  intput tensor index
 *
 * @retval input tensor data type
 */
ACL_FUNC_VISIBILITY aclDataType aclmdlGetInputDataType(const aclmdlDesc *modelDesc, size_t index);

/**
 * @ingroup AscendCL
 * @brief get output data type by index
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]  output tensor index
 *
 * @retval output tensor data type
 */
ACL_FUNC_VISIBILITY aclDataType aclmdlGetOutputDataType(const aclmdlDesc *modelDesc, size_t index);

/**
 * @ingroup AscendCL
 * @brief get input tensor index by name
 *
 * @param modelDesc [IN]  model description
 * @param name [IN]    intput tensor name
 * @param index [OUT]  intput tensor index
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetInputIndexByName(const aclmdlDesc *modelDesc, const char *name, size_t *index);

/**
 * @ingroup AscendCL
 * @brief get output tensor index by name
 *
 * @param modelDesc [IN]  model description
 * @param name [IN]  output tensor name
 * @param index [OUT]  output tensor index
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetOutputIndexByName(const aclmdlDesc *modelDesc, const char *name, size_t *index);

/**
 * @ingroup AscendCL
 * @brief get dynamic batch info
 *
 * @param modelDesc [IN]  model description
 * @param batch [OUT]  dynamic batch info
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetDynamicBatch(const aclmdlDesc *modelDesc, aclmdlBatch *batch);

/**
 * @ingroup AscendCL
 * @brief get dynamic height&width info
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]  input tensor index
 * @param hw [OUT]  dynamic height&width info
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetDynamicHW(const aclmdlDesc *modelDesc, size_t index, aclmdlHW *hw);

/**
 * @ingroup AscendCL
 * @brief get dynamic gear count
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]  unused, must be -1
 * @param gearCount [OUT]  dynamic gear count
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetInputDynamicGearCount(const aclmdlDesc *modelDesc, size_t index,
                                                            size_t *gearCount);

/**
 * @ingroup AscendCL
 * @brief get dynamic dims info
 *
 * @param modelDesc [IN]  model description
 * @param index [IN]  unused, must be -1
 * @param dims [OUT]  value of dynamic dims
 * @param gearCount [IN]  dynamic gear count
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetInputDynamicDims(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims,
                                                       size_t gearCount);

/**
 * @ingroup AscendCL
 * @brief Create data of type aclmdlAIPP
 *
 * @param batchSize [IN]    batchsizes of model
 *
 * @retval the aclmdlAIPP pointer
 */
ACL_FUNC_VISIBILITY aclmdlAIPP *aclmdlCreateAIPP(uint64_t batchSize);

/**
 * @ingroup AscendCL
 * @brief destroy data of type aclmdlAIPP
 *
 * @param aippParmsSet [IN]    Pointer for aclmdlAIPP to be destroyed
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlDestroyAIPP(const aclmdlAIPP *aippParmsSet);

/**
 * @ingroup AscendCL
 * @brief Get dynamic aipp data need size according to batchSize
 *
 * @param batchSize [IN]    batchsizes of model
 * @param size [OUT]    Pointer of aipp data need size according to batchSize
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlGetAippDataSize(uint64_t batchSize, size_t *size);

/**
 * @ingroup AscendCL
 * @brief set InputFormat of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]  Pointer for aclmdlAIPP
 * @param inputFormat [IN]    The inputFormat of aipp
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
 */
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPInputFormat(aclmdlAIPP *aippParmsSet, aclAippInputFormat inputFormat);

/**
 * @ingroup AscendCL
 * @brief set cscParms of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]    Pointer for aclmdlAIPP
 * @param csc_switch [IN]       Csc switch
 * @param cscMatrixR0C0 [IN]    Csc_matrix_r0_c0
 * @param cscMatrixR0C1 [IN]    Csc_matrix_r0_c1
 * @param cscMatrixR0C2 [IN]    Csc_matrix_r0_c2
 * @param cscMatrixR1C0 [IN]    Csc_matrix_r1_c0
 * @param cscMatrixR1C1 [IN]    Csc_matrix_r1_c1
 * @param cscMatrixR1C2 [IN]    Csc_matrix_r1_c2
 * @param cscMatrixR2C0 [IN]    Csc_matrix_r2_c0
 * @param cscMatrixR2C1 [IN]    Csc_matrix_r2_c1
 * @param cscMatrixR2C2 [IN]    Csc_matrix_r2_c2
 * @param cscOutputBiasR0 [IN]  Output Bias for RGB to YUV, element of row 0, unsigned number
 * @param cscOutputBiasR1 [IN]  Output Bias for RGB to YUV, element of row 1, unsigned number
 * @param cscOutputBiasR2 [IN]  Output Bias for RGB to YUV, element of row 2, unsigned number
 * @param cscInputBiasR0 [IN]   Input Bias for YUV to RGB, element of row 0, unsigned number
 * @param cscInputBiasR1 [IN]   Input Bias for YUV to RGB, element of row 1, unsigned number
 * @param cscInputBiasR2 [IN]   Input Bias for YUV to RGB, element of row 2, unsigned number
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPCscParams(aclmdlAIPP *aippParmsSet, int8_t cscSwitch,
                                                    int16_t cscMatrixR0C0, int16_t cscMatrixR0C1, int16_t cscMatrixR0C2,
                                                    int16_t cscMatrixR1C0, int16_t cscMatrixR1C1, int16_t cscMatrixR1C2,
                                                    int16_t cscMatrixR2C0, int16_t cscMatrixR2C1, int16_t cscMatrixR2C2,
                                                    uint8_t cscOutputBiasR0, uint8_t cscOutputBiasR1,
                                                    uint8_t cscOutputBiasR2, uint8_t cscInputBiasR0,
                                                    uint8_t cscInputBiasR1, uint8_t cscInputBiasR2);

/**
 * @ingroup AscendCL
 * @brief set rb/ub swap switch of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]  Pointer for aclmdlAIPP
 * @param rbuvSwapSwitch [IN] rb/ub swap switch
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPRbuvSwapSwitch(aclmdlAIPP *aippParmsSet, int8_t rbuvSwapSwitch);

/**
 * @ingroup AscendCL
 * @brief set RGBA->ARGB, YUVA->AYUV swap switch of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]  Pointer for aclmdlAIPP
 * @param axSwapSwitch [IN]   RGBA->ARGB, YUVA->AYUV swap switch
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPAxSwapSwitch(aclmdlAIPP *aippParmsSet, int8_t axSwapSwitch);

/**
 * @ingroup AscendCL
 * @brief set source image of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]  Pointer for aclmdlAIPP
 * @param srcImageSizeW [IN]  Source image width
 * @param srcImageSizeH [IN]  Source image height
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPSrcImageSize(aclmdlAIPP *aippParmsSet, int32_t srcImageSizeW,
                                                       int32_t srcImageSizeH);

/**
 * @ingroup AscendCL
 * @brief set resize switch of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]  Pointer for aclmdlAIPP
 * @param scfSwitch [IN]      Resize switch
 * @param scfInputSizeW [IN]  Input width of scf
 * @param scfInputSizeH [IN]  Input height of scf
 * @param scfOutputSizeW [IN] Output width of scf
 * @param scfOutputSizeH [IN] Output height of scf
 * @param batchIndex [IN]     Batch parameter index
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPScfParams(aclmdlAIPP *aippParmsSet,
                                                    int8_t scfSwitch,
                                                    int32_t scfInputSizeW,
                                                    int32_t scfInputSizeH,
                                                    int32_t scfOutputSizeW,
                                                    int32_t scfOutputSizeH,
                                                    uint64_t batchIndex);

/**
 * @ingroup AscendCL
 * @brief set cropParams of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]  Pointer for aclmdlAIPP
 * @param cropSwitch [IN]     Crop switch
 * @param cropStartPosW [IN]  The start horizontal position of cropping
 * @param cropStartPosH [IN]  The start vertical position of cropping
 * @param cropSizeW [IN]      Crop width
 * @param cropSizeH [IN]      Crop height
 * @param batchIndex [IN]     Batch parameter index
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPCropParams(aclmdlAIPP *aippParmsSet,
                                                     int8_t cropSwitch,
                                                     int32_t cropStartPosW,
                                                     int32_t cropStartPosH,
                                                     int32_t cropSizeW,
                                                     int32_t cropSizeH,
                                                     uint64_t batchIndex);

/**
 * @ingroup AscendCL
 * @brief set paddingParams of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]      Pointer for aclmdlAIPP
 * @param paddingSwitch [IN]      Padding switch
 * @param paddingSizeTop [IN]     Top padding size
 * @param paddingSizeBottom [IN]  Bottom padding size
 * @param paddingSizeLeft [IN]    Left padding size
 * @param paddingSizeRight [IN]   Right padding size
 * @param batchIndex [IN]         Batch parameter index
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPPaddingParams(aclmdlAIPP *aippParmsSet, int8_t paddingSwitch,
                                                        int32_t paddingSizeTop, int32_t paddingSizeBottom,
                                                        int32_t paddingSizeLeft, int32_t paddingSizeRight,
                                                        uint64_t batchIndex);

/**
 * @ingroup AscendCL
 * @brief set DtcPixelMean of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]      Pointer for aclmdlAIPP
 * @param dtcPixelMeanChn0 [IN]   Mean value of channel 0
 * @param dtcPixelMeanChn1 [IN]   Mean value of channel 1
 * @param dtcPixelMeanChn2 [IN]   Mean value of channel 2
 * @param dtcPixelMeanChn3 [IN]   Mean value of channel 3
 * @param batchIndex [IN]         Batch parameter index
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPDtcPixelMean(aclmdlAIPP *aippParmsSet,
                                                       int16_t dtcPixelMeanChn0,
                                                       int16_t dtcPixelMeanChn1,
                                                       int16_t dtcPixelMeanChn2,
                                                       int16_t dtcPixelMeanChn3,
                                                       uint64_t batchIndex);

/**
 * @ingroup AscendCL
 * @brief set DtcPixelMin of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]    Pointer for aclmdlAIPP
 * @param dtcPixelMinChn0 [IN]  Min value of channel 0
 * @param dtcPixelMinChn1 [IN]  Min value of channel 1
 * @param dtcPixelMinChn2 [IN]  Min value of channel 2
 * @param dtcPixelMinChn3 [IN]  Min value of channel 3
 * @param batchIndex [IN]       Batch parameter index
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPDtcPixelMin(aclmdlAIPP *aippParmsSet,
                                                      float dtcPixelMinChn0,
                                                      float dtcPixelMinChn1,
                                                      float dtcPixelMinChn2,
                                                      float dtcPixelMinChn3,
                                                      uint64_t batchIndex);

/**
 * @ingroup AscendCL
 * @brief set PixelVarReci of type aclmdlAIPP
 *
 * @param aippParmsSet [OUT]       Pointer for aclmdlAIPP
 * @param dtcPixelVarReciChn0 [IN] sfr_dtc_pixel_variance_reci_ch0
 * @param dtcPixelVarReciChn1 [IN] sfr_dtc_pixel_variance_reci_ch1
 * @param dtcPixelVarReciChn2 [IN] sfr_dtc_pixel_variance_reci_ch2
 * @param dtcPixelVarReciChn3 [IN] sfr_dtc_pixel_variance_reci_ch3
 * @param batchIndex [IN]          Batch parameter index
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPPixelVarReci(aclmdlAIPP *aippParmsSet,
                                                       float dtcPixelVarReciChn0,
                                                       float dtcPixelVarReciChn1,
                                                       float dtcPixelVarReciChn2,
                                                       float dtcPixelVarReciChn3,
                                                       uint64_t batchIndex);

/**
 * @ingroup AscendCL
 * @brief set aipp parameters to model
 *
 * @param modelId [IN]        model id
 * @param dataset [IN]        Pointer of dataset
 * @param index [IN]          index of input for aipp data(ACL_DYNAMIC_AIPP_NODE)
 * @param aippParmsSet [IN]   Pointer for aclmdlAIPP
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlLoadFromFile | aclmdlLoadFromMem | aclmdlLoadFromFileWithMem |
 * aclmdlLoadFromMemWithMem | aclmdlGetInputIndexByName | aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetInputAIPP(uint32_t modelId,
                                                aclmdlDataset *dataset,
                                                size_t index,
                                                const aclmdlAIPP *aippParmsSet);

/**
 * @ingroup AscendCL
 * @brief set aipp parameters to model
 *
 * @param modelId [IN]        model id
 * @param dataset [IN]        Pointer of dataset
 * @param index [IN]          index of input for data which linked dynamic aipp(ACL_DATA_WITH_DYNAMIC_AIPP)
 * @param aippParmsSet [IN]   Pointer for aclmdlAIPP
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlLoadFromFile | aclmdlLoadFromMem | aclmdlLoadFromFileWithMem |
 * aclmdlLoadFromMemWithMem | aclmdlGetInputIndexByName | aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetAIPPByInputIndex(uint32_t modelId,
                                                       aclmdlDataset *dataset,
                                                       size_t index,
                                                       const aclmdlAIPP *aippParmsSet);

/**
 * @ingroup AscendCL
 * @brief get input aipp type
 *
 * @param modelId [IN]        model id
 * @param index [IN]          index of input
 * @param type [OUT]          aipp type for input.refrer to aclmdlInputAippType(enum)
 * @param dynamicAttachedDataIndex [OUT]     index for dynamic attached data(ACL_DYNAMIC_AIPP_NODE)
 *        valid when type is ACL_DATA_WITH_DYNAMIC_AIPP, invalid value is ACL_INVALID_NODE_INDEX
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlLoadFromFile | aclmdlLoadFromMem | aclmdlLoadFromFileWithMem |
 * aclmdlLoadFromMemWithMem | aclmdlGetInputIndexByName | aclmdlCreateAIPP
*/
ACL_FUNC_VISIBILITY aclError aclmdlGetAippType(uint32_t modelId,
                                               size_t index,
                                               aclmdlInputAippType *type,
                                               size_t *dynamicAttachedDataIndex);

/**
 * @ingroup AscendCL
 * @brief get static aipp parameters from model
 *
 * @param modelId [IN]        model id
 * @param index [IN]          index of tensor
 * @param aippInfo [OUT]      Pointer for static aipp info
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval ACL_ERROR_MODEL_AIPP_NOT_EXIST The tensor of index is not configured with aipp
 * @retval OtherValues Failure
 *
 * @see aclmdlLoadFromFile | aclmdlLoadFromMem | aclmdlLoadFromFileWithMem |
 * aclmdlLoadFromMemWithMem | aclmdlGetInputIndexByName
*/
ACL_FUNC_VISIBILITY aclError aclmdlGetFirstAippInfo(uint32_t modelId, size_t index, aclAippInfo *aippInfo);

/**
 * @ingroup AscendCL
 * @brief get op description info
 *
 * @param deviceId [IN]       device id
 * @param streamId [IN]       stream id
 * @param taskId [IN]         task id
 * @param opName [OUT]        pointer to op name
 * @param opNameLen [IN]      the length of op name
 * @param inputDesc [OUT]     pointer to input description
 * @param numInputs [OUT]     the number of input tensor
 * @param outputDesc [OUT]    pointer to output description
 * @param numOutputs [OUT]    the number of output tensor
 *
 * @retval ACL_SUCCESS The function is successfully executed
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclmdlCreateAndGetOpDesc(uint32_t deviceId, uint32_t streamId,
    uint32_t taskId, char *opName, size_t opNameLen, aclTensorDesc **inputDesc, size_t *numInputs,
    aclTensorDesc **outputDesc, size_t *numOutputs);

/**
 * @ingroup AscendCL
 * @brief init dump
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclmdlInitDump();

/**
 * @ingroup AscendCL
 * @brief set param of dump
 *
 * @param dumpCfgPath [IN]   the path of dump config
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclmdlSetDump(const char *dumpCfgPath);

/**
 * @ingroup AscendCL
 * @brief finalize dump.
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclmdlFinalizeDump();

/**
 * @ingroup AscendCL
 * @brief load model with config
 *
 * @param handle [IN]    pointer to model config handle
 * @param modelId [OUT]  pointer to model id
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclmdlLoadWithConfig(const aclmdlConfigHandle *handle, uint32_t *modelId);

/**
 * @ingroup AscendCL
 * @brief create model config handle of type aclmdlConfigHandle
 *
 * @retval the aclmdlConfigHandle pointer
 *
 * @see aclmdlDestroyConfigHandle
*/
ACL_FUNC_VISIBILITY aclmdlConfigHandle *aclmdlCreateConfigHandle();

/**
 * @ingroup AscendCL
 * @brief destroy data of type aclmdlConfigHandle
 *
 * @param handle [IN]   pointer to model config handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclmdlCreateConfigHandle
 */
ACL_FUNC_VISIBILITY aclError aclmdlDestroyConfigHandle(aclmdlConfigHandle *handle);

/**
 * @ingroup AscendCL
 * @brief set config for model load
 *
 * @param handle [OUT]    pointer to model config handle
 * @param attr [IN]       config attr in model config handle to be set
 * @param attrValue [IN]  pointer to model config value
 * @param valueSize [IN]  memory size of attrValue
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlSetConfigOpt(aclmdlConfigHandle *handle, aclmdlConfigAttr attr,
    const void *attrValue, size_t valueSize);

/**
 * @ingroup AscendCL
 * @brief set config for model execute
 *
 * @param handle [OUT]    pointer to model execute config handle
 * @param attr [IN]       config attr in model execute config handle to be set
 * @param attrValue [IN]  pointer to model execute config value
 * @param valueSize [IN]  memory size of attrValue
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclmdlSetExecConfigOpt(aclmdlExecConfigHandle *handle, aclmdlExecConfigAttr attr,
                                                    const void *attrValue, size_t valueSize);

/**
 * @ingroup AscendCL
 * @brief get real tensor name from modelDesc
 *
 * @param modelDesc [IN]  pointer to modelDesc
 * @param name [IN]       tensor name
 *
 * @retval the pointer of real tensor name
 * @retval Failure return NULL
 */
ACL_FUNC_VISIBILITY const char *aclmdlGetTensorRealName(const aclmdlDesc *modelDesc, const char *name);

#ifdef __cplusplus
}
#endif

#endif // INC_EXTERNAL_ACL_ACL_MODEL_H_
// End content from: acl/acl_mdl.h

// Begin content from: acl/acl_op.h
/**
* @file acl_op.h
*
* Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
*/
#ifndef INC_EXTERNAL_ACL_ACL_OP_H_
#define INC_EXTERNAL_ACL_ACL_OP_H_

// #include "acl_base.h"
// #include "acl_rt.h"

#ifdef __cplusplus
extern "C" {
#endif

typedef struct aclopHandle aclopHandle;
typedef struct aclopAttr aclopAttr;
typedef struct aclopKernelDesc aclopKernelDesc;

typedef void (*aclDataDeallocator)(void *data, size_t length);

static const int ACL_COMPILE_FLAG_BIN_SELECTOR = 1;

typedef enum aclEngineType {
    ACL_ENGINE_SYS,
    ACL_ENGINE_AICORE,
    ACL_ENGINE_VECTOR,
} aclopEngineType;

/**
 * @ingroup AscendCL
 * @brief Set base directory that contains single op models
 *
 * @par Restriction
 * The aclopSetModelDir interface can be called only once in a process.
 * @param  modelDir [IN]   path of the directory
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetModelDir(const char *modelDir);

/**
 * @ingroup AscendCL
 * @brief load single op models from memory
 *
 * @par Restriction
 * The aclopLoad interface can be called more than one times in a process.
 * @param model [IN]        address of single op models
 * @param modelSize [IN]    size of single op models
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopLoad(const void *model, size_t modelSize);

/**
 * @ingroup AscendCL
 * @brief create data of type aclopAttr
 *
 * @retval pointer to created instance.
 * @retval nullptr if run out of memory
 */
ACL_FUNC_VISIBILITY aclopAttr *aclopCreateAttr();

/**
 * @ingroup AscendCL
 * @brief destroy data of typ aclopAttr
 *
 * @param attr [IN]   pointer to the instance of aclopAttr
 */
ACL_FUNC_VISIBILITY void aclopDestroyAttr(const aclopAttr *attr);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is bool
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param attrValue [IN]   attribute value
 *                         false if attrValue is 0, true otherwise.
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrBool(aclopAttr *attr, const char *attrName, uint8_t attrValue);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is int64_t
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param attrValue [IN]   attribute value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrInt(aclopAttr *attr, const char *attrName, int64_t attrValue);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is float
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param attrValue [IN]   attribute value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrFloat(aclopAttr *attr, const char *attrName, float attrValue);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is string
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param attrValue [IN]   attribute value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrString(aclopAttr *attr, const char *attrName, const char *attrValue);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is aclDataType
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param attrValue [IN]   attribute value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrDataType(aclopAttr *attr, const char *attrName, aclDataType attrValue);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is list of aclDataType
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param numValues [IN]   number of values. false if attrValue is 0, true otherwise.
 * @param values [IN]      pointer to values
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrListDataType(aclopAttr *attr, const char *attrName, int numValues,
    const aclDataType values[]);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is list of bools
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param numValues [IN]   number of values. false if attrValue is 0, true otherwise.
 * @param values [IN]      pointer to values
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrListBool(aclopAttr *attr, const char *attrName, int numValues,
    const uint8_t *values);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is list of ints
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param numValues [IN]   number of values
 * @param values [IN]      pointer to values
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrListInt(aclopAttr *attr, const char *attrName, int numValues,
    const int64_t *values);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is list of floats
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param numValues [IN]   number of values
 * @param values [IN]      pointer to values
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrListFloat(aclopAttr *attr, const char *attrName, int numValues,
    const float *values);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is list of strings
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param numValues [IN]   number of values
 * @param values [IN]      pointer to values
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrListString(aclopAttr *attr, const char *attrName, int numValues,
    const char **values);

/**
 * @ingroup AscendCL
 * @brief set an attribute. the type of the attribute is list of list of ints
 *
 * @param attr [OUT]       pointer to the instance of aclopAttr
 * @param attrName [IN]    attribute name
 * @param numLists [IN]    number of lists
 * @param numValues [IN]   pointer to number of values of each list
 * @param values [IN]      pointer to values
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetAttrListListInt(aclopAttr *attr,
                                                     const char *attrName,
                                                     int numLists,
                                                     const int *numValues,
                                                     const int64_t *const values[]);

/**
 * @ingroup AscendCL
 * @brief Load and execute the specified operator asynchronously
 *
 * @par Restriction
 * @li The input and output organization of each operator is different,
 * and the application needs to organize the operator strictly
 * according to the operator input and output parameters when calling.
 * @li When the user calls aclopExecute,
 * the ACL finds the corresponding task according to the optype,
 * the description of the input tesnsor,
 * the description of the output tesnsor, and attr, and issues the execution.
 *
 * @param opType [IN]      type of op
 * @param numInputs [IN]   number of inputs
 * @param inputDesc [IN]   pointer to array of input tensor descriptions
 * @param inputs [IN]      pointer to array of input buffers
 * @param numOutputs [IN]  number of outputs
 * @param outputDesc [IN]  pointer to array of output tensor descriptions
 * @param outputs [OUT]    pointer to array of output buffers
 * @param attr [IN]        pointer to instance of aclopAttr.
 *                         may pass nullptr if the op has no attribute
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_DEPRECATED_MESSAGE("aclopExecute is deprecated, use aclopExecuteV2 instead")
ACL_FUNC_VISIBILITY aclError aclopExecute(const char *opType,
                                          int numInputs,
                                          const aclTensorDesc *const inputDesc[],
                                          const aclDataBuffer *const inputs[],
                                          int numOutputs,
                                          const aclTensorDesc *const outputDesc[],
                                          aclDataBuffer *const outputs[],
                                          const aclopAttr *attr,
                                          aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief Load and execute the specified operator
 *        The difference with aclopExecute is that aclopExecuteV2 will refresh outputDesc
 *
 * @par Restriction
 * @li The input and output organization of each operator is different,
 * and the application needs to organize the operator strictly
 * according to the operator input and output parameters when calling.
 * @li When the user calls aclopExecuteV2,
 * the ACL finds the corresponding task according to the optype,
 * the description of the input tesnsor,
 * the description of the output tesnsor, and attr, and issues the execution.
 *
 * @param opType [IN]      type of op
 * @param numInputs [IN]   number of inputs
 * @param inputDesc [IN]   pointer to array of input tensor descriptions
 * @param inputs [IN]      pointer to array of input buffers
 * @param numOutputs [IN]  number of outputs
 * @param outputDesc [IN|OUT]  pointer to array of output tensor descriptions
 * @param outputs [OUT]    pointer to array of output buffers
 * @param attr [IN]        pointer to instance of aclopAttr.
 *                         may pass nullptr if the op has no attribute
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopExecuteV2(const char *opType,
                                            int numInputs,
                                            aclTensorDesc *inputDesc[],
                                            aclDataBuffer *inputs[],
                                            int numOutputs,
                                            aclTensorDesc *outputDesc[],
                                            aclDataBuffer *outputs[],
                                            aclopAttr *attr,
                                            aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief create a instance of aclopHandle.
 *
 * @param opType [IN]      type of op
 * @param numInputs [IN]   number of inputs
 * @param inputDesc [IN]   pointer to array of input tensor descriptions
 * @param numOutputs [IN]  number of outputs
 * @param outputDesc [IN]  pointer to array of output tensor descriptions
 * @param opAttr [IN]      pointer to instance of aclopAttr.
 *                         may pass nullptr if the op has no attribute
 * @param handle [OUT]     pointer to the pointer to the handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopCreateHandle(const char *opType,
                                               int numInputs,
                                               const aclTensorDesc *const inputDesc[],
                                               int numOutputs,
                                               const aclTensorDesc *const outputDesc[],
                                               const aclopAttr *opAttr,
                                               aclopHandle **handle);

/**
 * @ingroup AscendCL
 * @brief destroy aclopHandle instance
 *
 * @param handle [IN]   pointer to the instance of aclopHandle
 */
ACL_FUNC_VISIBILITY void aclopDestroyHandle(aclopHandle *handle);

/**
 * @ingroup AscendCL
 * @brief execute an op with the handle.
 *        can save op model matching cost compared with aclopExecute
 *
 * @param handle [IN]      pointer to the instance of aclopHandle.
 *                         The aclopCreateHandle interface has been called
 *                         in advance to create aclopHandle type data.
 * @param numInputs [IN]   number of inputs
 * @param inputs [IN]      pointer to array of input buffers.
 *                         The aclCreateDataBuffer interface has been called
 *                         in advance to create aclDataBuffer type data.
 * @param numOutputs [IN]  number of outputs
 * @param outputs [OUT]    pointer to array of output buffers
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclopCreateHandle | aclCreateDataBuffer
 */
ACL_FUNC_VISIBILITY aclError aclopExecWithHandle(aclopHandle *handle,
                                                 int numInputs,
                                                 const aclDataBuffer *const inputs[],
                                                 int numOutputs,
                                                 aclDataBuffer *const outputs[],
                                                 aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief cast data type
 *
 * @param srcDesc [IN]     source tensor desc
 * @param srcBuffer [IN]   source tensor buffer
 * @param dstDesc [IN]     destination tensor desc
 * @param dstBuffer [OUT]  destination tensor buffer
 * @param truncate [IN]    do not truncate if value is 0, truncate otherwise
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopCast(const aclTensorDesc *srcDesc,
                                       const aclDataBuffer *srcBuffer,
                                       const aclTensorDesc *dstDesc,
                                       aclDataBuffer *dstBuffer,
                                       uint8_t truncate,
                                       aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief create a handle for casting datatype
 *
 * @param srcDesc [IN]    source tensor desc
 * @param dstDesc [IN]    destination tensor desc
 * @param truncate [IN]   do not truncate if value is 0, truncate otherwise
 * @param handle [OUT]    pointer to the pointer to the handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopCreateHandleForCast(aclTensorDesc *srcDesc,
                                                      aclTensorDesc *dstDesc,
                                                      uint8_t truncate,
                                                      aclopHandle **handle);


/**
 * @ingroup AscendCL
 * @brief create kernel
 *
 * @param opType [IN]           op type
 * @param kernelId [IN]         kernel id
 * @param kernelName [IN]       kernel name
 * @param binData [IN]          kernel bin data
 * @param binSize [IN]          kernel bin size
 * @param enginetype [IN]       enigne type
 * @param deallocator [IN]      callback function for deallocating bin data,
 *                              null if bin data to be deallocated by caller
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclopCompile
 */
ACL_FUNC_VISIBILITY aclError aclopCreateKernel(const char *opType,
                                               const char *kernelId,
                                               const char *kernelName,
                                               void *binData,
                                               int binSize,
                                               aclopEngineType enginetype,
                                               aclDataDeallocator deallocator);


/**
 * @ingroup AscendCL
 * @brief create kernel
 *
 * @param numInputs [IN]            number of inputs
 * @param inputDesc [IN]            pointer to array of input tensor descriptions
 * @param numOutputs [IN]           number of outputs
 * @param outputDesc [IN]           pointer to array of output tensor descriptions
 * @param opAttr [IN]               pointer to instance of aclopAttr
 * @param aclopKernelDesc [IN]      pointer to instance of aclopKernelDesc
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
typedef aclError (*aclopCompileFunc)(int numInputs,
                                     const aclTensorDesc *const inputDesc[],
                                     int numOutputs,
                                     const aclTensorDesc *const outputDesc[],
                                     const aclopAttr *opAttr,
                                     aclopKernelDesc *aclopKernelDesc);

/**
 * @ingroup AscendCL
 * @brief register compile function
 *
 * @param opType [IN]         op type
 * @param func [IN]           compile function
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclopUnregisterCompileFunc
 */
ACL_FUNC_VISIBILITY aclError aclopRegisterCompileFunc(const char *opType, aclopCompileFunc func);

/**
 * @ingroup AscendCL
 * @brief unregister compile function
 *
 * @param opType [IN]         op type
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopUnregisterCompileFunc(const char *opType);

/**
 * @ingroup AscendCL
 * @brief set kernel args
 *
 * @param kernelDesc [IN]               pointer to instance of aclopKernelDesc
 * @param kernelId [IN]                 kernel id
 * @param blockDim [IN]                 block dim
 * @param args [IN]                     args
 * @param argSize [IN]                  size in bytes of args
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetKernelArgs(aclopKernelDesc *kernelDesc,
                                                const char *kernelId,
                                                uint32_t blockDim,
                                                const void *args,
                                                uint32_t argSize);

/**
 * @ingroup AscendCL
 * @brief set workspace sizes
 *
 * @param kernelDesc [IN]               pointer to instance of aclopKernelDesc
 * @param numWorkspaces [IN]            number of workspaces
 * @param workspaceSizes [IN]           pointer to array of sizes of workspaces
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetKernelWorkspaceSizes(aclopKernelDesc *kernelDesc, int numWorkspaces,
                                                          size_t *workspaceSizes);

/**
 * @ingroup AscendCL
 * @brief compile op with dynamic shape
 *
 * @param opType [IN]       op type
 * @param numInputs [IN]    number of inputs
 * @param inputDesc [IN]    pointer to array of input tensor descriptions
 * @param numOutputs [IN]   number of outputs
 * @param outputDesc [IN]   pointer to array of output tensor descriptions
 * @param attr [IN]         pointer to instance of aclopAttr.
 *                          may pass nullptr if the op has no attribute
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopUpdateParams(const char *opType,
                                               int numInputs,
                                               const aclTensorDesc *const inputDesc[],
                                               int numOutputs,
                                               const aclTensorDesc *const outputDesc[],
                                               const aclopAttr *attr);

/**
 * @ingroup AscendCL
 * @brief set max op queue num
 *
 * @param maxOpNum [IN]   number of max op queue
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetMaxOpQueueNum(uint64_t maxOpNum);

/**
 * @ingroup AscendCL
 * @brief inferShape the specified operator synchronously
 *
 * @param opType [IN]       type of op
 * @param numInputs [IN]    number of inputs
 * @param inputDesc [IN]    pointer to array of input tensor descriptions
 * @param inputs [IN]       pointer to array of input buffers
 * @param numOutputs [IN]   number of outputs
 * @param outputDesc [OUT]  pointer to array of output tensor descriptions
 * @param attr [IN]         pointer to instance of aclopAttr.
 *                          may pass nullptr if the op has no attribute
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopInferShape(const char *opType,
                                             int numInputs,
                                             aclTensorDesc *inputDesc[],
                                             aclDataBuffer *inputs[],
                                             int numOutputs,
                                             aclTensorDesc *outputDesc[],
                                             aclopAttr *attr);

#define ACL_OP_DUMP_OP_AICORE_ARGS 0x00000001U

/**
 * @ingroup AscendCL
 * @brief Enable the dump function of the corresponding dump type.
 *
 * @param dumpType [IN]       type of dump
 * @param path     [IN]       dump path
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopStartDumpArgs(uint32_t dumpType, const char *path);

/**
 * @ingroup AscendCL
 * @brief Disable the dump function of the corresponding dump type.
 *
 * @param dumpType [IN]       type of dump
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopStopDumpArgs(uint32_t dumpType);

#ifdef __cplusplus
}
#endif

#endif // INC_EXTERNAL_ACL_ACL_OP_H_
// End content from: acl/acl_op.h

// Begin content from: aclnn/acl_meta.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_OP_API_COMMON_INC_EXTERNAL_ACL_META_H
#define OP_API_OP_API_COMMON_INC_EXTERNAL_ACL_META_H

#include <cstdint>
#include <cstdlib>
// #include <acl/acl_base.h>

#ifdef __cplusplus
extern "C" {
#endif

#if defined(_MSC_VER)
#ifdef FUNC_VISIBILITY
#define ACL_FUNC_VISIBILITY _declspec(dllexport)
#else
#define ACL_FUNC_VISIBILITY
#endif
#else
#ifdef FUNC_VISIBILITY
#define ACL_FUNC_VISIBILITY __attribute__((visibility("default")))
#else
#define ACL_FUNC_VISIBILITY
#endif
#endif

#ifdef __GNUC__
#define ACL_DEPRECATED __attribute__((deprecated))
#define ACL_DEPRECATED_MESSAGE(message) __attribute__((deprecated(message)))
#elif defined(_MSC_VER)
#define ACL_DEPRECATED __declspec(deprecated)
#define ACL_DEPRECATED_MESSAGE(message) __declspec(deprecated(message))
#else
#define ACL_DEPRECATED
#define ACL_DEPRECATED_MESSAGE(message)
#endif

#ifndef ACLNN_META
#define ACLNN_META
typedef struct aclOpExecutor aclOpExecutor;
typedef struct aclTensor aclTensor;
typedef struct aclScalar aclScalar;
typedef struct aclIntArray aclIntArray;
typedef struct aclFloatArray aclFloatArray;
typedef struct aclBoolArray aclBoolArray;
typedef struct aclTensorList aclTensorList;
typedef struct aclScalarList aclScalarList;

typedef int32_t aclnnStatus;
constexpr aclnnStatus OK = 0;
#endif

ACL_FUNC_VISIBILITY aclTensor *aclCreateTensor(const int64_t *viewDims, uint64_t viewDimsNum, aclDataType dataType,
                                               const int64_t *stride, int64_t offset, aclFormat format,
                                               const int64_t *storageDims, uint64_t storageDimsNum,
                                               void *tensorData);

ACL_FUNC_VISIBILITY aclScalar *aclCreateScalar(void *value, aclDataType dataType);
ACL_FUNC_VISIBILITY aclIntArray *aclCreateIntArray(const int64_t *value, uint64_t size);
ACL_FUNC_VISIBILITY aclFloatArray *aclCreateFloatArray(const float *value, uint64_t size);
ACL_FUNC_VISIBILITY aclBoolArray *aclCreateBoolArray(const bool *value, uint64_t size);
ACL_FUNC_VISIBILITY aclTensorList *aclCreateTensorList(const aclTensor *const *value, uint64_t size);
ACL_FUNC_VISIBILITY aclScalarList *aclCreateScalarList(const aclScalar *const *value, uint64_t size);

ACL_FUNC_VISIBILITY aclnnStatus aclDestroyTensor(const aclTensor *tensor);
ACL_FUNC_VISIBILITY aclnnStatus aclDestroyScalar(const aclScalar *scalar);
ACL_FUNC_VISIBILITY aclnnStatus aclDestroyIntArray(const aclIntArray *array);
ACL_FUNC_VISIBILITY aclnnStatus aclDestroyFloatArray(const aclFloatArray *array);
ACL_FUNC_VISIBILITY aclnnStatus aclDestroyBoolArray(const aclBoolArray *array);
ACL_FUNC_VISIBILITY aclnnStatus aclDestroyTensorList(const aclTensorList *array);
ACL_FUNC_VISIBILITY aclnnStatus aclDestroyScalarList(const aclScalarList *array);
ACL_FUNC_VISIBILITY aclnnStatus aclGetViewShape(const aclTensor *tensor, int64_t **viewDims, uint64_t *viewDimsNum);
ACL_FUNC_VISIBILITY aclnnStatus aclGetStorageShape(const aclTensor *tensor,
                                                   int64_t **storageDims,
                                                   uint64_t *storageDimsNum);
ACL_FUNC_VISIBILITY aclnnStatus aclGetViewStrides(const aclTensor *tensor,
                                                  int64_t **stridesValue,
                                                  uint64_t *stridesNum);
ACL_FUNC_VISIBILITY aclnnStatus aclGetViewOffset(const aclTensor *tensor, int64_t *offset);
ACL_FUNC_VISIBILITY aclnnStatus aclGetFormat(const aclTensor *tensor, aclFormat *format);
ACL_FUNC_VISIBILITY aclnnStatus aclGetDataType(const aclTensor *tensor, aclDataType *dataType);
ACL_FUNC_VISIBILITY aclnnStatus aclGetIntArraySize(const aclIntArray *array, uint64_t *size);
ACL_FUNC_VISIBILITY aclnnStatus aclGetFloatArraySize(const aclFloatArray *array, uint64_t *size);
ACL_FUNC_VISIBILITY aclnnStatus aclGetBoolArraySize(const aclBoolArray *array, uint64_t *size);
ACL_FUNC_VISIBILITY aclnnStatus aclGetTensorListSize(const aclTensorList *tensorList, uint64_t *size);
ACL_FUNC_VISIBILITY aclnnStatus aclGetScalarListSize(const aclScalarList *scalarList, uint64_t *size);

ACL_FUNC_VISIBILITY aclnnStatus aclInitTensor(aclTensor *tensor, const int64_t *viewDims, uint64_t viewDimsNum,
                                              aclDataType dataType, const int64_t *stride, int64_t offset,
                                              aclFormat format, const int64_t *storageDims, uint64_t storageDimsNum,
                                              void *tensorDataAddr);
ACL_FUNC_VISIBILITY aclnnStatus aclSetAclOpExecutorRepeatable(aclOpExecutor *executor);
ACL_FUNC_VISIBILITY aclnnStatus aclDestroyAclOpExecutor(aclOpExecutor *executor);
ACL_FUNC_VISIBILITY aclnnStatus AclSetInputTensorAddr(aclOpExecutor *executor, const size_t index,
                                                      aclTensor *tensor, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus AclSetOutputTensorAddr(aclOpExecutor *executor, const size_t index,
                                                       aclTensor *tensor, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus AclSetDynamicInputTensorAddr(aclOpExecutor *executor, size_t irIndex,
                                                             const size_t relativeIndex,
                                                             aclTensorList *tensors, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus AclSetDynamicOutputTensorAddr(aclOpExecutor *executor, size_t irIndex,
                                                              const size_t relativeIndex,
                                                              aclTensorList *tensors, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus AclSetTensorAddr(aclOpExecutor *executor, const size_t index,
                                                 aclTensor *tensor, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus AclSetDynamicTensorAddr(aclOpExecutor *executor, size_t irIndex,
                                                        const size_t relativeIndex,
                                                        aclTensorList *tensors, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus aclSetInputTensorAddr(aclOpExecutor *executor, const size_t index,
                                                      aclTensor *tensor, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus aclSetOutputTensorAddr(aclOpExecutor *executor, const size_t index,
                                                       aclTensor *tensor, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus aclSetDynamicInputTensorAddr(aclOpExecutor *executor, size_t irIndex,
                                                             const size_t relativeIndex,
                                                             aclTensorList *tensors, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus aclSetDynamicOutputTensorAddr(aclOpExecutor *executor, size_t irIndex,
                                                              const size_t relativeIndex,
                                                              aclTensorList *tensors, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus aclSetTensorAddr(aclOpExecutor *executor, const size_t index,
                                                 aclTensor *tensor, void *addr);
ACL_FUNC_VISIBILITY aclnnStatus aclSetDynamicTensorAddr(aclOpExecutor *executor, size_t irIndex,
                                                        const size_t relativeIndex,
                                                        aclTensorList *tensors, void *addr);
#ifdef __cplusplus
}
#endif

#endif // OP_API_OP_API_COMMON_INC_EXTERNAL_ACL_META_H
// End content from: aclnn/acl_meta.h

// Begin content from: acl/acl.h
/**
* @file acl.h
*
* Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
*/

#ifndef INC_EXTERNAL_ACL_ACL_H_
#define INC_EXTERNAL_ACL_ACL_H_

// #include "acl_rt.h"
// #include "acl_op.h"
// #include "acl_mdl.h"

#ifdef __cplusplus
extern "C" {
#endif

// Current version is 1.12.0
#define ACL_MAJOR_VERSION    1
#define ACL_MINOR_VERSION    12
#define ACL_PATCH_VERSION    0

/**
 * @ingroup AscendCL
 * @brief acl initialize
 *
 * @par Restriction
 * The aclInit interface can be called only once in a process
 * @param configPath [IN]    the config path,it can be NULL
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclInit(const char *configPath);

/**
 * @ingroup AscendCL
 * @brief acl finalize
 *
 * @par Restriction
 * Need to call aclFinalize before the process exits.
 * After calling aclFinalize,the services cannot continue to be used normally.
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclFinalize();

/**
 * @ingroup AscendCL
 * @brief query ACL interface version
 *
 * @param majorVersion[OUT] ACL interface major version
 * @param minorVersion[OUT] ACL interface minor version
 * @param patchVersion[OUT] ACL interface patch version
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclrtGetVersion(int32_t *majorVersion, int32_t *minorVersion, int32_t *patchVersion);

/**
 * @ingroup AscendCL
 * @brief get recent error message
 *
 * @retval null for failed
 * @retval OtherValues success
*/
ACL_FUNC_VISIBILITY const char *aclGetRecentErrMsg();

#ifdef __cplusplus
}
#endif

#endif // INC_EXTERNAL_ACL_ACL_H_
// End content from: acl/acl.h

// Begin content from: hccl/hccl_types.h
/*
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef HCCL_TYPES_H_
#define HCCL_TYPES_H_

#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif // __cplusplus

/**
 * @brief HCCL functions return value definition
 */
typedef enum {
    HCCL_SUCCESS = 0,               /**< success */
    HCCL_E_PARA = 1,                /**< parameter error */
    HCCL_E_PTR = 2,                 /**< empty pointer */
    HCCL_E_MEMORY = 3,              /**< memory error */
    HCCL_E_INTERNAL = 4,            /**< internal error */
    HCCL_E_NOT_SUPPORT = 5,         /**< not support feature */
    HCCL_E_NOT_FOUND = 6,           /**< not found specific resource */
    HCCL_E_UNAVAIL = 7,             /**< resource unavailable */
    HCCL_E_SYSCALL = 8,             /**< call system interface error */
    HCCL_E_TIMEOUT = 9,             /**< timeout */
    HCCL_E_OPEN_FILE_FAILURE = 10,  /**< open file fail */
    HCCL_E_TCP_CONNECT = 11,        /**< tcp connect fail */
    HCCL_E_ROCE_CONNECT = 12,       /**< roce connect fail */
    HCCL_E_TCP_TRANSFER = 13,       /**< tcp transfer fail */
    HCCL_E_ROCE_TRANSFER = 14,      /**< roce transfer fail */
    HCCL_E_RUNTIME = 15,            /**< call runtime api fail */
    HCCL_E_DRV = 16,                /**< call driver api fail */
    HCCL_E_PROFILING = 17,          /**< call profiling api fail */
    HCCL_E_CCE = 18,                /**< call cce api fail */
    HCCL_E_NETWORK = 19,            /**< call network api fail */
    HCCL_E_AGAIN = 20,              /**< try again */
    HCCL_E_REMOTE = 21,             /**< error cqe */
    HCCL_E_SUSPENDING = 22,         /**< error communicator suspending */
    HCCL_E_RESERVED                 /**< reserved */
} HcclResult;

/**
 * @brief handle to HCCL communicator
 */
typedef void *HcclComm;

/**
 * @brief HCCL Reduction opperation
 */
typedef enum {
    HCCL_REDUCE_SUM = 0,    /**< sum */
    HCCL_REDUCE_PROD = 1,   /**< prod */
    HCCL_REDUCE_MAX = 2,    /**< max */
    HCCL_REDUCE_MIN = 3,    /**< min */
    HCCL_REDUCE_RESERVED    /**< reserved */
} HcclReduceOp;

/**
 * @brief HCCL data type
 */
typedef enum {
    HCCL_DATA_TYPE_INT8 = 0,    /**< int8 */
    HCCL_DATA_TYPE_INT16 = 1,   /**< int16 */
    HCCL_DATA_TYPE_INT32 = 2,   /**< int32 */
    HCCL_DATA_TYPE_FP16 = 3,    /**< fp16 */
    HCCL_DATA_TYPE_FP32 = 4,    /**< fp32 */
    HCCL_DATA_TYPE_INT64 = 5,    /**< int64 */
    HCCL_DATA_TYPE_UINT64 = 6,    /**< uint64 */
    HCCL_DATA_TYPE_UINT8 = 7,    /**< uint8 */
    HCCL_DATA_TYPE_UINT16 = 8,   /**< uint16 */
    HCCL_DATA_TYPE_UINT32 = 9,   /**< uint32 */
    HCCL_DATA_TYPE_FP64 = 10, /**< fp64 */
    HCCL_DATA_TYPE_BFP16 = 11,    /**< bfp16 */
    HCCL_DATA_TYPE_INT128 = 12,   /**< int128 */
    HCCL_DATA_TYPE_RESERVED     /**< reserved */
} HcclDataType;

typedef enum {
    HCCL_DETERMINISTIC = 0,     /**< 0: non-deterministic, 1: deterministic */
    HCCL_CONFIG_RESERVED
} HcclConfig;


union HcclConfigValue {
    int32_t value;
};

const uint32_t HCCL_ROOT_INFO_BYTES =  4108; // 4108: root info length
const uint32_t COMM_NAME_MAX_LENGTH = 128; // group name max length
const uint32_t UDI_MAX_LENGTH = 128; // UDI max length
/**
 * @brief HCCL root info
 */
typedef struct HcclRootInfoDef {
    char internal[HCCL_ROOT_INFO_BYTES];
} HcclRootInfo;

const uint32_t HCCL_COMM_CONFIG_INFO_BYTES = 24;
const uint32_t HCCL_COMM_CONFIG_MAGIC_WORD = 0xf0f0f0f0;
const uint32_t HCCL_COMM_CONFIG_VERSION = 3;
const uint32_t HCCL_COMM_DEFAULT_BUFFSIZE = 200;
const uint32_t HCCL_COMM_DEFAULT_DETERMINISTIC = 0;

typedef struct HcclCommConfigDef {
    char reserved[HCCL_COMM_CONFIG_INFO_BYTES];
    uint32_t hcclBufferSize;
    uint32_t hcclDeterministic;
    char hcclCommName[COMM_NAME_MAX_LENGTH];
    char hcclUdi[UDI_MAX_LENGTH];
} HcclCommConfig;

typedef enum {
    HCCL_COMM_CONFIG_BUFFER_SIZE= 0,
    HCCL_COMM_CONFIG_DETERMINISTIC = 1,
    HCCL_COMM_CONFIG_COMM_NAME = 2,
    HCCL_COMM_CONFIG_RESERVED
} HcclCommConfigCapability;

typedef enum {
    HCCL_SEND = 0,
    HCCL_RECV = 1,
    HCCL_SEND_RECV_RESERVED
} HcclSendRecvType;

typedef struct HcclSendRecvItemDef {
    HcclSendRecvType sendRecvType;
    void *buf;
    uint64_t count;
    HcclDataType dataType;
    uint32_t remoteRank;
} HcclSendRecvItem;

#ifdef __cplusplus
}
#endif // __cplusplus
#endif // HCCL_TYPES_H_
// End content from: hccl/hccl_types.h

// Begin content from: aclnn_util.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_UTIL_H
#define OP_API_INC_ACLNN_UTIL_H
 
#define ACLNN_API __attribute__((visibility("default")))
#endif // OP_API_INC_ACLNN_UTIL_H// End content from: aclnn_util.h

// Begin content from: aclnn/aclnn_base.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_OP_API_COMMON_INC_EXTERNAL_ACLNN_BASE_H
#define OP_API_OP_API_COMMON_INC_EXTERNAL_ACLNN_BASE_H

#include <cstdint>
#include <cstdlib>
// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

#if defined(_MSC_VER)
#ifdef FUNC_VISIBILITY
#define ACL_FUNC_VISIBILITY _declspec(dllexport)
#else
#define ACL_FUNC_VISIBILITY
#endif
#else
#ifdef FUNC_VISIBILITY
#define ACL_FUNC_VISIBILITY __attribute__((visibility("default")))
#else
#define ACL_FUNC_VISIBILITY
#endif
#endif

#ifdef __GNUC__
#define ACL_DEPRECATED __attribute__((deprecated))
#define ACL_DEPRECATED_MESSAGE(message) __attribute__((deprecated(message)))
#elif defined(_MSC_VER)
#define ACL_DEPRECATED __declspec(deprecated)
#define ACL_DEPRECATED_MESSAGE(message) __declspec(deprecated(message))
#else
#define ACL_DEPRECATED
#define ACL_DEPRECATED_MESSAGE(message)
#endif

ACL_FUNC_VISIBILITY aclnnStatus aclnnInit(const char *configPath);
ACL_FUNC_VISIBILITY aclnnStatus aclnnFinalize();

#ifdef __cplusplus
}
#endif

#endif // OP_API_OP_API_COMMON_INC_EXTERNAL_ACLNN_BASE_H
// End content from: aclnn/aclnn_base.h

// Begin content from: hccl/hccl.h
/*
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef HCCL_H_
#define HCCL_H_

// #include <hccl/hccl_types.h>
// #include <acl/acl.h>

#ifdef __cplusplus
extern "C" {
#endif // __cplusplus

/**
 * @brief Initialize HCCL.
 *
 * @param clusterInfo A string identifying the cluster info file path, include file name.
 * @param rank A integer identifying the identify for the rank.
 * @param comm A pointer identifying the initialized communication resource.
 * @return HcclResult
 * @see HcclCommDestroy()
 */
extern HcclResult HcclCommInitClusterInfo(const char *clusterInfo, uint32_t rank, HcclComm *comm);

/**
 * @brief Initialize HCCL with config params.
 *
 * @param clusterInfo A string identifying the cluster info file path, include file name.
 * @param rank A integer identifying the identify for the rank.
 * @param config A pointer identifying config params about the current comm.
 * @param comm A pointer identifying the initialized communication resource.
 * @return HcclResult
 * @see HcclCommDestroy()
 */
extern HcclResult HcclCommInitClusterInfoConfig(const char *clusterInfo, uint32_t rank,
    HcclCommConfig *config, HcclComm *comm);

/**
 * @brief Initialize HCCL sub communication based on global communication with config params.
 *
 * @param comm A pointer identifying the global communication resource.
 * @param rankNum A integer identifying the rank size of the sub communication.
 * @param rankIds A array identifying the identifies for the ranks in the sub communication.
 * @param subCommId A integer identifying the identify of sub communication in global communication.
 * @param subCommRankId A array identifying the identify for the rank in the sub communication.
 * @param config A pointer identifying config params about the current comm.
 * @param comm A pointer identifying the initialized communication resource.
 * @return HcclResult
 * @see HcclCommDestroy()
 */
extern HcclResult HcclCreateSubCommConfig(HcclComm *comm, uint32_t rankNum, uint32_t *rankIds,
    uint64_t subCommId, uint32_t subCommRankId, HcclCommConfig *config, HcclComm *subComm);

/**
 * @brief Get hccl root info.
 *
 * @param rootInfo A pointer identifying the hccl root info.
 * @return HcclResult
 */
extern HcclResult HcclGetRootInfo(HcclRootInfo *rootInfo);

/**
 * @brief Initialize HCCL with root info.
 *
 * @param nRanks A integer identifying the rank size of the cluster.
 * @param rootInfo A struct identifying the hccl root info.
 * @param rank A integer identifying the identify for the rank.
 * @param comm A pointer identifying the initialized communication resource.
 * @return HcclResult
 * @see HcclCommDestroy()
 */
extern HcclResult HcclCommInitRootInfo(uint32_t nRanks, const HcclRootInfo *rootInfo, uint32_t rank, HcclComm *comm);

/**
 * @brief Initialize HCCL with root info and config params.
 *
 * @param nRanks A integer identifying the rank size of the cluster.
 * @param rootInfo A struct identifying the hccl root info.
 * @param rank A integer identifying the identify for the rank.
 * @param config A pointer identifying config params about the current comm.
 * @param comm A pointer identifying the initialized communication resource.
 * @return HcclResult
 * @see HcclCommDestroy()
 */
extern HcclResult HcclCommInitRootInfoConfig(uint32_t nRanks, const HcclRootInfo *rootInfo, uint32_t rank,
    const HcclCommConfig *config, HcclComm *comm);

/* *

 * @brief Set deterministic calculate
 *
 * @param config A struct identifying the Config
 * @param configValue An interger identifying the identify for the config.
 */

extern HcclResult HcclSetConfig(HcclConfig config, HcclConfigValue configValue);
extern HcclResult HcclGetConfig(HcclConfig config, HcclConfigValue *configValue);

/**

 * @brief get commName.
 *
 * @param commhandle A pointer identifying the initialized communication resource.
 * @param commName The name of commhandle.
 * @return HcclResult
 * @see HcclCommDestroy()
 */
extern HcclResult HcclGetCommName(HcclComm comm, char* commName);


/**
 * @brief AllReduce operator.
 *
 * @param sendBuf A pointer identifying the input data address of the operator.
 * @param recvBuf A pointer identifying the output data address of the operator.
 * @param count An integer(u64) identifying the number of the output data.
 * @param dataType The data type of the operator, must be one of the following types: int8, int16, int32,
float16, float32, bfloat16.
 * @param op The reduction type of the operator, must be one of the following types: sum, min, max, prod.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclAllReduce(void *sendBuf, void *recvBuf, uint64_t count, HcclDataType dataType,
    HcclReduceOp op, HcclComm comm, aclrtStream stream);

/**
 * @brief Broadcast operator.
 *
 * @param buf A pointer identifying the data address of the operator.
 * @param count An integer(u64) identifying the number of the data.
 * @param dataType The data type of the operator, must be one of the following types: int8, int16, int32, int64,
uint8, uint16, uint32, uint64, float16, float32, float64, bfloat16.
 * @param root An integer(u32) identifying the the root rank in the operator.
 * @param comm A pointer identifying the communication resource based on
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclBroadcast(void *buf, uint64_t count, HcclDataType dataType, uint32_t root, HcclComm comm,
    aclrtStream stream);

/**
 * @brief ReduceScatter operator.
 *
 * @param sendBuf A pointer identifying the input data address of the operator.
 * @param recvBuf A pointer identifying the output data address of the operator.
 * @param recvCount An integer(u64) identifying the number of the output data.
 * @param dataType The data type of the operator, must be one of the following types: int8, int32,
 float16, float32, bfloat16.
 * @param op The reduction type of the operator, must be one of the following types: sum, min, max, prod.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclReduceScatter(void *sendBuf, void *recvBuf, uint64_t recvCount, HcclDataType dataType,
    HcclReduceOp op, HcclComm comm, aclrtStream stream);

/**
 * @brief Scatter operator.
 *
 * @param sendBuf A pointer identifying the input data address of the operator.
 * @param recvBuf A pointer identifying the output data address of the operator.
 * @param recvCount An integer(u64) identifying the number of the data.
 * @param dataType The data type of the operator, must be one of the following types: int8, int32, float16, float32.
 * @param root An integer(u32) identifying the the root rank in the operator.
 * @param comm A pointer identifying the communication resource based on
 * @param stream A pointer identifying the stream information.
 * @return HcclResult 
 */
extern HcclResult HcclScatter(void *sendBuf, void *recvBuf, uint64_t recvCount, HcclDataType dataType, uint32_t root,
    HcclComm comm, aclrtStream stream);

/**
 * @brief AllGather operator.
 *
 * @param sendBuf A pointer identifying the input data address of the operator.
 * @param recvBuf A pointer identifying the output data address of the operator.
 * @param sendCount An integer(u64) identifying the number of the input data.
 * @param dataType The data type of the operator, must be one of the following types: int8, int16, int32, int64,
uint8, uint16, uint32, uint64, float16, float32, float64, bfloat16.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclAllGather(void *sendBuf, void *recvBuf, uint64_t sendCount, HcclDataType dataType,
    HcclComm comm, aclrtStream stream);
/**
 * @brief Get the rank size of this comm.
 *
 * @param comm A pointer identifying the communication resource based on.
 * @param rankSize  A pointer identifying the rank size.
 * @return HcclResult
 */
extern HcclResult HcclGetRankSize(HcclComm comm, uint32_t *rankSize);

/**
 * @brief Get the rank id of this comm.
 *
 * @param comm A pointer identifying the communication resource based on.
 * @param rankSize  A pointer identifying the rank id.
 * @return HcclResult
 */
extern HcclResult HcclGetRankId(HcclComm comm, uint32_t *rank);
/**
 * @brief Barrier operator.
 *
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclBarrier(HcclComm comm, aclrtStream stream);

/**
 * @brief Send operator.
 *
 * @param sendBuff A pointer identifying the input data address of the operator.
 * @param count An integer(u64) identifying the number of the send data.
 * @param dataType The data type of the operator, must be one of the following types: int8, int16, int32, int64,
uint8, uint16, uint32, uint64, float16, float32, float64, bfloat16.
 * @param destRank An integer identifying the destination rank.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclSend(void* sendBuf, uint64_t count, HcclDataType dataType, uint32_t destRank,
                           HcclComm comm, aclrtStream stream);
/**
 * @brief Recv operator.
 *
 * @param recvBuff A pointer identifying the output data address of the operator.
 * @param count An integer(u64) identifying the number of the receive data.
 * @param dataType The data type of the operator, must be one of the following types: int8, int16, int32, int64,
uint8, uint16, uint32, uint64, float16, float32, float64, bfloat16.
 * @param srcRank An integer identifying the source rank.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclRecv(void* recvBuf, uint64_t count, HcclDataType dataType, uint32_t srcRank,
                           HcclComm comm, aclrtStream stream);

/**
 * @brief AlltoAllV operator.
 *
 * @param sendBuff A pointer identifying the input data address of the operator.
 * @param sendCounts Integer array, where entry i specifies the number of elements to send to rank i.
 * @param sdispls Integer array, where entry i specifies the displacement (offset from sendbuf, in units of sendtype)
from which to send data to rank i.
 * @param sendType Datatype of send buffer elements, must be one of the following types: int8, int16, int32, int64,
uint8, uint16, uint32, uint64, float16, float32, float64, bfloat16.
 * @param recvBuf A pointer identifying the output data address of the operator.
 * @param recvCounts Integer array, where entry j specifies the number of elements to receive from rank j.
 * @param rdispls Integer array, where entry j specifies the displacement (offset from recvbuf, in units of recvtype)
 to which data from rank j should be written.
 * @param recvType Datatype of receive buffer elements, must be one of the following types: int8, int16, int32, int64,
uint8, uint16, uint32, uint64, float16, float32, float64.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclAlltoAllV(const void *sendBuf, const void *sendCounts, const void *sdispls, HcclDataType sendType,
                         const void *recvBuf, const void *recvCounts, const void *rdispls, HcclDataType recvType,
                         HcclComm comm, aclrtStream stream);

/**
 * @brief AlltoAll operator.
 *
 * @param sendBuff A pointer identifying the input data address of the operator.
 * @param sendCount Integer, number of elements to send to each proces.
 * @param sendType Datatype of send buffer elements, must be one of the following types: int8, int16, int32, int64,
uint8, uint16, uint32, uint64, float16, float32, float64, bfloat16.
 * @param recvBuf A pointer identifying the output data address of the operator.
 * @param recvCount Integer, number of elements received from any process.
 * @param recvType Datatype of receive buffer elements, must be one of the following types: int8, int16, int32, int64,
uint8, uint16, uint32, uint64, float16, float32, float64.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclAlltoAll(const void *sendBuf, uint64_t sendCount, HcclDataType sendType,
                               const void *recvBuf, uint64_t recvCount, HcclDataType recvType,
                               HcclComm comm, aclrtStream stream);

/**
 * @brief Reduce operator.
 *
 * @param sendBuf A pointer identifying the input data address of the operator.
 * @param recvBuf A pointer identifying the output data address of the operator.
 * @param count An integer(u64) identifying the number of the output data.
 * @param dataType The data type of the operator, must be one of the following types: int8, int16, int32, float16,
 float32, bfloat16.
 * @param op The reduction type of the operator, must be one of the following types: sum, min, max, prod.
 * @param root An integer(u32) identifying the the root rank in the operator.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
 * @return HcclResult
 */
extern HcclResult HcclReduce(void *sendBuf, void *recvBuf, uint64_t count, HcclDataType dataType,
                             HcclReduceOp op, uint32_t root, HcclComm comm, aclrtStream stream);

/**
 * @brief Destroy HCCL comm
 *
 * @param comm A pointer identifying the communication resource targetting
 * @return HcclResult
 * @see HcclCommInitClusterInfo()
 */
extern HcclResult HcclCommDestroy(HcclComm comm);

/**
 * @brief Create a single-process multi-npu communication domain. Cross-machine is not supported.
 *
 * @param ndev: the number of NPUs in a communication domain.
 * @param devices: Indicates the NPU list in the communication domain. The value is the device logic ID.
 The communication library creates communication domains in the sequence of devices.
 * @param comms: Generated communication domain handle, size: ndev * sizeof(HcclComm)
 * @return HcclResult
 */
extern HcclResult HcclCommInitAll(uint32_t ndev, int32_t* devices, HcclComm* comms);

/**
 * @brief Get hccl error.
 * @param comm A pointer identifying the communication resource based on.
 * @param asyncError A pointer identifying the communication error.
*/
extern HcclResult HcclGetCommAsyncError(HcclComm comm, HcclResult *asyncError);

/**
 * @brief  convert a hccl errorCode to a string.
 * @param code enum HcclResult.
*/
extern const char *HcclGetErrorString(HcclResult code);

/**
 * @brief  Batch SEND/RECV
 * @param sendRecvInfo A pointer to an send/recv item array.
 * @param itemNum The size of the send/recv item array.
 * @param comm A pointer identifying the communication resource based on.
 * @param stream A pointer identifying the stream information.
*/
extern HcclResult HcclBatchSendRecv(HcclSendRecvItem* sendRecvInfo, uint32_t itemNum, HcclComm comm, aclrtStream stream);


/**
 * @brief Initialize the comm configuration.
 * @param config Pointer to the comm configuration that needs to be initialized.
*/
inline void HcclCommConfigInit(HcclCommConfig *config)
{
    if (config == nullptr) {
        return;
    }

    typedef struct {
        size_t size;
        uint32_t magicWord;
        uint32_t version;
        uint64_t reserved;
    } configInfo_t;

    configInfo_t *info = (configInfo_t *)config;

    info->size = sizeof(HcclCommConfig);
    info->magicWord = HCCL_COMM_CONFIG_MAGIC_WORD;
    info->version = HCCL_COMM_CONFIG_VERSION;
    info->reserved = 0;

    config->hcclBufferSize = HCCL_COMM_DEFAULT_BUFFSIZE;
    config->hcclDeterministic = HCCL_COMM_DEFAULT_DETERMINISTIC;
    config->hcclCommName[0] = '\0';
}

/**
 * @brief Suspend communication.
 * @param comm A pointer identifying the communication resource based on.
*/
extern HcclResult HcclCommSuspend(HcclComm comm);
 
/**
 * @brief Clear and recover communication.
 * @param comm A pointer identifying the communication resource based on.
*/
extern HcclResult HcclCommResume(HcclComm comm);

/**
 * @brief Get a number that represents the capability of comm configuration.
*/
extern uint32_t HcclGetCommConfigCapability();

#ifdef __cplusplus
}
#endif // __cplusplus
#endif // HCCL_H
// End content from: hccl/hccl.h

// Begin content from: aclnn_dropout_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_DROPOUT_BACKWARD_H_
#define OP_API_INC_DROPOUT_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnDropoutBackwardworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnDropoutBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* mask,
                                                           double scale, aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnDropoutBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_DROPOUT_BACKWARD_H_
// End content from: aclnn_dropout_backward.h

// Begin content from: aclnn_dropout.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_DROPOUT_H_
#define OP_API_INC_DROPOUT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnDropoutworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnDropoutGetWorkspaceSize(const aclTensor* input, double p, bool train, int64_t seed,
                                                   int64_t offset, aclTensor* out, aclTensor* maskOut,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnDropout(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_DROPOUT_H_
// End content from: aclnn_dropout.h

// Begin content from: aclnn_normal_out.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_NORMAL_OUT_H_
#define OP_API_INC_NORMAL_OUT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnNormalworkspace
 * @domain aclnn_rand
 * @param [in] mean: npu
 * deviceaclTensorstdshapestdbroadcast
 * TensorNDstd
 * @param [in] std: npu
 * deviceaclTensormeanshapemeanbroadcast
 * TensorNDmean
 * @param [in] seed: hostint64_t
 * @param [in] offset: hostint64_t 
 * @param [out] out: hostint64_t, 
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNormalTensorTensorGetWorkspaceSize(const aclTensor* mean, const aclTensor* std, int64_t seed,
                                                              int64_t offset, aclTensor* out, uint64_t* workspaceSize,
                                                              aclOpExecutor** executor);

/**
 * @brief aclnnNormalTensorFloatworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnNormalTensorFloatGetWorkspaceSize(const aclTensor* mean, float std, int64_t seed,
                                                             int64_t offset, aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnNormalFloatTensorworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnNormalFloatTensorGetWorkspaceSize(float mean, const aclTensor* std, int64_t seed,
                                                             int64_t offset, aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnNormalFloatFloatworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnNormalFloatFloatGetWorkspaceSize(float mean, float std, int64_t seed, int64_t offset,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnNormal
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNormalTensorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              aclrtStream stream);

ACLNN_API aclnnStatus aclnnNormalTensorFloat(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

ACLNN_API aclnnStatus aclnnNormalFloatTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

ACLNN_API aclnnStatus aclnnNormalFloatFloat(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_NORMAL_OUT_H_
// End content from: aclnn_normal_out.h

// Begin content from: aclnn_bernoulli.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BERNOULLI_H_
#define OP_API_INC_BERNOULLI_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBernoulliworkspace
 * @domain aclnn_rand
 *
 * 
 * 
 * $$ out_iBernoulli(self_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]  --> B([l0::Contiguous]) -->D([l0op::StatelessBernoulli]) --> I([l0op::ViewCopy]) --> J[(Out)]
 * K((p)) --> K0([ConvertToTensor]) --> D
 * E((seed)) --> D
 * F((offset)) --> D
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorTensorND
 * @param [in] prob: hostaclScalar$ 0p1 $
 * @param [in] seed: hostaclScalar
 * @param [in] offset: hostaclScalar
 * @param [in] out: npu
 * deviceaclTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBernoulliGetWorkspaceSize(const aclTensor* self, const aclScalar* prob, int64_t seed,
                                                     int64_t offset, aclTensor* out, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnBernoulli
 *
 * 
 * 
 * $$ out_iBernoulli(input_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]  --> B([l0::Contiguous]) -->D([l0op::StatelessBernoulli]) --> I([l0op::ViewCopy]) --> J[(Out)]
 * K((p)) --> K0([ConvertToTensor]) --> D
 * E((seed)) --> D
 * F((offset)) --> D
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBernoulli(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

/**
 * @brief aclnnBernoulliTensorworkspace
 * @domain aclnn_rand
 *
 * 
 * 
 * $$ out_iBernoulli(self_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]  --> B([l0::Contiguous]) -->D([l0op::StatelessBernoulli]) --> I([l0op::ViewCopy]) --> J[(Out)]
 * K((p)) --> K0([ConvertToTensor]) --> D
 * E((seed)) --> D
 * F((offset)) --> D
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorTensorND
 * @param [in] prob: npu
 * deviceaclTensorTensorND
 * @param [in] seed: hostaclScalar
 * @param [in] offset: hostaclScalar
 * @param [in] out: npu
 * deviceaclTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBernoulliTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* prob, int64_t seed,
                                                           int64_t offset, aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnBernoulliTensor
 *
 * 
 * 
 * $$ out_iBernoulli(input_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]  --> B([l0::Contiguous]) -->D([l0op::StatelessBernoulli]) --> I([l0op::ViewCopy]) --> J[(Out)]
 * K((p)) --> K0([ConvertToTensor]) --> D
 * E((seed)) --> D
 * F((offset)) --> D
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBernoulliTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

/**
 * @brief aclnnInplaceBernoulliworkspace
 * @domain aclnn_rand
 *
 * 
 * 
 * $$ out_iBernoulli(selfRef_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]  --> B([l0::Contiguous]) -->D([l0op::StatelessBernoulli]) --> I([l0op::ViewCopy]) --> J[(Self)]
 * K((p)) --> K0([ConvertToTensor]) --> D
 * E((seed)) --> D
 * F((offset)) --> D
 * ```
 *
 * @param [in] selfRef: npu
 * deviceaclTensorTensorND
 * @param [in] prob: hostaclScalar$ 0p1 $
 * @param [in] seed: hostaclScalar
 * @param [in] offset: hostaclScalar
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBernoulliGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* prob, int64_t seed,
                                                            int64_t offset, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBernoulli
 *
 * 
 * 
 * $$ out_iBernoulli(input_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]  --> B([l0::Contiguous]) -->D([l0op::StatelessBernoulli]) --> I([l0op::ViewCopy]) --> J[(Self)]
 * K((p)) --> K0([ConvertToTensor]) --> D
 * E((seed)) --> D
 * F((offset)) --> D
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBernoulli(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

/**
 * @brief aclnnInplaceBernoulliTensorworkspace
 * @domain aclnn_rand
 *
 * 
 * 
 * $$ out_iBernoulli(selfRef_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]  --> B([l0::Contiguous]) -->D([l0op::StatelessBernoulli]) --> I([l0op::ViewCopy]) --> J[(Self)]
 * K((p)) --> K0([ConvertToTensor]) --> D
 * E((seed)) --> D
 * F((offset)) --> D
 * ```
 *
 * @param [in] selfRef: npu
 * deviceaclTensorTensorND
 * @param [in] prob: npu
 * deviceaclTensorTensorND
 * @param [in] seed: hostaclScalar
 * @param [in] offset: hostaclScalar
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBernoulliTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* prob,
                                                                  int64_t seed, int64_t offset, uint64_t* workspaceSize,
                                                                  aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBernoulliTensor
 *
 * 
 * 
 * $$ out_iBernoulli(input_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]  --> B([l0::Contiguous]) -->D([l0op::StatelessBernoulli]) --> I([l0op::ViewCopy]) --> J[(Self)]
 * K((p)) --> K0([ConvertToTensor]) --> D
 * E((seed)) --> D
 * F((offset)) --> D
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBernoulliTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BERNOULLI_H_
// End content from: aclnn_bernoulli.h

// Begin content from: aclnn_multinomial.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_MULTINOMIAL_H_
#define OP_API_INC_LEVEL2_ACLNN_MULTINOMIAL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMultinomialworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnMultinomialGetWorkspaceSize(const aclTensor* self, int64_t numsamples, bool replacement,
                                                       int64_t seed, int64_t offset, aclTensor* out,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMultinomial
 */
ACLNN_API aclnnStatus aclnnMultinomial(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_MULTINOMIAL_H_
// End content from: aclnn_multinomial.h

// Begin content from: aclnn_dropout_do_mask.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_DROPOUT_DO_MASK_H_
#define OP_API_INC_DROPOUT_DO_MASK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnDropoutDoMaskworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnDropoutDoMaskGetWorkspaceSize(const aclTensor* self, const aclTensor* mask, double prob,
                                                         aclTensor* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnDropoutDoMask(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_DROPOUT_DO_MASK_H_
// End content from: aclnn_dropout_do_mask.h

// Begin content from: aclnn_random.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_RANDOM_H_
#define OP_API_INC_LEVEL2_ACLNN_RANDOM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceRandomworkspace
 * @domain aclnn_rand
 * @param [in] self: npu deviceaclTensorFLOATINT32INT64BFLOAT16FLOAT16
 * INT16INT8UINT8BOOLDOUBLENDTensor
 * @param [in] from: hostDOUBLE
 * @param [in] to: hostDOUBLE
 * @param [in] seed: ,UINT64_T
 * @param [in] offset: ,
 * UINT64_T
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRandomGetWorkspaceSize(const aclTensor* selfRef, int64_t from, int64_t to,
                                                         int64_t seed, int64_t offset, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnInplaceRandom
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceRandom
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnInplaceRandom(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_RANDOM_H_
// End content from: aclnn_random.h

// Begin content from: aclnn_uniform.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNIFORM_H_
#define OP_API_INC_UNIFORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceUniformworkspace
 * @domain aclnn_rand
 *
 * [from, to)self
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *  A[(selfRef)] -.->B([l0op::Contiguous])
 *  B --> D([l0op::StatelessRandomUniformV2])
 *  E[(seed)] -->D
 *  X[(offset)] -->D
 *  P[(alg)] -->D
 *  D --> F([l0op::Muls])
 *  G[(to)] --> F
 *  D --> H([l0op::Muls])
 *  I[(from)] --> H
 *  H --> J([l0op::Sub])
 *  K[(from)] --> J
 *  F --> L([l0op::Sub])
 *  J --> L
 *  L --> Q([l0op::Cast])
 *  Q -.-> N([l0op::ViewCopy])
 *  N --> O[(Out)]
 * ```
 *
 * @param [in] selfRef: npu deviceaclTensor
 * FLOATINT32INT64FLOAT16INT16INT8UINT8BOOLDOUBLENDTensor
 * @param [in] from: hostDOUBLE
 * @param [in] to: hostDOUBLE
 * @param [in] seed: ,UINT64_T
 * @param [in] offset:
 * ,UINT64_T
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceUniformGetWorkspaceSize(const aclTensor* selfRef, double from, double to,
                                                          uint64_t seed, uint64_t offset, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

/**
 * @brief aclnnInplaceUniform
 *
 * [from, to)self
 * 
 * api
 * ```mermaid
 * graph LR
 *  A[(selfRef)] -.->B([l0op::Contiguous])
 *  B --> D([l0op::StatelessRandomUniformV2])
 *  E[(seed)] -->D
 *  X[(offset)] -->D
 *  P[(alg)] -->D
 *  D --> F([l0op::Muls])
 *  G[(to)] --> F
 *  D --> H([l0op::Muls])
 *  I[(from)] --> H
 *  H --> J([l0op::Sub])
 *  K[(from)] --> J
 *  F --> L([l0op::Sub])
 *  J --> L
 *  L --> Q([l0op::Cast])
 *  Q -.-> N([l0op::ViewCopy])
 *  N --> O[(Out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnUniformGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceUniform(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                          const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNIFORM_H_
// End content from: aclnn_uniform.h

// Begin content from: aclnn_dropout_gen_mask.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_DROPOUT_GEN_MASK_H_
#define OP_API_INC_DROPOUT_GEN_MASK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnDropoutGenMaskworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnDropoutGenMaskGetWorkspaceSize(const aclIntArray* shape, double prob, int64_t seed,
                                                          int64_t offset, aclTensor* out, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnDropoutGenMask(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

/**
 * @brief aclnnDropoutGenMaskV2workspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnDropoutGenMaskV2GetWorkspaceSize(const aclIntArray* shape, double prob, int64_t seed,
                                                            int64_t offset, aclDataType probDataType, aclTensor* out,
                                                            uint64_t* workspaceSize, aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnDropoutGenMaskV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_DROPOUT_GEN_MASK_H_
// End content from: aclnn_dropout_gen_mask.h

// Begin content from: aclnn_randperm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_RANDPERM_H_
#define OP_API_INC_LEVEL2_ACLNN_RANDPERM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRandpermworkspace
 * @domain aclnn_rand
 */
ACLNN_API aclnnStatus aclnnRandpermGetWorkspaceSize(int64_t n, int64_t seed, int64_t offset, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnRandperm
 */
ACLNN_API aclnnStatus aclnnRandperm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_RANDPERM_H_
// End content from: aclnn_randperm.h

// Begin content from: aclnn_normal.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_NORMAL_H_
#define OP_API_INC_NORMAL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnInplaceNormalworkspace
 * @domain aclnn_rand
 * @param [in] self: npu
 * deviceaclTensorothershapeotherbroadcast
 * TensorNDNCHWNHWCHWCNNDHWCNCDHWother
 * @param [in] other: npu
 * deviceaclTensorselfshapeselfbroadcast
 * TensorNDNCHWNHWCHWCNNDHWCNCDHWself
 * @param [in] alpha: hostaclScalarselfother
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNormalGetWorkspaceSize(const aclTensor* selfRef, float mean, float std, int64_t seed,
                                                         int64_t offset, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnInplaceNormal
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNormal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_NORMAL_H_
// End content from: aclnn_normal.h

// Begin content from: acl/ops/acl_cblas.h
/**
* @file acl_cblas.h
*
* Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
*/
#ifndef INC_EXTERNAL_ACL_OPS_ACL_CBLAS_H_
#define INC_EXTERNAL_ACL_OPS_ACL_CBLAS_H_

// #include "acl/acl.h"

#ifdef __cplusplus
extern "C" {
#endif

typedef enum aclTransType {
    ACL_TRANS_N,
    ACL_TRANS_T,
    ACL_TRANS_NZ,
    ACL_TRANS_NZ_T
} aclTransType;

typedef enum aclComputeType {
    ACL_COMPUTE_HIGH_PRECISION,
    ACL_COMPUTE_LOW_PRECISION
} aclComputeType;

/**
 * @ingroup AscendCL
 * @brief perform the matrix-vector multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param m [IN]           number of rows of matrix A
 * @param n [IN]           number of columns of matrix A
 * @param alpha [IN]       pointer to scalar used for multiplication.
 *                         of same type as dataTypeC
 * @param a [IN]           pointer to matrix A
 * @param lda [IN]         leading dimension used to store the matrix A
 * @param dataTypeA [IN]   datatype of matrix A
 * @param x [IN]           pointer to vector x
 * @param incx [IN]        stride between consecutive elements of vector x
 * @param dataTypeX [IN]   datatype of vector x
 * @param beta [IN]        pointer to scalar used for multiplication.
 *                         of same type as dataTypeC If beta == 0,
 *                         then y does not have to be a valid input
 * @param y [IN|OUT]       pointer to vector y
 * @param incy [IN]        stride between consecutive elements of vector y
 * @param dataTypeY [IN]   datatype of vector y
 * @param type [IN]        computation type
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclblasGemvEx(aclTransType transA, int m, int n,
    const void *alpha, const void *a, int lda, aclDataType dataTypeA,
    const void *x, int incx, aclDataType dataTypeX,
    const void *beta, void *y, int incy, aclDataType dataTypeY,
    aclComputeType type, aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief create a handle for performing the matrix-vector multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param m [IN]           number of rows of matrix A
 * @param n [IN]           number of columns of matrix A
 * @param dataTypeA [IN]   datatype of matrix A
 * @param dataTypeX [IN]   datatype of vector x
 * @param dataTypeY [IN]   datatype of vector y
 * @param type [IN]        computation type
 * @param handle [OUT]     pointer to the pointer to the handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
*/
ACL_FUNC_VISIBILITY aclError aclblasCreateHandleForGemvEx(aclTransType transA,
                                                          int m,
                                                          int n,
                                                          aclDataType dataTypeA,
                                                          aclDataType dataTypeX,
                                                          aclDataType dataTypeY,
                                                          aclComputeType type,
                                                          aclopHandle **handle);

/**
 * @ingroup AscendCL
 * @brief perform the matrix-vector multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param m [IN]           number of rows of matrix A
 * @param n [IN]           number of columns of matrix A
 * @param alpha [IN]       pointer to scalar used for multiplication
 * @param a [IN]           pointer to matrix A
 * @param lda [IN]         leading dimension used to store the matrix A
 * @param x [IN]           pointer to vector x
 * @param incx [IN]        stride between consecutive elements of vector x
 * @param beta [IN]        pointer to scalar used for multiplication.
 *                         If beta value == 0,
 *                         then y does not have to be a valid input
 * @param y [IN|OUT]       pointer to vector y
 * @param incy [IN]        stride between consecutive elements of vector y
 * @param type [IN]        computation type
 * @param stream [IN]      stream
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasHgemv(aclTransType transA,
                                          int m,
                                          int n,
                                          const aclFloat16 *alpha,
                                          const aclFloat16 *a,
                                          int lda,
                                          const aclFloat16 *x,
                                          int incx,
                                          const aclFloat16 *beta,
                                          aclFloat16 *y,
                                          int incy,
                                          aclComputeType type,
                                          aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief create a handle for performing the matrix-vector multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param m [IN]           number of rows of matrix A
 * @param n [IN]           number of columns of matrix A
 * @param type [IN]        computation type
 * @param handle [OUT]     pointer to the pointer to the handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasCreateHandleForHgemv(aclTransType transA,
                                                         int m,
                                                         int n,
                                                         aclComputeType type,
                                                         aclopHandle **handle);

/**
 * @ingroup AscendCL
 * @brief perform the matrix-vector multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param m [IN]           number of rows of matrix A
 * @param n [IN]           number of columns of matrix A
 * @param alpha [IN]       pointer to scalar used for multiplication
 * @param a [IN]           pointer to matrix A
 * @param lda [IN]         leading dimension used to store the matrix A
 * @param x [IN]           pointer to vector x
 * @param incx [IN]        stride between consecutive elements of vector x
 * @param beta [IN]        pointer to scalar used for multiplication.
 *                         If beta value == 0,
 *                         then y does not have to be a valid input
 * @param y [IN|OUT]       pointer to vector y
 * @param incy [IN]        stride between consecutive elements of vector y
 * @param type [IN]        computation type
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasS8gemv(aclTransType transA,
                                           int m,
                                           int n,
                                           const int32_t *alpha,
                                           const int8_t *a,
                                           int lda,
                                           const int8_t *x,
                                           int incx,
                                           const int32_t *beta,
                                           int32_t *y,
                                           int incy,
                                           aclComputeType type,
                                           aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief create a handle for performing the matrix-vector multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param m [IN]           number of rows of matrix A
 * @param n [IN]           number of columns of matrix A
 * @param handle [OUT]     pointer to the pointer to the handle
 * @param type [IN]        computation type
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasCreateHandleForS8gemv(aclTransType transA,
                                                          int m,
                                                          int n,
                                                          aclComputeType type,
                                                          aclopHandle **handle);

/**
 * @ingroup AscendCL
 * @brief perform the matrix-matrix multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param transB [IN]      transpose type of matrix B
 * @param transC [IN]      transpose type of matrix C
 * @param m [IN]           number of rows of matrix A and matrix C
 * @param n [IN]           number of columns of matrix B and matrix C
 * @param k [IN]           number of columns of matrix A and rows of matrix B
 * @param alpha [IN]       pointer to scalar used for multiplication. of same type as dataTypeC
 * @param matrixA [IN]     pointer to matrix A
 * @param lda [IN]         leading dimension array used to store  matrix A
 * @param dataTypeA [IN]   datatype of matrix A
 * @param matrixB [IN]     pointer to matrix B
 * @param ldb [IN]         leading dimension array used to store  matrix B
 * @param dataTypeB [IN]   datatype of matrix B
 * @param beta [IN]        pointer to scalar used for multiplication.
 *                         of same type as dataTypeC If beta == 0,
 *                         then matrixC does not have to be a valid input
 * @param matrixC [IN|OUT] pointer to matrix C
 * @param ldc [IN]         leading dimension array used to store  matrix C
 * @param dataTypeC [IN]   datatype of matrix C
 * @param type [IN]        computation type
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasGemmEx(aclTransType transA,
                                           aclTransType transB,
                                           aclTransType transC,
                                           int m,
                                           int n,
                                           int k,
                                           const void *alpha,
                                           const void *matrixA,
                                           int lda,
                                           aclDataType dataTypeA,
                                           const void *matrixB,
                                           int ldb,
                                           aclDataType dataTypeB,
                                           const void *beta,
                                           void *matrixC,
                                           int ldc,
                                           aclDataType dataTypeC,
                                           aclComputeType type,
                                           aclrtStream stream);


/**
 * @ingroup AscendCL
 * @brief create a handle for performing the matrix-matrix multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param transB [IN]      transpose type of matrix B
 * @param transC [IN]      transpose type of matrix C
 * @param m [IN]           number of rows of matrix A and matrix C
 * @param n [IN]           number of columns of matrix B and matrix C
 * @param k [IN]           number of columns of matrix A and rows of matrix B
 * @param dataTypeA [IN]   datatype of matrix A
 * @param dataTypeB [IN]   datatype of matrix B
 * @param dataTypeC [IN]   datatype of matrix C
 * @param type [IN]        computation type
 * @param handle [OUT]     pointer to the pointer to the handle
 * @param type [IN]        computation type
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasCreateHandleForGemmEx(aclTransType transA,
                                                          aclTransType transB,
                                                          aclTransType transC,
                                                          int m,
                                                          int n,
                                                          int k,
                                                          aclDataType dataTypeA,
                                                          aclDataType dataTypeB,
                                                          aclDataType dataTypeC,
                                                          aclComputeType type,
                                                          aclopHandle **handle);


/**
 * @ingroup AscendCL
 * @brief perform the matrix-matrix multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param transB [IN]      transpose type of matrix B
 * @param transC [IN]      transpose type of matrix C
 * @param m [IN]           number of rows of matrix A and matrix C
 * @param n [IN]           number of columns of matrix B and matrix C
 * @param k [IN]           number of columns of matrix A and rows of matrix B
 * @param alpha [IN]       pointer to scalar used for multiplication
 * @param matrixA [IN]     pointer to matrix A
 * @param lda [IN]         leading dimension used to store the matrix A
 * @param matrixB [IN]     pointer to matrix B
 * @param ldb [IN]         leading dimension used to store the matrix B
 * @param beta [IN]        pointer to scalar used for multiplication.
 *                         If beta value == 0,
 *                         then matrixC does not have to be a valid input
 * @param matrixC [IN|OUT] pointer to matrix C
 * @param ldc [IN]         leading dimension used to store the matrix C
 * @param type [IN]        computation type
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasHgemm(aclTransType transA,
                                          aclTransType transB,
                                          aclTransType transC,
                                          int m,
                                          int n,
                                          int k,
                                          const aclFloat16 *alpha,
                                          const aclFloat16 *matrixA,
                                          int lda,
                                          const aclFloat16 *matrixB,
                                          int ldb,
                                          const aclFloat16 *beta,
                                          aclFloat16 *matrixC,
                                          int ldc,
                                          aclComputeType type,
                                          aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief create a handle for performing the matrix-matrix multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param transB [IN]      transpose type of matrix B
 * @param transC [IN]      transpose type of matrix C
 * @param m [IN]           number of rows of matrix A and matrix C
 * @param n [IN]           number of columns of matrix B and matrix C
 * @param k [IN]           number of columns of matrix A and rows of matrix B
 * @param type [IN]        computation type
 * @param handle [OUT]     pointer to the pointer to the handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasCreateHandleForHgemm(aclTransType transA,
                                                         aclTransType transB,
                                                         aclTransType transC,
                                                         int m,
                                                         int n,
                                                         int k,
                                                         aclComputeType type,
                                                         aclopHandle **handle);

/**
 * @ingroup AscendCL
 * @brief perform the matrix-matrix multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param transB [IN]      transpose type of matrix B
 * @param transC [IN]      transpose type of matrix C
 * @param m [IN]           number of rows of matrix A and matrix C
 * @param n [IN]           number of columns of matrix B and matrix C
 * @param k [IN]           number of columns of matrix A and rows of matrix B
 * @param alpha [IN]       pointer to scalar used for multiplication
 * @param matrixA [IN]     pointer to matrix A
 * @param lda [IN]         leading dimension used to store the matrix A
 * @param matrixB [IN]     pointer to matrix B
 * @param ldb [IN]         leading dimension used to store the matrix B
 * @param beta [IN]        pointer to scalar used for multiplication.
 *                         If beta value == 0,
 *                         then matrixC does not have to be a valid input
 * @param matrixC [IN|OUT] pointer to matrix C
 * @param ldc [IN]         leading dimension used to store the matrix C
 * @param type [IN]        computation type
 * @param stream [IN]      stream
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasS8gemm(aclTransType transA,
                                           aclTransType transB,
                                           aclTransType transC,
                                           int m,
                                           int n,
                                           int k,
                                           const int32_t *alpha,
                                           const int8_t *matrixA,
                                           int lda,
                                           const int8_t *matrixB,
                                           int ldb,
                                           const int32_t *beta,
                                           int32_t *matrixC,
                                           int ldc,
                                           aclComputeType type,
                                           aclrtStream stream);


/**
 * @ingroup AscendCL
 * @brief create a handle for performing the matrix-matrix multiplication
 *
 * @param transA [IN]      transpose type of matrix A
 * @param transB [IN]      transpose type of matrix B
 * @param transC [IN]      transpose type of matrix C
 * @param m [IN]           number of rows of matrix A and matrix C
 * @param n [IN]           number of columns of matrix B and matrix C
 * @param k [IN]           number of columns of matrix A and rows of matrix B
 * @param type [IN]        computation type
 * @param handle [OUT]     pointer to the pointer to the handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclblasCreateHandleForS8gemm(aclTransType transA,
                                                          aclTransType transB,
                                                          aclTransType transC,
                                                          int m,
                                                          int n,
                                                          int k,
                                                          aclComputeType type,
                                                          aclopHandle **handle);

#ifdef __cplusplus
}
#endif

#endif // INC_EXTERNAL_ACL_OPS_ACL_CBLAS_H_
// End content from: acl/ops/acl_cblas.h

// Begin content from: acl/acl_op_compiler.h
/**
* @file acl_op_compiler.h
*
* Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
*/
#ifndef INC_EXTERNAL_ACL_ACL_OP_COMPILER_H_
#define INC_EXTERNAL_ACL_ACL_OP_COMPILER_H_

// #include "acl_base.h"
// #include "acl_op.h"

#ifdef __cplusplus
extern "C" {
#endif

typedef enum aclCompileType {
    ACL_COMPILE_SYS,
    ACL_COMPILE_UNREGISTERED
} aclopCompileType;

typedef enum {
    ACL_PRECISION_MODE,
    ACL_AICORE_NUM,
    ACL_AUTO_TUNE_MODE, // The auto_tune_mode has been discarded
    ACL_OP_SELECT_IMPL_MODE,
    ACL_OPTYPELIST_FOR_IMPLMODE,
    ACL_OP_DEBUG_LEVEL,
    ACL_DEBUG_DIR,
    ACL_OP_COMPILER_CACHE_MODE,
    ACL_OP_COMPILER_CACHE_DIR,
    ACL_OP_PERFORMANCE_MODE,
    ACL_OP_JIT_COMPILE,
    ACL_OP_DETERMINISTIC,
    ACL_CUSTOMIZE_DTYPES,
    ACL_OP_PRECISION_MODE,
    ACL_ALLOW_HF32,
    ACL_PRECISION_MODE_V2,
    ACL_OP_DEBUG_OPTION
} aclCompileOpt;

typedef enum aclCompileFlag {
    ACL_OP_COMPILE_DEFAULT,
    ACL_OP_COMPILE_FUZZ
} aclOpCompileFlag;

typedef struct aclGraphDumpOption aclGraphDumpOption;

/**
 * @ingroup AscendCL
 * @brief compile op
 *
 * @param opType [IN]           op type
 * @param numInputs [IN]        number of inputs
 * @param inputDesc [IN]        pointer to array of input tensor descriptions
 * @param numOutputs [IN]       number of outputs
 * @param outputDesc [IN]       pointer to array of output tensor descriptions
 * @param attr [IN]           pointer to instance of aclopAttr.
 *                              may pass nullptr if the op has no attribute
 * @param engineType [IN]       engine type
 * @param compileFlag [IN]      compile flag
 * @param opPath [IN]           path of op
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopCompile(const char *opType,
                                          int numInputs,
                                          const aclTensorDesc *const inputDesc[],
                                          int numOutputs,
                                          const aclTensorDesc *const outputDesc[],
                                          const aclopAttr *attr,
                                          aclopEngineType engineType,
                                          aclopCompileType compileFlag,
                                          const char *opPath);

/**
 * @ingroup AscendCL
 * @brief compile and execute op
 *
 * @param opType [IN]           op type
 * @param numInputs [IN]        number of inputs
 * @param inputDesc [IN]        pointer to array of input tensor descriptions
 * @param inputs [IN]           pointer to array of input buffers
 * @param numOutputs [IN]       number of outputs
 * @param outputDesc [IN]       pointer to array of output tensor descriptions
 * @param outputs [IN]          pointer to array of outputs buffers
 * @param attr [IN]             pointer to instance of aclopAttr.
 *                              may pass nullptr if the op has no attribute
 * @param engineType [IN]       engine type
 * @param compileFlag [IN]      compile flag
 * @param opPath [IN]           path of op
 * @param stream [IN]           stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopCompileAndExecute(const char *opType,
    int numInputs, const aclTensorDesc *const inputDesc[], const aclDataBuffer *const inputs[],
    int numOutputs, const aclTensorDesc *const outputDesc[], aclDataBuffer *const outputs[],
    const aclopAttr *attr, aclopEngineType engineType, aclopCompileType compileFlag,
    const char *opPath, aclrtStream stream);


/**
 * @ingroup AscendCL
 * @brief compile and execute op
 *
 * @param opType [IN]           op type
 * @param numInputs [IN]        number of inputs
 * @param inputDesc [IN]        pointer to array of input tensor descriptions
 * @param inputs [IN]           pointer to array of input buffers
 * @param numOutputs [IN]       number of outputs
 * @param outputDesc [IN|OUT]   pointer to array of output tensor descriptions
 * @param outputs [IN]          pointer to array of outputs buffers
 * @param attr [IN]             pointer to instance of aclopAttr.
 *                              may pass nullptr if the op has no attribute
 * @param engineType [IN]       engine type
 * @param compileFlag [IN]      compile flag
 * @param opPath [IN]           path of op
 * @param stream [IN]           stream handle
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopCompileAndExecuteV2(const char *opType,
    int numInputs, aclTensorDesc *inputDesc[], aclDataBuffer *inputs[],
    int numOutputs, aclTensorDesc *outputDesc[], aclDataBuffer *outputs[],
    aclopAttr *attr, aclopEngineType engineType, aclopCompileType compileFlag,
    const char *opPath, aclrtStream stream);

/**
 * @ingroup AscendCL
 * @brief set compile option
 *
 * @param aclCompileOpt [IN]      compile option
 * @param value [IN]              pointer for the option value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclSetCompileopt(aclCompileOpt opt, const char *value);

/**
 * @ingroup AscendCL
 * @brief get compile option value size
 *
 * @param aclCompileOpt [IN]      compile option
 *
 * @retval size of compile option value
 */
ACL_FUNC_VISIBILITY size_t aclGetCompileoptSize(aclCompileOpt opt);

/**
 * @ingroup AscendCL
 * @brief get compile option
 *
 * @param aclCompileOpt [IN]      compile option
 * @param value [OUT]             pointer for the option value
 * @param length [IN]             length of value
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclGetCompileopt(aclCompileOpt opt, char *value, size_t length);

/**
 * @ingroup AscendCL
 * @brief set compile flag
 *
 * @param flag [IN]    compile flag, ACL_OP_COMPILE_DEFAULT means compile with default mode
 *                     ACL_OP_COMPILE_FUZZ means compile with fuzz mode
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclopSetCompileFlag(aclOpCompileFlag flag);

/**
 * @ingroup AscendCL
 * @brief generate graph and dump
 *
 * @param opType [IN]           op type
 * @param numInputs [IN]        number of inputs
 * @param inputDesc [IN]        pointer to array of input tensor descriptions
 * @param inputs [IN]           pointer to array of input buffers
 * @param numOutputs [IN]       number of outputs
 * @param outputDesc [IN]       pointer to array of output tensor descriptions
 * @param outputs [IN]          pointer to array of outputs buffers
 * @param attr [IN]             pointer to instance of aclopAttr.
 *                              may pass nullptr if the op has no attribute
 * @param engineType [IN]       engine type
 * @param graphDumpPath [IN]    dump path, if the suffix is ".txt", it means file path, else it means directory path
 * @param graphDumpOpt [IN]     dump option, nullptr is supported
 *
 * @retval ACL_SUCCESS The function is successfully executed.
 * @retval OtherValues Failure
 */
ACL_FUNC_VISIBILITY aclError aclGenGraphAndDumpForOp(const char *opType,
    int numInputs, const aclTensorDesc *const inputDesc[], const aclDataBuffer *const inputs[],
    int numOutputs, const aclTensorDesc *const outputDesc[], aclDataBuffer *const outputs[],
    const aclopAttr *attr, aclopEngineType engineType,
    const char *graphDumpPath, const aclGraphDumpOption *graphDumpOpt);

/**
 * @ingroup AscendCL
 * @brief Create the graph dump option
 *
 * @retval null for failed
 * @retval OtherValues success
 *
 * @see aclDestroyGraphDumpOpt
 */
ACL_FUNC_VISIBILITY aclGraphDumpOption *aclCreateGraphDumpOpt();

/**
 * @ingroup AscendCL
 * @brief Destroy graph dump option
 *
 * @param graphDumpOpt [IN]  pointer to the graph dump option
 *
 * @retval ACL_SUCCESS  The function is successfully executed.
 * @retval OtherValues Failure
 *
 * @see aclCreateGraphDumpOpt
 */
ACL_FUNC_VISIBILITY aclError aclDestroyGraphDumpOpt(const aclGraphDumpOption *graphDumpOpt);

#ifdef __cplusplus
}
#endif

#endif // INC_EXTERNAL_ACL_ACL_OP_COMPILER_H_
// End content from: acl/acl_op_compiler.h

// Begin content from: aclnn_incre_flash_attention_v2.h
/**
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef ACLNN_INCRE_FLASH_ATTENTION_V2_H_
#define ACLNN_INCRE_FLASH_ATTENTION_V2_H_

// #include "aclnn/aclnn_base.h"
#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIncreFlashAttentionV2workspace
 * @domain aclnn_ops_infer
 * funtion: aclnnIncreFlashAttentionV2GetWorkspaceSize
 * @param [in] query : required
 * @param [in] key : dynamic
 * @param [in] value : dynamic
 * @param [in] pseShift : optional
 * @param [in] attenMask : optional
 * @param [in] actualSeqLengths : optional
 * @param [in] dequantScale1 : optional
 * @param [in] quantScale1 : optional
 * @param [in] dequantScale2 : optional
 * @param [in] quantScale2 : optional
 * @param [in] quantOffset2 : optional
 * @param [in] numHeads : required
 * @param [in] scaleValue : optional
 * @param [in] inputLayout : optional
 * @param [in] numKeyValueHeads : optional
 * @param [out] attentionOut : required
 * @param [out] workspaceSize : size of workspace(output).
 * @param [out] executor : executor context(output).
 * @return aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnIncreFlashAttentionV2GetWorkspaceSize(
    const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShift,
    const aclTensor *attenMask, const aclIntArray *actualSeqLengths, const aclTensor *dequantScale1,
    const aclTensor *quantScale1, const aclTensor *dequantScale2, const aclTensor *quantScale2,
    const aclTensor *quantOffset2, int64_t numHeads, double scaleValue, char *inputLayout, int64_t numKeyValueHeads,
    const aclTensor *attentionOut, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnIncreFlashAttentionV2
 * funtion: aclnnIncreFlashAttentionV2
 * @param [in] workspace : workspace memory addr(input).
 * @param [in] workspaceSize : size of workspace(input).
 * @param [in] executor : executor context(input).
 * @param [in] stream : acl stream.
 * @return aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnIncreFlashAttentionV2(void *workspace, uint64_t workspaceSize,
                                                                              aclOpExecutor *executor,
                                                                              const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_incre_flash_attention_v2.h

// Begin content from: aclnn_batch_norm_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BATCH_NORM_BACKWARD_H_
#define OP_API_INC_BATCH_NORM_BACKWARD_H_

#include <array>
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchNormBackwardBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnBatchNormBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* input,
                                                             const aclTensor* weight, const aclTensor* runningMean,
                                                             const aclTensor* runningVar, const aclTensor* saveMean,
                                                             const aclTensor* saveInvstd, bool training, double eps,
                                                             const aclBoolArray* outputMask, aclTensor* gradInput,
                                                             aclTensor* gradWeight, aclTensor* gradBias,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnBatchNormBackward
 */
ACLNN_API aclnnStatus aclnnBatchNormBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BATCH_NORM_BACKWARD_H_
// End content from: aclnn_batch_norm_backward.h

// Begin content from: aclnn_foreach_pow_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_POW_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_POW_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachPowScalarV2workspace
 * scalar
 * 
 * out_{i}=x_{i}^scalar
 * @domain aclnnop_math
 * 
 * @param [in]   x
 * TensorFLOATFLOAT16BFLOAT16ND
 * @param [in]   scalar
 * ScalarFLOATFLOAT16ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachPowScalarV2GetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachPowScalarV2
 * scalar
 * 
 * out_{i}=x_{i}^scalar
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachPowScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachPowScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_pow_scalar_v2.h

// Begin content from: aclnn_aminmax.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_AMINMAX_H_
#define OP_API_INC_AMINMAX_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAminmaxworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] self: npu deviceaclTensorTensorND
 * @param [in] dim: hostaclIntArray
 * @param [in] keepDim: hostboolreduce
 * @param [in] minOut: npu deviceaclTensorTensorND
 * @param [in] maxOut: npu deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAminmaxGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim,
                                                   aclTensor* minOut, aclTensor* maxOut, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnAminmax
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAminmaxGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAminmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AMINMAX_H_
// End content from: aclnn_aminmax.h

// Begin content from: aclnn_dynamic_quant.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef ACLNN_DYNAMIC_QUANT_H_
#define ACLNN_DYNAMIC_QUANT_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnDynamicQuantGetWorkspaceSizeworkspace
 * @domain aclnn_ops_infer
 */
__attribute__((visibility("default"))) aclnnStatus aclnnDynamicQuantGetWorkspaceSize(
    const aclTensor* x, const aclTensor* smoothScalesOptional, const aclTensor* yOut, const aclTensor* scaleOut,
    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnDynamicQuant
 */
__attribute__((visibility("default"))) aclnnStatus aclnnDynamicQuant(void* workspace, uint64_t workspaceSize,
                                                                       aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // ACLNN_DYNAMIC_QUANT_H_// End content from: aclnn_dynamic_quant.h

// Begin content from: aclnn_max_pool3d_with_argmax.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_MAX_POOL3D_WITH_ARGMAX_H_
#define OP_API_INC_LEVEL2_ACLNN_MAX_POOL3D_WITH_ARGMAX_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxPool3dWithArgmax First segment interface. Calculate the workspace size based on the specific calculation process.
 * Function description: Calculates the aclnnMaxPool3dWithArgmax from the input tensor, at the output contains 2 tensors: out and indices
 * @domain aclnn_ops_infer
 * @param [in] self: aclTensor on the NPU device. the data type can be float32/float16/bfloat16. The data format supports ND.
 * @param [in] kernelSize: aclIntArray type, indicating the maxpooling window size.
 * @param [in] stride: aclIntArray type, the step size of the window movement.
 * @param [in] padding: aclIntArray type, number of padding layers for each edge. The value is negative infinity.
 * @param [in] dilation: aclIntArray type, controls the stride of elements in the window.
 * @param [in] ceilMode: bool type, when true, the output shape is calculated using round-up method. By default is rounding down.
 * @param [in] out: aclTensor on the NPU device. the data type can be float32/float16/bfloat16. The data format supports ND.
 * @param [in] indices: aclTensor on the NPU device. the data type can be int32. The data format supports ND.
 * @param [out] workspaceSize: Returns the workspace size that the user needs to apply for on the npu device side.
 * @param [out] executor: Return the op executor, including the operator calculation process.
 * @return aclnnStatus: Return the status code.
 */

ACLNN_API aclnnStatus aclnnMaxPool3dWithArgmaxGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize,
                                                               const aclIntArray* stride, const aclIntArray* padding,
                                                               const aclIntArray* dilation, bool ceilMode, aclTensor* out,
                                                               aclTensor* indices, uint64_t* workspaceSize,
                                                               aclOpExecutor** executor);
/**
 * @brief A second interface of aclnnMaxPool3dWithArgmax, used to perform calculation.
 * @param [in] workspace: start address of the workspace memory allocated on the NPU device.
 * @param [in] workspaceSize: size of the workspace applied on the NPU device, which is obtained by calling the first segment interface aclnnMaxPool3dWithArgmaxGetWorkspaceSize.
 * @param [in] exector: op executor, including the operator calculation process.
 * @param [in] stream: acl stream.
 * @return aclnnStatus: returned status code
 */

ACLNN_API aclnnStatus aclnnMaxPool3dWithArgmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_MAX_POOL3D_WITH_ARGMAX_H_// End content from: aclnn_max_pool3d_with_argmax.h

// Begin content from: aclnn_sign.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_SIGN_H_
#define OP_API_INC_LEVEL2_ACLNN_SIGN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSignworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnSignGetWorkspaceSize(const aclTensor* self, aclTensor* result, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnSign
 */
ACLNN_API aclnnStatus aclnnSign(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_sign.h

// Begin content from: aclnn_moe_init_routing_quant_v2.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_INIT_ROUTING_QUANT_V2_H_
#define ACLNN_MOE_INIT_ROUTING_QUANT_V2_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeInitRoutingQuantV2GetWorkspaceSize
 * parameters :
 * x : required
 * expertIdx : required
 * scaleOptional : optional
 * offsetOptional : optional
 * activeNum : optional
 * expertCapacity : optional
 * expertNum : optional
 * dropPadMode : optional
 * expertTokensCountOrCumsumFlag : optional
 * expertTokensBeforeCapacityFlag : optional
 * quantMode : optional
 * expandedXOut : required
 * expandedRowIdxOut : required
 * expertTokensCountOrCumsumOutOptional : optional
 * expertTokensBeforeCapacityOutOptional : optional
 * dynamicQuantScaleOutOptional : optional
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingQuantV2GetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *expertIdx,
    const aclTensor *scaleOptional,
    const aclTensor *offsetOptional,
    int64_t activeNum,
    int64_t expertCapacity,
    int64_t expertNum,
    int64_t dropPadMode,
    int64_t expertTokensCountOrCumsumFlag,
    bool expertTokensBeforeCapacityFlag,
    int64_t quantMode,
    const aclTensor *expandedXOut,
    const aclTensor *expandedRowIdxOut,
    const aclTensor *expertTokensCountOrCumsumOutOptional,
    const aclTensor *expertTokensBeforeCapacityOutOptional,
    const aclTensor *dynamicQuantScaleOutOptional,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeInitRoutingQuantV2
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingQuantV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_init_routing_quant_v2.h

// Begin content from: aclnn_logsigmoid_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOGSIGMOID_BACKWARD_H_
#define OP_API_INC_LOGSIGMOID_BACKWARD_H_

#include <array>
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogSigmoidBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnLogSigmoidBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                              const aclTensor* buffer, aclTensor* gradInput,
                                                              uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogSigmoidBackward
 */
ACLNN_API aclnnStatus aclnnLogSigmoidBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOGSIGMOID_BACKWARD_H_
// End content from: aclnn_logsigmoid_backward.h

// Begin content from: aclnn_matmul_reduce_scatter.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MATMUL_REDUCE_SCATTER_
#define OP_API_INC_MATMUL_REDUCE_SCATTER_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * mm + reduceScatter
 * @brief aclnnMatmulReduceScatterworkspace
 * @domain aclnn_ops_infer
 * @param [in] x1: matmulfloat16, bf16
 * @param [in] x2: matmulfloat16, bf16
 * @param [in] bias: float16, bf16
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl0/1
 * @param [out] output: +
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMatmulReduceScatterGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                               const aclTensor* bias, const char* group,
                                                               const char* reduceOp, int64_t commTurn,
                                                               int64_t streamMode, const aclTensor* output,
                                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMatmulReduceScatter
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAbsGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMatmulReduceScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MATMUL_REDUCE_SCATTER_// End content from: aclnn_matmul_reduce_scatter.h

// Begin content from: aclnn_moe_finalize_routing_v2.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_FINALIZE_ROUTING_V2_H_
#define ACLNN_MOE_FINALIZE_ROUTING_V2_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeFinalizeRoutingV2GetWorkspaceSize
 * parameters :
 * expandedX : required
 * expandedRowIdx : required
 * x1Optional : optional
 * x2Optional : optional
 * biasOptional : optional
 * scalesOptional : optional
 * expertIdxOptional : optional
 * dropPadMode : optional
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeFinalizeRoutingV2GetWorkspaceSize(
    const aclTensor *expandedX,
    const aclTensor *expandedRowIdx,
    const aclTensor *x1Optional,
    const aclTensor *x2Optional,
    const aclTensor *biasOptional,
    const aclTensor *scalesOptional,
    const aclTensor *expertIdxOptional,
    int64_t dropPadMode,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeFinalizeRoutingV2
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeFinalizeRoutingV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_finalize_routing_v2.h

// Begin content from: aclnn_trans_matmul_weight.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TRANS_MATMUL_WEIGHT_H_
#define OP_API_INC_TRANS_MATMUL_WEIGHT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief
 * aclnnCalculateMatmulWeightSizeV2aclnnMatMulaclnnMmaclnnWeightQuantBatchMatmulV2
 * aclnnWeightQuantBatchMatmulV3aclnnQuantMatmulV3weight tensor
 * @domain aclnn_ops_infer
 *
 * @param [in] tensorShape: MatmulweightShape
 * @param [in] dataType: WeightDatatype, INT8Float16
 * @param [out] weightTensorSize: MatMulWeight
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCalculateMatmulWeightSizeV2(const aclIntArray* tensorShape, aclDataType dataType,
                                                       uint64_t* weightTensorSize);

/**
 * @brief aclnnCalculateMatmulWeightSizeaclnnMatMulaclnnMmweight tensor
 *
 *
 * @param [in] tensorShape: MatmulweightShape
 * @param [in] weightTensorSize: MatMulWeight
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCalculateMatmulWeightSize(const aclIntArray* tensorShape, uint64_t* weightTensorSize);

/**
 * @brief aclnnTransMatmulWeightworkspace
 * @domain aclnn_ops_infer
 *
 * tensordtype
 *
 * @param [in] mmWeightRef: matmulweightTensorNDFloat16
 * tensormatmul weightTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTransMatmulWeightGetWorkspaceSize(aclTensor* mmWeightRef, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);
/**
 * @brief aclnnTransMatmulWeight
 *
 * tensordtype
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnTransMatmulWeightGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTransMatmulWeight(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TRANS_MATMUL_WEIGHT_H_
// End content from: aclnn_trans_matmul_weight.h

// Begin content from: aclnn_upsample_nearest_2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_NEAREST_2D_H_
#define OP_API_INC_UNAMPLE_NEAREST_2D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearest2Dworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> D([l0op::TransData])
 *  D --> I([l0op::ResizeNearestNeighborV2])
 *  C[(outputSize)] --> I
 *  I --> J([l0op::TransData])
 *  J -.-> P([l0op::ViewCopy])
 *  P --> G[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLEUIN8NCHWNHWCTensor
 * @param [in] outputSize: npu deviceaclIntArray
 * @param [in] out: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLEUIN8NCHWNHWCTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                             aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleNearest2D
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> D([l0op::TransData])
 *  D --> I([l0op::ResizeNearestNeighborV2])
 *  C[(outputSize)] --> I
 *  I --> J([l0op::TransData])
 *  J -.-> P([l0op::ViewCopy])
 *  P --> G[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnUpsampleNearest2dGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_2D_H_
// End content from: aclnn_upsample_nearest_2d.h

// Begin content from: aclnn_complex.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_COMPLEX_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_COMPLEX_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnComplexworkspace
 * @domain aclnn_math
 * @param [in] real: npu deviceaclTensor
 * FLOAT16,FLOAT
 * shapeimagbroadcastTensorND
 * @param [in] imag: npu deviceaclTensor
 * FLOAT16,FLOAT
 * shaperealbroadcastTensorNDreal
 * @param [in] out: npu deviceaclTensorND
 * @param [in] Tout: hostint
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnComplexGetWorkspaceSize(const aclTensor* real, const aclTensor* imag, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnComplex
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnComplexGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnComplex(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_COMPLEX_TENSOR_H_// End content from: aclnn_complex.h

// Begin content from: aclnn_reciprocal.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_RECIPROCAL_H_
#define OP_API_INC_LEVEL2_ACLNN_RECIPROCAL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReciprocalworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnReciprocalGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnReciprocal
 */
ACLNN_API aclnnStatus aclnnReciprocal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

/**
 * @brief aclnnInplaceReciprocalworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceReciprocalGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnInplaceReciprocal
 */
ACLNN_API aclnnStatus aclnnInplaceReciprocal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_RECIPROCAL_H_// End content from: aclnn_reciprocal.h

// Begin content from: aclnn_fused_infer_attention_score.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef ACLNN_FUSED_INFER_ATTENTION_SCORE_H_
#define ACLNN_FUSED_INFER_ATTENTION_SCORE_H_
// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief The first interface of aclnnFusedInferAttentionScore calculates the workspace size based on the specific calculation process.
 * @domain aclnn_ops_infer
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFusedInferAttentionScoreGetWorkspaceSize(
    const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShift,
    const aclTensor *attenMask, const aclIntArray *actualSeqLengths, const aclIntArray *actualSeqLengthsKv,
    const aclTensor *deqScale1, const aclTensor *quantScale1, const aclTensor *deqScale2, const aclTensor *quantScale2,
    const aclTensor *quantOffset2, const aclTensor *antiquantScale, const aclTensor *antiquantOffset,
    const aclTensor *blockTable, const aclTensor *queryPaddingSize, const aclTensor *kvPaddingSize, int64_t numHeads,
    double scaleValue, int64_t preTokens, int64_t nextTokens, char *inputLayout, int64_t numKeyValueHeads,
    int64_t sparseMode, int64_t innerPrecise, int64_t blockSize, int64_t antiquantMode, bool softmaxLseFlag,
    const aclTensor *attentionOut, const aclTensor *softmaxLse, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief The second interface of aclnnFusedInferAttentionScore is used to perform calculations.
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFusedInferAttentionScore(void *workspace,
                                                                                 uint64_t workspaceSize,
                                                                                 aclOpExecutor *executor,
                                                                                 const aclrtStream stream);


#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_fused_infer_attention_score.h

// Begin content from: aclnn_var_mean.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_VAR_MEAN_H_
#define OP_API_INC_VAR_MEAN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnVarMeanworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnVarMeanGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, int64_t correction,
                                                   bool keepdim, aclTensor* varOut, aclTensor* meanOut,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnVarMean
 */
ACLNN_API aclnnStatus aclnnVarMean(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_var_mean.h

// Begin content from: aclnn_amin.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_AMIN_H_
#define OP_API_INC_AMIN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAminworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] self:
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLEINT8INT16INT32INT64UINT8BOOLND
 * Tensor
 * @param [in] dim: hostaclIntArray INT32INT64
 * @param [in] keepDim: host
 * @param [in] out: deviceaclTensorselfNDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAminGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim,
                                                aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAmin
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAminGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAmin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AMIN_H_// End content from: aclnn_amin.h

// Begin content from: aclnn_grouped_matmul.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GROUPED_MATMUL_H
#define OP_API_INC_GROUPED_MATMUL_H
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupedMatmulworkspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: xFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [in] weight:
 * weightFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [in] biasOptional:
 * biasFLOAT16FLOAT32INT32ND128
 * @param [in] scaleOptional: UINT64ND128
 * @param [in] offsetOptional: FLOAT32ND128
 * @param [in] antiquantScaleOptional:
 * FLOAT16BFLOAT16ND128
 * @param [in] antiquantOffsetOptional:
 * FLOAT16BFLOAT16ND128
 * @param [in] groupListOptional: MINT64128
 * @param [in] splitItem:
 * tensor0/1tensor2/3tensor0
 * @param [out] y: yFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatmulGetWorkspaceSize(
    const aclTensorList* x, const aclTensorList* weight, const aclTensorList* biasOptional,
    const aclTensorList* scaleOptional, const aclTensorList* offsetOptional,
    const aclTensorList* antiquantScaleOptional, const aclTensorList* antiquantOffsetOptional,
    const aclIntArray* groupListOptional, int64_t splitItem, const aclTensorList* y, uint64_t* workspaceSize,
    aclOpExecutor** executor);

/**
 * @brief aclnnGroupedMatmul
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_grouped_matmul.h

// Begin content from: aclnn_foreach_addcdiv_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADDCDIV_LIST_H_
#define ACLNN_FOREACH_ADDCDIV_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddcdivListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * x3 : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcdivListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *x3,
    const aclTensor *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddcdivList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcdivList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_addcdiv_list.h

// Begin content from: aclnn_gather_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GATHER_V2_H_
#define OP_API_INC_LEVEL2_ACLNN_GATHER_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Tensordimindexout Tensor
 * 
 * 
 *   x=$\begin{bmatrix}[[1,&2],&[3,&4]], \\ [[5,&6],&[7,&8]], \\ [[9,&10],&[11,&12]]\end{bmatrix}$
 *   idx=[1, 0],
 * dim0   I=index[i];  &nbsp;&nbsp;   y$[i][m][n]$ = x$[I][m][n]$
 * dim1   J=index[j];  &nbsp;&nbsp;&nbsp;    y$[l][j][n]$ = x$[l][J][n]$
 * dim2   K=index[k]; &nbsp;  y$[l][m][k]$ = x$[l][m][K]$
 *
 * 
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   B --> In_0([l0op::cast]) --> Op([GatherV2])
 *   In_1[(index)] --> con([l0op::Contiguous])--> Op
 *   In_2(dim) --> a(dimVec) --> Op
 *   Op --> C([l0op::cast]) --> D([l0op::ViewCopy]) --> Out[(out)]
 * ```
 */

/**
 * @brief aclnnGatherV2workspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16INT64INT32INT16INT8UINT8BOOLDOUBLE
 * COMPLEX64COMPLEX128BFLOAT16TensorND8
 * @param [in] dim: hostINT64
 * @param [in] index: npu
 * deviceaclTensorINT64INT32TensorND 8
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16INT64INT32INT16INT8UINT8BOOLDOUBLE
 * COMPLEX64COMPLEX128BFLOAT16selfselfindexdimindexshape
 * selfND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGatherV2GetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index,
                                                    aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGatherV2
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGatherV2GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGatherV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GATHER_V2_H_
// End content from: aclnn_gather_v2.h

// Begin content from: aclnn_smooth_l1_loss.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_SILU_H_
#define OP_API_INC_LEVEL2_ACLNN_SILU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSmoothL1Lossworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnSmoothL1LossGetWorkspaceSize(const aclTensor* self, const aclTensor* target,
                                                        int64_t reduction, float beta, aclTensor* result,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnSmoothL1Loss
 */
ACLNN_API aclnnStatus aclnnSmoothL1Loss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_smooth_l1_loss.h

// Begin content from: aclnn_max_pool2d_with_indices.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_MAX_POOL2D_WITH_INDICES_H_
#define OP_API_INC_LEVEL2_ACLNN_MAX_POOL2D_WITH_INDICES_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxPool2dWithMaskworkspace
 * @domain aclnn_ops_infer
 * 2
 *
 * @param [in] self: npu deviceaclTensorfloat16float32bfloat16910B AI
 * 910_93 AINCHW(ND) Tensor
 * @param [in] kernelSize: aclIntArray 
 * @param [in] stride: aclIntArray 
 * @param [in] padding: aclIntArray 
 * @param [in] dilation: aclIntArray 
 * @param [in] ceilMode: aclIntArray true
 * @param [in] out: npu deviceaclTensorfloat16float32bfloat16910B
 * AI910_93 AI NCHW(ND) Tensor
 * @param [in] indices: npu
 * deviceaclTensormaskkernelbitTensorint8NCHW(ND)
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxPool2dWithMaskGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize,
                                                             const aclIntArray* stride, const aclIntArray* padding,
                                                             const aclIntArray* dilation, bool ceilMode,
                                                             aclTensor* out, aclTensor* indices,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMaxPool2dWithMask
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnMaxPool2dWithMaskGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxPool2dWithMask(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

/**
 * @brief aclnnMaxPool2dWithIndicesworkspace
 * @domain aclnn_ops_infer
 * 2
 *
 * @param [in] self: npu deviceaclTensorfloat32910B AI910_93 AI
 * NCHW(ND)Tensor
 * @param [in] kernelSize: aclIntArray 
 * @param [in] stride: aclIntArray 
 * @param [in] padding: aclIntArray 
 * @param [in] dilation: aclIntArray 
 * @param [in] ceilMode: aclIntArray true
 * @param [in] out: npu deviceaclTensorfloat32910B AINCHW(ND)
 * Tensor
 * @param [in] indices: npu deviceaclTensortensorint32NCHW(ND)
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxPool2dWithIndicesGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize,
                                                                const aclIntArray* stride, const aclIntArray* padding,
                                                                const aclIntArray* dilation, bool ceilMode,
                                                                aclTensor* out, aclTensor* indices,
                                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMaxPool2dWithIndices
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnMaxPool2dWithIndicesGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxPool2dWithIndices(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_MAX_POOL2D_WITH_INDICES_H_
// End content from: aclnn_max_pool2d_with_indices.h

// Begin content from: aclnn_l1_loss_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_L1_LOSS_BACKWARD_H_
#define OP_API_INC_L1_LOSS_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnL1LossBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 *
 * @param [in] gradOutputnpu deviceaclTensorselftarget
 * FLOATFLOAT16shapeselftargetbroadcastTensorND
 * @param [in] selfnpu deviceaclTensorgradOutputtarget
 * FLOATFLOAT16shapegradOutputtargetbroadcastTensorND
 * @param [in] targetnpu deviceaclTensorselfgradOutput
 * FLOATFLOAT16shapegradOutputselfbroadcastTensorND
 * @param [in] reductionhostint64 0('none') | 1('mean') | 2('sum')'none'
 *  'mean' 'sum' 
 * @param [in] gradInputnpu deviceaclTensorFLOATFLOAT16
 * shapetargetselfgradOutput broadcastshapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnL1LossBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                          const aclTensor* target, int64_t reduction,
                                                          aclTensor* gradInput, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

/**
 * @brief aclnnL1LossBackward
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnL1LossBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnL1LossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_L1_LOSS_BACKWARD_H_
// End content from: aclnn_l1_loss_backward.h

// Begin content from: aclnn_is_inf.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_IS_INF_H_
#define ACLNN_IS_INF_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnIsInfGetWorkspaceSize
 * parameters :
 * x : required
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnIsInfGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnIsInf
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnIsInf(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_is_inf.h

// Begin content from: aclnn_glu_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GLU_BACKWARD_H_
#define OP_API_INC_GLU_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGluBackwardworkspace
 * @domain aclnn_ops_train
 * GLU
 *
 * $$
 * \frac{\partial GLU(a,b)}{\partial(a,b)}=cat(\sigma(b),\sigma(b) \otimes a \otimes (1-\sigma(b)))
 * $$
 *
 * 
 * GLUGrad:out=[a_grad, b_grad]
 * sig_b = sigmoid(b)
 * **a_grad** = y_grad * sig_b
 * **b_grad** = a_grad * (a - a * sig_b)
 * y_grad gradOutadimb
 *
 * 
 * ```mermaid
 * graph LR
 *    A0[(gradOut)] -->B0([l0op::Contiguous])-->C1([l0op::Mul])-->C2([l0op::Mul])
 *    A1[(self)] -->B1([l0op::Contiguous])
 *    B1 -->D0([l0op::SplitV])--a--> C0-->G0([l0op::Sub])
 *    D0--a-->G0-->C2--b_grad-->H0([l0op::ConcatD])
 *    E0((dim)) -->D0--b-->D1([l0op::Sigmoid])-->C0([l0op::Mul])
 *    D1-->C1--a_grad-->H0
 *    E0-->H0
 *    H0 -->F0([l0op::ViewCopy])--> J0[(out)]
 * ```
 *
 * @param [in] gradOut: DOUBLE,FLOAT,FLOAT16self
 * shape$(*_1,M,*_2)$$*$self$M = N /2$TensorND
 * @param [in] self:
 * DOUBLE,FLOAT,FLOAT16tensor0shapedim2
 * shape$(*_1,N,*_2)$$*$$N$dimTensorND
 * @param [in] dim: selfINT64[-self.dimself.dim-1]
 * @param [out] out: DOUBLE,FLOAT,FLOAT16self
 * shapeselfshapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGluBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* self, int64_t dim,
                                                       const aclTensor* out, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnGluBackward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GLU_BACKWARD_H_
// End content from: aclnn_glu_backward.h

// Begin content from: aclnn_upsample_linear_1d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNAMPLE_LINEAR_1D_BACKWARD_H_
#define OP_API_INC_UNAMPLE_LINEAR_1D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleLinear1dBackward
 */
ACLNN_API aclnnStatus aclnnUpsampleLinear1dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                    aclrtStream stream);

/**
 * @brief aclnnUpsampleLinear1dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnUpsampleLinear1dBackwardGetWorkspaceSize(const aclTensor* gradOut,
                                                                    const aclIntArray* outputSize,
                                                                    const aclIntArray* inputSize, bool alignCorners,
                                                                    double scales, aclTensor* out,
                                                                    uint64_t* workspaceSize, aclOpExecutor** executor);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_LINEAR_1D_BACKWARD_H_// End content from: aclnn_upsample_linear_1d_backward.h

// Begin content from: aclnn_erfinv.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ERFINV_H_
#define OP_API_INC_LEVEL2_ACLNN_ERFINV_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnErfinvworkspace
 * @domain aclnn_ops_infer
 * erfinverfTensor
 * 
 * $$
 * y = erfinv(x) \\
 * x = erf(y)=\frac{2}{\sqrt{\pi } } \int_{0}^{y} e^{-t^{2} } \mathrm{d}t
 * $$
 *
 * 
 * ErfinvFLOAT32FLOAT16BFLOAT16Erfinv
 * ```mermaid
 * graph LR
 * A[(Self)] --> B([l0op::Contiguous]) --> C([l0op::Erfinv])
 * C --> D([l0op::Cast]) --E D([l0op::ViewCopy]) --> F[(out)]
 * ```
 *
 * BOOLINT8INT16INT32INT64UINT8FLOAT
 * ```mermaid
 * graph LR
 * A[(Self)] --> B([l0op::Contiguous]) --> C([l0op::Cast]) --> D([l0op::Erfinv])
 * D --> E([l0op::Cast]) --> F([l0op::ViewCopy]) --> G[(out)]
 * ```
 *
 * @param [in] self: erfinvnpu deviceaclTensor
 * FLOAT32FLOAT16BFLOAT16INT8INT16INT32INT64UINT8BOOLND Tensor
 * @param [in] out: erfinvnpu deviceaclTensor
 * FLOAT32FLOAT16BFLOAT16NDshapeselfTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnErfinvGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnErfinv
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnErfinvGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnErfinv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                  const aclrtStream stream);

/**
 * @brief aclnnInplaceErfinvworkspace
 * @domain aclnn_ops_infer
 * Tensor
 *
 * @param [in] selfRef: erfinvnpu deviceaclTensor
 * FLOAT32FLOAT16BFLOAT16ND Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceErfinvGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnInplaceinv
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnErfinvGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceErfinv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ERFINV_H_// End content from: aclnn_erfinv.h

// Begin content from: aclnn_upsample_nearest_exact3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_NEAREST_EXACT3D_GRAD_H_
#define OP_API_INC_UNAMPLE_NEAREST_EXACT3D_GRAD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearestExact3dBackwardworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleNearestExact3dBackwardGetWorkspaceSize(
    const aclTensor *gradOut, const aclIntArray *outputSize, const aclIntArray *inputSize, double scalesD,
    double scalesH, double scalesW, aclTensor *gradInput, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnUpsampleNearestExact3dBackward
 */
ACLNN_API aclnnStatus aclnnUpsampleNearestExact3dBackward(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_EXACT3D_GRAD_H_
// End content from: aclnn_upsample_nearest_exact3d_backward.h

// Begin content from: aclnn_hardsigmoid.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_HARDSIGMOID_H_
#define OP_API_INC_HARDSIGMOID_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHardsigmoidworkspace
 * @domain aclnn_ops_infer
 *
 * 
 * $$
 * Hardsigmoid(x)=\begin{cases}
 * 1, & x\gt3 \\
 * 0, &  x\le -3 \\
 * x/6 + 1/2 , & otherwise
 * \end{cases}
 * $$
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Hardsigmoid])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensor FLOATFLOAT16INT32Tensor
 * TensorND
 * @param [in] out: npu
 * deviceaclTensor FLOATFLOAT16INT32TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardsigmoidGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);
/**
 * @brief aclnnHardsigmoid
 *
 * 
 * $$
 * Hardsigmoid(x)=\begin{cases}
 * 1, & x\gt3 \\
 * 0, &  x\le -3 \\
 * x/6 + 1/2 , & otherwise
 * \end{cases}
 * $$
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Hardsigmoid])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnHardsigmoidGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardsigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

/**
 * @brief aclnnInplaceHardsigmoidworkspace
 * @domain aclnn_ops_infer
 *
 * 
 * $$
 * Hardsigmoid(x)=\begin{cases}
 * 1, & x\gt3 \\
 * 0, &  x\le -3 \\
 * x/6 + 1/2 , & otherwise
 * \end{cases}
 * $$
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Hardsigmoid])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
```
 *
 * @param [in] self: npu
 * deviceaclTensor FLOATFLOAT16INT32TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceHardsigmoidGetWorkspaceSize(const aclTensor* self, uint64_t* workspaceSize,
                                                              aclOpExecutor** executor);

/**
 * @brief aclnnInplaceHardsigmoid
 *
 * 
 * $$
 * Hardsigmoid(x)=\begin{cases}
 * 1, & x\gt3 \\
 * 0, &  x\le -3 \\
 * x/6 + 1/2 , & otherwise
 * \end{cases}
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Hardsigmoid])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceHardsigmoidGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceHardsigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_HARDSIGMOID_H
// End content from: aclnn_hardsigmoid.h

// Begin content from: aclnn_quant_matmul_weight_nz.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_QUANT_MATMUL_NZ
#define OP_API_INC_QUANT_MATMUL_NZ

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQuantMatmulWeightNzworkspace
 * @domain aclnn_ops_infer
 * aclnnQuantBatchMatmulV4, x2nz
 * @param [in] x1: matmulint8
 * @param [in] x2: matmulint8
 * @param [in] x1Scale: float32
 * @param [in] x2Scale: uint64_t, float, bfloat16, int64_t
 * @param [in] yScale: 
 * @param [in] x1Offset: 
 * @param [in] x2Offset: float32
 * @param [in] yOffset: 
 * @param [in] bias: int32_t, bfloat16, float16, float32
 * @param [in] transposeX1: afalse
 * @param [in] transposeX2: bfalse
 * @param [in] groupSize: 
 * @param [out] out: half, int8, bfloat16
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulWeightNzGetWorkspaceSize(const aclTensor *x1, const aclTensor *x2,
                                                               const aclTensor *x1Scale, const aclTensor *x2Scale,
                                                               const aclTensor *yScale, const aclTensor *x1Offset,
                                                               const aclTensor *x2Offset, const aclTensor *yOffset,
                                                               const aclTensor *bias, bool transposeX1,
                                                               bool transposeX2, int64_t groupSize, aclTensor *out,
                                                               uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnQuantMatmulWeightNz
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnQuantMatmulNZGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulWeightNz(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QUANT_MATMUL_NZ// End content from: aclnn_quant_matmul_weight_nz.h

// Begin content from: aclnn_foreach_sinh.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_SINH_H_
#define ACLNN_FOREACH_SINH_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachSinhGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSinhGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachSinh
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSinh(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sinh.h

// Begin content from: aclnn_max_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAX_V2_H_
#define OP_API_INC_MAX_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxV2workspace
 * @domain aclnn_math
 *
 * tensor
 *
 * @param [in] self: deviceaclTensorTensorND
 * @param [in] dims: hostaclIntArray INT32INT64
 * @param [in] keepDims: host
 * @param [in] noopWithEmptyDims: hostdims
 * @param [in] out: deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxV2GetWorkspaceSize(const aclTensor* self, const aclIntArray* dims, bool keepDims,
                                                 bool noopWithEmptyDims, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnMaxV2
 *
 * tensor
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMaxV2GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAX_V2_H_
// End content from: aclnn_max_v2.h

// Begin content from: aclnn_foreach_addcdiv_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADDCDIV_SCALAR_LIST_H_
#define ACLNN_FOREACH_ADDCDIV_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddcdivScalarListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * x3 : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcdivScalarListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *x3,
    const aclTensor *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddcdivScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcdivScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_addcdiv_scalar_list.h

// Begin content from: aclnn_trace.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TRACE_H_
#define OP_API_INC_TRACE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTraceworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnTraceGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnTrace
 */
ACLNN_API aclnnStatus aclnnTrace(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TRACE_H_// End content from: aclnn_trace.h

// Begin content from: aclnn_min.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MIN_H_
#define OP_API_INC_MIN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMinworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorTensorND
 * @param [in] out: npu deviceaclTensorselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMinGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnMin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMinGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MIN_H_// End content from: aclnn_min.h

// Begin content from: aclnn_hardtanh_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_HARDTANH_BACKWARD_H_
#define OP_API_INC_HARDTANH_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHardtanhBackwardworkspace
 * @domain aclnn_ops_train
 *
 * Hardtanh
 *
 * api
 * 
 * ```mermaid
 * graph LR
 *     A[(gradOutput)] -->B([l0op::Contiguous])
 *     B -->C([l0op::HardtanhGrad])
 *     D[(self)] -->E([l0op::Contiguous])
 *     E -->C([l0op::HardtanhGrad])
 *     F((min)) --> C([l0op::HardtanhGrad])
 *     G((max)) --> C([l0op::HardtanhGrad])
 *     C --> H([l0op::ViewCopy])
 *     H --> K[(out)]
 * ```
 *
 * @param [in] gradOutput: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16(910B910_93
 * AI)TensorND
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16(910B910_93
 * AI)TensorND
 * @param [in] min: 
 * @param [in] max: 
 * @param [out] out: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16(910B910_93
 * AI)TensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardtanhBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                            const aclScalar* min, const aclScalar* max, aclTensor* out,
                                                            uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnHardtanhBackwardworkspace
 *
 * Hardtanh
 *
 * api
 * 
 * ```mermaid
 * graph LR
 *     A[(gradOutput)] -->B([l0op::Contiguous])
 *     B -->C([l0op::HardtanhGrad])
 *     D[(self)] -->E([l0op::Contiguous])
 *     E -->C([l0op::HardtanhGrad])
 *     F((min)) --> C([l0op::HardtanhGrad])
 *     G((max)) --> C([l0op::HardtanhGrad])
 *     C --> H([l0op::ViewCopy])
 *     H --> K[(out)]
 * ```
 *
 * @param [in] gradOutput: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16(910B910_93
 * AI)TensorND
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16(910B910_93
 * AI)TensorND
 * @param [in] min: 
 * @param [in] max: 
 * @param [out] out: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16(910B910_93
 * AI)TensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardtanhBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_HARDTANH_BACKWARD_H_
// End content from: aclnn_hardtanh_backward.h

// Begin content from: aclnn_avgpool3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_AVGPOOL3D_BACKWARD_H_
#define OP_API_INC_AVGPOOL3D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAvgPool3dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * avgpool3d
 *
 * @param [in] gradOutput: npu
 * deviceaclTensorFLOAT, BFLOAT16, FLOAT1645TensorND
 * @param [in] self: npu
 * deviceaclTensorFLOAT, BFLOAT16, FLOAT1645TensorND
 * @param [in] kernelSize: npu
 * deviceaclIntArray1(kD=kH=kW)3(kD,kH,kW)INT32INT640
 * @param [in] stride: npu
 * deviceaclIntArray0(kernelSize)1(sD=sH=sW)3(sD,sH,sW)
 * INT32INT640
 * @param [in] padding: npu
 * deviceaclIntArray1(padD=padH=padW)3(padD,padH,padW)DHWpadding0
 * INT32INT64[0, kernelSize/2]
 * @param [in] ceilMode: BOOLshapeFalse
 * @param [in] countIncludePad: BOOLTrue
 * @param [in] divisorOverride: INT640
 * @param [out] output: npu
 * deviceaclTensorTensorFLOAT16BFLOAT16FLOAT45TensorND
 * gradOutput
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAvgPool3dBackwardGetWorkspaceSize(const aclTensor* gradOuput, const aclTensor* self,
                                                             const aclIntArray* kernelSize, const aclIntArray* stride,
                                                             const aclIntArray* padding, bool ceilMode, bool countIncludePad,
                                                             int64_t divisorOverride, aclTensor* output,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAvgPool3dBackward
 *
 * avgpool3d
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAvgPool3dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAvgPool3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AVGPOOL3D_BACKWARD_H_
// End content from: aclnn_avgpool3d_backward.h

// Begin content from: aclnn_batch_norm_backward_reduce.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_BATCH_NORM_BACKWARD_REDUCE_H_
#define OP_API_INC_LEVEL2_ACLNN_BATCH_NORM_BACKWARD_REDUCE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchNormReduceBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnBatchNormReduceBackwardGetWorkspaceSize(
    const aclTensor* gradOut, const aclTensor* input, const aclTensor* mean, const aclTensor* invstd,
    const aclTensor* weight, const bool inputG, const bool weightG, const bool biasG, aclTensor* sumDy,
    aclTensor* sumDyXmu, aclTensor* gradWeight, aclTensor* gradBias, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnBatchNormReduceBackward
 */
ACLNN_API aclnnStatus aclnnBatchNormReduceBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_BATCH_NORM_BACKWARD_REDUCE_H_
// End content from: aclnn_batch_norm_backward_reduce.h

// Begin content from: aclnn_batchmatmul_quant.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BATCHMATMUL_QUANT_H_
#define OP_API_INC_BATCHMATMUL_QUANT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchMatmulQuantworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnBatchMatmulQuantGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                            const aclTensor* quantParam, const aclTensor* bias,
                                                            bool transposeX1, bool transposeX2, aclTensor* out,
                                                            uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnBatchMatmulQuant
 */
ACLNN_API aclnnStatus aclnnBatchMatmulQuant(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BATCHMATMUL_QUANT_H// End content from: aclnn_batchmatmul_quant.h

// Begin content from: aclnn_geglu_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GEGLU_BACKWARD_H_
#define OP_API_INC_LEVEL2_ACLNN_GEGLU_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGeGluBackwardworkspace
 * @domain aclnn_ops_train
 *
 * GeGlu
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(gradOutput)] --> B([l0op::Contiguous])
 *     C[(self)] --> D([l0op::Contiguous])
 *     E[(gelu)] --> F([l0op::Contiguous])
 *     B --> G([l0op::GeGluV2Grad])
 *     D --> G
 *     F --> G
 *     H((dim)) --> G
 *     I((approximate)) --> G
 *     G --> J([l0op::ViewCopy])
 *     J --> K[(gradInput)]
 * ```
 */

/**
 * @param [in] gradOutputnpu
 * deviceaclTensorFLOAT16shapedimself
 * dimselfTensorND
 * @param [in] selfnpu
 * deviceaclTensorFLOAT16shapedimgradOutput
 * dimgradOutputTensorND
 * @param [in] gelunpu
 * deviceaclTensorFLOAT16shapegradOutputTensor ND
 * @param [in] dim: hostINT64-1
 * @param [in] approximate: hostINT640('none')1('tanh') 
 * 1('tanh') 
 * @param [in] activateLeft:
 * hostfalseactivate
 * @param [out] gradInputnpu
 * deviceaclTensorFLOAT16shapeselfTensor ND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeGluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                         const aclTensor* gelu, int64_t dim, int64_t approximate,
                                                         aclTensor* gradInput, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnGeGluV3Backwardworkspace
 * @domain aclnn_ops_train
 * @param [in] gradOutputnpu
 * deviceaclTensorFLOAT16shapedimself
 * dimselfTensorND
 * @param [in] selfnpu
 * deviceaclTensorFLOAT16shapedimgradOutput
 * dimgradOutputTensorND
 * @param [in] gelunpu
 * deviceaclTensorFLOAT16shapegradOutputTensor ND
 * @param [in] dim: hostINT64-1
 * @param [in] approximate: hostINT640('none')1('tanh') 
 * 1('tanh') 
 * @param [in] activateLeft:
 * hostfalseactivate
 * @param [out] gradInputnpu
 * deviceaclTensorFLOAT16shapeselfTensor ND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeGluV3BackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                           const aclTensor* gelu, int64_t dim, int64_t approximate,
                                                           bool activateLeft, aclTensor* gradInput,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGeGluBackward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGeGluBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeGluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

/**
 * @brief aclnnGeGluBackward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGeGluBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeGluV3Backward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GEGLU_BACKWARD_H_
// End content from: aclnn_geglu_backward.h

// Begin content from: aclnn_batch_norm_elemt_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BATCH_NORM_ELEMT_BACKWARD_H_
#define OP_API_INC_BATCH_NORM_ELEMT_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchNormElemtBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnBatchNormElemtBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* input,
                                                                  const aclTensor* mean, const aclTensor* invstd,
                                                                  const aclTensor* weight, const aclTensor* sumDy,
                                                                  const aclTensor* sumDyXmu, aclTensor* counter,
                                                                  aclTensor* gradInput, uint64_t* workspaceSize,
                                                                  aclOpExecutor** executor);

/**
 * @brief aclnnBatchNormElemtBackward
 */
ACLNN_API aclnnStatus aclnnBatchNormElemtBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BATCH_NORM_ELEMT_BACKWARD_H_
// End content from: aclnn_batch_norm_elemt_backward.h

// Begin content from: aclnn_silu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_SILU_H_
#define OP_API_INC_LEVEL2_ACLNN_SILU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSiluworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnSiluGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnSilu
 */
ACLNN_API aclnnStatus aclnnSilu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_silu.h

// Begin content from: aclnn_replication_pad1d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REPLICATION_PAD1D_H_
#define OP_API_INC_REPLICATION_PAD1D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReplicationPad1dworkspace
 * @domain aclnn_ops_infer
 *
 * tensor
 * @param [in] self: FLOAT16, FLOAT32, DOUBLE, INT8, INT16, INT32, INT64, UINT8,
 * COMPLEX64, COMPLEX128TensorNDpad
 * @param [in] padding: INT642
 * @param [in] out: selfselfpadding
 * Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad1dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief: aclnnReplicationPad1d
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnReplicationPad1dGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REPLICATION_PAD1D_H_// End content from: aclnn_replication_pad1d.h

// Begin content from: aclnn_prompt_flash_attention.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License. 
 */

#ifndef ACLNN_PROMPT_FLASH_ATTENTION_H_
#define ACLNN_PROMPT_FLASH_ATTENTION_H_
// #include "aclnn/acl_meta.h"
// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief The first interface of aclnnPromptFlashAttention is used to calculate the workspace size based on the specific calculation process.
 * @domain aclnn_math
*/
__attribute__ ((visibility("default"))) aclnnStatus aclnnPromptFlashAttentionGetWorkspaceSize(
    const aclTensor *query,
    const aclTensor *key,
    const aclTensor *value,
    const aclTensor *pseShift,
    const aclTensor *attenMask,
    const aclIntArray *actualSeqLengths,
    int64_t numHeads,
    double scaleValue,
    int64_t preTokens,
    int64_t nextTokens,
    char *inputLayout,
    int64_t numKeyValueHeads,
    const aclTensor *attentionOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief The second interface of aclnnPromptFlashAttention is used to perform calculations.
*/
__attribute__ ((visibility("default"))) aclnnStatus aclnnPromptFlashAttention(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_prompt_flash_attention.h

// Begin content from: aclnn_x_log_y_scalar_other.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_X_LOG_Y_SCALAR_OTHER_H_
#define OP_API_INC_X_LOG_Y_SCALAR_OTHER_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnXLogYScalarOtherworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnXLogYScalarOtherGetWorkspaceSize(const aclTensor* self, const aclScalar* other,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnXLogYScalarOther
 */
ACLNN_API aclnnStatus aclnnXLogYScalarOther(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

/**
 * @brief aclnnInplaceXLogYScalarOtherworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceXLogYScalarOtherGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceXLogYScalarOther
 */
ACLNN_API aclnnStatus aclnnInplaceXLogYScalarOther(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_X_LOG_Y_SCALAR_OTHER_H_// End content from: aclnn_x_log_y_scalar_other.h

// Begin content from: aclnn_layer_norm_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_LAYER_NORM_BACKWARD_H_
#define OP_API_INC_LEVEL2_LAYER_NORM_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLayerNormBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnLayerNormBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* input,
                                                             const aclIntArray* normalizedShape, const aclTensor* mean,
                                                             const aclTensor* rstd, const aclTensor* weightOptional,
                                                             const aclTensor* biasOptional,
                                                             const aclBoolArray* outputMask, aclTensor* gradInputOut,
                                                             aclTensor* gradWeightOut, aclTensor* gradBiasOut,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLayerNormBackward
 */
ACLNN_API aclnnStatus aclnnLayerNormBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_LAYER_NORM_BACKWARD_H_
// End content from: aclnn_layer_norm_backward.h

// Begin content from: aclnn_copy.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_COPY_H_
#define OP_API_INC_COPY_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceCopy workspace
 * @domain aclnn_ops_infer
 *
 * srcselfRefselfRef
 *
 * @param [in] selfRef: npu deviceaclTensorint8, int16, int32, int64, uint8, float16, float32, bool,
 * double, complex64, complex128, uint16, uint32, uint64[Tensor](#)ND
 * @param [in] src: npu deviceaclTensorint8, int16, int32, int64, uint8, float16, float32, bool,
 * double, complex64, complex128, uint16, uint32, uint64[Tensor](#)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCopyGetWorkspaceSize(aclTensor* selfRef, const aclTensor* src,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceCopy 
 *
 * srcselfRefselfRef
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceZeroGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCopy(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CONVOLUTION_H_
// End content from: aclnn_copy.h

// Begin content from: aclnn_fmod_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_FMOD_SCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_FMOD_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFmodScalarworkspace
 * @domain aclnn_math
 *
 * selfother
 * $$ out_{i} = self_{i} - (other_{i} *\left \lfloor (self_{i}/other_{i}) \right \rfloor) $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(self)] -->B([l0op::Contiguous])
 * B -->C([l0op::Cast])
 * C -->D([l0op::Mod])
 * E[(other)]-->F([l0op::Cast])
 * F --> D
 * D--> G([l0op::Cast])
 * G --> I([l0op::ViewCopy])
 * I --> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensor
 * DOUBLEBFLOAT16FLOAT16FLOAT32INT32INT64INT8UNIT8
 * otherTensorND
 * @param [in] other: npu deviceaclScalar
 * DOUBLEBFLOAT16FLOAT16FLOAT32INT32INT64INT8UNIT8
 * selfTensorND
 * @param [in] out: npu deviceaclTensorDOUBLEBFLOAT16FLOAT16FLOAT32INT32INT64INT8UNIT8
 * shapeselfother broadcastshapeTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnFmodScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnFmodScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnFmodScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFmodScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

/**
 * @brief aclnnInplaceFmodScalarworkspace
 * @domain aclnn_math
 *
 * selfRefother
 * $$ out_{i} = self_{i} - (other_{i} *\left \lfloor (self_{i}/other_{i}) \right \rfloor) $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(self)] -->B([l0op::Contiguous])
 * B -->C([l0op::Cast])
 * C -->D([l0op::Mod])
 * E[(other)]-->F([l0op::Cast])
 * F --> D
 * D--> G([l0op::Cast])
 * G --> I([l0op::ViewCopy])
 * I --> J[(out)]
 * ```
 *
 * @param [in] selfRef: npu deviceaclTensor
 * DOUBLEFLOAT16FLOAT32INT32INT64INT8UNIT8
 * otherTensorND
 * @param [in] other: npu deviceaclScalar
 * DOUBLEFLOAT16FLOAT32INT32INT64INT8UNIT8
 * selfTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnInplaceFmodScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceFmodScalar
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceFmodScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFmodScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_FMOD_SCALAR_H_
// End content from: aclnn_fmod_scalar.h

// Begin content from: aclnn_lerp_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_LERP_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_LERP_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLerpworkspace
 * @domain aclnn_math
 * TensorTensor

 *
 * 
 * ```mermaid
 * graph LR
 * A1[(self)] --> B1([l0op::Contiguous])
 * A2[(end)] --> B2([l0op::Contiguous])
 * A3[(weight)] --> B3([l0op::Contiguous])
 * C([l0op::Lerp])
 * B1 --> C
 * B2 --> C
 * B3 --> C
 * C --> D([l0op::Cast])
 * D --> E([l0op::ViewCopy]) --> F[(out)]
 * ```
 *
 * @param [in] self: startFLOAT16FLOATshapeendweightbroadcast
 * TensorND
 * @param [in] end: endFLOAT16FLOATselfshapeselfweightbroadcast
 * TensorND
 * @param [in] weight: weightFLOAT16FLOAT`self`shape`self``end`broadcast
 * TensorND
 * @param [in] out: outFLOAT16FLOATselfshapeselfendweight
 * broadcastshapeTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLerpGetWorkspaceSize(const aclTensor* self, const aclTensor* end, const aclTensor* weight,
                                                aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLerp
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLerpGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLerp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceLerpworkspace
 * @domain aclnn_math
 * TensorTensor

 *
 * @param [in] selfRef: startFLOAT16FLOATshapeendweightbroadcastbroadcastshapeselfRef
 * TensorND
 * @param [in] end: endFLOAT16FLOATselfshapeselfRefweightbroadcast
 * broadcastshapeselfRef TensorND
 * @param [in] weight: weightFLOAT16FLOATshapeselfRefendbroadcastTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLerpGetWorkspaceSize(aclTensor* selfRef, const aclTensor* end,
                                                       const aclTensor* weight, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLerp
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceLerpGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLerp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_LERP_TENSOR_H_// End content from: aclnn_lerp_tensor.h

// Begin content from: aclnn_l1_loss.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_L1_LOSS_H_
#define OP_API_INC_L1_LOSS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnL1Lossworkspace
 * @domain aclnn_ops_train
 *
 * xy
 *
 * @param [in] self:
 * `self`targetINT64FLOATFLOAT16shapetargetbroadcast
 * TensorND
 * @param [in] target:
 * `target`selfINT64FLOATFLOAT16shapeselfbroadcast
 * TensorND
 * @param [in] reduction: `reduction`
 *  0('none') | 1('mean') | 2('sum')
 * 'none' 'mean' 'sum' 
 * @param [in] out:
 * `out`INT64FLOATFLOAT16reduction0shapeselftargetbroadcastshape
 * rank1de TensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnL1LossGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction,
                                                  aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnL1Loss
 *
 * xy
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnL1LossGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnL1Loss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_L1_LOSS_H_
// End content from: aclnn_l1_loss.h

// Begin content from: aclnn_logaddexp2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOG_ADD_EXP_2_H_
#define OP_API_INC_LOG_ADD_EXP_2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogAddExp2workspace
 * @domain aclnn_math
 *
 * 2
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEothershapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEselfshapeselfbroadcast
 * TensorNDself
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEselfothershapeselfother
 * broadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogAddExp2GetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogAddExp2
 *
 * 2
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLogAddExp2GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogAddExp2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOG_ADD_EXP_2_H_
// End content from: aclnn_logaddexp2.h

// Begin content from: aclnn_moe_init_routing_v2.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_INIT_ROUTING_V2_H_
#define ACLNN_MOE_INIT_ROUTING_V2_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeInitRoutingV2GetWorkspaceSize
 * parameters :
 * x : required
 * expertIdx : required
 * activeNum : optional
 * expertCapacity : optional
 * expertNum : optional
 * dropPadMode : optional
 * expertTokensCountOrCumsumFlag : optional
 * expertTokensBeforeCapacityFlag : optional
 * expandedXOut : required
 * expandedRowIdxOut : required
 * expertTokensCountOrCumsumOutOptional : optional
 * expertTokensBeforeCapacityOutOptional : optional
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingV2GetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *expertIdx,
    int64_t activeNum,
    int64_t expertCapacity,
    int64_t expertNum,
    int64_t dropPadMode,
    int64_t expertTokensCountOrCumsumFlag,
    bool expertTokensBeforeCapacityFlag,
    const aclTensor *expandedXOut,
    const aclTensor *expandedRowIdxOut,
    const aclTensor *expertTokensCountOrCumsumOutOptional,
    const aclTensor *expertTokensBeforeCapacityOutOptional,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeInitRoutingV2
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_init_routing_v2.h

// Begin content from: aclnn_exp2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_EXP2_H_
#define OP_API_INC_LEVEL2_ACLNN_EXP2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * 
 * 
 * $$
 *     out_{i} = 2^{self_{i}}
 * $$
 * @brief aclnnExp2workspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLE
 * TensorND8
 * @param [in] out: npu
 * deviceaclTensorselfshapeselfTensor
 * ND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnExp2GetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnExp2
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnExp2GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnExp2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceExp2workspace
 * @domain aclnn_math
 * @param [in] selfRef: npu deviceaclTensorFLOATFLOAT16BFLOAT16910B
 * DOUBLETensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceExp2GetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceExp2
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceExp2GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceExp2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_EXP2_H_
// End content from: aclnn_exp2.h

// Begin content from: aclnn_unique.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNIQUE_H_
#define OP_API_INC_UNIQUE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUniqueworkspace
 * @domain aclnn_math
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B ---> F([UniqueWithCountsAndSorting])
 *     C[(sorted)] --->F
 *     D[(returnInverse)] --->F
 *     F --> G([valueOut])
 *     F --> H([inverseOut])
 * ```
 *
 * @param [in] self: npu deviceaclTensorBOOL, FLOAT, FLOAT16, DOUBLE, UINT8, INT8, UINT16, INT16,
 * INT32, UINT32, UINT64, INT64TensorND
 * @param [in] sorted: False valueOut 
 * @param [in] returnInverse: False valueOut 
 * @param [in] valueOut: npu deviceaclTensor, BOOL, FLOAT,
 * FLOAT16, DOUBLE, UINT8, INT8, UINT16, INT16, INT32, UINT32, UINT64, INT64ND
 * @param [in] inverseOut: npu
 * deviceaclTensorreturnInversieTrueselfvalueOut
 *                      INT64shapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUniqueGetWorkspaceSize(const aclTensor* self, bool sorted, bool returnInverse,
                                                  aclTensor* valueOut, aclTensor* inverseOut, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnUnique
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnUniqueGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUnique(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNIQUE_H_// End content from: aclnn_unique.h

// Begin content from: aclnn_grouped_matmul_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GROUPED_MATMUL_V2_H
#define OP_API_INC_GROUPED_MATMUL_V2_H
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupedMatmulV2workspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: xFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [in] weight:
 * weightFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [in] biasOptional:
 * biasFLOAT16FLOAT32INT32ND128
 * @param [in] scaleOptional: UINT64ND128
 * @param [in] offsetOptional: FLOAT32ND128
 * @param [in] antiquantScaleOptional:
 * FLOAT16BFLOAT16ND128
 * @param [in] antiquantOffsetOptional:
 * FLOAT16BFLOAT16ND128
 * @param [in] groupListOptional: INT64128
 * @param [in] splitItem:
 * tensor0/1tensor2/3tensor0
 * @param [in] groupType:
 * -10M1N2K
 * @param [out] y: outFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatmulV2GetWorkspaceSize(
    const aclTensorList* x, const aclTensorList* weight, const aclTensorList* biasOptional,
    const aclTensorList* scaleOptional, const aclTensorList* offsetOptional,
    const aclTensorList* antiquantScaleOptional, const aclTensorList* antiquantOffsetOptional,
    const aclIntArray* groupListOptional, int64_t splitItem, int64_t groupType, const aclTensorList* y,
    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGroupedMatmulV2
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatmulV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_grouped_matmul_v2.h

// Begin content from: aclnn_convert_weight_to_int4_pack.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_CONVERT_WEIGHT_TO_INT4_PACK_H_
#define OP_API_INC_LEVEL2_ACLNN_CONVERT_WEIGHT_TO_INT4_PACK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnConvertWeightToINT4Packworkspace
 * @domain aclnn_ops_infer
*/
ACLNN_API aclnnStatus aclnnConvertWeightToINT4PackGetWorkspaceSize(const aclTensor *weight, aclTensor *weightInt4Pack,
                                                                   uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnConvertWeightToINT4Pack
*/
ACLNN_API aclnnStatus aclnnConvertWeightToINT4Pack(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif // OP_API_INC_LEVEL2_ACLNN_CONVERT_WEIGHT_TO_INT4_PACK_H_// End content from: aclnn_convert_weight_to_int4_pack.h

// Begin content from: aclnn_cummax.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_CUMMAX_H_
#define OP_API_INC_LEVEL2_ACLNN_CUMMAX_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * self
 * 
 * $self_{i}$selfdimdim
 * $$
 * valuesOut_{i} = max(self_{1}, self_{2}, self_{3}, ......, self_{i})
 * $$
 * $$
 * indicesOut_{i} = argmax(self_{1}, self_{2}, self_{3}, ......, self_{i})
 * $$
 */

/**
 * @brief aclnnCummaxworkspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu deviceaclTensorFLOATDOUBLEUINT8INT8INT16INT32INT64
 * FLOAT16BFLOAT16BOOLoutTensorND8
 * @param [in] dim: hostINT64
 * @param [in] valuesOutnpu deviceaclTensorFLOATDOUBLEUINT8INT8INT16INT32INT64
 * FLOAT16BFLOAT16BOOLTensorND8, shapeself
 * @param [in] indicesOutnpu deviceaclTensorINT32INT64TensorND
 * 8, shapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCummaxGetWorkspaceSize(const aclTensor* self, int64_t dim, aclTensor* valuesOut,
                                                  aclTensor* indicesOut, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnCummax
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCummaxGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCummax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_CUMMAX_H_
// End content from: aclnn_cummax.h

// Begin content from: aclnn_foreach_minimum_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_MINIMUM_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_MINIMUM_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachMinimumScalarV2workspace
 * scalar
 * 
 * out_{i}=min(x_{i}, scalar)
 * @domain aclnnop_math
 * 
 * @param [in]   x
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   scalar
 * ScalarFLOATFLOAT16INT32ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachMinimumScalarV2GetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachMinimumScalarV2
 * scalar
 * 
 * out_{i}=min(x_{i}, scalar)
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachMinimumScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachMinimumScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_minimum_scalar_v2.h

// Begin content from: aclnn_argmax.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ARGMAX_H_
#define OP_API_INC_ARGMAX_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnArgMaxworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * 
 * api
 * ```mermaid
 *  graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> C([l0op::ArgMaxV2])
 *  C --> F([l0op::Cast])
 *  D([dim]) --> C
 *  F -.-> E([l0op::ViewCopy])
 *  E --> O[(Out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16NDTensor
 * @param [in] dim: hostint64
 * @param [in] keepdim: host
 * @param [in] out: npu deviceaclTensorINT32INT64NDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnArgMaxGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepdim,
                                                  aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnArgMaxworkspace
 *
 * 
 *
 * 
 * api
 * ```mermaid
 *  graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> C([l0op::ArgMaxV2])
 *  C --> F([l0op::Cast])
 *  D([dim]) --> C
 *  F -.-> E([l0op::ViewCopy])
 *  E --> O[(Out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnArgMaxGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnArgMax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ARGMAX_H_// End content from: aclnn_argmax.h

// Begin content from: aclnn_pdist_forward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_PDIST_H_
#define OP_API_INC_PDIST_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnPdistForwardworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnPdistForwardGetWorkspaceSize(const aclTensor* self, const aclScalar* pScalar, aclTensor* out,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnPdistForward
 */
ACLNN_API aclnnStatus aclnnPdistForward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_pdist_forward.h

// Begin content from: aclnn_rsub.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_RSUB_H_
#define OP_API_INC_RSUB_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRsubsworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ out_i = other - self_i * alpha $$
 *
 * @param [in] self: npu deviceaclTensorother
 * shapeotherbroadcastTensorND
 * @param [in] other: hostaclScalarself
 * @param [in] alpha: hostaclScalarselfother
 * @param [in] out: npu deviceaclTensor
 * selfothershapeselfTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRsubsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, const aclScalar* alpha,
                                                 aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnRsubs
 *
 * 
 * 
 * $$ out_i = other - self_i * alpha $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnRsubsGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRsubs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnRsubworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ out_i = other_i - self_i * alpha $$
 *
 * @param [in] self: npu deviceaclTensorother
 * shapeotherbroadcastTensorND
 * @param [in] other: npu deviceaclTensorself
 * shapeselfbroadcastTensorND
 * @param [in] alpha: hostaclScalarselfother
 * @param [in] out: npu deviceaclTensor
 * selfothershapeselfother broadcastshape
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRsubGetWorkspaceSize(const aclTensor* self, const aclTensor* other, const aclScalar* alpha,
                                                aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnRsub
 *
 * 
 * 
 * $$ out_i = other_i - self_i * alpha $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRsubGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRsub(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_RSUB_H_
// End content from: aclnn_rsub.h

// Begin content from: aclnn_reflection_pad1d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REFLECTION_PAD1D_H_
#define OP_API_INC_REFLECTION_PAD1D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReflectionPad1dworkspace
 * @domain aclnn_ops_infer
 *
 * tensor
 * @param [in] self: npu deviceaclTensor, BFLOAT16,FLOAT16, FLOAT32, DOUBLE, INT8, INT16,
 * INT32, INT64, UINT8, BOOLND
 * @param [in] padding: npu deviceaclIntArray,
 * INT642 self
 * @param [in] out: npu deviceaclTensor,
 * selfselfpadding
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad1dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief: aclnnReflectionPad1d
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnReflectionPad1dGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REFLECTION_PAD1D_H_// End content from: aclnn_reflection_pad1d.h

// Begin content from: aclnn_swin_transformer_ln_qkv_quant.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_SWIN_TRANSFORMER_LN_QKV_QUANT_H_
#define ACLNN_SWIN_TRANSFORMER_LN_QKV_QUANT_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnSwinTransformerLnQkvQuantGetWorkspaceSize
 * parameters :
 * x : required
 * gamma : required
 * beta : required
 * weight : required
 * bias : required
 * quantScale : required
 * quantOffset : required
 * dequantScale : required
 * headNum : required
 * seqLength : required
 * epsilon : required
 * oriHeight : required
 * oriWeight : required
 * hWinSize : required
 * wWinSize : required
 * weightTranspose : required
 * queryOutputOut : required
 * keyOutputOut : required
 * valueOutputOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnSwinTransformerLnQkvQuantGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *gamma,
    const aclTensor *beta,
    const aclTensor *weight,
    const aclTensor *bias,
    const aclTensor *quantScale,
    const aclTensor *quantOffset,
    const aclTensor *dequantScale,
    int64_t headNum,
    int64_t seqLength,
    double epsilon,
    int64_t oriHeight,
    int64_t oriWeight,
    int64_t hWinSize,
    int64_t wWinSize,
    bool weightTranspose,
    const aclTensor *queryOutputOut,
    const aclTensor *keyOutputOut,
    const aclTensor *valueOutputOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnSwinTransformerLnQkvQuant
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnSwinTransformerLnQkvQuant(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_swin_transformer_ln_qkv_quant.h

// Begin content from: aclnn_masked_scatter.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MASKED_SCATTER_H_
#define OP_API_INC_MASKED_SCATTER_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaskedScatterworkspace
 * @domain aclnn_ops_infer
 *
 * maskTruesourceselfRef
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *   A[(selfRef)] -->B([l0op::Contiguous])
 *   B  -->D([l0op::MaskedScatter])
 *   D  -->J([l0op::ViewCopy])
 *   J   --> K[(selfRef)]
 *   A2[(mask)] -->B2([l0op::Contiguous])
 *   B2 --> C2([l0op::Cast])
 *   C2  -->D
 *   A1[(source)]-->B1([l0op::Contiguous])
 *   B1-->D
 * ```
 *
 * @param [in] selfRef: npu deviceaclTensorFLOATFLOAT16DOUBLEINT8INT16INT32INT64UINT8
 * TensorND
 * @param [in] mask: npu deviceaclTensorBOOLUINT8shapeselfRefselfRef
 * broadcastND
 * @param [in] source:npu deviceaclTensorselfRef
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMaskedScatterGetWorkspaceSize(aclTensor* selfRef, const aclTensor* mask,
                                                                const aclTensor* source, uint64_t* workspaceSize,
                                                                aclOpExecutor** executor);
/**
 * @brief aclnnMaskedScatter
 *
 * maskTruesourceself
 * 
 * api
 * ```mermaid
 * graph LR
 *   A[(selfRef)] -->B([l0op::Contiguous])
 *   B  -->D([l0op::MaskedScatter])
 *   D  -->J([l0op::ViewCopy])
 *   J   --> K[(selfRef)]
 *   A2[(mask)] -->B2([l0op::Contiguous])
 *   B2 --> C2([l0op::Cast])
 *   C2  -->D
 *   A1[(source)]-->B1([l0op::Contiguous])
 *   B1-->D
 * ```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMaskedScatterGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMaskedScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MASKED_SCATTER_H_
// End content from: aclnn_masked_scatter.h

// Begin content from: aclnn_ge_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GESCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_GESCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGeScalarworkspace
 * @domain aclnn_math
 * Tensorother ScalarBoolTensor
 * Tensor
 *  $$ out_{i}= (self_i >= other) ? True : False $$
 *
 * @param [in] self: ge,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BFLOAT16ND,
 * Tensor
 * @param [in] other: ge,aclScalar
 * @param [in] out: genpu deviceaclTensor
 * BOOLTensorND
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGeScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGeScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    const aclrtStream stream);

/**
 * @brief aclnnInplaceGeScalarworkspace
 * @domain aclnn_math
 * Tensorother Scalar
 *  $$ selfRef_{i} = (selfRef_{i} >= other_{i}) ? True : False $$
 *
 * @param [in] selfRef: ge,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BOOLBFLOAT16NDTensor
 * @param [in] other: ge,aclScalar
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceGeScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceGeScalar
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceGeScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceGeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GESCALAR_H_
// End content from: aclnn_ge_scalar.h

// Begin content from: aclnn_scatter_update.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SCATTER_UPDATE_H_
#define OP_API_INC_SCATTER_UPDATE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnScatterUpdateworkspace
 * @domain aclnn_ops_infer
 *
 *  tensor updatesaxisindicestensor data,
 * tensorflowpytorch
 * @param [in] data: npu deviceaclTensor, FLOAT16, FLOAT32, INT8, BFLOAT16,data
 * updatesTensorND
 * @param [in] indices: npu deviceaclTensorINT32,
 * int64TensorND
 * @param [in] updates: npu deviceaclTensorFLOAT16, FLOAT32, INT8,
 * BFLOAT16,data TensorND,
 * @param [in] axis: hostaxis, INT64
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceScatterUpdateGetWorkspaceSize(aclTensor* data, const aclTensor* indices,
                                                                const aclTensor* updates, int64_t axis,
                                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnScatterUpdate
 *
 * : tensor updatesaxisindicestensor data,
 * tensorflowpytorch
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceScatterUpdateGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceScatterUpdate(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SCATTER_UPDATE_H_// End content from: aclnn_scatter_update.h

// Begin content from: aclnn_median.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MEDIAN_H_
#define OP_API_INC_MEDIAN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMedianworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64
 * valuesOut[Tensor](#Tensor)ND[](#)
 * @param [in] valuesOut: deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64
 * selfvaluesOutTensorshape(1,)[Tensor](#Tensor)ND[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMedianGetWorkspaceSize(const aclTensor* self, aclTensor* valuesOut, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnMedian
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMedianGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMedian(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnMedianDimworkspace
 * @domain aclnn_math
 * @param [in] self: selfnpu deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64
 * [Tensor](#Tensor)ND
 * @param [in] dimINT64
 * @param [in] keepDimreduceBOOL
 * @param [in] valuesOut: npu deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64
 * [Tensor](#Tensor)ND
 * @param [in] indicesOutnpu
 * deviceaclTensorINT64[Tensor](#Tensor)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMedianDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepDim,
                                                     aclTensor* valuesOut, aclTensor* indicesOut,
                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMedianDim
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMedianDimGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMedianDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

/**
 * @brief aclnnNanMedianworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64
 * valuesOut[Tensor](#Tensor)ND[](#)
 * @param [in] out: deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64
 * selfoutTensorshape(1,)[Tensor](#Tensor)ND[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNanMedianGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnNanMedian
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMedianGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNanMedian(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

/**
 * @brief aclnnNanMedianDimworkspace
 * @domain aclnn_math
 * @param [in] self: selfnpu deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64
 * [Tensor](#Tensor)ND
 * @param [in] dimINT64
 * @param [in] keepDimreduceBOOL
 * @param [in] valuesOut: npu deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64
 * [Tensor](#Tensor)ND
 * @param [in] indicesOutnpu
 * deviceaclTensorINT64[Tensor](#Tensor)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNanMedianDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepDim,
                                                        aclTensor* valuesOut, aclTensor* indicesOut,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnNanMedianDim
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnNanMedianDimGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNanMedianDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MEDIAN_H_// End content from: aclnn_median.h

// Begin content from: aclnn_bitwise_xor_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http: *www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_BITWISE_XOR_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_BITWISE_XOR_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * selfotherselfother
 * 
 * 
 * $$
 * \text{out}_i =
 * \text{self}_i \, \bigoplus\, \text{other}_i
 * $$
 *
 * 
 * 
 * BOOLl0::NotEqual
 *
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   B --> C([l0op::NotEqual])
 *   D[(other)] --> E([l0op::Contiguous])
 *   E --> C
 *   C --> F([l0op::Cast])
 *   F --> G([l0op::ViewCopy])
 *   G --> H[(out)]
 * ```
 *
 * 
 * l0::BitwiseXor
 *
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   B --> C([l0op::Cast])
 *   C --> D([l0op::BitwiseXor])
 *   E[(other)] --> F([l0op::Contiguous])
 *   F --> G([l0op::Cast])
 *   G --> D
 *   D --> H([l0op::Cast])
 *   H --> I([l0op::ViewCopy])
 *   I --> J[(out)]
 * ```
 */

/**
 * @brief aclnnBitwiseXorTensorworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * deviceaclTensorBOOLINT8INT16INT32INT64UINT8other
 * shapeotherbroadcastTensorND8
 * @param [in] othernpu
 * deviceaclTensorBOOLINT8INT16INT32INT64UINT8self
 * shapeselfbroadcastTensorND8
 * @param [in] out: npu
 * deviceaclTensorBOOLINT8INT16INT32INT64UINT8FLOATFLOAT16DOUBLE
 * BFLOAT16COMPLEX64COMPLEX128selfothershapeselfother
 * broadcast shapeTensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseXorTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnBitwiseXorTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnBitwiseXorTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseXorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

/**
 * @brief aclnnInplaceBitwiseXorTensorworkspace
 * @domain aclnn_math
 * @param [in] selfRef: npu deviceaclTensorBOOLINT8INT16INT32INT64UINT8other
 * selfRefshapeotherbroadcast
 * broadcastshapeselfRefshapeTensorND8
 * @param [in] othernpu deviceaclTensorBOOLINT8INT16INT32INT64UINT8selfRef
 * shapeselfRefbroadcastTensorND8
 * 
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseXorTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBitwiseXorTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceBitwiseXorTensorGetWorkspaceSize 
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseXorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_BITWISE_XOR_TENSOR_H_// End content from: aclnn_bitwise_xor_tensor.h

// Begin content from: aclnn_silu_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_SILU_BACKWARD_H_
#define OP_API_INC_LEVEL2_ACLNN_SILU_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSiluBackwardGetWorkspaceSizeworkspace
 * @domain aclnn_ops_train
 * silu
 */
ACLNN_API aclnnStatus aclnnSiluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                        aclTensor* gradInput, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/*
 * @brief aclnnSiluBackwardGetWorkspaceSize
 */
ACLNN_API aclnnStatus aclnnSiluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_BINARY_CROSS_ENTROPY_BACKWARD_H_// End content from: aclnn_silu_backward.h

// Begin content from: aclnn_apply_fused_ema_adam.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_APPLY_FUSED_EMA_ADAM_H_
#define ACLNN_APPLY_FUSED_EMA_ADAM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnApplyFusedEmaAdamGetWorkspaceSize
 * parameters :
 * grad : required
 * varRef : required
 * mRef : required
 * vRef : required
 * sRef : required
 * step : required
 * lr : optional
 * emaDecay : optional
 * beta1 : optional
 * beta2 : optional
 * eps : optional
 * mode : optional
 * biasCorrection : optional
 * weightDecay : optional
 * varRef : required
 * mRef : required
 * vRef : required
 * sRef : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnApplyFusedEmaAdamGetWorkspaceSize(
    const aclTensor *grad,
    aclTensor *varRef,
    aclTensor *mRef,
    aclTensor *vRef,
    aclTensor *sRef,
    const aclTensor *step,
    double lr,
    double emaDecay,
    double beta1,
    double beta2,
    double eps,
    int64_t mode,
    bool biasCorrection,
    double weightDecay,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnApplyFusedEmaAdam
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnApplyFusedEmaAdam(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_apply_fused_ema_adam.h

// Begin content from: aclnn_bitwise_or_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_BITWISE_OR_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_BITWISE_OR_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBitwiseOrTensorworkspace
 * @domain aclnn_math
 *
 *
 selfother
 * 
 * $$
 * \text{out}_i =
 * \text{self}_i \, | \, \text{other}_i
 * $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalOr

 * ```mermaid
 * graph LR
 * A[(self)] --> B([l0op::Contiguous])
 * B --> C([l0op::Cast])
 * C --> D([l0op::LogicalOr])
 * E[(other)] --> D
 * D --> F([l0op::Cast])
 * F --> G([l0op::ViewCopy])
 * G --> H[(out)]
 * ```
 *
 * 
 * l0::BitwiseOr
 *
 * ```mermaid
 * graph LR
 * A[(self)] --> B([l0op::Contiguous])
 * B --> C([l0op::Cast])
 * C --> D([l0op::BitwiseOr])
 * E[(other)] --> D
 * D --> F([l0op::Cast])
 * F --> G([l0op::ViewCopy])
 * G --> H[(out)]
 * ```
 *
 * @param [in] self: npu
 deviceaclTensorBOOLINT8INT16INT32INT64UINT8UINT16UINT32UINT64
 * otherTensorND8
 * @param [in] othernpu
 deviceaclTensorBOOLINT8INT16INT32INT64UINT8UINT16UINT32UINT64
 * self
 * @param [in] out: npu
 deviceaclTensorBOOLINT8INT16INT32INT64UINT8UINT16UINT32UINT64
 * FLOATFLOAT16DOUBLEBFLOAT16COMPLEX64COMPLEX128selfother
 * shapeselfTensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseOrTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnBitwiseOrTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnBitwiseOrTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseOrTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

/**
 * @brief aclnnInplaceBitwiseOrTensorworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorBOOLINT8INT16INT32INT64UINT8
 * otherTensorND8
 * @param [in] othernpu deviceaclTensorBOOLINT8INT16INT32INT64UINT8
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseOrTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBitwiseOrTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace
 * aclnnInplaceBitwiseOrTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseOrTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_BITWISE_OR_TENSOR_H_
// End content from: aclnn_bitwise_or_tensor.h

// Begin content from: aclnn_max_pool2d_with_indices_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_MAX_POOL2D_WITH_INDICES_BACKWARD_H_
#define OP_API_INC_LEVEL2_ACLNN_MAX_POOL2D_WITH_INDICES_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxPool2dWithMaskBackwardworkspace
 * @domain aclnn_ops_train
 * aclnnMaxPool2dWithMask
 *
 * @param [in] gradOutput: Tensorshapenpu
 * deviceaclTensorfloat16float32910B AI, NCHW(CHW)
 * Tensor
 * @param [in] self: npu deviceaclTensorfloat16float32910B AI,
 * NCHW(CHW) Tensor
 * @param [in] indices: npu
 * deviceaclTensormaskkernelbitTensorint8NCHW(CHW)
 * Tensor
 * @param [in] kernelSize: aclIntArray 
 * @param [in] stride: aclIntArray 
 * @param [in] padding: aclIntArray 
 * @param [in] dilation: aclIntArray 
 * @param [in] ceilMode: aclIntArray true
 * @param [in] gradInput: npu deviceaclTensorfloat16float32910B
 * AINCHW(CHW) Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxPool2dWithMaskBackwardGetWorkspaceSize(
    const aclTensor* gradOutput, const aclTensor* self, const aclTensor* indices, const aclIntArray* kernelSize,
    const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool ceilMode,
    aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMaxPool2dWithMaskBackward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnMaxPool2dWithMaskBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxPool2dWithMaskBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                     aclrtStream stream);

/**
 * @brief aclnnMaxPool2dWithIndicesBackwardworkspace
 * @domain aclnn_ops_train
 * aclnnMaxPool2dWithIndices
 *
 * @param [in] gradOutput: Tensorshapenpu deviceaclTensorfloat32910B
 * AI, NCHW(CHW) Tensor
 * @param [in] self: npu deviceaclTensorfloat32910B AI, NCHW(CHW)
 * Tensor
 * @param [in] indices: npu deviceaclTensortensorint32NCHW(CHW)
 * Tensor
 * @param [in] kernelSize: aclIntArray 
 * @param [in] stride: aclIntArray 
 * @param [in] padding: aclIntArray 
 * @param [in] dilation: aclIntArray 
 * @param [in] ceilMode: aclIntArray true
 * @param [in] gradInput: npu deviceaclTensorfloat32910B
 * AINCHW(CHW) Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxPool2dWithIndicesBackwardGetWorkspaceSize(
    const aclTensor* gradOutput, const aclTensor* self, const aclTensor* indices, const aclIntArray* kernelSize,
    const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool ceilMode,
    aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMaxPool2dWithIndicesBackward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnMaxPool2dWithIndicesBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxPool2dWithIndicesBackward(void* workspace, uint64_t workspaceSize,
                                                        aclOpExecutor* executor, aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_MAX_POOL2D_WITH_INDICES_BACKWARD_H_// End content from: aclnn_max_pool2d_with_indices_backward.h

// Begin content from: aclnn_foreach_zero_inplace.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ZERO_INPLACE_H_
#define ACLNN_FOREACH_ZERO_INPLACE_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachZeroInplaceGetWorkspaceSize
 * parameters :
 * x : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachZeroInplaceGetWorkspaceSize(
    const aclTensorList *x,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachZeroInplace
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachZeroInplace(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_zero_inplace.h

// Begin content from: aclnn_foreach_mul_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MUL_SCALAR_H_
#define ACLNN_FOREACH_MUL_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMulScalarGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMulScalarGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMulScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMulScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_mul_scalar.h

// Begin content from: aclnn_apply_adam_w_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_APPLY_ADAM_W_V2_H_
#define OP_API_INC_APPLY_ADAM_W_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnApplyAdamWV2workspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnApplyAdamWV2GetWorkspaceSize(aclTensor* varRef, aclTensor* mRef, aclTensor* vRef,
                                                        aclTensor* maxGradNormOptionalRef, const aclTensor* grad,
                                                        const aclTensor* step, float lr, float beta1, float beta2,
                                                        float weightDecay, float eps, bool amsgrad, bool maximize,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);
/* @brief aclnnApplyAdamWV2 */
ACLNN_API aclnnStatus aclnnApplyAdamWV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_apply_adam_w_v2.h

// Begin content from: aclnn_slice_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_SLICEV2_H_
#define OP_API_INC_LEVEL2_ACLNN_SLICEV2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSliceV2workspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnSliceV2GetWorkspaceSize(const aclTensor* self, const aclIntArray* starts,
                                                   const aclIntArray* ends, const aclIntArray* axes,
                                                   const aclIntArray* steps, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnSliceV2
 */
ACLNN_API aclnnStatus aclnnSliceV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SLICEV2_H_
// End content from: aclnn_slice_v2.h

// Begin content from: aclnn_roi_align.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_ROI_ALIGN_H_
#define OP_API_INC_LEVEL2_ACLNN_ROI_ALIGN_H_

#include <cstring>
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRoiAlignworkspace
 * @domain aclnn_ops_infer
 *
 * ROIAlign
 *
 * @param [in] self: npu deviceaclTensorFLOAT16FLOAT32TensorNCHW
 * @param [in] rois: npu deviceaclTensorFLOAT16FLOAT32TensorND
 * @param [in] batchIndices: npu deviceaclTensorINT64TensorND
 * @param [in] out: npu
 * deviceaclTensorFLOAT16FLOAT32selfTensorNCHW
 * @param [in] mode: hoststring"avg""max"
 * @param [in] outputHeight: hostintROIH
 * @param [in] outputWidth: hostintROIW
 * @param [in] samplingRatio: hostintWbin
 * @param [in] spatialScale: hostfloatROI
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRoiAlignGetWorkspaceSize(const aclTensor* self, const aclTensor* rois,
                                                    const aclTensor* batchIndices, const char* mode, int outputHeight,
                                                    int outputWidth, int samplingRatio, float spatialScale,
                                                    aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnRoiAlign
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnRoiAlignGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRoiAlign(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ROI_ALIGN_H_// End content from: aclnn_roi_align.h

// Begin content from: aclnn_quant_matmul_all_reduce_v3.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_quant_matmul_all_reduce_v3.h
 * \brief
 */
#ifndef OP_API_INC_QUANT_MATMUL_ALL_REDUCE_V3_
#define OP_API_INC_QUANT_MATMUL_ALL_REDUCE_V3_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQuantMatmulAllReduceV3workspace
 * @domain aclnn_ops_infer
 * mm+AllReduce
 * @param [in] x1: matmulint8
 * @param [in] x2: matmulint8
 * @param [in] biasOptional: int32
 * @param [in] x3Optional: addfloat16,bfloat16
 * @param [in] dequantScale: int64,uint64,bfloat16,float32
 * @param [in] pertokenScaleOptional: per-tokenfloat32
 * @param [in] commQuantScale1Optional: float16, bfloat16
 * @param [in] commQuantScale2Optional: float16, bfloat16
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [out] output: +float16,bfloat16
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulAllReduceV3GetWorkspaceSize(const aclTensor *x1, const aclTensor *x2,
                                                        const aclTensor *biasOptional, const aclTensor *x3Optional,
                                                        const aclTensor *dequantScale,
                                                        const aclTensor *pertokenScaleOptional, const aclTensor* commQuantScale1Optional,
                                                        const aclTensor* commQuantScale2Optional, const char* group,
                                                        const char *reduceOp, int64_t commTurn,
                                                        int64_t streamMode, const aclTensor *output,
                                                        uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnQuantMatmulAllReduceV3
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnQuantMatmulAllReduceV3GetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulAllReduceV3(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QUANT_MATMUL_ALL_REDUCE_V3_// End content from: aclnn_quant_matmul_all_reduce_v3.h

// Begin content from: aclnn_grid_sampler2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GRID_SAMPLER2D_BACKWARD_H_
#define OP_API_INC_GRID_SAMPLER2D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGridSampler2DBackwardworkspace
 * @domain aclnn_ops_train
 *
 * aclnnGridSampler2D
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(gradOutput)] --> B([l0op::Contiguous]) --> C([l0op::GridSampler2DGrad])
 *     D[(input)] --> E([l0op::Contiguous]) --> C
 *     F[(grid)] --> G([l0op::Contiguous]) --> C
 *     H((interpolationMode)) --> C
 *     I((paddingMode)) --> C
 *     J((alignCorners)) --> C
 *     C --> K([l0op::ViewCopy]) --> Out1[("inputGrad")]
 *     C --> L([l0op::ViewCopy]) --> Out2[("gridGrad")]
 * ```
 *
 * @param [in] gradOutput: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [in] input: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [in] grid: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [in] interpolationModeint64_t0bilinear1nearest
 * @param [in] paddingModeint64_tx,y
 * 0zeros1border2reflection
 * @param [in] alignCornersbooltrue
 * @param [in] outputMaskaclBoolArray
 * @param [in] inputGrad: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [in] gridGrad: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGridSampler2DBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* input,
                                                                 const aclTensor* grid, int64_t interpolationMode,
                                                                 int64_t paddingMode, bool alignCorners,
                                                                 const aclBoolArray* outputMask, aclTensor* inputGrad,
                                                                 aclTensor* gridGrad, uint64_t* workspaceSize,
                                                                 aclOpExecutor** executor);

/**
 * @brief aclnnGridSampler2DBackward
 *
 * aclnnGridSampler2D
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(gradOutput)] --> B([l0op::Contiguous]) --> C([l0op::GridSampler2DGrad])
 *     D[(input)] --> E([l0op::Contiguous]) --> C
 *     F[(grid)] --> G([l0op::Contiguous]) --> C
 *     H((interpolationMode)) --> C
 *     I((paddingMode)) --> C
 *     J((alignCorners)) --> C
 *     C --> K([l0op::ViewCopy]) --> Out1[("inputGrad")]
 *     C --> L([l0op::ViewCopy]) --> Out2[("gridGrad")]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGridSampler2DBackwardGetWorkspaceSize
 * 
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGridSampler2DBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GRID_SAMPLER2D_BACKWARD_H_// End content from: aclnn_grid_sampler2d_backward.h

// Begin content from: aclnn_all_to_all_all_gather_batch_matmul.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023-2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ALL_TO_ALL_ALL_GATHER_BATCH_MATMUL_
#define OP_API_INC_ALL_TO_ALL_ALL_GATHER_BATCH_MATMUL_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * alltoall + allGather + bmm 
 * @brief aclnnAlltoAllAllGatherBatchMatMulworkspace
 * @domain aclnn_ops_infer
 * @param [in] x: Tensorfloat16bfloat16AllToAllAllGather3NDBatchMatMul
 * @param [in] weight: Tensorfloat16, bfloat16x3NDBatchMatMul
 * @param [in] biasOptional: Tensorfloat16, float32xfloat16biasfloat16xbfloat16biasfloat32NDBatchMatMulbias
 * @param [in] groupEp: strep
 * @param [in] groupTp: strtpTensor
 * @param [in] epWorldSize: intepsize2/4/8/16
 * @param [in] tpWorldSize: inttpsize2/4/8/16
 * @param [in] xShardType: int00Htpallgather1Ctpallgathershard_type1
 * @param [in] actType: int00/1/2/3/4, [0: None, 1: GELU, 2: Silu, 3: Relu, 4: FastGELU]
 * @param [out] y1Out: Tensorfloat16, bfloat163BatchMatMulx
 * @param [out] y2OutOptional: Tensorfloat16, bfloat163AllGatherxallgather
 * @param [out] y3OutOptional: Tensorfloat16, bfloat163BatchMatMulxctType0bmm
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 *
 * BatchMatMulshapeep=epWorldSizetp=tpWorldSize
 * x: (E, C/tp, H)
 * weight(E/ep, H, M/tp)
 * bias(E/ep, 1, M/tp) shape(E/ep, M/tp)
 * y1(E/ep, ep * tp * C/tp, M/tp)
 * y2(E/ep, ep * tp * C/tp, H)
 * y3(E/ep, ep * tp * C/tp, M/tp)
 * 
 * x.size(0)Eweight.size(0)E/epx.size(0) = ep * weight.size(0)x.size(0)ep
 * E[2, 512]Eep
 * H[1, 65535]
 * M/tp[1, 65535]
 * E/ep[1, 32]
 * eptp24816
 * groupEpgroupTp
 * C0device
 * epAlltoAlltpAllGather
 */
ACLNN_API aclnnStatus aclnnAlltoAllAllGatherBatchMatMulGetWorkspaceSize(const aclTensor* x, const aclTensor* weight,
                                                                        const aclTensor* biasOptional, 
                                                                        const char* groupEp, const char* groupTp,
                                                                        int64_t epWorldSize, int64_t tpWorldSize,
                                                                        int64_t xShardType, int64_t actType,
                                                                        aclTensor* y1Out, aclTensor* y2OutOptional,
                                                                        aclTensor* y3OutOptional,
                                                                        uint64_t* workspaceSize,
                                                                        aclOpExecutor** executor);

/**
 * @brief aclnnAlltoAllAllGatherBatchMatMul
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAlltoAllAllGatherBatchMatMulGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAlltoAllAllGatherBatchMatMul(void* workspace, uint64_t workspaceSize,
                                                        aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ALL_TO_ALL_ALL_GATHER_BATCH_MATMUL_// End content from: aclnn_all_to_all_all_gather_batch_matmul.h

// Begin content from: aclnn_eq_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_EQTENSOR_H_
#define OP_API_INC_EQTENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnEqTensorworkspace
 * @domain aclnn_math
 * TensorTensorself=otherTrue(1.)False(0.)
 *
 * $$ out = (self == other)  ?  [True] : [False] $$
 *
 *
 * 
 * ```mermaid
 * graph LR
 *    A[(Self)] -->B([l0op::Contiguous])
 *    B -->C1([l0op::Cast])-->D([l0op::Equal])
 *    E[(other)] -->F([l0op::Contiguous])
 *    F --> C2([l0op::Cast])-->D
 *    D --> C3([l0op::Cast])-->F1([l0op::ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorFLOAT16,FLOAT,INT64,INT32,INT8,UINT8,BOOL,BFLOAT16,
 * DOUBLE,INT16,COMPLEX64,COMPLEX128shapeotherbroadcast
 * otherTensorND
 * @param [in] other: npu deviceaclTensorFLOAT16,FLOAT,INT64,INT32,INT8,UINT8,BOOL,BFLOAT16,
 * DOUBLE,INT16,COMPLEX64,COMPLEX128shapeselfbroadcast
 * selfTensorND
 * @param [in] out: npu deviceaclTensorFLOAT16,FLOAT,INT64,INT32,INT8,UINT8,BOOL,BFLOAT16,
 * DOUBLE,INT16,COMPLEX64,COMPLEX128ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEqTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnEqTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnEqTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEqTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceEqTensorworkspace
 * @domain aclnn_math
 *
 * selfRefotherselfRefotherselfRef
 *
 * $$ selfRef = (selfRef == other)  ?  [True] : [False] $$
 *
 * @param [in] selfRef: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,INT32,INT8,UINT8,BOOL,BFLOAT16(1971),DOUBLE,INT16,COMPLEX64,COMPLEX128
 * NDTensor
 * @param [in] other: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,INT32,INT8,UINT8,BOOL,BFLOAT16(1971) ,DOUBLE,INT16,COMPLEX64,COMPLEX128
 * NDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceEqTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceEqTensor
 *
 * selfRefotherselfRefotherselfRef
 *
 * $$ selfRef = (selfRef == other)  ?  [True] : [False] $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceEqTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_EQTENSOR_H_// End content from: aclnn_eq_tensor.h

// Begin content from: aclnn_trunc.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TRUNC_H_
#define OP_API_INC_TRUNC_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTruncworkspace
 * @domain aclnn_math
 *
 *  Tensortrunc
 * @param [in] selfRef: npu deviceaclTensor, FLOATBFLOAT16FLOAT16shapeout
 *  TensorND8
 * @param [in] out: npu deviceaclTensor, FLOATBFLOAT16FLOAT16, shapeselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTruncGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief: aclnnTrunc
 *
 *  Tensortrunc
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTruncGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTrunc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceTruncworkspace
 * @domain aclnn_math
 *
 *  Tensortrunc
 * @param [in] selfRef: npu deviceaclTensor,
 * FLOATFLOAT16TensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTruncGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size,
                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceTrunc
 *
 *  Tensortrunc
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTruncGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTrunc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TRUNC_H_// End content from: aclnn_trunc.h

// Begin content from: aclnn_le_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_LE_SCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_LE_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLeScalarworkspace
 * @domain aclnn_math
 * selfotherselfotherout
 * @param [in] self: npu deviceaclTensor
 * INT8,UINT8,INT16,UINT16,INT32,INT64,FLOAT16,FLOAT,DOUBLENDTensor
 * @param [in] other: hostaclScalarINT8,UINT8,INT16,UINT16,INT32,INT64,FLOAT16,FLOAT,DOUBLE
 * self
 * @param [in] out: npu deviceaclTensorINT8,UINT8,INT16,UINT16,INT32,INT64,FLOAT16,FLOAT,DOUBLE
 * shapeselfshapeND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLeScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLeScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLeScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceLeScalarGetWorkspaceSizeworkspace
 * @domain aclnn_math
 * selfRef Tensorother
 * ScalarselfRefselfRef<=otherTrueFalse
 * @param [in] selfRef: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,INT32,UINT8,BOOL,UINT64,UINT32,DOUBLE,UINT16BFLOAT16
 * shapeotherbroadcastTensorND
 * @param [in] other: hostaclScalarshapeotherbroadcast
 * @param [in] out: npu deviceaclTensorBOOLTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLeScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLeScalar
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLeScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_LE_SCALAR_H_
// End content from: aclnn_le_scalar.h

// Begin content from: aclnn_deep_norm_grad.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_DEEP_NORM_GRAD_H_
#define ACLNN_DEEP_NORM_GRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnDeepNormGradGetWorkspaceSize
 * parameters :
 * dy : required
 * x : required
 * gx : required
 * gamma : required
 * mean : required
 * rstd : required
 * alpha : optional
 * dxOut : required
 * dgxOut : required
 * dbetaOut : required
 * dgammaOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnDeepNormGradGetWorkspaceSize(
    const aclTensor *dy,
    const aclTensor *x,
    const aclTensor *gx,
    const aclTensor *gamma,
    const aclTensor *mean,
    const aclTensor *rstd,
    double alpha,
    const aclTensor *dxOut,
    const aclTensor *dgxOut,
    const aclTensor *dbetaOut,
    const aclTensor *dgammaOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnDeepNormGrad
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnDeepNormGrad(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_deep_norm_grad.h

// Begin content from: aclnn_stack.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_STACK_H_
#define OP_API_INC_STACK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnStackworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnStackGetWorkspaceSize(const aclTensorList* tensors, int64_t dim, aclTensor* out,
                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnStack
 */
ACLNN_API aclnnStatus aclnnStack(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                 const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_STACK_H_
// End content from: aclnn_stack.h

// Begin content from: aclnn_bincount.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BINCOUNT_H_
#define OP_API_INC_BINCOUNT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBincount workspace
 * @domain aclnn_math
 *
 * 
 * 
 * nselfiweights
 * out[n] = out[n] + weights[i]
 * 
 * out[n] = out[n] + 1
 *
 * @param [in] self: npu deviceaclTensorINT8INT16INT32INT64UINT8
 * 1NDTensor
 * @param [in] weights:  npu deviceaclTensorself
 * FLOATFLOAT16FLOAT64INT8INT16INT32INT64UINT8BOOL
 * 1NDshapeselfTensor
 * @param [in] minlength: hostinttensorsizeminlength
 * minlengthsize
 * @param [in] out: npu
 * deviceaclTensorINT32INT64FLOATDOUBLE1NDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBincountGetWorkspaceSize(const aclTensor* self, const aclTensor* weights, int64_t minlength,
                                                    aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnBincountworkspace
 *
 * 
 * 
 * nselfiweights
 * out[n] = out[n] + weights[i]
 * 
 * out[n] = out[n] + 1

 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnBincountGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBincount(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BINCOUNT_H_// End content from: aclnn_bincount.h

// Begin content from: aclnn_foreach_addcmul_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADDCMUL_SCALAR_LIST_H_
#define ACLNN_FOREACH_ADDCMUL_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddcmulScalarListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * x3 : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcmulScalarListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *x3,
    const aclTensor *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddcmulScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcmulScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_addcmul_scalar_list.h

// Begin content from: aclnn_upsample_bicubic_2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023 All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_BICUBIC_2D_BACKWARD_H_
#define OP_API_INC_UNAMPLE_BICUBIC_2D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleBicubic2dBackward
 */
ACLNN_API aclnnStatus aclnnUpsampleBicubic2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                     aclrtStream stream);

/**
 * @brief aclnnUpsampleBicubic2dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnUpsampleBicubic2dBackwardGetWorkspaceSize(
    const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, const bool alignCorners,
    double scalesH, double scalesW, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_Bicubic_2D_BACKWARD_H_// End content from: aclnn_upsample_bicubic_2d_backward.h

// Begin content from: aclnn_bitwise_and_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BITWISE_AND_SCALAR_H_
#define OP_API_INC_BITWISE_AND_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBitwiseAndScalarworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output_i = self_i\&other_i $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([LogicalAnd])
 *     D[(other)] -->G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 * 
 * selfotherINTl0::BitwiseAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([BitwiseAnd])
 *     D[(other)] -->G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorINT16,UINT16,INT32,INT64,INT8,UINT8,BOOL
 * otherTensorND
 * @param [in] other:
 * hostaclScalarINT16,UINT16,INT32,INT64,INT8,UINT8,BOOLself
 * @param [in] out: npu deviceaclTensorINT16,UINT16,INT32,INT64,INT8,UINT8,BOOL
 * selfothershapeselfNDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseAndScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnBitwiseAndScalar
 *
 * 
 * 
 * $$ output_i = self_i\&other_i $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([LogicalAnd])
 *     D[(other)] -->G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 * 
 * selfotherINTl0::BitwiseAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([BitwiseAnd])
 *     D[(other)] -->G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnBitwiseAndScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseAndScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

/**
 * @brief aclnnInplaceBitwiseAndScalarworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output_i = self_i\&other_i $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([LogicalAnd])
 *     D[(other)] -->G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 * 
 * selfotherINTl0::BitwiseAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([BitwiseAnd])
 *     D[(other)] -->G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorINT16,UINT16,INT32,INT64,INT8,UINT8,BOOL
 * otherTensorND
 * @param [in] other:
 * hostaclScalarINT16,UINT16,INT32,INT64,INT8,UINT8,BOOLself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseAndScalarGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* other,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBitwiseAndScalar
 *
 * 
 * 
 * $$ output_i = self_i\&other_i $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([LogicalAnd])
 *     D[(other)] -->G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 * 
 * selfotherINTl0::BitwiseAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([BitwiseAnd])
 *     D[(other)] -->G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceBitwiseAndScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseAndScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BITWISE_AND_SCALAR_H_
// End content from: aclnn_bitwise_and_scalar.h

// Begin content from: aclnn_batch_norm_elemt.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_BATCH_NORM_ELEMT_H_
#define OP_API_INC_BATCH_NORM_ELEMT_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchNormElemtworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnBatchNormElemtGetWorkspaceSize(const aclTensor* input, const aclTensor* weight,
                                                          const aclTensor* bias, aclTensor* mean, aclTensor* invstd,
                                                          double eps, aclTensor* output, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

/**
 * @brief aclnnBatchNormElemt
 */
ACLNN_API aclnnStatus aclnnBatchNormElemt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_batch_norm_elemt.h

// Begin content from: aclnn_grouped_mat_mul_all_reduce.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GROUPED_MATMUL_ALL_REDUCE_H_
#define OP_API_INC_GROUPED_MATMUL_ALL_REDUCE_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupedMatMulAllReduceworkspace
 * @domain aclnnop_ops_infer
 *  gmm + AllReduce 
 * @param [in] x: xFLOAT16BFLOAT16ND128
 * @param [in] weight:
 * weightFLOAT16BFLOAT16ND128
 * @param [in] bias: biasFLOAT16BFLOAT16ND128
 * @param [in] groupListOptional:
 * MmatmulINT64128
 * @param [in] splitItemOptional:
 * tensor12
 * 3
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl0/1.
 * @param [out] out: outFLOAT16BFLOAT16ND128
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatMulAllReduceGetWorkspaceSize(
    const aclTensorList* x, const aclTensorList* weight, const aclTensorList* bias,
    const aclIntArray* groupListOptional, int64_t splitItem, const char* group, const char* reduceOp, int64_t commTurn,
    int64_t streamMode, const aclTensorList* y, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGroupedMatMulAllReduce
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGtTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatMulAllReduce(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif
#endif  // OP_API_INC_GROUPED_MATMUL_ALL_REDUCE_H_// End content from: aclnn_grouped_mat_mul_all_reduce.h

// Begin content from: aclnn_linalg_qr.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LINALG_QR_H_
#define OP_API_INC_LINALG_QR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLinalgQrworkspace
 * @domain aclnn_math
 *
 *  TensorQR
 * @param [in] self: , FLOATFLOAT16DOUBLECOMPLEX64COMPLEX128, ND,
 * Tensor
 * @param [in] mode: , tensor shapecomplete, int64_t
 * @param [out] Q: ,
 * QrFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128self ND,
 * Tensor
 * @param [out] R: ,
 * QrFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128self ND,
 * Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLinalgQrGetWorkspaceSize(const aclTensor* self, int64_t mode, aclTensor* Q, aclTensor* R,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnLinalgQr
 *
 *  TensorQr 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLinalgQrGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLinalgQr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LINALG_QR_H_
// End content from: aclnn_linalg_qr.h

// Begin content from: aclnn_chamfer_distance_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CHAMFER_DISTANCE_BACKWARD_H_
#define OP_API_INC_CHAMFER_DISTANCE_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnChamferDistanceBackward
 */
ACLNN_API aclnnStatus aclnnChamferDistanceBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   aclrtStream stream);

/**
 * @brief aclnnChamferDistanceBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnChamferDistanceBackwardGetWorkspaceSize(const aclTensor* xyz1, const aclTensor* xyz2,
                                                                   const aclTensor* idx1, const aclTensor* idx2,
                                                                   const aclTensor* gradDist1,
                                                                   const aclTensor* gradDist2, aclTensor* gradXyz1,
                                                                   aclTensor* gradXyz2, uint64_t* workspaceSize,
                                                                   aclOpExecutor** executor);
#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_chamfer_distance_backward.h

// Begin content from: aclnn_cumsum.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_CUMSUM_H_
#define OP_API_INC_LEVEL2_ACLNN_CUMSUM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * selfdimout
 * 
 * $x_{i}$selfdimdim
 * $y_{i}$out
 *
 * $$
 * y_{i} = x_{1} + x_{2} + x_{3} + ...... + x_{i}
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] --> B([l0op::Contiguous])
 *     B --> C([l0op::Cast])
 *     C --> D([l0op::Cumsum])
 *     E((dim)) --> D
 *     F((dtype)) --> C
 *     D --> G([l0op::ViewCopy])
 *     G --> H[(out)]
 * ```
 */

/**
 * @brief aclnnCumsumworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * deviceaclTensorFLOATDOUBLECOMPLEX64COMPLEX128UINT8INT8INT16INT32
 * INT64FLOAT16BFLOAT16BOOLoutTensorND8
 * @param [in] dim: hostINT64
 * @param [in]
 * dtypehostFLOATFLOAT16INT32DOUBLEUINT8INT8INT16
 * INT64COMPLEX64COMPLEX128BFLOAT16910Bout
 * @param [in] outnpu deviceaclTensorFLOATFLOAT16INT32DOUBLEUINT8INT8INT16INT64
 * COMPLEX64COMPLEX128BFLOAT16910BdtypeshapeselfTensor
 * ND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCumsumGetWorkspaceSize(const aclTensor* self, int64_t dim, aclDataType dtype, aclTensor* out,
                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnCumsum
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCumsumGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCumsum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnCumsumV2workspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnCumsumV2GetWorkspaceSize(const aclTensor* self, int64_t dim, bool exclusive, bool reverse,
                                                    aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnCumsumV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_CUMSUM_H_
// End content from: aclnn_cumsum.h

// Begin content from: aclnn_foreach_exp.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_EXP_H_
#define ACLNN_FOREACH_EXP_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachExpGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachExpGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachExp
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachExp(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_exp.h

// Begin content from: aclnn_foreach_copy.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_COPY_H_
#define ACLNN_FOREACH_COPY_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachCopyGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachCopyGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachCopy
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachCopy(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_copy.h

// Begin content from: aclnn_foreach_neg.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_NEG_H_
#define ACLNN_FOREACH_NEG_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachNegGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachNegGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachNeg
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachNeg(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_neg.h

// Begin content from: aclnn_embedding.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_EMBEDDING_H_
#define OP_API_INC_EMBEDDING_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnEmbeddingworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(weight)] --> B([l0op::Contiguous])
 *     B --> C([l0op::GatherV2])
 *     D[(indices)] --> E([l0op::Contiguous]) --> C
 *     F((dim=0)) --> G[(dimTensor)] --> C
 *     C --> H([l0op::ViewCopy]) --> Out[(out)]
 * ```
 *
 * @param [in] weight: npu
 * deviceaclTensorBFLOAT16,
 * FLOATFLOAT16INT64INT32INT16INT8UINT8BOOLDOUBLECOMPLEX64
 * COMPLEX128TensorND
 * @param [in] indices: npu
 * deviceaclTensorINT64INT32TensorND
 * @param [out] out: npu
 * deviceaclTensorweightNDindices1
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEmbeddingGetWorkspaceSize(const aclTensor* weight, const aclTensor* indices,
                                                     const aclTensor* out, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnEmbedding
 *
 * * 
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(weight)] --> B([l0op::Contiguous])
 *     B --> C([l0op::GatherV2])
 *     D[(indices)] --> E([l0op::Contiguous]) --> C
 *     F((dim=0)) --> G[(dimTensor)] --> C
 *     C --> H([l0op::ViewCopy]) --> Out[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnEmbeddingGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEmbedding(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_EMBEDDING_H_// End content from: aclnn_embedding.h

// Begin content from: aclnn_foreach_cos.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_COS_H_
#define ACLNN_FOREACH_COS_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachCosGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachCosGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachCos
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachCos(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_cos.h

// Begin content from: aclnn_upsample_nearest_2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_NEAREST_2D_BACKWARD_H_
#define OP_API_INC_UNAMPLE_NEAREST_2D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearest2dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * upsample_nearest2d
 *
 * @param [in] gradOut: npu deviceaclTensorFLOATBFLOAT16FLOAT16
 * [Tensor](#Tensor)NCHWNHWC[](#)
 * @param [in] outputSize: IntArraysize2gradOutHW
 * @param [in] inputSize: IntArraysize4outNCHW
 * @param [in] scalesH: doubleoutheight
 * @param [in] scalesW: doubleoutwidth
 * @param [out] gradInput: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16gradOut
 * [Tensor](#Tensor)NCHWNHWC[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest2dBackwardGetWorkspaceSize(const aclTensor* gradOut,
                                                                     const aclIntArray* outputSize,
                                                                     const aclIntArray* inputSize, double scalesH,
                                                                     double scalesW, aclTensor* gradInput,
                                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleNearest2dBackward
 *
 * upsample_nearest2d
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace
 * aclnnUpsampleNearest2dBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_2D_BACKWARD_H_
// End content from: aclnn_upsample_nearest_2d_backward.h

// Begin content from: aclnn_add_layer_norm_grad.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_ADD_LAYER_NORM_GRAD_H_
#define ACLNN_ADD_LAYER_NORM_GRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnAddLayerNormGradGetWorkspaceSize
 * parameters :
 * dy : required
 * x1 : required
 * x2 : required
 * rstd : required
 * mean : required
 * gamma : required
 * dsumOptional : optional
 * dxOut : required
 * dgammaOut : required
 * dbetaOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnAddLayerNormGradGetWorkspaceSize(
    const aclTensor *dy,
    const aclTensor *x1,
    const aclTensor *x2,
    const aclTensor *rstd,
    const aclTensor *mean,
    const aclTensor *gamma,
    const aclTensor *dsumOptional,
    const aclTensor *dxOut,
    const aclTensor *dgammaOut,
    const aclTensor *dbetaOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnAddLayerNormGrad
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnAddLayerNormGrad(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_add_layer_norm_grad.h

// Begin content from: aclnn_ne_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_NE_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_NE_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNeTensorworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,UINT64,INT32,INT8,UINT8,BOOL,UINT32,BFLOAT16,INT16
 * shapeotherbroadcastTensorND
 * @param [in] other: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,UINT64,INT32,INT8,UINT8,BOOL,UINT32,BFLOAT16,INT16
 * shapeotherbroadcastTensorND
 * @param [in] out: npu deviceaclTensorBOOLTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNeTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnNeTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnNeTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceNeTensorworkspace
 * @domain aclnn_math
 * @param [in] selfRef: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,UINT64,INT32,INT8,UINT8,BOOL,UINT32,BFLOAT16,INT16
 * shapeotherbroadcastTensorNDselfRef
 * @param [in] other: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,UINT64,INT32,INT8,UINT8,BOOL,UINT32,BFLOAT16,INT16
 * shapeotherbroadcastTensorND
 * @param [in] out: npu deviceaclTensorBOOLTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNeTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceNeTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceNeTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_NE_TENSOR_H_// End content from: aclnn_ne_tensor.h

// Begin content from: aclnn_logical_or.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LogicalOr_H_
#define OP_API_INC_LogicalOr_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogicalOrworkspace
 * @domain aclnn_math
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A1[(self)] -->B1([Contiguous])-->C1([Cast])-->D([LogicalOr])
 * A2[(other)]-->B2([Contiguous])-->C2([Cast])-->D([LogicalOr])
 * D([LogicalOr])-->E([Cast])-->F([ViewCopy])-->G[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * shapeotherbroadcastTensorNDother
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL,
 * shapeselfbroadcastTensorNDself
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * shapeselfotherbroadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogicalOrGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogicalOr
 *
 * 
 *
 * 
 * api:
 * ```mermaid
 * graph LR
 * A1[(self)] -->B1([Contiguous])-->C1([Cast])-->D([LogicalOr])
 * A2[(other)]-->B2([Contiguous])-->C2([Cast])-->D([LogicalOr])
 * D([LogicalOr])-->E([Cast])-->F([ViewCopy])-->G[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLogicalOrGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogicalOr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

/**
 * @brief aclnnInplaceLogicalOrworkspace
 * @domain aclnn_math
 * @param [in] selfRef: npu deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8
 * BOOLCOMPLEX64COMPLEX128BFLOAT16910BshapeotherbroadcastbroadcastshapeselfRef
 * shapeTensorND
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX64COMPLEX128BFLOAT16910BshapeselfRefbroadcastTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLogicalOrGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                            uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLogicalOr
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceLogicalOrGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLogicalOr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LogicalOr_H_
// End content from: aclnn_logical_or.h

// Begin content from: aclnn_split_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_SPLIT_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_SPLIT_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSplitTensorworkspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16DOUBLEBFLOAT16INT32INT64INT16INT8
 * UINT8BOOLCOMPLEX128COMPLEX64TensorND
 * @param [in] splitSections: host, UINT64dim,
 * splitSections
 * @param [in] dim: hostINT64tensorsplit
 * @param [in] out: npu deviceaclTensorListsplittensorFLOATFLOAT16DOUBLE
 * BFLOAT16INT32INT64INT16INT8UINT8BOOLCOMPLEX128COMPLEX64TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSplitTensorGetWorkspaceSize(const aclTensor* self, uint64_t splitSections, int64_t dim,
                                                       aclTensorList* out, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnSplitTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSplitTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSplitTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SPLIT_TENSOR_H_
// End content from: aclnn_split_tensor.h

// Begin content from: aclnn_log10.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOG10_H_
#define OP_API_INC_LOG10_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLog10workspace
 * @domain aclnn_math
 *
 * 10
 * 
 * $$ output_i=log_{10}(self_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([l0op::Contiguous])
 *     B -->C([l0op::Cast])
 *     C -->D([l0op::Log])
 *     D -->E([l0op::Cast])
 *     E -->I([l0op::ViewCopy])
 *     I -->J[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorBOOLINT8INT16INT32INT64UINT8FLOATFLOAT16BFLOAT16
 *                   TensorND
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16BFLOAT16self
 *                  shapeselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLog10GetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnLog10
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLog10GetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLog10(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceLog10workspace
 * @domain aclnn_math
 *
 * 10Tensor
 * 
 * $$ output_i=log_{10}(self_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([l0op::Contiguous])
 *     B -->C([l0op::Cast])
 *     C -->D([l0op::Log])
 *     D -->E([l0op::Cast])
 *     E -->I([l0op::ViewCopy])
 *     I -->J[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorBOOLINT8INT16INT32INT64UINT8FLOATFLOAT16BFLOAT16
 *                   TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLog10GetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLog10
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceLog10GetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLog10(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOG10_H_
// End content from: aclnn_log10.h

// Begin content from: aclnn_global_max_pool.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GLOBAL_MAX_POOL_H_
#define OP_API_INC_GLOBAL_MAX_POOL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGlobalMaxPoolworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * @param [in] self: npu
 * npu deviceaclTensorFLOAT16FLOAT32DOUBLE
 * TensorND
 * @param [in] out:
 * npu deviceaclTensorFLOAT16FLOAT32DOUBLETensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGlobalMaxPoolGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnGlobalMaxPool
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGlobalMaxPoolGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGlobalMaxPool(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GLOBAL_MAX_POOL_H_// End content from: aclnn_global_max_pool.h

// Begin content from: aclnn_max_pool.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_MAX_POOL_H_
#define OP_API_INC_LEVEL2_ACLNN_MAX_POOL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxPoolworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnMaxPoolGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelShape,
                                                   const aclIntArray* strides, const int64_t autoPad,
                                                   const aclIntArray* pads, const aclIntArray* dilations,
                                                   const int64_t ceilMode, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnMaxPool
 */
ACLNN_API aclnnStatus aclnnMaxPool(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_MAX_POOL_H_// End content from: aclnn_max_pool.h

// Begin content from: aclnn_upsample_linear_1d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNAMPLE_LINEAR_H_
#define OP_API_INC_UNAMPLE_LINEAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleLinear1d
 */
ACLNN_API aclnnStatus aclnnUpsampleLinear1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

/**
 * @brief aclnnUpsampleLinear1dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleLinear1dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                            const bool alignCorners, const double scales,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_LINEAR_H_// End content from: aclnn_upsample_linear_1d.h

// Begin content from: aclnn_sinh.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SINH_H_
#define OP_API_INC_SINH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSinhworkspace
 * @domain aclnn_math
 *
 *  Tensorsinh
 * @param [in] selfRef: npu deviceaclTensor, INT8INT16INT32, INT64, UINT8BOOLFLOATFLOAT16
 *  BFLOAT16DOUBLECOMPLEX64COMPLEX128shapeTensorND
 * @param [in] out: npu deviceaclTensor, FLOATBFLOAT16FLOAT16DOUBLECOMPLEX64COMPLEX128,
 * shapeself ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSinhGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief: aclnnSinh
 *
 *  Tensorsinh
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSinhGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSinh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceSinhworkspace
 * @domain aclnn_math
 *
 *  Tensorsinh
 * @param [in] selfRef: npu deviceaclTensor, INT8INT16INT32, INT64, UINT8BOOLFLOAT
 *  FLOAT16BFLOAT16DOUBLECOMPLEX64COMPLEX128shapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSinhGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size,
                                                       aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceSinh
 *
 *  Tensorsinh
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSinhGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSinh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SINH_H_// End content from: aclnn_sinh.h

// Begin content from: aclnn_foreach_sub_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_SUB_LIST_H_
#define ACLNN_FOREACH_SUB_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachSubListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * alpha : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSubListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensor *alpha,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachSubList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSubList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sub_list.h

// Begin content from: aclnn_foreach_sin.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_SIN_H_
#define ACLNN_FOREACH_SIN_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachSinGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSinGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachSin
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSin(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sin.h

// Begin content from: aclnn_upsample_nearest_3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_NEAREST_3D_H_
#define OP_API_INC_UNAMPLE_NEAREST_3D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearest3dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                             double scalesD, double scalesH, double scalesW,
                                                             aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleNearest3d
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_3D_H_
// End content from: aclnn_upsample_nearest_3d.h

// Begin content from: aclnn_hardsigmoid_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_HARDSIGMOID_BACKWARD_H_
#define OP_API_INC_HARDSIGMOID_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHardsigmoidBackwardworkspace
 * @domain aclnn_ops_train
 *
 * hardsigmoid
 *
 * @param [in] gradOutput(aclTensor*, ): FLOATFLOAT16TensorND
 * @param [in] self(aclTensor*, ): FLOATFLOAT16TensorND
 * @param [out] out(aclTensor*, ): FLOATFLOAT16TensorND
 * @param [out] workspace_size(uint64_t*, ): npu deviceworkspace
 * @param [out] executor(aclOpExecutor**, ): op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardsigmoidBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                               aclTensor* out, uint64_t* workspaceSize,
                                                               aclOpExecutor** executor);

/**
 * @brief aclnnHardsigmoidBackward
 *
 * hardsigmoid
 *
 * @param [in] workspace(void*, ): npu deviceworkspace
 * @param [in] workspaceSize(uint64_t, ): npu
 * deviceworkspaceaclnnHardsigmoidBackwardGetWorkspaceSize
 * @param [in] executor(aclOpExecutor*, ): op
 * @param [in] stream(aclrtStream, ): acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardsigmoidBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_HARDSIGMOID_BACKWARD_H_
// End content from: aclnn_hardsigmoid_backward.h

// Begin content from: aclnn_moe_gating_top_k_softmax_v2.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_GATING_TOP_KSOFTMAX_V2_H_
#define ACLNN_MOE_GATING_TOP_KSOFTMAX_V2_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeGatingTopKSoftmaxV2GetWorkspaceSize
 * parameters :
 * x : required
 * finishedOptional : optional
 * k : required
 * renorm : optional
 * outputSoftmaxResultFlag : optional
 * yOut : required
 * expertIdxOut : required
 * softmaxResultOutOptional : optional
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeGatingTopKSoftmaxV2GetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *finishedOptional,
    int64_t k,
    int64_t renorm,
    bool outputSoftmaxResultFlag,
    const aclTensor *yOut,
    const aclTensor *expertIdxOut,
    const aclTensor *softmaxResultOutOptional,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeGatingTopKSoftmaxV2
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeGatingTopKSoftmaxV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_gating_top_k_softmax_v2.h

// Begin content from: aclnn_mse_loss_out.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MSE_LOSS_OUT_H_
#define OP_API_INC_MSE_LOSS_OUT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMseLossOutworkspace
 * @domain aclnn_ops_train
 *
 * xy
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16shapetargetbroadcast
 * TensorND
 * @param [in] target: npu deviceaclTensorFLOATFLOAT16shapeselfbroadcast
 * TensorND
 * @param [in] reduction: hostint64 0('none') | 1('mean') | 2('sum')
 * 'none' 'mean' reduce 0'sum' reduce 0
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMseLossOutGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction,
                                                      aclTensor* out, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnMseLossOut
 *
 * xy
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnMseLossOutGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMseLossOut(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MSE_LOSS_OUT_H_
// End content from: aclnn_mse_loss_out.h

// Begin content from: aclnn_moe_gating_top_k_softmax.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_GATING_TOP_KSOFTMAX_H_
#define ACLNN_MOE_GATING_TOP_KSOFTMAX_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeGatingTopKSoftmaxGetWorkspaceSize
 * parameters :
 * x : required
 * finishedOptional : optional
 * k : required
 * yOut : required
 * expertIdxOut : required
 * rowIdxOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeGatingTopKSoftmaxGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *finishedOptional,
    int64_t k,
    const aclTensor *yOut,
    const aclTensor *expertIdxOut,
    const aclTensor *rowIdxOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeGatingTopKSoftmax
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeGatingTopKSoftmax(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_gating_top_k_softmax.h

// Begin content from: aclnn_addcdiv.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ADDCDIV_H_
#define OP_API_INC_ADDCDIV_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAddcdivworkspace
 * @domain aclnn_math
 *
 *  tensor1  tensor2  value  input
 * 
 * $$ out_i = self_i + value \times {tensor1_i \over tensor2_i} $$
 *
 * 
 * api
 * ```mermaid
 graph LR
 *  A[(self)] -->B([l0op::Contiguous])
 *  B --> K([l0op::Cast])
 *  K --> C([l0op::Addcdiv])
 *  D[(tensor1)] -->E([l0op::Contiguous])
 *  E --> L([l0op::Cast])
 *  L --> C
 *  F[(tensor2)] --> G([l0op::Contiguous])
 *  G --> M([l0op::Cast])
 *  M --> C
 *  H((value)) --> C
 *  C --> O([l0op::Cast])
 *  O --> I([l0op::ViewCopy])
 *  I --> J[(out)]
 * ```
 *
 * @param [in] self: npu
 * npu deviceaclTensorDT_BFLOAT16DT_FLOAT16DT_FLOATDT_DOUBLEDT_INT64
 *
 tensor1tensor2shapetensor1tensor2tensorbroadcastTensorND
 * @param [in] tensor1: npu
 * npu deviceaclTensorDT_BFLOAT16DT_FLOAT16DT_FLOATDT_DOUBLEDT_INT64
 * selftensor2shapetensor2broadcastTensorND
 * @param [in] tensor2: npu
 * npu deviceaclTensorDT_BFLOAT16DT_FLOAT16DT_FLOATDT_DOUBLEDT_INT64
 * selftensor1shapetensor1broadcastTensorND
 * @param [in] value: hostaclScalarselftensor1tensor2
 * @param [in] out: npu
 * npu deviceaclTensorDT_FLOAT16DT_FLOATDT_DOUBLEDT_INT64
 * selftensor1tensor2shapeselftensor1tensor2
 broadcastshapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddcdivGetWorkspaceSize(const aclTensor* self, const aclTensor* tensor1,
                                                   const aclTensor* tensor2, const aclScalar* value,
                                                   const aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnAddcdiv
 *
 * *  tensor1  tensor2  value  input
 * 
 * $$ out_i = self_i + value \times {tensor1_i \over tensor2_i} $$
 *
 * 
 * api
 * ```mermaid
 graph LR
 *  A[(self)] -->B([l0op::Contiguous])
 *  B --> K([l0op::Cast])
 *  K --> C([l0op::Addcdiv])
 *  D[(tensor1)] -->E([l0op::Contiguous])
 *  E --> L([l0op::Cast])
 *  L --> C
 *  F[(tensor2)] --> G([l0op::Contiguous])
 *  G --> M([l0op::Cast])
 *  M --> C
 *  H((value)) --> C
 *  C --> O([l0op::Cast])
 *  O --> I([l0op::ViewCopy])
 *  I --> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddcdivGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddcdiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   const aclrtStream stream);

/**
 * @brief aclnnInplaceAddcdivworkspace
 * @domain aclnn_math
 *
 *  tensor1  tensor2  value  input
 * 
 * $$ out_i = self_i + value \times {tensor1_i \over tensor2_i} $$
 *
 * 
 * api
 * ```mermaid
 graph LR
 *  A[(self)] -->B([l0op::Contiguous])
 *  B --> K([l0op::Cast])
 *  K --> C([l0op::Addcdiv])
 *  D[(tensor1)] -->E([l0op::Contiguous])
 *  E --> L([l0op::Cast])
 *  L --> C
 *  F[(tensor2)] --> G([l0op::Contiguous])
 *  G --> M([l0op::Cast])
 *  M --> C
 *  H((value)) --> C
 *  C --> O([l0op::Cast])
 *  O --> I([l0op::ViewCopy])
 *  I --> J[(out)]
 * ```
 *
 * @param [in] selfRef: npu
 * npu deviceaclTensorDT_BFLOAT16DT_FLOAT16DT_FLOATDT_DOUBLEDT_INT64
 *
 tensor1tensor2shapetensor1tensor2tensorbroadcastTensorND
 * @param [in] tensor1: npu
 * npu deviceaclTensorDT_BFLOAT16DT_FLOAT16DT_FLOATDT_DOUBLEDT_INT64
 * selftensor2shapetensor2broadcastTensorND
 * @param [in] tensor2: npu
 * npu deviceaclTensorDT_BFLOAT16DT_FLOAT16DT_FLOATDT_DOUBLEDT_INT64
 * selftensor1shapetensor1broadcastTensorND
 * @param [in] value: hostaclScalarselftensor1tensor2
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAddcdivGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* tensor1,
                                                          const aclTensor* tensor2, const aclScalar* value,
                                                          uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceAddcdiv
 *
 * *  tensor1  tensor2  value  input
 * 
 * $$ out_i = self_i + value \times {tensor1_i \over tensor2_i} $$
 *
 * 
 * api
 * ```mermaid
 graph LR
 *  A[(self)] -->B([l0op::Contiguous])
 *  B --> K([l0op::Cast])
 *  K --> C([l0op::Addcdiv])
 *  D[(tensor1)] -->E([l0op::Contiguous])
 *  E --> L([l0op::Cast])
 *  L --> C
 *  F[(tensor2)] --> G([l0op::Contiguous])
 *  G --> M([l0op::Cast])
 *  M --> C
 *  H((value)) --> C
 *  C --> O([l0op::Cast])
 *  O --> I([l0op::ViewCopy])
 *  I --> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddcdivGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAddcdiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADDCDIV_H_
// End content from: aclnn_addcdiv.h

// Begin content from: aclnn_foreach_sign.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_SIGN_H_
#define ACLNN_FOREACH_SIGN_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachSignGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSignGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachSign
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSign(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sign.h

// Begin content from: aclnn_all_gather_matmul.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ALL_GATHER_MATMUL_
#define OP_API_INC_ALL_GATHER_MATMUL_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * allGather + mm 
 * @brief aclnnAllGatherMatmulworkspace
 * @domain aclnn_ops_infer
 * @param [in] x1: matmulfloat16, bf16
 * @param [in] x2: matmulfloat16, bf16
 * @param [in] bias: float16, bf16
 * @param [in] group: 
 * @param [in] gatherIndex: gather010
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl0/1
 * @param [out] output: +
 * @param [out] gatherOut: gather
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAllGatherMatmulGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                           const aclTensor* bias, const char* group,
                                                           int64_t gatherIndex, int64_t commTurn, int64_t streamMode,
                                                           const aclTensor* output, const aclTensor* gatherOut,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAllGatherMatmul
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAbsGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAllGatherMatmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ALL_GATHER_MATMUL_// End content from: aclnn_all_gather_matmul.h

// Begin content from: aclnn_foreach_minimum_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MINIMUM_SCALAR_H_
#define ACLNN_FOREACH_MINIMUM_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMinimumScalarGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMinimumScalarGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMinimumScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMinimumScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_minimum_scalar.h

// Begin content from: aclnn_sort.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SORT_H_
#define OP_API_INC_SORT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSortworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorsort
 * @param [in] self: npu
 * deviceaclTensorFLOAT16FLOAT32INT8INT16INT32INT64UINT8Tensor
 * [Tensor](#)
 * @param [in] stable: , TrueFalse, BOOLEAN
 * @param [in] dim: , INT [-N, N-1]
 * @param [in] descending: TrueFalse, BOOLEAN
 * @param [in] valuesOut: npu deviceaclTensor, FLOAT16FLOAT32INT8INT16INT32INT64UINT8
 * Tensor[Tensor](#)ND([](#))shapeself
 * @param [in] indicesOut: npu deviceaclTensor,
 * INT64Tensor[Tensor](#) ND([](#))shapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSortGetWorkspaceSize(const aclTensor* self, bool stable, int64_t dim, bool descending,
                                                aclTensor* valuesOut, aclTensor* indicesOut, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief: aclnnSort
 *
 *  Tensorsort
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSortGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSort(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_sort.h

// Begin content from: aclnn_foreach_mul_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MUL_LIST_H_
#define ACLNN_FOREACH_MUL_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMulListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMulListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMulList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMulList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_mul_list.h

// Begin content from: aclnn_foreach_maximum_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MAXIMUM_SCALAR_H_
#define ACLNN_FOREACH_MAXIMUM_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMaximumScalarGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMaximumScalarGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMaximumScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMaximumScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_maximum_scalar.h

// Begin content from: aclnn_adaptive_avg_pool2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_AdaptiveAvgPool2dBackward_H_
#define OP_API_INC_AdaptiveAvgPool2dBackward_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAdaptiveAvgPool2dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * aclnnAdaptiveAvgPool2d
 *
 * 
 * api
 * ```mermaid
 * @param [in] gradOutput: npu deviceaclTensorFLOAT16FLOAT32
 * selfTensorNCHWself
 * @param [in] self: npu deviceaclTensorFLOAT16FLOAT32,
 * TensorNCHW
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnAdaptiveAvgPool2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                     aclTensor* out, uint64_t* workspaceSize,
                                                                     aclOpExecutor** executor);

/**
 * @brief aclnnAdaptiveAvgPool2dBackward
 *
 * aclnnAdaptiveAvgPool2d
 *
 * 
 * api
 * ```mermaid
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnAdaptiveAvgPool2dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAdaptiveAvgPool2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                     const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AdaptiveAvgPool2dBackward_H_
// End content from: aclnn_adaptive_avg_pool2d_backward.h

// Begin content from: aclnn_foreach_addcmul_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADDCMUL_SCALAR_H_
#define ACLNN_FOREACH_ADDCMUL_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddcmulScalarGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * x3 : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcmulScalarGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *x3,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddcmulScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcmulScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_addcmul_scalar.h

// Begin content from: aclnn_masked_fill_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MASKEF_FILL_TENSOR_H_
#define OP_API_INC_MASKEF_FILL_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceMaskedFillTensorworkspace
 * @domain aclnn_ops_infer
 *
 * valueselfRefmasktrue
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *  A[(selfRef)] -->B([Contiguous])
 *  B  -->C([Unsqueeze])
 *  C  -->D([MaskedFill])
 *  D  -->I([Squeeze])
 *  I   --> J([ViewCopy])
 *  J   --> K[(out)]
 *
 *  A1[(mask)] -->B1([Contiguous])
 *  B1  -->C1([Cast])
 *  C1  -->D
 *
 *  A2[(value)]-->B2[(Cast)]
 *  B2-->D
 * ```
 *
 * @param [in] selfRef: npu deviceaclTensorBOOLUINT8INT8INT16INT32INT64FLOAT
 *                      FLOAT16BFLOAT16DOUBLECOMPLEX64COMPLEX128
 *                      TensorND
 * @param [in] mask: npu deviceaclTensorBOOLshapeselfRefbroadcastND
 * @param [in] value: npu deviceaclTensorshapeselfRefbroadcastND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMaskedFillTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* mask,
                                                                   const aclTensor* value, uint64_t* workspaceSize,
                                                                   aclOpExecutor** executor);
/**
 * @brief aclnnInplaceMaskedFillTensor
 *
 * valueselfRefmasktrue
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *  A[(selfRef)] -->B([Contiguous])
 *  B  -->C([Unsqueeze])
 *  C  -->D([MaskedFill])
 *  D  -->I([Squeeze])
 *  I   --> J([ViewCopy])
 *  J   --> K[(out)]
 *
 *  A2[(mask)] -->B2([Contiguous])
 *  B2 --> C2([Cast])
 *  C2  -->D
 *
 *  A1[(value)]-->B1([Contiguous])
 *  B1-->C1([Cast])
 *  C1-->D
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnInplaceMaskedFillTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMaskedFillTensor(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MASKEF_FILL_TENSOR_H_// End content from: aclnn_masked_fill_tensor.h

// Begin content from: aclnn_reduce_log_sum.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REDUCE_LOG_SUM_H_
#define OP_API_INC_REDUCE_LOG_SUM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnReduceLogSumworkspace
 * @domain aclnn_math
 * * tensor
 * @param [in] data: 8DeviceaclTensor[Tensor](common/Tensor.md)
 * FLOAT16FLOAT32[](common/.md)ND
 * @param [in] axes: HostaclIntArrayINT64[-self.dim(), self.dim()-1]
 * @param [in] keepDims: HostBOOL
 * @param [in] noopWithEmptyAxes: axesfalsetrueHostBOOL
 * @param [in] reduce: 8DeviceaclTensor[Tensor](common/Tensor.md)
 * FLOAT16FLOAT32data[](common/.md)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReduceLogSumGetWorkspaceSize(const aclTensor* data, const aclIntArray* axes, bool keepDims,
                                                     bool noopWithEmptyAxes, aclTensor* reduce, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnReduceLogSum
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceRandom
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReduceLogSum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REDUCE_LOG_SUM_H_
// End content from: aclnn_reduce_log_sum.h

// Begin content from: aclnn_zero.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_Zero_H_
#define OP_API_INC_Zero_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceZeroworkspace
 * @domain aclnn_math
 *
 * self
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(selfRef)]-->B([l0op::Contiguous])
 *     B-->C([l0op::Zeros_Like])
 *     C-->D([l0op::ViewCopy])
 *     D-->E[(selfRef)]
 * ```
 *
 * @param [in] selfRef: npu
 * deviceaclTensorINT8INT16INT32INT64QINT8QINT16QINT32UINT8UINT16
 * UINT32UINT64QUINT8QUINT16FLOAT16FLOAT32DOUBLECOMPLEX64COMPLEX128[Tensor](#)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceZeroGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceZero
 *
 * self
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(selfRef)]-->B([l0op::Contiguous])
 *     B-->C([l0op::Zeros_Like])
 *     C-->D([l0op::ViewCopy])
 *     D-->E[(selfRef)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceZeroGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceZero(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_Zero_H_
// End content from: aclnn_zero.h

// Begin content from: aclnn_resize.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_RESIZE_H_
#define OP_API_INC_RESIZE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnResizeworkspace
 * @domain aclnn_ops_infer
 * 
 * @param [in]   self TensorFLOAT,  FLOAT16TensorNCHW.
 * @param [in]   scales aclFloatArray INT32.
 * @param [in]   mode const char*
 * @param [out]  workspaceSize npu deviceworkspace
 * @param [out]  executor op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnResizeGetWorkspaceSize(const aclTensor* self, const aclFloatArray* scales, const char* mode,
                                                  aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnResize
 * @domain aclnn_ops_infer
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnResizeGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnResize(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_RESIZE_H_// End content from: aclnn_resize.h

// Begin content from: aclnn_sinkhorn.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SINKHORN_H_
#define OP_API_INC_SINKHORN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSinkhornworkspace
 * @domain aclnn_ops_infer
 *
 * Sinkhorn
 *
 * @param [in] cost: npu deviceaclTensorFLOATFLOAT16BFLOAT16ND.
 * @param [in] tol: FLOATtol0.0001
 * @param [in] p: npu deviceaclTensorFLOATFLOAT16BFLOAT16ND.
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSinkhornGetWorkspaceSize(
    const aclTensor* cost, 
    const aclScalar* tol,
    aclTensor* p,
    uint64_t* workspaceSize, 
    aclOpExecutor** executor);
/**
 * @brief aclnnSinkhorn
 *
 *  Tensor cost Sinkhorn Tensor 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSinkhornGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSinkhorn(
    void* workspace, 
    uint64_t workspaceSize, 
    aclOpExecutor* executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SINKHORN_H_
// End content from: aclnn_sinkhorn.h

// Begin content from: aclnn_prompt_flash_attention_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License. 
 */

#ifndef ACLNN_PROMPT_FLASH_ATTENTION_V2_H_
#define ACLNN_PROMPT_FLASH_ATTENTION_V2_H_
// #include "aclnn/acl_meta.h"
// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief The first interface of aclnnPromptFlashAttentionV2 is used to calculate the workspace size based on the specific calculation process.
 * @domain aclnn_ops_infer
*/
__attribute__ ((visibility("default"))) aclnnStatus aclnnPromptFlashAttentionV2GetWorkspaceSize(
    const aclTensor *query,
    const aclTensor *key,
    const aclTensor *value,
    const aclTensor *pseShift,
    const aclTensor *attenMask, // attenMask of V2
    const aclIntArray *actualSeqLengths,
    const aclIntArray *actualSeqLengthsKv,
    const aclTensor *deqScale1,
    const aclTensor *quantScale1,
    const aclTensor *deqScale2,
    const aclTensor *quantScale2,
    const aclTensor *quantOffset2,
    int64_t numHeads, // q_n of V2
    double scaleValue,
    int64_t preTokens,
    int64_t nextTokens,
    char *inputLayout,
    int64_t numKeyValueHeads,
    int64_t sparseMode, // sparse of V2
    const aclTensor *attentionOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief The second interface of aclnnPromptFlashAttentionV2 is used to perform calculations.
*/
__attribute__ ((visibility("default"))) aclnnStatus aclnnPromptFlashAttentionV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_prompt_flash_attention_v2.h

// Begin content from: aclnn_maxn.h
/*
 * Copyright (c) 2023 Huawei Technologies Co., Ltd.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * <p>
 * http://www.apache.org/licenses/LICENSE-2.0
 * <p>
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAXN_H_
#define OP_API_INC_MAXN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxNworkspace
 * @domain aclnn_math
 *
 * tensorstensormax
 *
 * @param [in] tensors: npu deviceaclTensorListshapeoutbroadcast
 * TensorND
 * @param [in] out: npu deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxNGetWorkspaceSize(const aclTensorList* tensors, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnMaxN
 *
 * tensorstensormax
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnSumGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxN(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAXN_H_
// End content from: aclnn_maxn.h

// Begin content from: aclnn_mean.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MEAN_H_
#define OP_API_INC_MEAN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMeanworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnMeanGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim,
                                                aclDataType dtype, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnMean
 */
ACLNN_API aclnnStatus aclnnMean(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnMeanV2workspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnMeanV2GetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim,
                                                  bool noopWithEmptyAxes, aclTensor* out, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnMeanV2
 */
ACLNN_API aclnnStatus aclnnMeanV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_mean.h

// Begin content from: aclnn_moe_finalize_routing_v2_grad.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_FINALIZE_ROUTING_V2GRAD_H_
#define ACLNN_MOE_FINALIZE_ROUTING_V2GRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeFinalizeRoutingV2GradGetWorkspaceSize
 * parameters :
 * gradY : required
 * expandedRowIdx : required
 * expandedXOptional : optional
 * scalesOptional : optional
 * expertIdxOptional : optional
 * biasOptional : optional
 * dropPadMode : optional
 * activeNum : optional
 * expertNum : optional
 * expertCapacity : optional
 * gradExpandedXOut : required
 * gradScalesOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeFinalizeRoutingV2GradGetWorkspaceSize(
    const aclTensor *gradY,
    const aclTensor *expandedRowIdx,
    const aclTensor *expandedXOptional,
    const aclTensor *scalesOptional,
    const aclTensor *expertIdxOptional,
    const aclTensor *biasOptional,
    int64_t dropPadMode,
    int64_t activeNum,
    int64_t expertNum,
    int64_t expertCapacity,
    const aclTensor *gradExpandedXOut,
    const aclTensor *gradScalesOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeFinalizeRoutingV2Grad
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeFinalizeRoutingV2Grad(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_finalize_routing_v2_grad.h

// Begin content from: aclnn_moe_token_permute.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_TOKEN_PERMUTE_H_
#define ACLNN_MOE_TOKEN_PERMUTE_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeTokenPermuteGetWorkspaceSize
 * parameters :
 * tokens : required
 * indices : required
 * numOutTokens : optional
 * paddedMode : optional
 * permuteTokensOut : required
 * sortedIndicesOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeTokenPermuteGetWorkspaceSize(
    const aclTensor *tokens,
    const aclTensor *indices,
    int64_t numOutTokens,
    bool paddedMode,
    const aclTensor *permuteTokensOut,
    const aclTensor *sortedIndicesOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeTokenPermute
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeTokenPermute(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_token_permute.h

// Begin content from: aclnn_inplace_matmul_all_reduce_add_rms_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_inplace_matmul_all_reduce_add_rms_norm.h
 * \brief
 */
#ifndef OP_API_INC_INPLACE_MATMUL_ALL_REDUCE_ADD_RMS_NORM_
#define OP_API_INC_INPLACE_MATMUL_ALL_REDUCE_ADD_RMS_NORM_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceMatmulAllReduceAddRmsNormworkspace
 * @domain aclnn_ops_infer
 * MatmulAllReduce+AddRmsNorm
 * @param [in] x1: matmulfloat16, bfloat16
 * @param [in] x2: matmulfloat16, bfloat16
 * @param [in] bias: float16, bf16MatmulAllReduce+Add(residual)
 * @param [in] residual: float16, bfloat16
 * @param [in] gamma: RmsNormfloat16, bfloat16
 * @param [in] epsilon: 0double
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [out] normOut: MatmulAllReduce+AddRmsNorm
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMatmulAllReduceAddRmsNormGetWorkspaceSize(
    const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const aclTensor* residual, const aclTensor* gamma,
    double epsilon, const char* group, const char* reduceOp, int64_t commTurn, int64_t streamMode,
    const aclTensor* normOut, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceMatmulAllReduceAddRmsNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspace
 *                             aclnnInplaceMatmulAllReduceAddRmsNormGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMatmulAllReduceAddRmsNorm(void* workspace, uint64_t workspaceSize,
                                                            aclOpExecutor* executor, const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_INPLACE_MATMUL_ALL_REDUCE_ADD_RMS_NORM_// End content from: aclnn_inplace_matmul_all_reduce_add_rms_norm.h

// Begin content from: aclnn_foreach_maximum_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MAXIMUM_LIST_H_
#define ACLNN_FOREACH_MAXIMUM_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMaximumListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMaximumListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMaximumList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMaximumList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_maximum_list.h

// Begin content from: aclnn_var.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_VAR_H_
#define OP_API_INC_VAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnVarworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnVarGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool unbiased,
                                               bool keepdim, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnVar
 */
ACLNN_API aclnnStatus aclnnVar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnVarCorrectionworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnVarCorrectionGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim,
                                                         int64_t correction, bool keepdim, aclTensor* out,
                                                         uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnVarCorrection
 */
ACLNN_API aclnnStatus aclnnVarCorrection(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_var.h

// Begin content from: aclnn_lt_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LTTENSOR_H_
#define OP_API_INC_LTTENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLtTensorGetWorkspaceSizeworkspace
 * @domain aclnn_math
 *
 * self Tensor(<)other
 * TensorBoolTensorself<otherTrueFalse $$ out = (self < other)  ? [True]
 * : [False] $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(Self)] -->B([Contiguous])
 * B-->C1([Cast])-->D([Less])
 * E[(other)] -->F([Contiguous])
 * F --> C2([Cast])-->D
 * D -->F1([ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensor
 * float,int32,int8,uint8,int64,int16,double,kHalf,kBool
 * shapeotherbroadcastTensorND
 * @param [in] other: npu deviceaclTensor
 * float,int32,int8,uint8,int64,int16,double,kHalf,kBool
 * shapeotherbroadcastTensorND
 * @param [in] out: npu deviceaclTensorBOOLTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLtTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLtTensor
 *
 * self Tensor(<)other
 * TensorBoolTensorself<otherTrueFalse $$ out = (self < other)  ? [True]
 * : [False] $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(Self)] -->B([Contiguous])
 * B-->C1([Cast])-->D([Less])
 * E[(other)] -->F([Contiguous])
 * F --> C2([Cast])-->D
 * D -->F1([ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLtTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceLtTensorGetWorkspaceSizeworkspace
 * @domain aclnn_math
 *
 * self Tensor(<)other
 * TensorselfRefself<otherTrueFalse $$ out = (self < other)  ?  [True] :
 * [False] $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)] -->B([Contiguous])
 * B-->C1([Cast])-->D([Less])
 * E[(other)] -->F([Contiguous])
 * F --> C2([Cast])-->D
 * D -->F1([ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensor
 * float,int32,int8,uint8,int64,int16,double,kHalf,kBool
 * shapeotherbroadcastTensorND
 * @param [in] other: npu deviceaclTensor
 * float,int32,int8,uint8,int64,int16,double,kHalf,kBool
 * shapeotherbroadcastTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLtTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLtTensor
 *
 * self Tensor(<)other
 * TensorBoolTensorself<otherTrueFalse $$ out = (self < other)  ? [True]
 * : [False] $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)] -->B([Contiguous])
 * B-->C1([Cast])-->D([Less])
 * E[(other)] -->F([Contiguous])
 * F --> C2([Cast])-->D
 * D -->F1([ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceLtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLtTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LTTENSOR_H_
// End content from: aclnn_lt_tensor.h

// Begin content from: aclnn_tril.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_TRIL_H_
#define OP_API_INC_LEVEL2_ACLNN_TRIL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTrilworkspace
 * @domain aclnn_math
 * 2-D `Tensor``Tensor`out0

 *
 * 
 * ```mermaid
 * graph LR
 *   A[(self)] -->B([l0::Contiguous])
 *   B --> E([l0::Tril])
 *   C[(diagonal)] --> E
 *   E --> G([l0::ViewCopy])
 *   G --> H[(out)]
 * ```
 *
 * @param [in] self: trilnpu deviceaclTensor
 * DOUBLE,FLOAT,FLOAT16,INT16,INT32,INT64,INT8,UINT16,UINT32,UINT64,UINT8,BOOL
 * TensorND
 * @param [in] diagonal: INT
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTrilGetWorkspaceSize(const aclTensor* self, int64_t diagonal, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnTril
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAllGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTril(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceTrilworkspace
 * @domain aclnn_math
 * 2-D `Tensor``Tensor`out0
 *
 * @param [in] selfRef: trilnpu deviceaclTensor
 * DOUBLE,FLOAT,FLOAT16,INT16,INT32,INT64,INT8,UINT16,UINT32,UINT64,UINT8,BOOL
 * TensorND
 * @param [in] diagonal: INT
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTrilGetWorkspaceSize(const aclTensor* selfRef, int64_t diagonal,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceTril
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAllGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTril(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_TRIL_H_// End content from: aclnn_tril.h

// Begin content from: aclnn_ffn_v2.h
/**
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

/*!
 * \file aclnn_ffn_v2.h
 * \brief
 */

#ifndef OP_API_INC_FFN_V2_H
#define OP_API_INC_FFN_V2_H
// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFFNV2workspace
 * FFNMoeFFNFFN
 * y=activation(xW1+b1)W2+b2
 * @domain aclnn_ops_infer
 * @param [in]
 * xDeviceaclTensorxFLOAT16BFLOAT16INT8ND2[M,
 * K1]8
 * @param [in]
 * weight1DeviceaclTensorW1FLOAT16BFLOAT16INT8INT4ND/[E,
 * K1, N1]/[K1, N1]
 * @param [in]
 * weight2DeviceaclTensorW2FLOAT16BFLOAT16INT8INT4ND/[E,
 * K2, N2]/[K2, N2]
 * @param [in]
 * expertTokensHostaclIntArraytokenINT64ND256
 * @param [in]
 * bias1DeviceaclTensorb1FLOAT16FLOAT32INT32ND/[E,
 * N1]/[N1]
 * @param [in]
 * bias2DeviceaclTensorb2FLOAT16FLOAT32INT32ND/[E,
 * N2]/[N2]
 * @param [in]
 * scaleDeviceaclTensorFLOAT32NDper-tensor//[E]/[1]per-channel///[E,
 * N1]/[N1]
 * @param [in]
 * offsetDeviceaclTensorFLOAT32ND/[E]/[1]
 * @param [in]
 * deqScale1DeviceaclTensormatmulUINT64INT64FLOAT32BFLOAT16ND/[E,
 * N1]/[N1]
 * @param [in]
 * deqScale2DeviceaclTensormatmulUINT64INT64FLOAT32BFLOAT16ND/[E,
 * N2]/[N2]
 * @param [in]
 * antiquantScale1DeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N1]/[N1]per-in-group/[E, G, N1]/[G, N1]
 * @param [in]
 * antiquantScale2DeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N2]/[N2]per-in-group/[E, G, N2]/[G, N2]
 * @param [in]
 * antiquantOffset1DeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N1]/[N1]per-in-group/[E, G, N1]/[G, N1]
 * @param [in]
 * antiquantOffset2DeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N2]/[N2]per-in-group/[E, G, N2]/[G, N2]
 * @param [in]
 * activationHostactivationfastgelu/gelu/relu/silugeglu/swiglu/reglu
 * @param [in]
 * innerPreciseHostintINT64FLOAT16BFLOAT16INT8
 * @param [in] tokensIndexFlagHostboolexpertTokensbool
 * @param [out] yTensoryFLOAT16BFLOAT16NDx
 * @param [out] workspaceSizeDeviceworkspace
 * @param [out] executorop
 * @return      aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFFNV2GetWorkspaceSize(
    const aclTensor *x, const aclTensor *weight1, const aclTensor *weight2, const aclIntArray *expertTokens,
    const aclTensor *bias1, const aclTensor *bias2, const aclTensor *scale, const aclTensor *offset,
    const aclTensor *deqScale1, const aclTensor *deqScale2, const aclTensor *antiquantScale1,
    const aclTensor *antiquantScale2, const aclTensor *antiquantOffset1, const aclTensor *antiquantOffset2,
    const char *activation, int64_t innerPrecise, bool tokensIndexFlag, const aclTensor *y, uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnFFNV2
 * @param [in] workspace: Deviceworkspace
 * @param [in] workspaceSize: DeviceworkspaceaclnnFFNV2GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: AscendCL stream
 * @return     aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFFNV2(void *workspace, uint64_t workspaceSize,
                                                              aclOpExecutor *executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif // OP_API_INC_FFN_V2_H// End content from: aclnn_ffn_v2.h

// Begin content from: aclnn_atanh.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ATANH_H_
#define OP_API_INC_ATANH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAtanhworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * out_{i}=ln((1 + input_{i})/(1 - input_{i}))
 * 
 * @param [in]   input
 * TensorFLOATBFLOAT16, FLOAT16DOUBLECOMPLEX64COMPLEX128TensorND
 * @param [in]   out
 * TensorFLOATBFLOAT16, FLOAT16DOUBLECOMPLEX64COMPLEX128TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnAtanhGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);
/**
 * @brief aclnnAtanh
 * Tensor
 * 
 * out_{i}=ln((1 + input_{i})/(1 - input_{i}))
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B --> C([l0op::Atanh])
    C --> G([l0op::Cast])
    G --> E([l0op::ViewCopy])
    E --> S[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAtanhGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAtanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceAtanhworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * out_{i}=ln((1 + input_{i})/(1 - input_{i}))
 * 
 * @param [in]   input
 * TensorINT8INT16INT32INT64UINT8BOOLFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceAtanhGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceAtanh
 *
 *  Tensoratanh
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAtanhGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAtanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_atanh.h

// Begin content from: aclnn_addcmul.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ADD_CMUL_H_
#define OP_API_INC_ADD_CMUL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAddcmulworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output=self+ value \times tensor1 \times tensor2 $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]--> B([l0op::Contiguous]) --> C([l0op::Cast]) -->D([Addcmul])
 * E[(tensor1)]--> B1([l0op::Contiguous]) --> G([l0op::Cast]) --> D
 * E1[(tensor2)]--> B2([l0op::Contiguous]) --> G1([l0op::Cast])  --> D
 * D --> H([l0op::Cast]) --> I([l0op::ViewCopy]) --> J[(out)]
 * K((value)) --> L([l0op::Cast]) --> D
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorshapebroadcast
 * TensorND
 * @param [in] tensor1: npu
 * deviceaclTensorshapebroadcast
 * TensorND
 * @param [in] tensor2: npu
 * deviceaclTensorshapebroadcast
 * TensorND
 * @param [in] value: hostaclScalar
 * @param [in] out: npu
 * deviceaclTensorshape
 * broadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddcmulGetWorkspaceSize(const aclTensor* self, const aclTensor* tensor1,
                                                   const aclTensor* tensor2, const aclScalar* value, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAddcmul
 *
 * 
 * 
 * $$ output=self+ value \times tensor1 \times tensor2 $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]--> B([l0op::Contiguous]) --> C([l0op::Cast]) -->D([Addcmul])
 * E[(tensor1)]--> B1([l0op::Contiguous]) --> G([l0op::Cast]) --> D
 * E1[(tensor2)]--> B2([l0op::Contiguous]) --> G1([l0op::Cast])  --> D
 * D --> H([l0op::Cast]) --> I([l0op::ViewCopy]) --> J[(out)]
 * K((value)) --> L([l0op::Cast]) --> D
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddcmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

/**
 * @brief aclnnInplaceAddcmulworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output=self+ value \times tensor1 \times tensor2 $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]--> B([l0op::Contiguous]) --> C([l0op::Cast]) -->D([Addcmul])
 * E[(tensor1)]--> B1([l0op::Contiguous]) --> G([l0op::Cast]) --> D
 * E1[(tensor2)]--> B2([l0op::Contiguous]) --> G1([l0op::Cast])  --> D
 * D --> H([l0op::Cast]) --> I([l0op::ViewCopy]) --> J[(out)]
 * K((value)) --> L([l0op::Cast]) --> D
 * ```
 *
 * @param [in] selfRef: npu
 * deviceaclTensorshapebroadcast
 * TensorND
 * @param [in] tensor1: npu
 * deviceaclTensorshapebroadcast
 * TensorND
 * @param [in] tensor2: npu
 * deviceaclTensorshapebroadcast
 * TensorND
 * @param [in] value: hostaclScalar
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAddcmulGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* tensor1,
                                                          const aclTensor* tensor2, const aclScalar* value,
                                                          uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceAddcmul
 *
 * 
 * 
 * $$ output=self+ value \times tensor1 \times tensor2 $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(Self)]--> B([l0op::Contiguous]) --> C([l0op::Cast]) -->D([Addcmul])
 * E[(tensor1)]--> B1([l0op::Contiguous]) --> G([l0op::Cast]) --> D
 * E1[(tensor2)]--> B2([l0op::Contiguous]) --> G1([l0op::Cast])  --> D
 * D --> H([l0op::Cast]) --> I([l0op::ViewCopy]) --> J[(out)]
 * K((value)) --> L([l0op::Cast]) --> D
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAddcmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADD_CMUL_H_
// End content from: aclnn_addcmul.h

// Begin content from: aclnn_isin.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_IS_IN_H_
#define OP_API_INC_IS_IN_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIsInScalarTensorworkspace
 * @domain aclnn_math
 *
 * elementtestElements
 *
 * @param [in] element: npu deviceaclScalar
 * @param [in] testElements: hostaclTensorTensorND
 * @param [in] assumeUnique: hostbooltestElements
 * @param [in] invert: hostbool
 * @param [in] out: npu deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsInScalarTensorGetWorkspaceSize(const aclScalar* element, const aclTensor* testElements,
                                                            bool assumeUnique, bool invert, aclTensor* out,
                                                            uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnIsInScalarTensor
 *
 * elementtestElements
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnIsInScalarTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsInScalarTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_IS_IN_H_
// End content from: aclnn_isin.h

// Begin content from: aclnn_adaptive_avg_pool2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_ADAPTIVE_AVG_POOL2D_H_
#define OP_API_INC_ADAPTIVE_AVG_POOL2D_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#include <array>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAdaptiveAvgPool2dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnAdaptiveAvgPool2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                             aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnAdaptiveAvgPool2d
 */
ACLNN_API aclnnStatus aclnnAdaptiveAvgPool2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_adaptive_avg_pool2d.h

// Begin content from: aclnn_acosh.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACOSH_H_
#define OP_API_INC_ACOSH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAcoshworkspace
 * @domain aclnn_math
 *
 * Tensor
 * 
 * $$ out_{i}=cosh^{-1}(self_{i}) $$
 *
 * @param [in] self: TensorTensorND
 * @param [in] out: TensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAcoshGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnAcosh
 *
 * Tensor
 * 
 * $$ out_{i}=cosh^{-1}(self_{i}) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAcoshGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAcosh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceAcoshworkspace
 * @domain aclnn_math
 *
 * Tensor
 * 
 * $$ selfRef_{i}=cosh^{-1}(selfRef_{i}) $$
 *
 * @param [in] selfRef: TensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAcoshGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnInplaceAcosh
 *
 * Tensor
 * 
 * $$ selfRef_{i}=cosh^{-1}(selfRef_{i}) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceAcoshGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAcosh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ACOSH_H_
// End content from: aclnn_acosh.h

// Begin content from: aclnn_batch_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BATCH_NORM_H_
#define OP_API_INC_BATCH_NORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchNormworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnBatchNormGetWorkspaceSize(const aclTensor* input, const aclTensor* weight,
                                                     const aclTensor* bias, aclTensor* runningMean,
                                                     aclTensor* runningVar, bool training, double momentum, double eps,
                                                     aclTensor* output, aclTensor* saveMean, aclTensor* saveInvstd,
                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnBatchNorm
 */
ACLNN_API aclnnStatus aclnnBatchNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BATCH_NORM_H_
// End content from: aclnn_batch_norm.h

// Begin content from: aclnn_cast.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CAST_H_
#define OP_API_INC_CAST_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCastworkspace
 * @domain aclnn_math
 *
 * tensordtype
 *
 * @param [in] self: npu
 * deviceaclTensorFLOAT16FLOATFlOAT64INT8UINT8INT16INT32INT64BOOL
 * TensorND
 * @param [in] dtype: 	hostaclDataTypetensordtype
 * @param [in] out: npu
 * deviceaclTensorFLOAT16FLOATFlOAT64INT8UINT8INT16INT32INT64BOOL
 * COMPLEX64COMPLEX128dtypeshapeselfNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCastGetWorkspaceSize(const aclTensor* self, const aclDataType dtype, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnCast
 *
 * tensordtype
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCastGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCast(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CAST_H_
// End content from: aclnn_cast.h

// Begin content from: aclnn_replication_pad1d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REPLICATION_PAD1D_BACKWARD_H_
#define OP_API_INC_REPLICATION_PAD1D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReplicationPad1dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * replication_pad1d
 * @param [in] gradOutput: FLOAT16, FLOAT32, DOUBLE, COMPLEX64,
 * COMPLEX128[Tensor](#)ND([](#))
 * selfgradInputshapereplication_pad1doutput
 * @param [in] self:
 * gradOutput[Tensor](#)ND([](#))gradOutput
 * gradInputshapegradInput
 * @param [in] padding: INT642
 * @param [in] gradInput:
 * gradOutputshapeself[Tensor](#)ND([](#))
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad1dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                    const aclIntArray* padding, aclTensor* gradInput,
                                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnReplicationPad1dBackward
 *
 * replication_pad1d
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnReplicationPad1dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad1dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REPLICATION_PAD1D_BACKWARD_H_// End content from: aclnn_replication_pad1d_backward.h

// Begin content from: aclnn_foreach_atan.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ATAN_H_
#define ACLNN_FOREACH_ATAN_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAtanGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAtanGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAtan
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAtan(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_atan.h

// Begin content from: aclnn_foreach_sub_list_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_SUB_LIST_V2_H_
#define OP_API_INC_ACLNN_FOREACH_SUB_LIST_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachSubListV2workspace
 * TensorTensoralpha
 * 
 * out_{i}=x1_{i}-x2_{i}*alpha
 * @domain aclnnop_math
 * 
 * @param [in]   x1
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   x2
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   alpha
 * ScalarFLOATFLOAT16INT32ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachSubListV2GetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclScalar *alpha,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachSubListV2
 * TensorTensoralpha
 * 
 * out_{i}=x1_{i}-x2_{i}*alpha
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachSubListV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachSubListV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sub_list_v2.h

// Begin content from: aclnn_inplace_quant_matmul_all_reduce_add_rms_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_inplace_quant_matmul_all_reduce_add_rms_norm.h
 * \brief
 */
#ifndef OP_API_INC_INPLACE_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_
#define OP_API_INC_INPLACE_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceQuantMatmulAllReduceAddRmsNormworkspace
 * @domain aclnn_ops_infer
 * MatmulAllReduce+AddRmsNorm
 * @param [in] x1: matmulint8
 * @param [in] x2: matmulint8
 * @param [in] bias: int32
 * @param [in] dequantScale: int64,uint64,bfloat16
 * @param [in] residual: float16, bfloat16MatmulAllReduce+Add(residual)
 * @param [in] gamma: RmsNormfloat16, bfloat16
 * @param [in] epsilon: 0double
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [out] normOut: MatmulAllReduce+AddRmsNorm
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnInplaceQuantMatmulAllReduceAddRmsNormGetWorkspaceSize(
    const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const aclTensor* dequantScale,
    const aclTensor* residual, const aclTensor* gamma, double epsilon, const char* group, const char* reduceOp,
    int64_t commTurn, int64_t streamMode, const aclTensor* normOut, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceQuantMatmulAllReduceAddRmsNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspace
 *                             aclnnInplaceQuantMatmulAllReduceAddRmsNormGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceQuantMatmulAllReduceAddRmsNorm(void* workspace, uint64_t workspaceSize,
                                                                 aclOpExecutor* executor, const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_INPLACE_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_// End content from: aclnn_inplace_quant_matmul_all_reduce_add_rms_norm.h

// Begin content from: aclnn_quant_matmul_all_reduce_add_rms_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_quant_matmul_all_reduce_add_rms_norm.h
 * \brief
 */
#ifndef OP_API_INC_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_
#define OP_API_INC_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQuantMatmulAllReduceAddRmsNormworkspace
 * @domain aclnn_ops_infer
 * MatmulAllReduce+AddRmsNorm
 * @param [in] x1: matmulint8
 * @param [in] x2: matmulint8
 * @param [in] bias: int32
 * @param [in] dequantScale: uint64,bfloat16
 * @param [in] residual: float16, bfloat16
 * @param [in] gamma: RmsNormfloat16, bfloat16
 * @param [in] epsilon: 0double
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [out] y: MatmulAllReduce+Add(residual)
 * @param [out] normOut: MatmulAllReduce+AddRmsNorm
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnQuantMatmulAllReduceAddRmsNormGetWorkspaceSize(
    const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const aclTensor* dequantScale,
    const aclTensor* residual, const aclTensor* gamma, double epsilon, const char* group, const char* reduceOp,
    int64_t commTurn, int64_t streamMode, const aclTensor* y, const aclTensor* normOut, uint64_t* workspaceSize,
    aclOpExecutor** executor);

/**
 * @brief aclnnQuantMatmulAllReduceAddRmsNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnQuantMatmulAllReduceAddRmsNormGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulAllReduceAddRmsNorm(void* workspace, uint64_t workspaceSize,
                                                          aclOpExecutor* executor, const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_// End content from: aclnn_quant_matmul_all_reduce_add_rms_norm.h

// Begin content from: aclnn_floor_divide.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_FLOORDIVIDE_H_
#define OP_API_INC_FLOORDIVIDE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFloorDivideworkspace
 * @domain aclnn_math
 *
 * @param [in] self: npu
 * deviceaclTensorothershapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorselfshapeselfbroadcast
 * TensorNDself
 * @param [in] out: npu
 * deviceaclTensorselfothershapeselfother
 * broadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFloorDivideGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnFloorDividesworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnFloorDividesGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceFloorDivideworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceFloorDivideGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                              uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceFloorDividesworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceFloorDividesGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnFloorDivide
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnFloorDivideGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFloorDivide(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

ACLNN_API aclnnStatus aclnnFloorDivides(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

ACLNN_API aclnnStatus aclnnInplaceFloorDivide(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              aclrtStream stream);

ACLNN_API aclnnStatus aclnnInplaceFloorDivides(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_FLOORDIVIDE_H_
// End content from: aclnn_floor_divide.h

// Begin content from: aclnn_logsigmoid.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOG_SIGMOID_H_
#define OP_API_INC_LOG_SIGMOID_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogSigmoidworkspace
 * @domain aclnn_ops_infer
 *
 * TensorLogSigmoid
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16TensorND
 * shapeoutout
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16TensorND
 * shapeselfself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogSigmoidGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnLogSigmoidForwardworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnLogSigmoidForwardGetWorkspaceSize(const aclTensor* self, aclTensor* out, aclTensor* buffer,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogSigmoid
 *
 * TensorLogSigmoid
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLogSigmoidGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogSigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

/**
 * @brief aclnnLogSigmoidForward
 */
ACLNN_API aclnnStatus aclnnLogSigmoidForward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOG_SIGMOID_H_
// End content from: aclnn_logsigmoid.h

// Begin content from: aclnn_all.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ALL_H_
#define OP_API_INC_LEVEL2_ACLNN_ALL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

#define ACLNN_MAX_SHAPE_RANK 8
#define DIM_BITS_LEN 64

/**
 * @brief aclnnAllworkspace
 * @domain aclnn_math
 * Tensor

 *
 * 
 * ```mermaid
 * graph LR
 *   A[(self)] -->B([l0::Contiguous])
 *   B --> E([l0::ReduceAll])
 *   C[(dim)] --> E
 *   D[(keepdim)] --> E
 *   E --> G([l0::ViewCopy])
 *   G --> H[(out)]
 * ```
 *
 * @param [in] self: allnpu deviceaclTensor
 * BOOLNDTensor
 * @param [in] dim: TensorINT
 * @param [in] keepdim: `dim`BOOL
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAllGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepdim,
                                               aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAll
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAllGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAll(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                               const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ALL_H_// End content from: aclnn_all.h

// Begin content from: aclnn_softshrink_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SOFT_SHRINK_BACKWARD_H_
#define OP_API_INC_SOFT_SHRINK_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSoftshrinkBackwardworkspace
 * @domain aclnn_ops_train
 * @param [in] gradOutput: npu deviceaclTensorFLOATFLOAT16DOUBLE
 * output,shapeoutput[Tensor](#Tensor)ND
 * @param [in] output: npu deviceaclTensorFLOATFLOAT16DOUBLE
 * [Tensor](#Tensor)ND
 * @param [out] gradInput: npu deviceaclTensorFLOATFLOAT16DOUBLE
 * [Tensor](#Tensor)ND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftshrinkBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                              const aclScalar* lambda, aclTensor* gradInput,
                                                              uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnSoftshrinkBackward
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnSoftshrinkBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftshrinkBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SOFT_SHRINK_BACKWARD_H_// End content from: aclnn_softshrink_backward.h

// Begin content from: aclnn_upsample_nearest_1d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNAMPLE_NEAREST_H_
#define OP_API_INC_UNAMPLE_NEAREST_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearest1dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest1dBackwardGetWorkspaceSize(const aclTensor* gradOut,
                                                                     const aclIntArray* outputSize,
                                                                     const aclIntArray* inputSize, double scales,
                                                                     aclTensor* out, uint64_t* workspaceSize,
                                                                     aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleNearest1dBackward
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest1dBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_H_
// End content from: aclnn_upsample_nearest_1d_backward.h

// Begin content from: aclnn_selu_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_SILU_GRAD_H_
#define OP_API_INC_LEVEL2_ACLNN_SILU_GRAD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSeluworkspace
 * @domain aclnn_ops_train
 *
 *  Tensorselubackward
 * @param [in] gradOutput: npu deviceaclTensor, INT8INT32,
 * FLOATFLOAT16shapeTensorND
 * @param [in] result: npu deviceaclTensor, INT8INT32, FLOATFLOAT16, shapegradOutput
 *  ND
 * @param [in] gradInput: npu deviceaclTensor, INT8INT32, FLOATFLOAT16, shapegradOutput
 *  ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSeluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* result,
                                                        aclTensor* gradInput, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnSelu
 *
 *  Tensorselu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSeluGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSeluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_selu_backward.h

// Begin content from: aclnn_adaptive_max_pool2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_ADAPTIVE_MAX_POOL2D_H_
#define OP_API_INC_ADAPTIVE_MAX_POOL2D_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#include <array>

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAdaptiveMaxPool2dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnAdaptiveMaxPool2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                             aclTensor* outputOut, aclTensor* indicesOut,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAdaptiveMaxPool2d
 */
ACLNN_API aclnnStatus aclnnAdaptiveMaxPool2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_adaptive_max_pool2d.h

// Begin content from: aclnn_addr.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_ADDR_H_
#define OP_API_INC_LEVEL2_ACLNN_ADDR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAddrworkspace
 * @domain aclnn_ops_infer
 * Tensor
 * 
 * $$ out_{i} = addr(self, vec1, vec2, beta=1, alpha=1) $$
 * @param [in] self: addrnpu deviceaclTensor,
 * FLOATFLOAT16DOUBLEINT8INT16INT32INT64UINT8BOOLNDTensor
 * @param [in] vec1: addrnpu deviceaclTensor,
 * FLOATFLOAT16DOUBLEINT8INT16INT32INT64UINT8BOOLNDTensor
 * @param [in] vec2: addrnpu deviceaclTensor,
 * FLOATFLOAT16DOUBLEINT8INT16INT32INT64UINT8BOOLNDTensor
 * @param [in] betaOptional: addrhostaclScalar
 * @param [in] alphaOptional: addrhostaclScalar
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddrGetWorkspaceSize(const aclTensor* self, const aclTensor* vec1, const aclTensor* vec2,
                                                const aclScalar* betaOptional, const aclScalar* alphaOptional,
                                                aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAddr
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddrGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceAddrworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnInplaceAddrGetWorkspaceSize(aclTensor* selfRef, const aclTensor* vec1, const aclTensor* vec2,
                                                       const aclScalar* betaOptional, const aclScalar* alphaOptional,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);
ACLNN_API aclnnStatus aclnnInplaceAddr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ADDR_H_// End content from: aclnn_addr.h

// Begin content from: aclnn_celu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_CELU_H_
#define OP_API_INC_LEVEL2_ACLNN_CELU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * selfxCELUout
 * 
 * $$
 * CELU(x) = max(0, x) + min(0, \alpha \ast (exp(x / \alpha) - 1))
 * $$
 *
 * 
 *
 * 
 *
 * ```mermaid
 * graph LR
 *     A[(Self)] --> B([l0op::Contiguous])
 *     B --> C([l0op::CeluV2])
 *     C --> D([l0op::Cast])
 *     D --> E([l0op::ViewCopy])
 *     E --> F[(out)]
 *     G((alpha)) --> C
 * ```
 */

/**
 * @brief aclnnCeluworkspace
 * @domain aclnn_ops_infer
 * @param [in] self: CELUnpu deviceaclTensorFLOATFLOAT16BFLOAT16
 * Tensor, ND8
 * @param [in] alpha: CELUhostaclScalarFLOAT
 * @param [in] out: CELUnpu
 * deviceaclTensorselfshapeself
 * TensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCeluGetWorkspaceSize(const aclTensor* self, const aclScalar* alpha, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnCelu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCeluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceCeluworkspace
 * @domain aclnn_ops_infer
 * @param [in] selfRef: CELUnpu
 * deviceaclTensorFLOATFLOAT16Tensor ND8
 * @param [in] alpha: CELUhostaclScalarFLOAT
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCeluGetWorkspaceSize(aclTensor* selfRef, const aclScalar* alpha,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceCelu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceCeluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_CELU_H_
// End content from: aclnn_celu.h

// Begin content from: aclnn_weight_quant_batch_matmul_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_WEIGHT_QUANT_BATCH_MATMUL_V2_H_
#define OP_API_INC_LEVEL2_ACLNN_WEIGHT_QUANT_BATCH_MATMUL_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnWeightQuantBatchMatmulV2workspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnWeightQuantBatchMatmulV2GetWorkspaceSize(
    const aclTensor* x, const aclTensor* weight, const aclTensor* antiquantScale,
    const aclTensor* antiquantOffsetOptional, const aclTensor* quantScaleOptional, const aclTensor* quantOffsetOptional,
    const aclTensor* biasOptional, int antiquantGroupSize, const aclTensor* y, uint64_t* workspaceSize,
    aclOpExecutor** executor);

/**
 * @brief aclnnWeightQuantBatchMatmulV2
 */
ACLNN_API aclnnStatus aclnnWeightQuantBatchMatmulV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_WEIGHT_QUANT_BATCH_MATMUL_V2_H_// End content from: aclnn_weight_quant_batch_matmul_v2.h

// Begin content from: aclnn_foreach_mul_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MUL_SCALAR_LIST_H_
#define ACLNN_FOREACH_MUL_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMulScalarListGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMulScalarListGetWorkspaceSize(
    const aclTensorList *x,
    const aclScalarList *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMulScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMulScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_mul_scalar_list.h

// Begin content from: aclnn_diag.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_DIAG_H_
#define OP_API_INC_DIAG_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnDiagworkspace
 * @domain aclnn_math
 *
 * @param [in] self: npu
 * deviceaclTensorTensorND
 * @param [in] diagonal: 0INT64
 * @param [in] out: npu
 * deviceaclTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDiagGetWorkspaceSize(const aclTensor* self, int64_t diagonal, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnDiag
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnDiagGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDiag(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_DIAG_H_
// End content from: aclnn_diag.h

// Begin content from: aclnn_aminmax_dim.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_AMINMAX_DIM_H_
#define OP_API_INC_AMINMAX_DIM_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAminmaxDimworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] self: npu deviceaclTensorTensorND
 * @param [in] dim: hostInt64_t
 * @param [in] keepDim: hostboolreduce
 * @param [in] minOut: npu deviceaclTensorTensorND
 * @param [in] maxOut: npu deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAminmaxDimGetWorkspaceSize(const aclTensor* self, const int64_t dim, bool keepDim,
                                                      aclTensor* minOut, aclTensor* maxOut, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnAminmaxDim
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAminmaxDimGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAminmaxDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AMINMAX_DIM_H_
// End content from: aclnn_aminmax_dim.h

// Begin content from: aclnn_sigmoid_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SIGMOID_BACKWARD_H_
#define OP_API_INC_SIGMOID_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSigmoidgBackwardworkspace
 * @domain aclnn_ops_train
 *
 *  Tensorsigmoid backward
 * @param [in] gradOutput: npu deviceaclTensor, FLOATFLOAT16DOUBLECOMPLEX64COMPLEX128,
 * shape ND, Tensor
 * @param [in] output: npu deviceaclTensor, FLOATFLOAT16DOUBLECOMPLEX64COMPLEX128,
 * shapegradOutputND, Tensor
 * @param [in] gradInput: npu deviceaclTensor, FLOATFLOAT16DOUBLECOMPLEX64COMPLEX128
 * shapegradOutputND, Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSigmoidBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* output,
                                                           aclTensor* gradInput, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief: aclnnSigmoidBackward
 *
 *  Tensorsigmoid backward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSigmoidBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSigmoidBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SIGMOID_BACKWARD_H_// End content from: aclnn_sigmoid_backward.h

// Begin content from: aclnn_matmul_compress_dequant.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MM_UNZIP_H_
#define OP_API_INC_MM_UNZIP_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMatmulCompressDequantworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnMatmulCompressDequantGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                                 const aclTensor* compressIndex, const aclTensor* bias,
                                                                 const aclTensor* deqScale, const aclTensor* offsetW,
                                                                 int offsetX, const aclIntArray* compressInfo,
                                                                 aclTensor* out, uint64_t* workspaceSize,
                                                                 aclOpExecutor** executor);

/**
 * @brief aclnnMatmulCompressDequant
 */
ACLNN_API aclnnStatus aclnnMatmulCompressDequant(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MM_UNZIP_H_
// End content from: aclnn_matmul_compress_dequant.h

// Begin content from: aclnn_reduce_nansum.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REDUCE_NANSUM_H_
#define OP_API_INC_REDUCE_NANSUM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReduceNansumworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnReduceNansumGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim,
                                                        aclDataType dtype, aclTensor* out, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnReduceNansum
 */
ACLNN_API aclnnStatus aclnnReduceNansum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REDUCE_SUM_H_
// End content from: aclnn_reduce_nansum.h

// Begin content from: aclnn_add.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ADD_H_
#define OP_API_INC_ADD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAddworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output_i = self_i+alpha*other_i $$
 *
 * @param [in] self: npu
 * deviceaclTensorothershapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorselfshapeselfbroadcast
 * TensorNDself
 * @param [in] alpha: hostaclScalarselfother
 * @param [in] out: npu
 * deviceaclTensorselfothershapeselfother
 * broadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddGetWorkspaceSize(const aclTensor* self, const aclTensor* other, const aclScalar* alpha,
                                               aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAdd
 *
 * 
 * 
 * $$ output_i = self_i+alpha*other_i $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAdd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnAddsworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnAddsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, const aclScalar* alpha,
                                                aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
ACLNN_API aclnnStatus aclnnAdds(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceAddworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output_i = self_i+alpha*other_i $$
 *
 * @param [in] self: npu
 * deviceaclTensorothershapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorselfshapeselfbroadcast
 * TensorNDself
 * @param [in] alpha: hostaclScalarselfother
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAddGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other,
                                                      const aclScalar* alpha, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnInplaceAdd
 *
 * 
 * 
 * $$ output_i = self_i+alpha*other_i $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAdd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

/**
 * @brief aclnnInplaceAddsworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceAddsGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* other,
                                                       const aclScalar* alpha, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnInplaceAdds(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADD_H_
// End content from: aclnn_add.h

// Begin content from: aclnn_rand.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_ACLNN_RAND_H_
#define OP_API_INC_ACLNN_RAND_H_

// #include "aclnn_normal.h"
// #include "aclnn_randperm.h"
// #include "aclnn_dropout_gen_mask.h"
// #include "aclnn_uniform.h"
// #include "aclnn_random.h"
// #include "aclnn_dropout_do_mask.h"
// #include "aclnn_multinomial.h"
// #include "aclnn_bernoulli.h"
// #include "aclnn_normal_out.h"
// #include "aclnn_dropout.h"
// #include "aclnn_dropout_backward.h"

#endif // OP_API_INC_ACLNN_RAND_H_// End content from: aclnn_rand.h

// Begin content from: aclnn_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_NORM_H_
#define OP_API_INC_NORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief workspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu deviceaclTensor, 
 * @param [in] p: hostaclScalar, 
 * @param [in] dim: npu deviceaclIntArray, Axis
 * @param [in] keepdim: hostbool, dim
 * @param [in] workspaceSize: npu deviceworkspace
 * @param [in] executor: op
 * @return aclnnStatus: 
 * */
ACLNN_API aclnnStatus aclnnNormGetWorkspaceSize(const aclTensor* self, const aclScalar* pScalar, const aclIntArray* dim,
                                                bool keepdim, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * aclnnNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnNormGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_norm.h

// Begin content from: aclnn_one_hot.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ONE_HOT_H_
#define OP_API_INC_ONE_HOT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnOneHotworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnOneHotGetWorkspaceSize(const aclTensor* self, int numClasses, const aclTensor* onValue,
                                                  const aclTensor* offValue, int64_t axis, aclTensor* out,
                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnOneHot
 */
ACLNN_API aclnnStatus aclnnOneHot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ONE_HOT_H_
// End content from: aclnn_one_hot.h

// Begin content from: aclnn_upsample_nearest_exact2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_NEAREST_EXACT1D_H_
#define OP_API_INC_UNAMPLE_NEAREST_EXACT1D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearestExact2dworkspace
 * 
 * 
 * out(N, C, l) = self(N, C, min(floor((l + 0.5) * scales),  L- 1))
 * @domain aclnn_ops_train aclnn_ops_infer
 * 
 * @param [in]   self
 * TensorFLOATFLOAT16BFLOAT16TensorNDNCHW
 * @param [in]   outputSize
 * sizeINT32INT64
 * @param [in]   scaleH
 * HDOUBLE
 * @param [in]   scaleW
 * WDOUBLE
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16TensorNDNCHW
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnUpsampleNearestExact2dGetWorkspaceSize(const aclTensor *self, const aclIntArray *outputSize, 
                                                                  double scalesH, double scalesW, aclTensor *out, 
                                                                  uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnUpsampleNearestExact2d
 * 
 * 
 * 
 * @domain aclnn_ops_train aclnn_ops_infer
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnUpsampleNearestExact2dGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus:  
*/
ACLNN_API aclnnStatus aclnnUpsampleNearestExact2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_EXACT1D_H_
// End content from: aclnn_upsample_nearest_exact2d.h

// Begin content from: aclnn_foreach_erfc.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ERFC_H_
#define ACLNN_FOREACH_ERFC_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachErfcGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachErfcGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachErfc
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachErfc(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_erfc.h

// Begin content from: aclnn_ring_attention_update.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_RING_ATTENTION_UPDATE_H_
#define ACLNN_RING_ATTENTION_UPDATE_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnRingAttentionUpdateGetWorkspaceSize
 * parameters :
 * prevAttnOut : required
 * prevSoftmaxMax : required
 * prevSoftmaxSum : required
 * curAttnOut : required
 * curSoftmaxMax : required
 * curSoftmaxSum : required
 * actualSeqQlenOptional : optional
 * inputLayoutOptional : optional
 * attnOutOut : required
 * softmaxMaxOut : required
 * softmaxSumOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnRingAttentionUpdateGetWorkspaceSize(
    const aclTensor *prevAttnOut,
    const aclTensor *prevSoftmaxMax,
    const aclTensor *prevSoftmaxSum,
    const aclTensor *curAttnOut,
    const aclTensor *curSoftmaxMax,
    const aclTensor *curSoftmaxSum,
    const aclTensor *actualSeqQlenOptional,
    char *inputLayoutOptional,
    const aclTensor *attnOutOut,
    const aclTensor *softmaxMaxOut,
    const aclTensor *softmaxSumOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnRingAttentionUpdate
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnRingAttentionUpdate(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_ring_attention_update.h

// Begin content from: aclnn_precision_compare.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_PRECISION_COMPARE_H_
#define OP_API_INC_PRECISION_COMPARE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnPrecisionCompareworkspace
 * @domain aclnn_math
 * Tensor:
 *
 * @param [in] golden: npu deviceaclTensor
 * FLOAT16,FLOAT
 * goldenrealdata
 * @param [in] realdata: npu deviceaclTensor
 * FLOAT16,FLOAT
 * realdatagolden
 * @param [in] out: UINT32Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnPrecisionCompareGetWorkspaceSize(const aclTensor *golden, const aclTensor *realdata,
                                                            aclTensor *out, uint64_t *workspaceSize,
                                                            aclOpExecutor **executor);
/**
 * @brief aclnnPrecisionCompare
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnPrecisionCompareGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnPrecisionCompare(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                            aclrtStream stream);
#ifdef __cplusplus
}
#endif
#endif  // OP_API_INC_PRECISION_COMPARE_H_// End content from: aclnn_precision_compare.h

// Begin content from: aclnn_foreach_lerp_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_LERP_LIST_H_
#define ACLNN_FOREACH_LERP_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachLerpListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * weight : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLerpListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *weight,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachLerpList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLerpList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_lerp_list.h

// Begin content from: aclnn_moe_init_routing_quant.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_INIT_ROUTING_QUANT_H_
#define ACLNN_MOE_INIT_ROUTING_QUANT_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeInitRoutingQuantGetWorkspaceSize
 * parameters :
 * x : required
 * rowIdx : required
 * expertIdx : required
 * activeNum : required
 * scale : required
 * offset : required
 * expandedXOut : required
 * expandedRowIdxOut : required
 * expandedExpertIdxOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingQuantGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *rowIdx,
    const aclTensor *expertIdx,
    int64_t activeNum,
    double scale,
    double offset,
    const aclTensor *expandedXOut,
    const aclTensor *expandedRowIdxOut,
    const aclTensor *expandedExpertIdxOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeInitRoutingQuant
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingQuant(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_init_routing_quant.h

// Begin content from: aclnn_channel_shuffle.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_CHANNEL_SHUFFLE_H_
#define OP_API_INC_LEVEL2_ACLNN_CHANNEL_SHUFFLE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnChannelShuffleworkspace
 * @domain aclnn_ops_infer
 *
 * $(*, C, H, W)$channels$g$$(*, C_{,}^{\underline{g}}g, H, W)$
 * shape
 *
 * @param [in] self: npu deviceaclTensorBFLOAT16FLOAT16FLOATDOUBLEUINT8INT8INT16INT32
 * LONGCOMPLEX64COMPLEX128BOOLTensorND27
 * @param [in] groupshostint64_t selfchannels0selfchannels
 * @param [in] out: npu deviceaclTensorselfTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnChannelShuffleGetWorkspaceSize(const aclTensor* self, int64_t groups, aclTensor* out,
                                                          uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnChannelShuffle
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnChannelShuffleGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnChannelShuffle(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_CHANNEL_SHUFFLE_H_// End content from: aclnn_channel_shuffle.h

// Begin content from: aclnn_rrelu_with_noise.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_RRELU_WITH_NOISE_H_
#define OP_API_INC_RRELU_WITH_NOISE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRReluWithNoiseworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnRReluWithNoiseGetWorkspaceSize(const aclTensor* self, const aclTensor* noise,
                                                          const aclScalar* lower, const aclScalar* upper, bool training,
                                                          int64_t seed, int64_t offset, aclTensor* out,
                                                          uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceRReluWithNoiseworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnInplaceRReluWithNoiseGetWorkspaceSize(const aclTensor* self, const aclTensor* noise,
                                                                 const aclScalar* lower, const aclScalar* upper,
                                                                 bool training, int64_t seed, int64_t offset,
                                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnRReluWithNoise
 */
ACLNN_API aclnnStatus aclnnRReluWithNoise(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          const aclrtStream stream);

/**
 * @brief aclnnInplaceRReluWithNoise
 */
ACLNN_API aclnnStatus aclnnInplaceRReluWithNoise(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BINARY_CROSS_ENTROPY_H_
// End content from: aclnn_rrelu_with_noise.h

// Begin content from: aclnn_sub.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SUB_H_
#define OP_API_INC_SUB_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSubworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output_i = self_i - alpha * other_i $$
 *
 * @param [in] self: npu
 * deviceaclTensorothershapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorselfshapeselfbroadcast
 * TensorNDself
 * @param [in] alpha: hostaclScalarselfother
 * @param [in] out: npu
 * deviceaclTensorselfothershapeselfother
 * broadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSubGetWorkspaceSize(const aclTensor* self, const aclTensor* other, const aclScalar* alpha,
                                               aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnSub
 *
 * 
 * 
 * $$ output_i = self_i - alpha * other_i $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSubGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSub(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnSubsworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnSubsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, const aclScalar* alpha,
                                                aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
ACLNN_API aclnnStatus aclnnSubs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceSubworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ selfRef_{i} = selfRef_{i} - alpha \times other_{i} $$
 *
 * @param [in] self: npu
 * deviceaclTensorothershapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorselfshapeselfbroadcast
 * TensorNDself
 * @param [in] alpha: hostaclScalarselfother
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSubGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, const aclScalar* alpha,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceSub
 *
 * 
 * 
 * $$ selfRef_{i} = selfRef_{i} - alpha \times other_{i} $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceSubGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSub(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

/**
 * @brief aclnnInplaceSubsworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceSubsGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, const aclScalar* alpha,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnInplaceSubs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SUB_H_
// End content from: aclnn_sub.h

// Begin content from: aclnn_binary_cross_entropy.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BINARY_CROSS_ENTROPY_H_
#define OP_API_INC_BINARY_CROSS_ENTROPY_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

enum Reduction { None = 0, Mean = 1, Sum = 2 };

/**
 * @brief aclnnBinaryCrossEntropyworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnBinaryCrossEntropyGetWorkspaceSize(const aclTensor* self, const aclTensor* target,
                                                              const aclTensor* weight, int64_t reduction,
                                                              aclTensor* out, uint64_t* workspaceSize,
                                                              aclOpExecutor** executor);

/*
 * @brief aclnnBinaryCrossEntropy
 */
ACLNN_API aclnnStatus aclnnBinaryCrossEntropy(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BINARY_CROSS_ENTROPY_H_
// End content from: aclnn_binary_cross_entropy.h

// Begin content from: aclnn_x_log_y_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_X_LOG_Y_TENSOR_H_
#define OP_API_INC_X_LOG_Y_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnXLogYTensorworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnXLogYTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnXLogYTensor
 */
ACLNN_API aclnnStatus aclnnXLogYTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

/**
 * @brief aclnnInplaceXLogYTensorworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceXLogYTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                              uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceXLogYTensor
 */
ACLNN_API aclnnStatus aclnnInplaceXLogYTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_X_LOG_Y_TENSOR_H_// End content from: aclnn_x_log_y_tensor.h

// Begin content from: aclnn_convolution.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CONVOLUTION_H_
#define OP_API_INC_CONVOLUTION_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief convolutionworkspace
 * @domain aclnn_ops_infer
 *
 * @param [in] input: npufeature map
 * deviceaclTensorFLOAT16FLOAT32FLOAT64
 * TensorNDNCHWNHWCHWCNNDHWCNCDHW
 * @param [in] weight: npu, kernels
 * deviceaclTensorinput
 * Tensorinput
 * @param [in] bias: npu
 * deviceaclTensorinput
 * Tensorinput
 * @param [in] stride: 
 * int64input-2kernel size -12D2
 * @param [in] padding: 
 * int64input-2kernel size -12Dpadding2
 * @param [in] dilation: kernel>1
 * int64input-2kernel size -12Ddilation2
 * @param [in] transposed: 
 * boolTrue
 * @param [in] outputPadding
 * int64input-2stridedilation2Ddilation2
 * @param [in] groups
 * int640inputoutput input = weight*groups
 * @param [out] output: npu
 * deviceaclTensorinput
 * broadcastshapeinput
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnConvolutionGetWorkspaceSize(const aclTensor* input, const aclTensor* weight,
                                                       const aclTensor* bias, const aclIntArray* stride,
                                                       const aclIntArray* padding, const aclIntArray* dilation,
                                                       bool transposed, const aclIntArray* outputPadding,
                                                       const int64_t groups, aclTensor* output, int8_t cubeMathType,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnConvTbcGetWorkspaceSize(const aclTensor* self, const aclTensor* weight,
                                                   const aclTensor* bias, const int64_t pad, aclTensor* output,
                                                   int8_t cubeMathType, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnConvDepthwise2dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnConvDepthwise2dGetWorkspaceSize(const aclTensor* self, const aclTensor* weight,
                                                           const aclIntArray* kernelSize, const aclTensor* bias,
                                                           const aclIntArray* stride, const aclIntArray* padding,
                                                           const aclIntArray* dilation, aclTensor* out,
                                                           int8_t cubeMathType, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief convolutionkernellaunch
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnConvolutionGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: opexecutor
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnConvolution(void* workspace, const uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

ACLNN_API aclnnStatus aclnnConvTbc(void* workspace, const uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

ACLNN_API aclnnStatus aclnnConvDepthwise2d(void* workspace, const uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CONVOLUTION_H_
// End content from: aclnn_convolution.h

// Begin content from: aclnn_split_with_size.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_SPLIT_WITH_SIZE_H_
#define OP_API_INC_LEVEL2_ACLNN_SPLIT_WITH_SIZE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSplitWithSizeworkspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEBFLOAT16INT32INT64INT16INT8UINT8
 * BOOLCOMPLEX128COMPLEX64TensorND
 * @param [in] splitSizehostaclIntArray,
 * splitINT64INT32self dimshape
 * @param [in] dim: hostINT64tensorsplit
 * @param [in] out: npu deviceaclTensorListsplittensorFLOATFLOAT16DOUBLE
 * BFLOAT16INT32INT64INT16INT8UINT8BOOLCOMPLEX128COMPLEX64ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSplitWithSizeGetWorkspaceSize(const aclTensor* self, const aclIntArray* splitSize,
                                                         int64_t dim, aclTensorList* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnSplitWithSize
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSplitWithSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSplitWithSize(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SPLIT_WITH_SIZE_H_
// End content from: aclnn_split_with_size.h

// Begin content from: aclnn_foreach_sigmoid.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_SIGMOID_H_
#define ACLNN_FOREACH_SIGMOID_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachSigmoidGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSigmoidGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachSigmoid
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSigmoid(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sigmoid.h

// Begin content from: aclnn_foreach_erf.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ERF_H_
#define ACLNN_FOREACH_ERF_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachErfGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachErfGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachErf
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachErf(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_erf.h

// Begin content from: aclnn_layer_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_LAYER_NORM_H_
#define OP_API_INC_LEVEL2_LAYER_NORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLayerNormworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnLayerNormGetWorkspaceSize(const aclTensor* input, const aclIntArray* normalizedShape,
                                                     const aclTensor* weightOptional, const aclTensor* biasOptional,
                                                     double eps, aclTensor* out, aclTensor* meanOutOptional,
                                                     aclTensor* rstdOutOptional, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnLayerNormWithImplModeworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnLayerNormWithImplModeGetWorkspaceSize(
    const aclTensor* input, const aclIntArray* normalizedShape, const aclTensor* weightOptional,
    const aclTensor* biasOptional, double eps, aclTensor* out, aclTensor* meanOutOptional, aclTensor* rstdOutOptional,
    int32_t implMode, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLayerNorm
 */
ACLNN_API aclnnStatus aclnnLayerNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

/**
 * @brief aclnnLayerNormWithImplMode
 */
ACLNN_API aclnnStatus aclnnLayerNormWithImplMode(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_LAYER_NORM_H_
// End content from: aclnn_layer_norm.h

// Begin content from: aclnn_max_unpool2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAX_UNPOOL2d_BACKWARD_H_
#define OP_API_INC_MAX_UNPOOL2d_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxUnpool2dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnMaxUnpool2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                               const aclTensor* indices, const aclIntArray* outputSize,
                                                               aclTensor* out, uint64_t* workspaceSize,
                                                               aclOpExecutor** executor);

/**
 * @brief aclnnMaxUnpool2dBackward
 */
ACLNN_API aclnnStatus aclnnMaxUnpool2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAX_UNPOOL2d_BACKWARD_H_
// End content from: aclnn_max_unpool2d_backward.h

// Begin content from: aclnn_bitwise_not.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BITWISE_NOT_H_
#define OP_API_INC_BITWISE_NOT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBitwiseNotworkspace
 * @domain aclnn_math
 *
 * tensor

 * 
 * $$ output_i = \lnot self_i $$
 *
 * :
 * api
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Invert])
 *     C --> D([ViewCopy])
 *     D --> E([out])
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensor, INT16,INT32,INT64,INT8,UINT8,BOOL,Tensor,ND
 * @param [in] out: npu
 * deviceaclTensor, INT16,INT32,INT64,INT8,UINT8,BOOL,self,
 * shapeself, ND, self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseNotGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);
/**
 * @brief aclnnBitwiseNot
 *
 * tensor
 * 
 * $$ output_i = \lnot self_i $$
 *
 * :
 * api
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Invert])
 *     C --> D([ViewCopy])
 *     D --> E([out])
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnBitwiseNotGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseNot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BITWISE_NOT_H_// End content from: aclnn_bitwise_not.h

// Begin content from: aclnn_sigmoid.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SIGMOID_H_
#define OP_API_INC_SIGMOID_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSigmoidworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorsigmoid
 * @param [in] self: npu deviceaclTensor, shapeTensorND
 * Tensor
 * @param [in] out: npu deviceaclTensor, , shapeselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSigmoidGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief: aclnnSigmoid
 *
 *  Tensorsigmoid
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSigmoidGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   const aclrtStream stream);

/**
 * @brief aclnnInplaceSigmoidworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorsigmoid
 * @param [in] self: npu deviceaclTensor,
 * shapeTensorNDNCHW
 * NHWCTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSigmoidGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size,
                                                          aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceSigmoid
 *
 *  Tensorsigmoid
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSigmoidGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SIGMOID_H_// End content from: aclnn_sigmoid.h

// Begin content from: aclnn_lgamma.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_LGAMMA_H_
#define OP_API_INC_LEVEL2_ACLNN_LGAMMA_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

#define ACLNN_MAX_SHAPE_RANK 8

/**
 * @brief aclnnLgammaworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * $$ out_{i} = lgamma(self_{i}) $$ *
 * @param [in] self: lgammanpu deviceaclTensor,
 * FLOATFLOAT16DOUBLENDTensor
 * @param [in] out: lgammanpu deviceaclTensor,
 * FLOATFLOAT16DOUBLENDTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLgammaGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnLgamma
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLgammaGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLgamma(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_LGAMMA_H_// End content from: aclnn_lgamma.h

// Begin content from: aclnn_foreach_log10.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_LOG10_H_
#define ACLNN_FOREACH_LOG10_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachLog10GetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLog10GetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachLog10
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLog10(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_log10.h

// Begin content from: aclnn_addbmm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ADDBMM_H_
#define OP_API_INC_ADDBMM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAddbmmworkspace
 * @domain aclnn_ops_infer
 *
 * batch1batch2batch
 * shapeshapeself
 * 
 * $$ out = self+(\sum_{i=0}^{b-1}batch1_{i}@batch2_{i}) $$
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16batch1@batch2
 * shapebatch1@batch2broadcastTensorTensorND
 * @param [in] batch1: npu
 * deviceaclTensorFLOATFLOAT16batch2,
 * shapebatch2bmmTensorTensorND
 * @param [in] batch2: npu
 * deviceaclTensorFLOATFLOAT16batch1
 * shapebatch1bmmTensorTensorND
 * @param [in] beta: hostaclScalarselfbatch1@batch2
 * @param [in] alpha: hostaclScalarselfbatch1@batch2
 * @param [in] cubeMathType:
 * INT8CubeHFLOAT32
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16selfshapebatch1@batch2
 * TensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddbmmGetWorkspaceSize(const aclTensor* self, const aclTensor* batch1,
                                                  const aclTensor* batch2, const aclScalar* beta,
                                                  const aclScalar* alpha, aclTensor* out, int8_t cubeMathType,
                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAddbmm
 *
 * batch1batch2batch
 * shapeshapeself
 * 
 * $$ out = self+(\sum_{i=0}^{b-1}batch1_{i}@batch2_{i}) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnBaddbmmGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAddbmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceAddbmmworkspace
 * @domain aclnn_ops_infer
 *
 * batch1batch2batch
 * shapeshapeselfRef
 * 
 * $$ selfRef = selfRef+(\sum_{i=0}^{b-1}batch1_{i}@batch2_{i}) $$
 *
 * @param [in] selfRef: npu
 * deviceaclTensorFLOATFLOAT16batch1@batch2
 * shapebatch1@batch2broadcastTensorTensorND
 * @param [in] batch1: npu
 * deviceaclTensorFLOATFLOAT16batch2,
 * shapebatch2bmmTensorTensorND
 * @param [in] batch2: npu
 * deviceaclTensorFLOATFLOAT16batch1
 * shapebatch1bmmTensorTensorND
 * @param [in] beta: hostaclScalarselfbatch1@batch2
 * @param [in] alpha: hostaclScalarselfbatch1@batch2
 * @param [in] cubeMathType:
 * INT8CubeHFLOAT32
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAddbmmGetWorkspaceSize(aclTensor* selfRef, const aclTensor* batch1,
                                                         const aclTensor* batch2, const aclScalar* beta,
                                                         const aclScalar* alpha, int8_t cubeMathType,
                                                         uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceAddbmm
 *
 * batch1batch2batch
 * shapeshapeselfRef
 * 
 * $$ selfRef = selfRef+(\sum_{i=0}^{b-1}batch1_{i}@batch2_{i}) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceAddbmmGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAddbmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BADDBMM_H_
// End content from: aclnn_addbmm.h

// Begin content from: aclnn_argsort.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ARGSORT_H_
#define OP_API_INC_ARGSORT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnArgsortworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnArgsortGetWorkspaceSize(const aclTensor* self, int64_t dim, bool descending, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnArgsort
 */
ACLNN_API aclnnStatus aclnnArgsort(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ARGSORT_H_// End content from: aclnn_argsort.h

// Begin content from: aclnn_isposinf.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_ISPOSINF_H_
#define OP_API_INC_ISPOSINF_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIsPosInfworkspace
 * @domain aclnn_math
 * 
 * -
 * 
 * 1
 * ```mermaid
 * graph LR
 *   A[(self)] -->B([l0op::Contiguous])
 *   B --> D([l0op::IsPosInf])
 *   D --> I([l0op::ViewCopy])
 *   I --> J[(out)]
 * ```
 * 2False
 * ```mermaid
 * graph LR
 *   A[(self)] -->B([l0op::Fill])
 *   B --> I([l0op::ViewCopy])
 *   I --> J[(out)]
 * ```
 *
 * @param [in] self`self`,FLOATFLOAT16BFLOAT16(Ascend910B),
 * INT32INT64INT16INT8UINT8BOOL[Tensor](#)ND[](#)
 * @param [out] out`out`,BOOLshapeself
 * [Tensor](#)ND[](#)
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsPosInfGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                    aclOpExecutor** executor);

/**
 * @brief aclnnIsPosInf
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnIsPosInfGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsPosInf(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                    const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ISPOSINF_H_
// End content from: aclnn_isposinf.h

// Begin content from: aclnn_max_dim.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAX_DIM_H_
#define OP_API_INC_MAX_DIM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxDimworkspace
 * @domain aclnn_math
 *
 * 
 *
 * api
 * ```mermaid
 *  graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> C([l0op::ArgMaxWithValue])
 *  C --> F([l0op::Cast])
 *  D([dim]) --> C
 *  F -.-> E([l0op::ViewCopy])
 *  E --> O[(Out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16BFLOAT16NDTensor
 * @param [in] dim: hostint64
 * @param [in] keepdim: host
 * @param [in] indices: npu deviceaclTensorINT32INT64NDTensor
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16NDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepdim,
                                                  aclTensor* out, aclTensor* indices, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnArgMaxworkspace
 *
 * 
 *
 * api
 * ```mermaid
 *  graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> C([l0op::ArgMaxWithValue])
 *  C --> F([l0op::Cast])
 *  D([dim]) --> C
 *  F -.-> E([l0op::ViewCopy])
 *  E --> O[(Out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnArgMaxGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAX_DIM_H_// End content from: aclnn_max_dim.h

// Begin content from: aclnn_grouped_bias_add_grad.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GROUPED_BIAS_ADD_GRAD_H_
#define OP_API_INC_GROUPED_BIAS_ADD_GRAD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupedBiasAddGradworkspace
 * @domain aclnn_ops_train
 * groupBiasAdd
 * @param [in] gradY: gradYDeviceaclTensorFLOAT,FLOAT16,BFLOAT16
 *                    groupIdxOptionalshape2groupIdxOptionalshape3
 * @param [in] groupIdxOptional: groupIdxOptionalDeviceaclTensorINT32INT64shape1
 * @param [out] out: biasoutDeviceaclTensorFLOAT,FLOAT16,BFLOAT16gradYshape2
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedBiasAddGradGetWorkspaceSize(const aclTensor *gradY,
                                                    const aclTensor *groupIdxOptional, aclTensor *out,
                                                    uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnGroupedBiasAddGrad
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGroupedBiasAddGradGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedBiasAddGrad(void *workspace, uint64_t workspaceSize,
                                              aclOpExecutor *executor, aclrtStream stream);

/**
 * @brief aclnnGroupedBiasAddGradworkspace
 * @domain aclnn_ops_train
 * groupBiasAdd
 * @param [in] gradY: gradYDeviceaclTensorFLOAT,FLOAT16,BFLOAT16
 *                    groupIdxOptionalshape2groupIdxOptionalshape3
 * @param [in] groupIdxOptional: groupIdxOptionalDeviceaclTensorINT32INT64shape1
 * @param [in] groupIdxType: groupIdx01
 * 0groupIdxOptionalgroup1groupIdxOptionalgroupInt64
 * @param [out] out: biasoutDeviceaclTensorFLOAT,FLOAT16,BFLOAT16gradYshape2
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedBiasAddGradV2GetWorkspaceSize(const aclTensor *gradY, const aclTensor *groupIdxOptional,
                                                    int64_t groupIdxType, aclTensor *out,
                                                    uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnGroupedBiasAddGrad
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGroupedBiasAddGradV2GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedBiasAddGradV2(void *workspace, uint64_t workspaceSize,
                                              aclOpExecutor *executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_grouped_bias_add_grad.h

// Begin content from: aclnn_index_copy.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/*!
 * \\file aclnn_index_copy.h
 * \\brief
 */
#ifndef OP_API_INC_INDEX_COPY_H_
#define OP_API_INC_INDEX_COPY_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnIndexCopyworkspace
 * @domain aclnn_ops_infer
 *
 * indexdimsourceoutRefoutRefselfRef
 *
 * @param [in] selfRef: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16INT32INT64INT16INT8UINT8
 * DOUBLEBOOLCOMPLEX128COMPLEX64[Tensor](#)ND[](#)
 * @param [in] dim: hostint64
 * @param [in] index: npu deviceaclTensorINT32INT64,1source
 * dim[Tensor](#)ND[](#)
 * @param [in] source: npu
 * deviceaclTensorselfRef,[Tensor](#)ND[](#)
 * @param [in] outRef: npu deviceaclTensor, selfRef
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIndexCopyGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclTensor* index,
                                                     const aclTensor* source, aclTensor* outRef,
                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnIndexCopy
 *
 * indexdimsourceoutRefselfRefoutRef
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceIndexCopyGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIndexCopy(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

/**
 * @brief aclnnInplaceIndexCopyworkspace
 * @domain aclnn_ops_infer
 *
 * indexdimsourceselfRef
 *
 * @param [in] selfRef: npu
 deviceaclTensorFLOATBFLOAT16FLOAT16INT32INT64INT16INT8UINT8
 * DOUBLEBOOLCOMPLEX128COMPLEX64[Tensor](#)ND[](#)
 * @param [in] dim: hostint64
 * @param [in] index: npu deviceaclTensorINT32INT64,1source
 * dim[Tensor](#)ND[](#)
 * @param [in] source: npu
 deviceaclTensorselfRef,[Tensor](#)ND[](#)

 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceIndexCopyGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclTensor* index,
                                                            const aclTensor* source, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnInplacePut
 *
 * indexdimsourceselfRef
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceIndexCopyGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceIndexCopy(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_INDEX_COPY_H_// End content from: aclnn_index_copy.h

// Begin content from: aclnn_foreach_addcmul_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_ADDCMUL_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_ADDCMUL_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachAddcmulScalarV2workspace
 * x2x3scalarx1
 * 
 * {\rm out}_i = x1_i + {\rm scalar}  x2_i  x3_i
 * @domain aclnnop_math
 * 
 * @param [in]   input
 * TensorFLOATFLOAT16BFLOAT16INT32ND
  * @param [in]   input
 * TensorFLOATFLOAT16BFLOAT16INT32ND
  * @param [in]   input
 * TensorFLOATFLOAT16BFLOAT16INT32ND
  * @param [in]  input
 * ScalarFLOATFLOAT16INT32ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachAddcmulScalarV2GetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *x3,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachAddcmulScalarV2
 * x2x3scalarx1
 * 
 * {\rm out}_i = x1_i + {\rm scalar}  x2_i  x3_i
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachAddcmulScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachAddcmulScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_addcmul_scalar_v2.h

// Begin content from: aclnn_moe_token_unpermute_grad.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_TOKEN_UNPERMUTE_GRAD_H_
#define ACLNN_MOE_TOKEN_UNPERMUTE_GRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeTokenUnpermuteGradGetWorkspaceSize
 * parameters :
 * permutedTokens : required
 * unpermutedTokensGrad : required
 * sortedIndices : required
 * probsOptional : optional
 * paddedMode : optional
 * restoreShapeOptional : optional
 * permutedTokensGradOut : required
 * probsGradOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeTokenUnpermuteGradGetWorkspaceSize(
    const aclTensor *permutedTokens,
    const aclTensor *unpermutedTokensGrad,
    const aclTensor *sortedIndices,
    const aclTensor *probsOptional,
    bool paddedMode,
    const aclIntArray *restoreShapeOptional,
    const aclTensor *permutedTokensGradOut,
    const aclTensor *probsGradOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeTokenUnpermuteGrad
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeTokenUnpermuteGrad(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_token_unpermute_grad.h

// Begin content from: aclnn_repeat_interleave.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_REPEAT_INTERLEAVE_H_
#define OP_API_INC_LEVEL2_ACLNN_REPEAT_INTERLEAVE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

// dim, tensor repeats
/**
 * @brief aclnnRepeatInterleaveworkspace
 * @domain aclnn_math
 *
 *  Tensorrepeatinterleave
 * @param [in] self: npu deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32BFLOAT16
 * tensor, tensorND
 * @param [in] repeats: npu deviceaclTensorINT64repeats0D / 1D Tensor1D Tensor
 * repeatssize1selftensortensorND
 * @param [in] outputSize: tensorINT64repeatsoutputSize =
 * self  * repeatsrepeatsoutputSize = repeats
 * @param [in] out: npu
 * deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveGetWorkspaceSize(const aclTensor* self, const aclTensor* repeats,
                                                            int64_t outputSize, aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief: aclnnRepeatInterleave
 *
 *  Tensorrepeatinterleave
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRepeatInterleaveGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleave(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

// dim, tensor repeats
/**
 * @brief aclnnRepeatInterleaveWithDimworkspace
 * @domain aclnn_math
 *
 *  Tensorrepeatinterleave
 * @param [in] self: npu deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32BFLOAT16
 * tensor tensorND
 * @param [in] repeats: npu deviceaclTensorINT64repeats0D / 1D tensor1D tensor
 * repeatssize1selfdimsizetensortensorND
 * @param [in] dim: INT64[-self, self-1]
 * @param [in] outputSize:
 * dimINT64repeatsoutputSizerepeats
 * repeatsoutputSizerepeats * selfdimsize
 * @param [in] out: npu
 * deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveWithDimGetWorkspaceSize(const aclTensor* self, const aclTensor* repeats,
                                                                   int64_t dim, int64_t outputSize, aclTensor* out,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnRepeatInterleaveWithDim
 *
 *  Tensorrepeatinterleave
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnRepeatInterleaveWithDimGetWorkspaceSize 
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveWithDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   aclrtStream stream);

// dim, int repeats
/**
 * @brief aclnnRepeatInterleaveIntworkspace
 * @domain aclnn_math
 *
 *  Tensorrepeatinterleave
 * @param [in] self: npu deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32BFLOAT16
 * tensor, tensorND
 * @param [in] repeats: INT64repeats
 * @param [in] outputSize: tensorINT64outputSizeself * repeats
 * @param [in] out: npu deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveIntGetWorkspaceSize(const aclTensor* self, int64_t repeats,
                                                               int64_t outputSize, aclTensor* out,
                                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnRepeatInterleaveInt
 *
 *  Tensorrepeatinterleave
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRepeatInterleaveIntGetWorkspaceSize
 * 
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveInt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

// dim, int repeats
/**
 * @brief aclnnRepeatInterleaveIntWithDimworkspace
 * @domain aclnn_math
 *
 *  Tensorrepeatinterleave
 * @param [in] self: npu deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32BFLOAT16
 * tensor tensorND
 * @param [in] repeats: INT64repeats
 * @param [in] dim: INT64[-self, self-1]
 * @param [in] outputSize: dimINT64outputSizerepeats *
 * selfdimsize
 * @param [in] out: npu deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveIntWithDimGetWorkspaceSize(const aclTensor* self, int64_t repeats,
                                                                      int64_t dim, int64_t outputSize, aclTensor* out,
                                                                      uint64_t* workspaceSize,
                                                                      aclOpExecutor** executor);

/**
 * @brief: aclnnRepeatInterleaveIntWithDim
 *
 *  Tensorrepeatinterleave
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace
 * aclnnRepeatInterleaveIntWithDimGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveIntWithDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                      aclrtStream stream);

// repeat_interleave.Tensor
/**
 * @brief aclnnRepeatInterleaveTensorworkspace
 * @domain aclnn_math
 *
 *  Tensorrepeatinterleave
 * @param [in] repeats: npu deviceaclTensorINT32INT64repeats1D Tensor
 * (shape=[0,]) tensorND
 * @param [in] outputSize: tensorINT64outputSizerepeats
 * @param [in] out: npu deviceaclTensorINT64self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveTensorGetWorkspaceSize(const aclTensor* repeats, int64_t outputSize,
                                                                  aclTensor* out, uint64_t* workspaceSize,
                                                                  aclOpExecutor** executor);

/**
 * @brief: aclnnRepeatInterleaveTensor
 *
 *  Tensorrepeatinterleave
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRepeatInterleaveTensorGetWorkspaceSize
 * 
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRepeatInterleaveTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_REPEAT_INTERLEAVE_H_// End content from: aclnn_repeat_interleave.h

// Begin content from: aclnn_logical_xor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LogicalXor_H_
#define OP_API_INC_LogicalXor_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogicalXorworkspace
 * @domain aclnn_math
 *
 * selfotherbool0False0True
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A1[(self)] -->B1([Contiguous])-->C1([Cast])-->D([LogicalXor])
 * A2[(other)]-->B2([Contiguous])-->C2([Cast])-->D([LogicalXor])
 * D([LogicalXor])-->E([Cast])-->F([ViewCopy])-->G[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorshapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorshapeselfbroadcast
 * TensorNDself
 * @param [in] out: npu
 * deviceaclTensorshapeselfother broadcastshapeND,
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogicalXorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogicalXor
 *
 * selfotherbool0False0True
 *
 * 
 * api:
 * ```mermaid
 * graph LR
 * A1[(self)] -->B1([Contiguous])-->C1([Cast])-->D([LogicalXor])
 * A2[(other)]-->B2([Contiguous])-->C2([Cast])-->D([LogicalXor])
 * D([LogicalXor])-->E([Cast])-->F([ViewCopy])-->G[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLogicalXorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogicalXor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LogicalXor_H_// End content from: aclnn_logical_xor.h

// Begin content from: aclnn_abs.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_ABS_H_
#define OP_API_INC_LEVEL2_ACLNN_ABS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

#define ACLNN_MAX_SHAPE_RANK 8

/**
 * @brief aclnnAbsworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * $$ out_{i} = abs(self_{i}) $$
 *
 * 
 * ```mermaid
 * graph LR
 *   A[(self)]--->B([l0op::Contiguous])
 *   B--->C([l0op::Abs])
 *   C--->D([l0op::ViewCopy])
 *   D--->E[(out)]
 * ```
 *
 * @param [in] self: absnpu deviceaclTensor,
 * FLOATFLOAT16DOUBLEINT8INT16INT32INT64UINT8BOOLNDTensor
 * @param [in] out: absnpu deviceaclTensor,
 * FLOATFLOAT16DOUBLEINT8INT16INT32INT64UINT8BOOLNDTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAbsGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnAbs
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAbsGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAbs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                               const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ABS_H_// End content from: aclnn_abs.h

// Begin content from: aclnn_upsample_bilinear_2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNAMPLE_BILINEAR_H_
#define OP_API_INC_UNAMPLE_BILINEAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleBilinear2d
 */
ACLNN_API aclnnStatus aclnnUpsampleBilinear2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              aclrtStream stream);

/**
 * @brief aclnnUpsampleBilinear2dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleBilinear2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                              const bool alignCorners, const double scalesH,
                                                              const double scalesW, aclTensor* out,
                                                              uint64_t* workspaceSize, aclOpExecutor** executor);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_BILINEAR_H_// End content from: aclnn_upsample_bilinear_2d.h

// Begin content from: aclnn_upsample_nearest_exact3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_NEAREST_EXACT3D_H_
#define OP_API_INC_UNAMPLE_NEAREST_EXACT3D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearestExact3dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleNearestExact3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                             double scalesD, double scalesH, double scalesW,
                                                             aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleNearestExact3d
 */
ACLNN_API aclnnStatus aclnnUpsampleNearestExact3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_EXACT3D_H_
// End content from: aclnn_upsample_nearest_exact3d.h

// Begin content from: aclnn_foreach_div_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_DIV_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_DIV_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachDivScalarV2workspace
 * xscalar
 * 
 * out_{i}=x_{i}/scalar
 * @domain aclnnop_math
 * 
 * @param [in]   x
 * TensorFLOATFLOAT16BFLOAT16ND
 * @param [in]   scalar
 * ScalarFLOATND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachDivScalarV2GetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachDivScalarV2
 * xscalar
 * 
 * out_{i}=x_{i}/scalar
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachDivScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachDivScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_div_scalar_v2.h

// Begin content from: aclnn_triangular_solve.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TRIANGULAR_SOLVE_H_
#define OP_API_INC_TRIANGULAR_SOLVE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTriangularSolveworkspace
 * @domain aclnn_math
 *
 *  TensorAX=b
 * @param [in] self: b, FLOATDOUBLECOMPLEX64COMPLEX12828
 * TensorNDshape(*,m,n)A(*,m,m)broadcast
 * @param [in] A: A, FLOATDOUBLECOMPLEX64COMPLEX12828
 * TensorNDshape(*,m,n)self(*,m,n)broadcast
 * @param [in] upper: trueAupperfalseA
 * @param [in] transpose: falsetransposetrueATX=B,ATA
 * @param [in] unitriangular: falseunitriangulartrueA1A
 * @param [out] xOut: XFLOATDOUBLECOMPLEX64COMPLEX12828
 * TensorNDshapebroadcastA,bAX=b
 * @param [out] mOut: broadcastAFLOATDOUBLECOMPLEX64COMPLEX128
 * 28TensorNDshapebroadcastA
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTriangularSolveGetWorkspaceSize(const aclTensor* self, const aclTensor* A, bool upper,
                                                           bool transpose, bool unitriangular, aclTensor* xOut,
                                                           aclTensor* mOut, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief: aclnnTriangularSolve
 *
 *  Tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTriangularSolveGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTriangularSolve(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TRIANGULAR_SOLVE_H_// End content from: aclnn_triangular_solve.h

// Begin content from: aclnn_softplus_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SOFTPLUS_BACKWARD_H_
#define OP_API_INC_SOFTPLUS_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSoftplusBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnSoftplusBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                            const aclScalar* beta, const aclScalar* threshold,
                                                            aclTensor* gradInput, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnSoftplusBackward
 */
ACLNN_API aclnnStatus aclnnSoftplusBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SOFTPLUS_BACKWARD_H_
// End content from: aclnn_softplus_backward.h

// Begin content from: aclnn_circular_pad3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CIRCULAR_PAD3D_BACKWARD_H_
#define OP_API_INC_CIRCULAR_PAD3D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnCircularPad3dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 * @param [in] gradOutput: npu deviceaclTensor, FLOAT16, FLOAT32, BFLOAT16, ND
 * selfgradInputshapecircular_pad3doutput
 * @param [in] self: npu deviceaclTensor,
 * gradOutputNDgradOutput gradInputshapegradInput
 * @param [in] padding: npu deviceaclIntArray, INT646
 * selfselfself
 * @param [in] gradInput: npu deviceaclTensor, gradOutputshapeselfND
 * gradOutputself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCircularPad3dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                   const aclIntArray* padding, aclTensor* gradInput,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnCircularPad3dBackward
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnCircularPad3dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCircularPad3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CIRCULAR_PAD3D_BACKWARD_H_// End content from: aclnn_circular_pad3d_backward.h

// Begin content from: aclnn_leaky_relu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEAKY_RELU_H_
#define OP_API_INC_LEAKY_RELU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLeakyReluworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLETensorND
 * @param [in] negativeSlope: hostaclScalarself<0
 * @param [in] out: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLEselfshapeselfTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLeakyReluGetWorkspaceSize(const aclTensor* self, const aclScalar* negativeSlope,
                                                     aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLeakyRelu
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLeakyReluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLeakyRelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

/**
 * @brief aclnnInplaceLeakyReluworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * @param [in] selfRef: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [in] negativeSlope: hostaclScalarself<0
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLeakyReluGetWorkspaceSize(aclTensor* selfRef, const aclScalar* negativeSlope,
                                                            uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLeakyRelu
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceLeakyReluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLeakyRelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEAKY_RELU_H_// End content from: aclnn_leaky_relu.h

// Begin content from: aclnn_foreach_pow_scalar_and_tensor.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_POW_SCALAR_AND_TENSOR_H_
#define ACLNN_FOREACH_POW_SCALAR_AND_TENSOR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachPowScalarAndTensorGetWorkspaceSize
 * parameters :
 * scalar : required
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachPowScalarAndTensorGetWorkspaceSize(
    const aclScalar *scalar,
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachPowScalarAndTensor
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachPowScalarAndTensor(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_pow_scalar_and_tensor.h

// Begin content from: aclnn_scatter_nd.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_SCATTER_ND_H_
#define OP_API_INC_SCATTER_ND_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnScatterNdworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnScatterNdGetWorkspaceSize(const aclTensor* data, const aclTensor* indices,
                                                     const aclTensor* updates, aclTensor* out, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnScatterNd
 */
ACLNN_API aclnnStatus aclnnScatterNd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SCATTER_ND_H_// End content from: aclnn_scatter_nd.h

// Begin content from: aclnn_reduce_sum.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REDUCE_SUM_H_
#define OP_API_INC_REDUCE_SUM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnReduceSumworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnReduceSumGetWorkspaceSize(const aclTensor* self, const aclIntArray* dims, bool keepDims,
                                                     aclDataType dtype, aclTensor* out, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnReduceSum
 */
ACLNN_API aclnnStatus aclnnReduceSum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REDUCE_SUM_H_
// End content from: aclnn_reduce_sum.h

// Begin content from: aclnn_moe_init_routing_v2_grad.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_INIT_ROUTING_V2GRAD_H_
#define ACLNN_MOE_INIT_ROUTING_V2GRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeInitRoutingV2GradGetWorkspaceSize
 * parameters :
 * gradExpandedX : required
 * expandedRowIdx : required
 * topK : required
 * dropPadMode : optional
 * activeNum : optional
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingV2GradGetWorkspaceSize(
    const aclTensor *gradExpandedX,
    const aclTensor *expandedRowIdx,
    int64_t topK,
    int64_t dropPadMode,
    int64_t activeNum,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeInitRoutingV2Grad
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingV2Grad(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_init_routing_v2_grad.h

// Begin content from: aclnn_index_select.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_INDEX_SELECT_H_
#define OP_API_INC_LEVEL2_ACLNN_INDEX_SELECT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIndexSelectworkspace
 * @domain aclnn_ops_infer
 * Tensor
 * 
 * 
 *   x=$\begin{bmatrix}[[1,&2],&[3,&4]], \\ [[5,&6],&[7,&8]], \\ [[9,&10],&[11,&12]]\end{bmatrix}$
 *   idx=[1, 0],
 * dim0, index_select(0, idx)   I=index[i];  &nbsp;&nbsp;   y$[i][m][n]$ = x$[I][m][n]$
 * dim1, index_select(1, idx)   J=index[j];  &nbsp;&nbsp;&nbsp;    y$[l][j][n]$ = x$[l][J][n]$
 * dim2, index_select(2, idx)   K=index[k]; &nbsp;  y$[l][m][k]$ = x$[l][m][K]$
 *
 * 
 * ```mermaid
 * graph LR
 *   A[(Self)] -->B([l0op::Contiguous])
 *   B --> In_0([l0op::cast]) --> Op([GatherV2])
 *   In_1[(index)] --> con([l0op::Contiguous])--> Op
 *   In_2(dim) --> a(dimVec) --> Op
 *   Op --> C([l0op::cast]) --> D([l0op::ViewCopy])  --> Out[(out)]
 * ```

 *
 * @param [in] self: npu deviceaclTensor
 *
 FLOATFLOAT16BFLOAT16INT64INT32INT16INT8UINT8BOOLDOUBLECOMPLEX64COMPLEX128NDTensor
 * @param [in] dim: hostint64
 * @param [in] index: indeciesnpu deviceaclTensor
 * INT64INT32ND0D1D Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIndexSelectGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index,
                                                       aclTensor* out, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnIndexSelect
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnIndexSelectGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIndexSelect(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_INDEX_SELECT_H_
// End content from: aclnn_index_select.h

// Begin content from: aclnn_searchsorted.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_SEARCHSORTED_H_
#define OP_API_INC_LEVEL2_ACLNN_SEARCHSORTED_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSearchSortedworkspace
 * @domain aclnn_ops_infer
 *
 *  sortedSequenceself
 * @param [in] sortedSequence: npu deviceaclTensor, FLOAT16, FLOAT32, INT32, INT8, UINT8, INT16, INT64,
 * TensorND
 * @param [in] self: npu deviceaclTensor, FLOAT16, FLOAT32, INT32, INT8, UINT8, INT16, INT64,
 * TensorND
 * @param [in] outInt32: hostBOOLTensorINT32
 * @param [in] right: hostBOOL
 * @param [in] sorter: npu deviceaclTensor, INT64, sortedSequence
 * @param [in] out: npu deviceaclTensor, FLOAT16, FLOAT32, INT32, INT8, UINT8, INT16, INT64,
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSearchSortedGetWorkspaceSize(const aclTensor* sortedSequence, const aclTensor* self,
                                                        const bool outInt32, const bool right, const aclTensor* sorter,
                                                        aclTensor* out, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnSearchSortedworkspace
 *
 *  sortedSequenceself
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSearchSortedGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSearchSorted(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

/**
 * @brief aclnnSearchSortedsworkspace
 * @domain aclnn_ops_infer
 *
 *  sortedSequenceself
 * @param [in] sortedSequence: npu deviceaclTensor, FLOAT16, FLOAT32, INT32, INT8, UINT8, INT16, INT64,
 * TensorND
 * @param [in] self: npu deviceaclScalar, FLOAT16, FLOAT32, INT32, INT8, UINT8, INT16, INT64
 * @param [in] outInt32: hostBOOLTensorINT32
 * @param [in] right: hostBOOL
 * @param [in] sorter: npu deviceaclTensor, INT64, sortedSequence
 * @param [in] out: npu deviceaclTensor, FLOAT16, FLOAT32, INT32, INT8, UINT8, INT16, INT64,
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSearchSortedsGetWorkspaceSize(const aclTensor* sortedSequence, const aclScalar* self,
                                                         const bool outInt32, const bool right, const aclTensor* sorter,
                                                         aclTensor* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnSearchSorteds
 *
 *  sortedSequenceself
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSearchSortedsGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSearchSorteds(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SEARCHSORTED_H_
// End content from: aclnn_searchsorted.h

// Begin content from: aclnn_foreach_norm.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_NORM_H_
#define ACLNN_FOREACH_NORM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachNormGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachNormGetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachNorm
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachNorm(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_norm.h

// Begin content from: aclnn_leaky_relu_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEAKY_RELU_BACKWARD_H_
#define OP_API_INC_LEAKY_RELU_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnLeakyReluBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 *
 * @param [in] gradOutput: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLEselfshapeself
 * [Tensor](#Tensor)ND[](#)
 * @param [in] self: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLE[Tensor](#Tensor)ND[](#)
 * @param [in] negativeSlope: hostaclScalarself<0
 * @param [in] selfIsResult: hostboolself
 * @param [in] out: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLE[Tensor](#Tensor)ND[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLeakyReluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                             const aclScalar* negativeSlope, bool selfIsResult,
                                                             aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);
/**
 * @brief aclnnLeakyReluBackward
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLeakyReluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLeakyReluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEAKY_RELU_BACKWARD_H_// End content from: aclnn_leaky_relu_backward.h

// Begin content from: aclnn_mish.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MISH_H_
#define OP_API_INC_MISH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMishworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * @param [in] self: npu deviceaclTensorFLOAT16BFLOAT16FLOATTensorND
 * @param [in] out: npu
 * deviceaclTensorFLOAT16BFLOAT16FLOATshapeselfselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMishGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnMish
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMishGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceMishworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * @param [in] selfRef: npu
 * deviceaclTensorFLOAT16BFLOAT16FLOATTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMishGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceMish
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceMishGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MISH_H_
// End content from: aclnn_mish.h

// Begin content from: aclnn_minimum.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MINIMUM_H_
#define OP_API_INC_MINIMUM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMinimumworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * othershapeotherbroadcastTensorND
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * othershapeotherbroadcastTensorND
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * selfothershapeselfother
 * broadcastshapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMinimumGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMinimum
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMinimumGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMinimum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MINIMUM_H_
// End content from: aclnn_minimum.h

// Begin content from: aclnn_arange.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ARANGE_H_
#define OP_API_INC_ARANGE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnArangeworkspace
 * @domain aclnn_ops_infer
 * startendstep1
 */
ACLNN_API aclnnStatus aclnnArangeGetWorkspaceSize(const aclScalar* start, const aclScalar* end, const aclScalar* step,
                                                  aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
/* @brief aclnnArange */
ACLNN_API aclnnStatus aclnnArange(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                  const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_arange.h

// Begin content from: aclnn_moe_compute_expert_tokens.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_COMPUTE_EXPERT_TOKENS_H_
#define ACLNN_MOE_COMPUTE_EXPERT_TOKENS_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeComputeExpertTokensGetWorkspaceSize
 * parameters :
 * sortedExperts : required
 * numExperts : required
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeComputeExpertTokensGetWorkspaceSize(
    const aclTensor *sortedExperts,
    int64_t numExperts,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeComputeExpertTokens
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeComputeExpertTokens(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_compute_expert_tokens.h

// Begin content from: aclnn_floor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_FLOOR_H_
#define OP_API_INC_LEVEL2_ACLNN_FLOOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFloorworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * $$ out_{i} =floor(self_{i}) $$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B{l0op::Contiguous}
 *     B -->C([l0op::Floor])
 *     C --> D{l0op::ViewCopy}
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: floornpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16NDout Tensor
 * @param [in] out: floornpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16NDself Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFloorGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnFloor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnFloorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFloor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceFloorworkspace
 * @domain aclnn_math
 * @param [in] selfRef: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND 8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFloorGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnInplaceFloor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceFloorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFloor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_FLOOR_H_
// End content from: aclnn_floor.h

// Begin content from: aclnn_tan.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TAN_H_
#define OP_API_INC_TAN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTanworkspace
 * @domain aclnn_math
 *
 * selfout
 * $$ out[i] = tan(self[i]) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([l0op::Contiguous])
 *     B --> C([l0op::Tan])
 *     C --> D([l0op::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensor
 *  FLOATBFLOAT16FLOAT16INT32DOUBLECOMPLEX64COMPLEX128, TensorND
 * @param [in] out: npu deviceaclTensor
 *  FLOATBFLOAT16FLOAT16INT32DOUBLECOMPLEX64COMPLEX128, TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTanGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnInplaceTanworkspace
 * @domain aclnn_math
 *
 * selfRefselfRef
 * $$ out[i] = tan(self[i]) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(selfRef)] -->B([l0op::Contiguous])
 *     B --> C([l0op::Tan])
 *     C --> D([l0op::ViewCopy])
 *     D --> E[(selfRef)]
 * ```
 *
 * @param [in] selfRef: npu deviceaclTensor
 *  FLOATFLOAT16INT32DOUBLECOMPLEX64COMPLEX128, TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTanGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnTan
 *
 * selfout
 * $$ out[i] = tan(self[i]) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([l0op::Contiguous])
 *     B --> C([l0op::Tan])
 *     C --> D([l0op::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTanhGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTan(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                               const aclrtStream stream);

/**
 * @brief aclnnInplaceTan
 *
 * selfRefselfRef
 * $$ out[i] = tan(self[i]) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(selfRef)] -->B([l0op::Contiguous])
 *     B --> C([l0op::Tan])
 *     C --> D([l0op::ViewCopy])
 *     D --> E[(selfRef)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTanhGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTan(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TANH_H// End content from: aclnn_tan.h

// Begin content from: aclnn_group_quant.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GROUP_QUANT_H_
#define OP_API_INC_LEVEL2_ACLNN_GROUP_QUANT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupQuantworkspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: GroupQuantnpu deviceaclTensor
 * float16, bfloat16, float32, ND
 * Tensor
 * @param [in] scale: npu deviceaclTensor, float, bf16, float16
 * @param [in] groupIndex: npu deviceaclTensorfloat, bf16, float16
 * @param [in] offsetOptional:  npu deviceaclTensorint, int64
 * @param [in] dstType:  hostaclScalar, int
 * @param [in] y: GroupQuantnpu deviceaclTensor
 * int8, int4, ND
 * Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupQuantGetWorkspaceSize(const aclTensor* x, const aclTensor* scale,
                                                      const aclTensor* groupIndex, const aclTensor* offsetOptional,
                                                      int32_t dstType, aclTensor* y,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGroupQuant
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGroupQuantGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupQuant(void* workspace, uint64_t workspaceSize,
                                      aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GROUP_QUANT_H_// End content from: aclnn_group_quant.h

// Begin content from: aclnn_hardswish_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_HARDSWISH_BACKWARD_H_
#define OP_API_INC_HARDSWISH_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHardswishBackwardworkspace
 * @domain aclnn_ops_train
 *
 * hardswish
 * 
 * $$ res_{i} = grad\_output_{i} \times grad\_self_{i} $$
 * $$
 * grad\_self_{i} = \begin{cases}
 * 0, & self_{i} \lt -3, \\
 * self_{i} / 3 + 0.5, &   -3 \le self_{i} \le 3, \\
 * 1, & self_{i} \gt 3
 * \end{cases}
 * $$
 *
 * 
 * api
 * ```mermaid
graph LR
 *     A[(gradOutput)] --> B([l0op::Contiguous])
 *     B --> C([l0op::HardSwishGrad])
 *     D[(self)] --> E([l0op::Contiguous])
 *     E --> C([l0op::HardSwishGrad])
 *     C --> F([l0op::ViewCopy])
 *     F --> g[(out)]
```
 *
 * @param [in] gradOutput: npu
 * deviceaclTensorselfshapeself
 * TensorNDNCHWNHWCother
 * @param [in] self: npu
 * deviceaclTensorgradOutputshapegradOutput
 * TensorNDNCHWNHWCgradOutput
 * @param [in] out: npu
 * deviceaclTensorgradOutputshapegradOutput
 * TensorNDNCHWNHWCgradOutput
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardswishBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                             aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnHardswishBackward
 *
 * hardswish
 * 
 * $$ res_{i} = grad\_output_{i} \times grad\_self_{i} $$
 * $$
 * grad\_self_{i} = \begin{cases}
 * 0, & self_{i} \lt -3, \\
 * self_{i} / 3 + 0.5, &   -3 \le self_{i} \le 3, \\
 * 1, & self_{i} \gt 3
 * \end{cases}
 * $$
 *
 * 
 * api
 * ```mermaid
graph LR
 *     A[(gradOutput)] --> B([l0op::Contiguous])
 *     B --> C([l0op::HardSwishGrad])
 *     D[(self)] --> E([l0op::Contiguous])
 *     E --> C([l0op::HardSwishGrad])
 *     C --> F([l0op::ViewCopy])
 *     F --> g[(out)]
```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSubGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardswishBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_HARDSWISH_BACKWARD_H_// End content from: aclnn_hardswish_backward.h

// Begin content from: aclnn_isfinite.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ISFINITE_H_
#define OP_API_INC_LEVEL2_ISFINITE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * 
 * 
 * True
 *
 * ```mermaid
 * graph LR
 *     A[(self)] --> C([l0op::Fill]) --> H([l0op::ViewCopy]) --> K[(out)]
 * ```
 *
 * IsFinite
 *
 * ```mermaid
 * graph LR
 *     A[(self)] --> B([l0op::Contiguous]) --> C([l0op::IsFinite]) --> H([l0op::ViewCopy]) --> K[(out)]
 * ```
 */

/**
 * @brief aclnnIsFiniteworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensor
 * FLOATFLOAT16BFLOAT16(910B)DOUBLEINT32INT64INT16INT8UINT8BOOLTensorND
 * @param [out] out: npu deviceaclTensorBOOLshapeselfTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsFiniteGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                    aclOpExecutor** executor);

/**
 * @brief aclnnIsFinite
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnIsFiniteGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsFinite(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ISFINITE_H_
// End content from: aclnn_isfinite.h

// Begin content from: aclnn_frac.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_FRAC_H_
#define OP_API_INC_FRAC_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFracworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * out_{i}=input_{i} - \lfloor \vert input_{i} \vert \rfloor * sgn(input_{i})
 * 
 * @param [in]   input
 * TensorFLOAT16FLOATUINT8INT8INT16INT32INT64TensorND
 * @param [in]   out
 * TensorFLOAT16FLOATUINT8INT8INT16INT32INT64TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnFracGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnFrac
 * Tensor
 * 
 * out_{i}=input_{i} - \lfloor \vert input_{i} \vert \rfloor * sgn(input_{i})
 * 
 * api
```mermaid
graph LR
    A[(Input)] -->B([l0op::Contiguous])
    B -->C([l0op::Sub])

    B -->F1([l0op::Trunc])
    F1 --> C
    C -->D([l0op::ViewCopy])
    D -->E[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnFracGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFrac(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceFracworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * @param [in]   inputRef
 * TensorFLOAT16FLOATUINT8INT8INT16INT32INT64TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceFracGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceFrac
 * Tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceFracGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFrac(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_frac.h

// Begin content from: aclnn_foreach_add_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_ADD_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_ADD_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachAddScalarV2workspace
 * scalar
 * 
 * out_{i}=x_{i}+scalar
 * @domain aclnnop_math
 * 
 * @param [in]   x
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   scalar
 * ScalarFLOATFLOAT16INT32ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachAddScalarV2GetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachAddScalarV2
 * scalar
 * 
 * out_{i}=x_{i}+scalar
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachAddScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachAddScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_add_scalar_v2.h

// Begin content from: aclnn_erfc.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ERFC_H_
#define OP_API_INC_LEVEL2_ACLNN_ERFC_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnErfcworkspace
 * @domain aclnn_ops_infer
 * Tensor
 * 
 * $$ erfc(x)=1-\frac{2}{\sqrt{\pi } } \int_{0}^{x} e^{-t^{2} } \mathrm{d}t $$
 *
 * ErfcFLOAT32BFLOAT16FLOAT16FLOAT64Erfc
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B([l0op::Contiguous])
 *     B --> C([l0op::Erfc])
 *     C --> D([l0op::Cast])
 *     D --> E([l0op::ViewCopy])
 *     E --> F[(out)]
 * ```
 *
 * selfBOOLINT64selfCASTFLOAT32Erfc
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B([l0op::Contiguous])
 *     B -->C([l0op::Cast])
 *     C -->D([l0op::Erfc])
 *     D --> E([l0op::Cast])
 *     E --> F([l0op::ViewCopy])
 *     F --> G[(out)]
 * ```
 *
 * @param [in] self: erfcnpu deviceaclTensor
 * FLOAT64FLOAT32BFLOAT16FLOAT16BOOLINT64ND Tensor
 * @param [in] out: erfcnpu deviceaclTensor
 * FLOAT64FLOAT32BFLOAT16FLOAT16selfselfBOOLINT64outFLOAT32
 * NDselfshapeTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnErfcGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnErfc
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnErfcGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnErfc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceErfcworkspace
 * @domain aclnn_ops_infer
 * Tensor
 * 
 * $$ erfc(x)=1-\frac{2}{\sqrt{\pi } } \int_{0}^{x} e^{-t^{2} } \mathrm{d}t $$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B{l0op::Contiguous}
 *     B -->C([l0op::Erfc])
 *     C --> D{l0op::ViewCopy}
 *     D --> E[(out)]
 * ```
 *
 * @param [in] selfRef: erfcnpu deviceaclTensor
 * FLOAT64FLOAT32BFLOAT16FLOAT16ND Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceErfcGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceErfc
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceErfcGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceErfc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ERFC_H_// End content from: aclnn_erfc.h

// Begin content from: aclnn_quant_scatter.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_QUANT_SCATTER_H_
#define OP_API_INC_LEVEL2_ACLNN_QUANT_SCATTER_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceQuantScatterworkspace
 * @domain aclnn_ops_infer
 * 
 * updatesupdatesaxisindicesselfRef,
 * tensorflowpytorch
 * @param [in] selfRef: npu deviceaclTensorINT8updates
 * TensorND
 * @param [in] indices: npu deviceaclTensorINT32TensorND
 * @param [in] updates: npu deviceaclTensorBFLOAT16910B AI
 * selfRefTensorND
 * @param [in] quantScales: npu deviceaclTensorBFLOAT16910B AI
 * tensorND
 * @param [in] quantZeroPoints: npu deviceaclTensorBFLOAT16910B AI
 * tensorND
 * @param [in] axis: scatterINT64
 * @param [in] quantAxis: INT64
 * @param [in] reduction: INT641('update')
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceQuantScatterGetWorkspaceSize(aclTensor* selfRef, const aclTensor* indices,
                                                               const aclTensor* updates, const aclTensor* quantScales,
                                                               const aclTensor* quantZeroPoints, int64_t axis,
                                                               int64_t quantAxis, int64_t reduction,
                                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceQuantScatter
 * @domain aclnn_ops_infer
 * 
 * updatesupdatesaxisindicesselfRef,
 * tensorflowpytorch
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceQuantScatterGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceQuantScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_QUANT_SCATTER_H_// End content from: aclnn_quant_scatter.h

// Begin content from: aclnn_fill_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_FILL_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_FILL_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Tensorvalue
 * 
 *   
 *
 * 
 * ```mermaid
 * graph LR
 *    A[(selfRef)] --> B(AclTensor: dims) -->C([l0op::Fill])
 *    D[(value)] --> C
 *    C --> E([l0op::ViewCopy])--> F[(out)]
 * ```
 */

/**
 * @brief aclnnInplaceFillTensorworkspace
 * @domain aclnn_ops_infer
 * @param [in] selfRef: npu deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64DOUBLE
 * COMPLEX64COMPLEX128BOOLBFLOAT16TensorND8
 * @param [in] value: npu deviceaclTensorFLOATFLOAT16UINT8INT8INT16INT32INT64DOUBLE
 * COMPLEX64COMPLEX128BOOLBFLOAT16selfRefND0D
 * size=11D
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFillTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* value,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceFillTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspacSize: npu deviceworkspaceaclnnFillTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFillTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_FILL_TENSOR_H_// End content from: aclnn_fill_tensor.h

// Begin content from: aclnn_atan.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ATAN_H_
#define OP_API_INC_ATAN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAtanworkspace
 * @domain aclnn_math
 * 
 * 
 * out_{i}=tan^{-1}(input_{i})
 * 
 * @param [in]   input
 * TensorFLOATBFLOAT16, FLOAT16DOUBLETensorND
 * @param [in]   out
 * TensorFLOATBFLOAT16, FLOAT16DOUBLETensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnAtanGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);
/**
 * @brief aclnnAtan
 * 
 * 
 * out_{i}=tan^{-1}(input_{i})
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B --> C([l0op::Atan])
    C --> G([l0op::Cast])
    G --> E([l0op::ViewCopy])
    E --> S[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAtan(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceAtanworkspace
 * @domain aclnn_math
 * 
 * 
 * out_{i}=tan^{-1}(input_{i})
 * 
 * @param [in]   input
 * TensorINT8INT16INT32INT64UINT8BOOLFLOATFLOAT16DOUBLETensorND
 * @param [in]   out
 * TensorFLOATFLOAT16DOUBLETensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceAtanGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceAtan
 *
 *  Tensoratan
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAtanGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAtan(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_atan.h

// Begin content from: aclnn_reflection_pad1d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REFLECTION_PAD1D_BACKWARD_H_
#define OP_API_INC_REFLECTION_PAD1D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReflectionPad1dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * reflection_pad1d
 * @param [in] gradOutput: FLOAT16, FLOAT32, DOUBLE, COMPLEX64,
 * COMPLEX128[Tensor](#)ND([](#))
 * selfgradInputshapereflection_pad1doutput
 * @param [in] self:
 * gradOutput[Tensor](#)ND([](#))gradOutput
 * gradInputshapegradInput
 * @param [in] padding: INT642self
 * @param [in] gradInput:
 * gradOutputshapeself[Tensor](#)ND([](#))
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad1dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                   const aclIntArray* padding, aclTensor* gradInput,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnReflectionPad1dBackward
 *
 * reflection_pad1d
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnReflectionPad1dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad1dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REFLECTION_PAD1D_BACKWARD_H_// End content from: aclnn_reflection_pad1d_backward.h

// Begin content from: aclnn_polar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_POLAR_H_
#define OP_API_INC_POLAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnPolarworkspace
 * @domain aclnn_ops_infer
 * 
 * absangle
 *
 * @param [in] input: npu deviceaclTensorFLOAT
 * TensorND
 * @param [in] angle: npu deviceaclTensorinput
 * TensorND
 * @param [out] out complex64
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 */
ACLNN_API aclnnStatus aclnnPolarGetWorkspaceSize(const aclTensor* input, const aclTensor* angle, aclTensor* out,
                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnPolar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnPolarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnPolar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_POLAR_H_// End content from: aclnn_polar.h

// Begin content from: aclnn_kl_div_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_KL_DIV_BACKWARD_H_
#define OP_API_INC_KL_DIV_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnKlDivBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnKlDivBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                         const aclTensor* target, int64_t reduction, bool logTarget,
                                                         aclTensor* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnKlDivBackward
 */
ACLNN_API aclnnStatus aclnnKlDivBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_KL_DIV_DBACKWARD_H_
// End content from: aclnn_kl_div_backward.h

// Begin content from: aclnn_foreach_log.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_LOG_H_
#define ACLNN_FOREACH_LOG_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachLogGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLogGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachLog
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLog(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_log.h

// Begin content from: aclnn_foreach_div_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_DIV_SCALAR_LIST_H_
#define ACLNN_FOREACH_DIV_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachDivScalarListGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachDivScalarListGetWorkspaceSize(
    const aclTensorList *x,
    const aclScalarList *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachDivScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachDivScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_div_scalar_list.h

// Begin content from: aclnn_nll_loss2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_NLL_LOSS2D_BACKWARD_H_
#define OP_API_INC_NLL_LOSS2D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNLLLoss2dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 *
 * @param [in] gradOutputnpu
 * deviceaclTensorshapeN1FLOATFLOAT16BFLOAT16
 * [Tensor](#)ND[](#)
 * @param [in] selfnpu deviceaclTensorshapeNbatch
 * sizeCFLOATFLOAT16 [Tensor](#)ND[](#)
 * @param [in] targetnpu deviceaclTensorshapeN[0, C -
 * 1]INT64UINT8 [Tensor](#)ND[](#)
 * @param [in] weightnpu deviceaclTensorshape(C, )FLOATFLOAT16
 * [Tensor](#)ND[](#)
 * @param [in] reductionhostint64_t 0('none') | 1('mean') | 2('sum')
 * 'none' 'mean' 'sum' 
 * @param [in] ignoreIndexhostint64_t
 * @param [in] totalWeightnpu
 * deviceaclTensorFLOATFLOAT16weightshape(1)ND[](#)
 * @param [out] outnpu deviceaclTensorshapeself[Tensor](#)ND[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNLLLoss2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                             const aclTensor* target, const aclTensor* weight,
                                                             int64_t reduction, int64_t ignoreIndex,
                                                             aclTensor* totalWeight, aclTensor* out,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnNLLLoss2dBackward
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnNLLLoss2dBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNLLLoss2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_NLL_LOSS2_DBACKWARD_H_
// End content from: aclnn_nll_loss2d_backward.h

// Begin content from: aclnn_adaptive_avg_pool3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_ADAPTIVE_AVG_POOL3D_H_
#define OP_API_INC_ADAPTIVE_AVG_POOL3D_H_

#include <array>
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAdaptiveAvgPool3dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnAdaptiveAvgPool3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                             aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnAdaptiveAvgPool3d
 */
ACLNN_API aclnnStatus aclnnAdaptiveAvgPool3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_adaptive_avg_pool3d.h

// Begin content from: aclnn_ger.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GER_H_
#define OP_API_INC_LEVEL2_ACLNN_GER_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGerworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnGerGetWorkspaceSize(const aclTensor* self, const aclTensor* vec2, aclTensor* out,
                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGer
 */
ACLNN_API aclnnStatus aclnnGer(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GER_H_// End content from: aclnn_ger.h

// Begin content from: aclnn_embedding_dense_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_EMBEDDING_DENSE_BACKWARD_H_
#define OP_API_INC_EMBEDDING_DENSE_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnEmbeddingDenseBackwardworkspace
 * @domain aclnn_ops_train
 *
 * Embedding
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(grad)] -->B([l0op::Contiguous])
 *     B --> L([l0op::Cast])
 *     L --> C([l0op::EmbeddingDenseGrad])
 *     D[(indices)] -->E([l0op::Contiguous])
 *     E --> F([l0op::Cast])
 *     F --> C
 *     C --> M([l0op::Cast])
 *     M --> G([l0op::ViewCopy])
 *     G --> K[(out)]
 *     H((numWeights)) --> C
 *     I((paddingIdx)) --> C
 *     J((scaleGradByFreq)) --> C
 * ```
 *
 * @param [in] grad: npu
 * deviceaclTensorTensorshapenpu
 * deviceaclTensorfloatfloat16bfloat16 NDindices
 * @param [in] indices: npu
 * deviceaclTensorint32TensorND
 * @param [in] numWeights: 
 * @param [in] paddingIdx:
 * IDNone0paddingIdx
 * @param [in] scaleGradByFreq: False
 * @param [out] out: npu
 * Tensorfloat322D
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEmbeddingDenseBackwardGetWorkspaceSize(const aclTensor* grad, const aclTensor* indices,
                                                                  uint64_t numWeights, uint64_t paddingIdx,
                                                                  bool scaleGradByFreq, const aclTensor* out,
                                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnEmbeddingDenseBackward
 *
 * Embedding
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(grad)] -->B([l0op::Contiguous])
 *     B --> L([l0op::Cast])
 *     L --> C([l0op::EmbeddingDenseGrad])
 *     D[(indices)] -->E([l0op::Contiguous])
 *     E --> F([l0op::Cast])
 *     F --> C
 *     C --> M([l0op::Cast])
 *     M --> G([l0op::ViewCopy])
 *     G --> K[(out)]
 *     H((numWeights)) --> C
 *     I((paddingIdx)) --> C
 *     J((scaleGradByFreq)) --> C
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnEmbeddingDenseBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEmbeddingDenseBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_EMBEDDING_DENSE_BACKWARD_H_
// End content from: aclnn_embedding_dense_backward.h

// Begin content from: aclnn_smooth_l1_loss_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_SMOOTH_L1_LOSS_BACKWARD_H_
#define OP_API_INC_SMOOTH_L1_LOSS_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSmoothL1LossBackwardworkspace
 * @domain aclnn_ops_train
 *
 *  TensorSmoothL1Loss backward
 * smoothL1Loss, $|x-y|<1$,$$\frac{\partial SmoothL1Loss(x,y)}{\partial x} = x - y $$
 * smoothL1Loss, $|x-y|\geq 1$,$$\frac{\partial SmoothL1Loss(x,y)}{\partial x} = sign(x-y)$$
 * @param [in] gradOut: npu deviceaclTensor, FLOATFLOAT16, ND, Tensor
 * @param [in] self: npu deviceaclTensor, FLOATFLOAT16, ND, Tensor
 * @param [in] target: npu deviceaclTensor, FLOATFLOAT16, ND, Tensor
 * @param [in] reduction: hostint64_t0("none"),1("mean"),2"sum")
 * @param [in] beta:L1L2double
 * @param [in] gradInput:npu deviceaclTensor, FLOATFLOAT16, ND, Tensor
 * reduction"none"shapeselfshape[1]
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus:  ACLNN_SUCCESS, 
 */
ACLNN_API aclnnStatus aclnnSmoothL1LossBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* self,
                                                                const aclTensor* target, int64_t reduction, float beta,
                                                                aclTensor* gradInput, uint64_t* workspaceSize,
                                                                aclOpExecutor** executor);

/**
 * @brief: aclnnSmoothL1LossBackward
 *
 *  TensorSmoothL1Loss backward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSigmoidBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: ,ACLNN_SUCCESS, 
 */
ACLNN_API aclnnStatus aclnnSmoothL1LossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SMOOTH_L1_LOSS_BACKWARD_H_// End content from: aclnn_smooth_l1_loss_backward.h

// Begin content from: aclnn_pad2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_PAD2D_BACKWARD_H_
#define OP_API_INC_PAD2D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReflectionPad2dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 * @param [in] gradOutput: npu deviceaclTensor, FLOAT16, FLOAT32, DOUBLE, COMPLEX64,
 * COMPLEX128ND
 * selfgradInputshapereflection_pad2doutput
 * @param [in] self: npu deviceaclTensor,
 * gradOutputNDgradOutput gradInputshapegradInput
 * @param [in] padding: npu deviceaclIntArray, INT644
 * selfself
 * @param [in] gradInput: npu deviceaclTensor, gradOutputshapeselfND
 * gradOutputself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                   const aclIntArray* padding, aclTensor* gradInput,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnReflectionPad2dBackward
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnReflectionPad2dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   const aclrtStream stream);

/**
 * @brief aclnnReplicationPad2dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 * @param [in] gradOutput: npu deviceaclTensor, FLOAT16, FLOAT32, DOUBLE, COMPLEX64,
 * COMPLEX128ND
 * selfgradInputshapereplication_pad2doutput
 * @param [in] self: npu deviceaclTensor,
 * gradOutputNDgradOutput gradInputshapegradInput
 * @param [in] padding: npu deviceaclIntArray, INT644
 * @param [in] gradInput: npu deviceaclTensor, gradOutputshapeselfND
 * gradOutputself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                    const aclIntArray* padding, aclTensor* gradInput,
                                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnReplicationPad2dBackward
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnReplicationPad2dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_PAD2D_BACKWARD_H_// End content from: aclnn_pad2d_backward.h

// Begin content from: aclnn_index_fill_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_INDEX_FILL_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_INDEX_FILL_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIndexFillTensorworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnIndexFillTensorGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclIntArray* index,
                                                           const aclScalar* value, aclTensor* out,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnIndexFillTensor
 */
ACLNN_API aclnnStatus aclnnIndexFillTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

/**
 * @brief aclnnInplaceIndexFillTensorworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnInplaceIndexFillTensorGetWorkspaceSize(aclTensor* selfRef, int64_t dim,
                                                                  const aclIntArray* index, const aclScalar* value,
                                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceIndexFillTensor
 */
ACLNN_API aclnnStatus aclnnInplaceIndexFillTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_INDEX_FILL_TENSOR_H_// End content from: aclnn_index_fill_tensor.h

// Begin content from: aclnn_histc.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_HISTC_H_
#define OP_API_INC_HISTC_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHistcworkspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [in] bins: binsINT32
 * @param [in] min: hostaclScalarFLOAT
 * @param [in] max: hostaclScalarFLOAT
 * @param [in] out: npu deviceaclTensorFLOATINT32selfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHistcGetWorkspaceSize(const aclTensor* self, int64_t bins, const aclScalar* min,
                                                 const aclScalar* max, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnHistc
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnHistcGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHistc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_HISTC_H_
// End content from: aclnn_histc.h

// Begin content from: aclnn_quant_matmul.h

/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_QUANT_MM_H_
#define OP_API_INC_QUANT_MM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQuantMatmulworkspace
 * @domain aclnn_ops_infer
 */
ACL_DEPRECATED_MESSAGE("aclnnQuantMatmulGetWorkspaceSize will be deprecated, use aclnnQuantMatmulV4GetWorkspaceSize instead")
ACLNN_API aclnnStatus aclnnQuantMatmulGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2, const aclTensor* bias,
                                                       float deqScale, aclTensor* out, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnQuantMatmul
 */
ACL_DEPRECATED_MESSAGE("aclnnQuantMatmul will be deprecated, use aclnnQuantMatmulV4 instead")
ACLNN_API aclnnStatus aclnnQuantMatmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

/**
 * @brief aclnnQuantMatmulV2workspace
 * @domain aclnn_ops_infer
 */
ACL_DEPRECATED_MESSAGE("aclnnQuantMatmulV2GetWorkspaceSize will be deprecated, use aclnnQuantMatmulV4GetWorkspaceSize instead")
ACLNN_API aclnnStatus aclnnQuantMatmulV2GetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                         const aclTensor* bias, const aclTensor* deqScale, bool adjX1,
                                                         bool adjX2, aclTensor* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnQuantMatmulV2
 */
ACL_DEPRECATED_MESSAGE("aclnnQuantMatmulV2 will be deprecated, use aclnnQuantMatmulV4 instead")
ACLNN_API aclnnStatus aclnnQuantMatmulV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QUANT_MM_H_
// End content from: aclnn_quant_matmul.h

// Begin content from: aclnn_atan2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ATAN2_H_
#define OP_API_INC_ATAN2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAtan2workspace
 * @domain aclnn_math
 * selfotherselfyotherx
 * 
 * out_{i}=tan^{-1}(self_{i}/other_{i})
 * 
 * @param [in] self:npu deviceaclTensorINT8INT16INT32, INT64, UINT8BOOLBFLOAT16
 * FLOATFLOAT16DOUBLETensorND8shapeotherbroadcast
 * @param [in] other:npu deviceaclTensorINT8INT16INT32, INT64, UINT8BOOLBFLOAT16
 * FLOATFLOAT16DOUBLETensorND8shapeselfbroadcast
 * @param [out] out:npu deviceaclTensorFLOATFLOAT16DOUBLETensor
 * ND8shapeselfother broadcastshape
 * @param [out] workspaceSize:npu deviceworkspace
 * @param [out] executor:op
 * @return aclnnStatus:
 */
ACLNN_API aclnnStatus aclnnAtan2GetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                 uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnAtan2
 * selfotherselfyotherx
 * 
 * out_{i}=tan^{-1}(self_{i}/other_{i})
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B --> C([l0op::Atan])
    C --> G([l0op::Cast])
    G --> E([l0op::ViewCopy])
    E --> S[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAtan2GetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAtan2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceAtan2workspace
 * @domain aclnn_math
 * selfotherselfyotherx
 * 
 * out_{i}=tan^{-1}(self_{i}/other_{i})
 * 
 * @param [in] self:npu deviceaclTensorINT8INT16INT32, INT64, UINT8BOOLBFLOAT16
 * FLOATFLOAT16DOUBLETensorND8shapeotherbroadcast
 * @param [in] other:npu deviceaclTensorINT8INT16INT32, INT64, UINT8BOOLBFLOAT16
 * FLOATFLOAT16DOUBLETensorND8shapeselfbroadcast
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceAtan2GetWorkspaceSize(aclTensor* selfRef, aclTensor* other, uint64_t* workspace_size,
                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceAtan2
 *
 *  selfotherselfyotherx
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAtan2GetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAtan2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_atan2.h

// Begin content from: aclnn_scatter.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SCATTER_H_
#define OP_API_INC_SCATTER_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnScatterworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorscatter
 * @param [in] self: npu deviceaclTensor,
 * UINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32DOUBLE
 * COMPLEX64COMPLEX128selfindexsrcselfsrctensor, 
 * tensorND
 * @param [in] dim: scatterINT64[-self, self-1]
 * @param [in] index: npu deviceaclTensorINT32,
 * INT64indexselfsrctensor tensorND
 * @param [in] src: npu
 * deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32DOUBLE
 * COMPLEX64COMPLEX128srcselfindexsrcselftensor
 *  tensorND
 * @param [in] reduce: reductionint (add, 1), (mul, 2)(none, 0)
 * 
 * 0srcindexout
 * 1srcindexout
 * 2srcindexout
 * @param [in] out: npu
 * deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32DOUBLE
 * COMPLEX64COMPLEX128shapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScatterGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index,
                                                   const aclTensor* src, int64_t reduce, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnScatter
 *
 *  Tensorscatter
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnScatterGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   const aclrtStream stream);

/**
 * @brief aclnnScatterValueworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorscatter
 * @param [in] self: npu deviceaclTensor,
 * UINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32DOUBLE
 * COMPLEX64COMPLEX128selfindexsrcselfsrctensor, 
 * tensorND
 * @param [in] dim: scatterINT64[-self, self-1]
 * @param [in] index: npu deviceaclTensorINT32,
 * INT64indexselfsrctensor tensorND
 * @param [in] value: hostaclScalar,
 * UINT8INT8INT16INT32INT64FLOAT16FLOAT32DOUBLECOMPLEX64
 * COMPLEX128valueCOMPLEXselfCOMPLEX tensor
 * @param [in] reduce: reductionint (add, 1), (mul, 2)(none, 0)
 * 
 * 0srcindexout
 * 1srcindexout
 * 2srcindexout
 * @param [in] out: npu
 * deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32DOUBLE
 * COMPLEX64COMPLEX128shapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScatterValueGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index,
                                                        const aclScalar* value, int64_t reduce, aclTensor* out,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnScatter
 *
 *  Tensorscatter
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnScatterValueGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScatterValue(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        const aclrtStream stream);

/**
 * @brief aclnnInplaceScatterworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorscatter
 * @param [in] selfRef:
 * UINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32DOUBLECOMPLEX64COMPLEX128
 * selfRefindexsrcselfRefsrctensor
 * tensorND
 * @param [in] dim: scatterINT64[-selfRef, selfRef-1]
 * @param [in] index: npu deviceaclTensorINT32,
 * INT64indexselfRefsrctensor tensorND
 * @param [in] src: npu
 * deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32DOUBLE
 * COMPLEX64COMPLEX128srcselfRefindexsrcselfReftensor
 *  tensorND
 * @param [in] reduce: reductionint (add, 1), (mul, 2)(none, 0)
 * 
 * 0srcindexout
 * 1srcindexout
 * 2srcindexout
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceScatterGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclTensor* index,
                                                          const aclTensor* src, int64_t reduce, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceScatter
 *
 *  Tensorscatter
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceScatterGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

/**
 * @brief aclnnInplaceScatterValueworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorscatter
 * @param [in] selfRef: npu deviceaclTensor, UINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32
 * DOUBLECOMPLEX64COMPLEX128selfRefindexsrcselfRefsrctensor,
 *  tensorND
 * @param [in] dim: scatterINT64[-selfRef, selfRef-1]
 * @param [in] index: npu deviceaclTensorINT32,
 * INT64indexselfRefsrctensor tensorND
 * @param [in] value: hostaclScalar,
 * UINT8INT8INT16INT32INT64FLOAT16FLOAT32DOUBLECOMPLEX64
 * COMPLEX128valueCOMPLEXselfRefCOMPLEX tensor
 * @param [in] reduce: reductionint (add, 1), (mul, 2)(none, 0)
 * 
 * 0srcindexout
 * 1srcindexout
 * 2srcindexout
 * @param [in] out: npu
 * deviceaclTensorUINT8INT8INT16INT32INT64BOOLFLOAT16FLOAT32DOUBLE
 * COMPLEX64COMPLEX128shapeselfRef
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceScatterValueGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclTensor* index,
                                                               const aclScalar* value, int64_t reduce,
                                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceScatterValue
 *
 *  Tensorscatter
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceScatterValueGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceScatterValue(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_scatter.h

// Begin content from: aclnn_mish_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MISH_BACKWARD_H_
#define OP_API_INC_MISH_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMishBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnMishBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                        aclTensor* gradInput, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnMishBackward
 */
ACLNN_API aclnnStatus aclnnMishBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MISH_DBACKWARD_H_
// End content from: aclnn_mish_backward.h

// Begin content from: aclnn_global_average_pool.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GLOBAL_AVERAGE_POOL_H_
#define OP_API_INC_GLOBAL_AVERAGE_POOL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGlobalAveragePoolworkspace
 * @domain aclnn_ops_infer
 *
 * GlobalAveragePool consumes an input tensor X and applies average pooling across the values in the same
 * channel.
 *
 * @param [in] self: npu
 * npu deviceaclTensorFLOAT16FLOAT32DOUBLE
 * TensorND
 * @param [in] out:
 * npu deviceaclTensorFLOAT16FLOAT32DOUBLETensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGlobalAveragePoolGetWorkspaceSize(const aclTensor* self, aclTensor* out,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGlobalAveragePool
 *
 * GlobalAveragePool consumes an input tensor X and applies average pooling across the values in the same
 * channel.
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnGlobalAveragePoolGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGlobalAveragePool(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GLOBAL_AVERAGE_POOL_H_// End content from: aclnn_global_average_pool.h

// Begin content from: aclnn_put.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_PUT_H_
#define OP_API_INC_PUT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplacePutworkspace
 * @domain aclnn_ops_infer
 *
 * selfRefindexaccumulatetruesourceselfRef;
 * accumulatefalsesourceselfRef
 *
 * @param [in] selfRef: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLEINT8INT16INT32INT64UINT8BOOL
 * [Tensor](#)ND[](#)
 * @param [in] index: npu
 * deviceaclTensorINT32INT64,source[Tensor](#)ND[](#)
 * TensorNDself
 * @param [in] source: npu
 * deviceaclTensorselfRef,index[Tensor](#)ND[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplacePutGetWorkspaceSize(aclTensor* selfRef, const aclTensor* index,
                                                      const aclTensor* source, bool accumulate, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnInplacePut
 *
 * selfRefindexaccumulatetruesourceselfRef;
 * accumulatefalsesourceselfRef
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplacePutGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplacePut(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_PUT_H_
// End content from: aclnn_put.h

// Begin content from: aclnn_threshold_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_THRESHOLD_BACKWARG_H_
#define OP_API_INC_THRESHOLD_BACKWARG_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnThresholdBackwardworkspace
 * @domain aclnn_ops_train
 *
 * threshold_forward
 * 
 * res(i) = gradOutput(i) if self(i) > threshold else 0
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(self)] --> B([l0op::Contiguous])
 * B --> C([l0op::ThresholdGradV2D or l0op::ReluGrad])
 * D[(grad_output)] -->  E([l0op::Contiguous])
 * E  --> C
 * F[(threshold)] --> C
 * C--> G([l0op::ViewCopy])
 * G --> H[(out)]
 * ```
 *
 * @param [in] gradOutput: npu deviceaclTensorFLOATBFLOAT16FLOAT16INT32INT8UINT8shapeself
 * TensorNDself
 * @param [in] self: npu deviceaclTensorFLOATBFLOAT16FLOAT16INT32INT8UINT8
 * TensorND
 * @param [in] threshold: hostaclScalarselfother
 * @param [in] out: npu deviceaclTensorFLOATBFLOAT16FLOAT16INT32INT8UINT8shapeself
 * TensorNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnThresholdBackwardGetWorkspaceSize(const aclTensor *gradOutput, const aclTensor *self,
                                                             const aclScalar *threshold, aclTensor *out,
                                                             uint64_t *workspaceSize, aclOpExecutor **executor);
/**
 * @brief aclnnAdd
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnThresholdBackward(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_THRESHOLD_BACKWARG_H_
// End content from: aclnn_threshold_backward.h

// Begin content from: aclnn_foreach_minimum_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MINIMUM_SCALAR_LIST_H_
#define ACLNN_FOREACH_MINIMUM_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMinimumScalarListGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMinimumScalarListGetWorkspaceSize(
    const aclTensorList *x,
    const aclScalarList *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMinimumScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMinimumScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_minimum_scalar_list.h

// Begin content from: aclnn_hardswish.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_HARDSWISH_H_
#define OP_API_INC_HARDSWISH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHardswishworkspace
 * @domain aclnn_ops_infer
 *
 * 
 * $$
 * Hardswish(x)=\begin{cases}
 * x, & x\ gt 3 \\
 * 0, & x\ le -3 \\
 * \frac{x  (x + 3)}{6}, & otherwise
 * \end{cases}
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Hardswish])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensor FLOATFLOAT16BFLOAT16Tensor
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardswishGetWorkspaceSize(const aclTensor* self, const aclTensor* out,
                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnHardswish
 *
 * 
 * $$
 * Hardswish(x)=\begin{cases}
 * x, & x\ gt 3 \\
 * 0, & x\ le -3 \\
 * \frac{x  (x + 3)}{6}, & otherwise
 * \end{cases}
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Hardswish])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnHardswishGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardswish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     const aclrtStream stream);

/**
 * @brief aclnnInplaceHardswishworkspace
 * @domain aclnn_ops_infer
 *
 * 
 * $$
 * Hardswish(x)=\begin{cases}
 * x, & x\ gt 3 \\
 * 0, & x\ le -3 \\
 * \frac{x  (x + 3)}{6}, & otherwise
 * \end{cases}
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Hardswish])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensor FLOATFLOAT16BFLOAT16Tensor
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceHardswishGetWorkspaceSize(const aclTensor* self, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnInplaceHardswish
 *
 * 
 * $$
 * Hardswish(x)=\begin{cases}
 * x, & x\ gt 3 \\
 * 0, & x\ le -3 \\
 * \frac{x  (x + 3)}{6}, & otherwise
 * \end{cases}
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Hardswish])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceHardswishGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceHardswish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_HARDSWISH_H
// End content from: aclnn_hardswish.h

// Begin content from: aclnn_gt_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GTTENSOR_H_
#define OP_API_INC_GTTENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGtTensor,,workspace
 * @domain aclnn_math
 * self Tensor(>)other Tensor,Tensor,self>otherTrue(1.),False(0.):
 *
 * $$ out = (self_i > other_i)  ?  [True] : [False] $$
 *
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([l0op::Contiguous])
 *     B -->C1([l0op::Cast])-->D([l0op::Greater])--> C3([l0op::Cast])
 *     E[(other)] -->F([l0op::Contiguous])
 *     F --> C2([l0op::Cast])-->D
 *     C3 -->F1([l0op::ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensor,FLOAT16,FLOAT,INT64,INT32,INT8,UINT8,BOOL,UINT64,
 * UINT32,INT16,DOUBLE,UINT16,BFLOAT16,shapeotherbroadcast,
 * other,Tensor,ND
 * @param [in] other: npu deviceaclTensor,FLOAT16,FLOAT,INT64,INT32,INT8,UINT8,BOOL,UINT64,
 * UINT32,INT16,DOUBLE,UINT16,BFLOAT16,shapeotherbroadcast,
 * self,Tensor,ND
 * @param [in] out: npu deviceaclTensor,FLOAT16,FLOAT,INT64,INT32,INT8,UINT8,BOOL,UINT64,
 * UINT32,INT16,DOUBLE,UINT16,BFLOAT16ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op,
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGtTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGtTensor,
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace,aclnnGtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op,
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGtTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceGtTensor,,workspace
 * @domain aclnn_math
 * selfRef Tensor(>)other Tensor,selfRef
 *
 * $$ selfRef = (selfRef_i > other_i)  ?  [True] : [False] $$
 *
 *
 * 
 * ```mermaid
 * graph LR
 *    A[(SelfRef)] -->B([l0op::Contiguous])
 *    B -->C1([l0op::Cast])-->D([l0op::Greater])--> C3([l0op::Cast])
 *    E[(other)] -->F([l0op::Contiguous])
 *    F --> C2([l0op::Cast])-->D
 *    C3 -->F1([l0op::ViewCopy])--> J[(SelfRef)]
 * ```
 *
 * @param [in] selfRef(aclTensor*): UINT8,INT8,DOUBLE,FLOAT,INT32,INT64,INT16,FLOAT16,BOOL,BFLOAT16,
 * shapeotherbroadcast,other,Tensor,
 * NDselfRefTensor
 * @param [in] other(aclTensor*): UINT8,INT8,DOUBLE,FLOAT,INT32,INT64,INT16,FLOAT16,BOOL,BFLOAT16,
 * shapeotherbroadcast,selfRef,Tensor,ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op,
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceGtTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGtTensor,
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace,aclnnGtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op,
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceGtTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GTTENSOR_H_
// End content from: aclnn_gt_tensor.h

// Begin content from: aclnn_foreach_maximum_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_MAXIMUM_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_MAXIMUM_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachMaximumScalarV2workspace
 * scalar
 * 
 * out_{i}=max(x_{i}, scalar)
 * @domain aclnnop_math
 * 
 * @param [in]   x
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   scalar
 * ScalarFLOATFLOAT32INT32ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachMaximumScalarV2GetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachMaximumScalarV2
 * scalar
 * 
 * out_{i}=max(x_{i}, scalar)
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachMaximumScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachMaximumScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_maximum_scalar_v2.h

// Begin content from: aclnn_upsample_bilinear_2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNAMPLE_BILINEAR_2D_BACKWARD_H_
#define OP_API_INC_UNAMPLE_BILINEAR_2D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleBilinear2dBackward
 */
ACLNN_API aclnnStatus aclnnUpsampleBilinear2dBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                                      aclrtStream stream);

/**
 * @brief aclnnUpsampleBilinear2dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnUpsampleBilinear2dBackwardGetWorkspaceSize(
    const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, bool alignCorners,
    double scalesH, double scalesW, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_BILINEAR_2D_BACKWARD_H_// End content from: aclnn_upsample_bilinear_2d_backward.h

// Begin content from: aclnn_embedding_bag.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/*!
 * \file aclnn_embedding_bag.h
 * \brief
 */
#ifndef OP_API_INC_EMBEDDING_BAG_H_
#define OP_API_INC_EMBEDDING_BAG_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnEmbeddingBagworkspace
 * @domain aclnn_ops_infer
 *
 * indicesweightoffsetsmodemaxsummean
 *
 * @param [in] weight: npu deviceaclTensorfloat32 float16 bfloat162D
 * @param [in] indices: npu deviceaclTensorUINT8INT8INT16INT32INT641D2D tensor
 * @param [in] offsets: npu
 * deviceaclTensorUINT8INT8INT16INT32INT64indicesINT32INT64,
 *                      indices1Doffsets1D tensor.
 * @param [in] scaleGradByFreq: bool
 * @param [in] mode: int64
 * @param [in] sparse: bool
 * @param [in] perSampleWeights: npu deviceaclTensor1D
 * tensorweightsumnull
 * @param [in] includeLastOffset: bool
 * @param [in] paddingIdx: int64[-n,n-1]nweigit
 * @param [out] workspaceSize: npuworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEmbeddingBagGetWorkspaceSize(const aclTensor* weight, const aclTensor* indices,
                                                        const aclTensor* offsets, bool scaleGradByFreq, int64_t mode,
                                                        bool sparse, const aclTensor* perSampleWeights,
                                                        bool includeLastOffset, int64_t paddingIdx, aclTensor* output,
                                                        aclTensor* offset2bag, aclTensor* bagSize,
                                                        aclTensor* maxIndices, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnEmbeddingBag
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceIndexCopyGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEmbeddingBag(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_INDEX_COPY_H_
// End content from: aclnn_embedding_bag.h

// Begin content from: aclnn_bitwise_or_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_BITWISE_OR_SCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_BITWISE_OR_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 *
 selfotherselfother
 * 
 * $$
 * \text{out}_i =
 * \text{self}_i \, | \, \text{other}
 * $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalOr

 * ```mermaid
 * graph LR
 * A[(self)] --> B([l0op::Contiguous])
 * B --> C([l0op::Cast])
 * C --> D([l0op::LogicalOr])
 * E((other)) --> D
 * D --> F([l0op::Cast])
 * F --> G([l0op::ViewCopy])
 * G --> H[(out)]
 * ```
 *
 * 
 * l0::BitwiseOr
 *
 * ```mermaid
 * graph LR
 * A[(self)] --> B([l0op::Contiguous])
 * B --> C([l0op::Cast])
 * C --> D([l0op::BitwiseOr])
 * E((other)) --> D
 * D --> F([l0op::Cast])
 * F --> G([l0op::ViewCopy])
 * G --> H[(out)]
 * ```
 */

/**
 * @brief aclnnBitwiseOrScalarworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * deviceaclTensorBOOLINT8INT16UINT16INT32INT64UINT8other
 * TensorND8
 * @param [in]
 * otherhostaclScalarBOOLINT8INT16UINT16INT32INT64UINT8self
 * 
 * @param [in] out: npu
 * deviceaclTensorBOOLINT8INT16UINT16INT32INT64UINT8FLOATFLOAT16DOUBLE
 * BFLOAT16COMPLEX64COMPLEX128selfothershapeself
 * TensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseOrScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnBitwiseOrScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnBitwiseOrScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseOrScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

/**
 * @brief aclnnInplaceBitwiseOrScalarworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorBOOLINT8INT16UINT16INT32INT64UINT8other
 * TensorND8
 * @param [in]
 * otherhostaclScalarBOOLINT8INT16UINT16INT32INT64UINT8self
 * 
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseOrScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBitwiseOrScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceBitwiseOrScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseOrScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_BITWISE_OR_SCALAR_H_
// End content from: aclnn_bitwise_or_scalar.h

// Begin content from: aclnn_bitwise_xor_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_BITWISE_XOR_SCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_BITWISE_XOR_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * selfotherselfother
 * 
 * $$
 * \text{out}_i =
 * \text{self}_i \, \bigoplus\, \text{other}
 * $$
 *
 * 
 * 
 * BOOLl0::NotEqual
 *
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   B --> C([l0op::NotEqual])
 *   D((other)) --> C
 *   C --> E([l0op::Cast])
 *   E --> F([l0op::ViewCopy])
 *   F --> G[(out)]
 * ```
 *
 * 
 * l0::BitwiseXor
 *
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   B --> C([l0op::Cast])
 *   C --> D([l0op::BitwiseXor])
 *   E((other)) --> D
 *   D --> F([l0op::Cast])
 *   F --> G([l0op::ViewCopy])
 *   G --> H[(out)]
 * ```
 */

/**
 * @brief aclnnBitwiseXorScalarworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * deviceaclTensorBOOLINT8INT16INT32INT64UINT8other
 * TensorND8
 * @param [in]
 * otherhostaclScalarBOOLINT8INT16INT32INT64UINT8self
 * 
 * @param [in] out: npu
 * deviceaclTensorBOOLINT8INT16INT32INT64UINT8FLOATFLOAT16DOUBLE
 * BFLOAT16COMPLEX64COMPLEX128selfothershapeself
 * TensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseXorScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnBitwiseXorScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnBitwiseXorScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseXorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

/**
 * @brief aclnnInplaceBitwiseXorScalarworkspace
 * @domain aclnn_math
 * @param [in] selfRef: npu deviceaclTensorBOOLINT8INT16INT32INT64UINT8other
 * selfRefTensorND
 * 8
 * @param [in]
 * otherhostaclScalarBOOLINT8INT16INT32INT64UINT8selfRef
 * 
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseXorScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBitwiseXorScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceBitwiseXorScalarGetWorkspaceSize 
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseXorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_BITWISE_XOR_SCALAR_H_// End content from: aclnn_bitwise_xor_scalar.h

// Begin content from: aclnn_mul.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_MUL_H_
#define OP_API_INC_LEVEL2_ACLNN_MUL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMulsworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64TensorND
 * @param [in] other: hostaclScalarFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64shapeselfshapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMulsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMulworkspace
 * @domain aclnn_math
 * @param [in] self: nnpu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64othershapeotherbroadcast
 * TensorND
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64selfshapeselfbroadcastTensor
 * ND
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64shapebroadcastshapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMulGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceMulsworkspace
 * @domain aclnn_math
 * @param [in] selfRefnpu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64TensorND
 * @param [in] other: hostaclScalarFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMulsGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceMulworkspace
 * @domain aclnn_math
 * @param [in] selfRefnpu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64otherselfRef
 * shapeotherbroadcastbroadcastshapeselfRefshapeTensorND
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * COMPLEX128COMPLEX64selfRefshapeselfRefbroadcastTensor
 * ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMulGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMuls
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMulsGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMuls(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnMul
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMulGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceMuls
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceMulsGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMuls(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

/**
 * @brief aclnnInplaceMul
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceMulGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_MUL_H_
// End content from: aclnn_mul.h

// Begin content from: aclnn_nan_to_num.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_NANTONUM_H_
#define OP_API_INC_LEVEL2_ACLNN_NANTONUM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNandworkspace
 * @domain aclnn_math
 * NaNnanposinfneginf
 *
 * @param [in] self: NanToNumnpu deviceaclTensor
 * FLOAT32FLOAT16BFLOAT16INT8INT16INT32INT64UINT8BOOL
 * NDout Tensor
 * @param [in] nan: FLOATtensorNaN
 * @param [in] posinf: FLOATtensor
 * @param [in] neginf: FLOATtensor
 * @param [out] out: NanToNumnpu deviceaclTensor
 * FLOAT32FLOAT16BFLOAT16INT8INT16INT32INT64UINT8BOOL
 * NDself Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNanToNumGetWorkspaceSize(const aclTensor* self, float nan, float posinf, float neginf,
                                                    aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnNanToNum
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnNanToNumGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNanToNum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceNanToNumworkspace
 * @domain aclnn_math
 * @param [in] selfRef: NanToNumnpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16NDout Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNanToNumGetWorkspaceSize(aclTensor* selfRef, float nan, float posinf, float neginf,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceNanToNum
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnNanToNumGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNanToNum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_NANTONUM_H_// End content from: aclnn_nan_to_num.h

// Begin content from: aclnn_gcd.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_GCD_H_
#define OP_API_INC_GCD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGcdworkspace
 * @domain aclnn_math
 *
 * selfotherelement-wise
 *
 * @param [in] self:
 * `self`otherINT32INT16(Ascend910B)shapeotherbroadcast
 * TensorND
 * @param [in] other:
 * `other`selfINT32INT16(Ascend910B)shapeselfbroadcast
 * TensorND
 * @param [in] out: `out`INT32INT16(Ascend910B)shapeselfotherbroadcastshape
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGcdGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGcd
 *
 * selfotherelement-wise
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGcdGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGcd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GCD_H_
// End content from: aclnn_gcd.h

// Begin content from: aclnn_real.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_REAL_H_
#define OP_API_INC_LEVEL2_ACLNN_REAL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

#define ACLNN_MAX_SHAPE_RANK 8

/**
 * @brief aclnnRealworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * $$ out_{i} = real(self_{i}) $$
 *
 * 
 * ```mermaid
 * graph LR
 *   A[(self)]--->B([l0op::Contiguous])
 *   B--->C([l0op::Real])
 *   C--->D([l0op::ViewCopy])
 *   D--->E[(out)]
 * ```
 *
 * @param [in] self: realnpu deviceaclTensor,
 * FLOATFLOAT16COMPLEX32COMPLEX64COMPLEX128NDTensor
 * @param [in] out: realnpu deviceaclTensor,
 * FLOATFLOAT16DOUBLENDTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRealGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnReal
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnRealGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_REAL_H_
// End content from: aclnn_real.h

// Begin content from: aclnn_ge_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GETENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_GETENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGeTensorworkspace
 * @domain aclnn_math
 * Tensorother TensorBoolTensor
 * Tensor
 *  $$ out_{i}= (self_i >= other_i) ? True : False $$
 *
 * @param [in] self: ge,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BFLOAT16ND,
 * Tensor
 * @param [in] other: ge,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BFLOAT16ND,
 * Tensor
 * @param [in] out: genpu deviceaclTensor
 * BOOLTensorND
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGeTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGeTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    const aclrtStream stream);

/**
 * @brief aclnnInplaceGeTensorworkspace
 * @domain aclnn_math
 * Tensorother Tensor
 *  $$ selfRef_{i} = (selfRef_{i} >= other_{i}) ? True : False $$
 *
 * @param [in] selfRef: ge,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BOOLBFLOAT16NDTensor
 * @param [in] other: ge,aclTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceGeTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceGeTensor
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceGeTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceGeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GETENSOR_H_
// End content from: aclnn_ge_tensor.h

// Begin content from: aclnn_ffn_v3.h
/**
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

/*!
 * \file aclnn_ffn_v3.h
 * \brief
 */

#ifndef OP_API_INC_FFN_V3_H
#define OP_API_INC_FFN_V3_H
// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFFNV3workspace
 * FFNMoeFFNFFN
 * y=activation(xW1+b1)W2+b2
 * @domain aclnn_ops_infer
 * @param [in]
 * xDeviceaclTensorxFLOAT16BFLOAT16INT8ND2[M,
 * K1]8
 * @param [in]
 * weight1DeviceaclTensorW1FLOAT16BFLOAT16INT8INT4ND/[E,
 * K1, N1]/[K1, N1]
 * @param [in]
 * weight2DeviceaclTensorW2FLOAT16BFLOAT16INT8INT4ND/[E,
 * K2, N2]/[K2, N2]
 * @param [in]
 * expertTokensOptionalDeviceaclTensortokenINT64ND256
 * @param [in]
 * bias1OptionalDeviceaclTensorb1FLOAT16FLOAT32INT32ND/[E,
 * N1]/[N1]
 * @param [in]
 * bias2OptionalDeviceaclTensorb2FLOAT16FLOAT32INT32ND/[E,
 * N2]/[N2]
 * @param [in]
 * scaleOptionalDeviceaclTensorFLOAT32NDper-tensor//[E]/[1]per-channel///[E,
 * N1]/[N1]
 * @param [in]
 * offsetOptionalDeviceaclTensorFLOAT32ND/[E]/[1]
 * @param [in]
 * deqScale1OptionalDeviceaclTensormatmulUINT64INT64FLOAT32BFLOAT16ND/[E,
 * N1]/[N1]
 * @param [in]
 * deqScale2OptionalDeviceaclTensormatmulUINT64INT64FLOAT32BFLOAT16ND/[E,
 * N2]/[N2]
 * @param [in]
 * antiquantScale1OptionalDeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N1]/[N1]per-in-group/[E, G, N1]/[G, N1]
 * @param [in]
 * antiquantScale2OptionalDeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N2]/[N2]per-in-group/[E, G, N2]/[G, N2]
 * @param [in]
 * antiquantOffset1OptionalDeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N1]/[N1]per-in-group/[E, G, N1]/[G, N1]
 * @param [in]
 * antiquantOffset2OptionalDeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N2]/[N2]per-in-group/[E, G, N2]/[G, N2]
 * @param [in]
 * activationHostactivationfastgelu/gelu/relu/silugeglu/swiglu/reglu
 * @param [in]
 * innerPreciseHostintINT64FLOAT16BFLOAT16INT8
 * @param [in] tokensIndexFlagHostboolexpertTokensbool
 * @param [out] yTensoryFLOAT16BFLOAT16NDx
 * @param [out] workspaceSizeDeviceworkspace
 * @param [out] executorop
 * @return      aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFFNV3GetWorkspaceSize(
    const aclTensor *x, const aclTensor *weight1, const aclTensor *weight2, const aclTensor *expertTokensOptional,
    const aclTensor *bias1Optional, const aclTensor *bias2Optional, const aclTensor *scaleOptional,
    const aclTensor *offsetOptional, const aclTensor *deqScale1Optional, const aclTensor *deqScale2Optional,
    const aclTensor *antiquantScale1Optional, const aclTensor *antiquantScale2Optional,
    const aclTensor *antiquantOffset1Optional, const aclTensor *antiquantOffset2Optional, const char *activation,
    int64_t innerPrecise, bool tokensIndexFlag, const aclTensor *y, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnFFNV3
 * @param [in] workspace: Deviceworkspace
 * @param [in] workspaceSize: DeviceworkspaceaclnnFFNV3GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: AscendCL stream
 * @return     aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFFNV3(void *workspace, uint64_t workspaceSize,
                                                              aclOpExecutor *executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif // OP_API_INC_FFN_V3_H// End content from: aclnn_ffn_v3.h

// Begin content from: aclnn_hardshrink.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_HARDSHRINK_H_
#define OP_API_INC_HARDSHRINK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHardshrinkworkspace
 * @domain aclnn_ops_infer
 * 
 * 
 * $$
 * Hardshrink(x)=
 * \begin{cases}
 * x, if x >  \\
 * x, if x < - \\
 * 0, otherwise \\
 * \end{cases}
 * $$
 * 
 * @param [in]   self
 * TensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in]   lambd
 * ScalarFLOAT
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnHardshrinkGetWorkspaceSize(const aclTensor* self, const aclScalar* lambd, aclTensor* out,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnHardshrink
 * 
 * 
 * $$
 * Hardshrink(x)=
 * \begin{cases}
 * x, if x >  \\
 * x, if x < - \\
 * 0, otherwise \\
 * \end{cases}
 * $$
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B -->C([l0op::HardShrink])
    C -->D([l0op::Cast])
    D -->E([l0op::ViewCopy])
    E -->F[(Out)]

    G((lambd)) -->C
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnHardshrinkGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardshrink(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_HARDSHRINK_H_
// End content from: aclnn_hardshrink.h

// Begin content from: aclnn_renorm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_RENORM_H_
#define OP_API_INC_RENORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRenormworkspace
 * @domain aclnn_ops_infer
 *
 * selfdimpmaxNorm
 * @param [in] self: npu deviceaclTensorFLOAT16, FLOAT, shape8Tensor
 * TensorND
 * @param [in] p: hostaclScalarFLOAT0
 * @param [in] dim:
 * hostINT64norm-1[-selfself-1]
 * @param [in] maxNorm: hostaclScalarFLOAT0
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16shapeself
 * TensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRenormGetWorkspaceSize(const aclTensor* self, const aclScalar* p, int64_t dim,
                                                  const aclScalar* maxNorm, aclTensor* out, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief: aclnnRenorm
 *
 * selfdimpmaxNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRenormGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRenorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceRenormworkspace
 * @domain aclnn_ops_infer
 *
 * selfRefdimpmaxNorm
 * @param [in] selfRef: npu deviceaclTensorFLOAT16, FLOAT, shape8Tensor
 * TensorND
 * @param [in] p: hostaclScalarFLOAT0
 * @param [in] dim:
 * hostINT64norm-1[-selfself-1]
 * @param [in] maxNorm: hostaclScalarFLOAT0
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRenormGetWorkspaceSize(aclTensor* selfRef, const aclScalar* p, int64_t dim,
                                                         const aclScalar* maxNorm, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceRenorm
 *
 * selfRefdimpmaxNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceRenormGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRenorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_RENORM_H_// End content from: aclnn_renorm.h

// Begin content from: aclnn_instance_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_INSTANCE_NORM_H_
#define OP_API_INC_INSTANCE_NORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInstanceNormworkspace
 * @domain aclnn_ops_infer
 *
 *  InstanceNorm 
 *
 * @param [in] x: npu
 * npu deviceaclTensorFLOAT16FLOAT32
 * TensorND
 * @param [in] gamma: npu
 * npu deviceaclTensorFLOAT16FLOAT32
 * TensorND
 * @param [in] beta: npu
 * npu deviceaclTensorFLOAT16FLOAT32
 * TensorND
 * @param [in] dataFormat:
 * tensor NHWCNCHW
 * @param [in] eps:
 * doublenormepsilon
 * @param [in] y: npu
 * npu deviceaclTensorFLOAT16FLOAT32
 *  x TensorND
 * @param [in] mean: npu
 * npu deviceaclTensorFLOAT16FLOAT32
 *  x TensorND
 * @param [in] variance: npu
 * npu deviceaclTensorFLOAT16FLOAT32
 *  x TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInstanceNormGetWorkspaceSize(const aclTensor* x, const aclTensor* gamma,
                                                        const aclTensor* beta, const char* dataFormat, double eps,
                                                        aclTensor* y, aclTensor* mean, aclTensor* variance,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnInstanceNorm
 *
 * k
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInstanceNormGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInstanceNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_INSTANCE_NORM_H_
// End content from: aclnn_instance_norm.h

// Begin content from: aclnn_binary_cross_entropy_with_logits_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BINARY_CROSS_ENTROPY_WITH_LOGITS_BACKEARD_H_
#define OP_API_INC_BINARY_CROSS_ENTROPY_WITH_LOGITS_BACKEARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBinaryCrossEntropyWithLogitsBackwardGetWorkspaceSizeworkspace
 * @domain aclnn_ops_train
 * 
 */
ACLNN_API aclnnStatus aclnnBinaryCrossEntropyWithLogitsBackwardGetWorkspaceSize(
    const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, const aclTensor* weightOptional,
    const aclTensor* posWeightOptional, int64_t reduction, aclTensor* out, uint64_t* workspaceSize,
    aclOpExecutor** executor);

/*
 * @brief aclnnBinaryCrossEntropyWithLogitsBackward
 */
ACLNN_API aclnnStatus aclnnBinaryCrossEntropyWithLogitsBackward(void* workspace, uint64_t workspaceSize,
                                                                aclOpExecutor* executor, const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BINARY_CROSS_ENTROPY_WITH_LOGITS_BACKEARD_H_
// End content from: aclnn_binary_cross_entropy_with_logits_backward.h

// Begin content from: aclnn_eye.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_EYE_H_
#define OP_API_INC_LEVEL2_ACLNN_EYE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnEyeworkspace
 * @domain aclnn_math
 *
 * 10
 *
 * @param [in] n: int64_t
 * @param [in] m: int64_t
 * @param [in] out: npu
 * deviceaclTensorFLOAT16Float32INT32INT16INT8UINT8INT64BOOLBFLOAT16Tensor
 * ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEyeGetWorkspaceSize(int64_t n, int64_t m, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnEye
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnEyeGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEye(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_EYE_H_
// End content from: aclnn_eye.h

// Begin content from: aclnn_circular_pad2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CIRCULAR_PAD_H_
#define OP_API_INC_CIRCULAR_PAD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCircularPad2dworkspace
 * @domain aclnn_ops_infer
 * @domain aclnn_ops_train
 *
 * tensor
 * @param [in] self: npu deviceaclTensor, BFLOAT16,FLOAT16, FLOAT32,INT8, INT32,ND
 * @param [in] padding: npu deviceaclIntArray, INT644
 * selfself
 * @param [in] out: npu deviceaclTensor,
 * selfself
 * paddingselfpadding
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCircularPad2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief: aclnnCircularPad2d
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCircularPad2dGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCircularPad2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CIRCULAR_PAD_H_// End content from: aclnn_circular_pad2d.h

// Begin content from: aclnn_aminmax_all.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_AMINMAX_ALL_H_
#define OP_API_INC_AMINMAX_ALL_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAminmaxAllworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] self: npu deviceaclTensorTensorND
 * @param [in] minOut: npu deviceaclTensorTensorND
 * @param [in] maxOut: npu deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnAminmaxAllGetWorkspaceSize(const aclTensor* self, aclTensor* minOut, aclTensor* maxOut,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAminmaxAll
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAminmaxAllGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAminmaxAll(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AMINMAX_ALL_H_
// End content from: aclnn_aminmax_all.h

// Begin content from: aclnn_linalg_cross.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LINALG_CROSS_H_
#define OP_API_INC_LINALG_CROSS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLinalgCrossworkspace
 * @domain aclnn_math
 *
 *  Tensorlinalg_cross
 * @param [in] self: npu deviceaclTensor, INT8INT16INT32UINT8FLOAT16FLOATFLOAT64
 *  COMPLEX64COMPLEX128BFLOAT16, shapeTensorotherbroadcastND
 * @param [in] other: npu deviceaclTensor, INT8INT16INT32UINT8FLOAT16FLOATFLOAT64
 *  COMPLEX64COMPLEX128BFLOAT16, shapeTensorselfbroadcastND
 * @param [in] dim: INT-1
 * @param [in] out: npu deviceaclTensor, INT8INT16INT32UINT8FLOAT16FLOATFLOAT64
 *  COMPLEX64COMPLEX128BFLOAT16, shapeselfotherbroadcastND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLinalgCrossGetWorkspaceSize(const aclTensor* self, const aclTensor* other, int64_t dim,
                                                       aclTensor* out, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief: aclnnLinalgCross
 *
 *  Tensorlinalg_cross
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLinalgCrossGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLinalgCross(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LINALG_CROSS_H_// End content from: aclnn_linalg_cross.h

// Begin content from: aclnn_soft_margin_loss_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SOFT_MARGIN_LOSS_BACKWARD_H_
#define OP_API_INC_SOFT_MARGIN_LOSS_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSoftMarginLossBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 *
 * @param [in] gradOutputnpu
 * deviceaclTensorFLOATFLOAT16selfshapeself
 * targetbroadcastTensorND
 * @param [in] selfnpu
 * deviceaclTensorFLOATFLOAT16shapegradOutputtargetbroadcast
 * TensorND
 * @param [in] targetnpu
 * deviceaclTensorFLOATFLOAT16selfshapegradOutput
 * selfbroadcastTensorND
 * @param [in] reductionhostint64 0('none') | 1('mean') | 2('sum')'none'
 *  'mean' 'sum' 
 * @param [in] outnpu
 * deviceaclTensorFLOATFLOAT16shapetargetselfgradOutputbroadcast
 * shapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftMarginLossBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                  const aclTensor* target, int64_t reduction,
                                                                  aclTensor* out, uint64_t* workspaceSize,
                                                                  aclOpExecutor** executor);

/**
 * @brief aclnnSoftMarginLossBackward
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspace
 * aclnnSoftMarginLossBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftMarginLossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SOFT_MARGIN_LOSS_BACKWARD_H_
// End content from: aclnn_soft_margin_loss_backward.h

// Begin content from: aclnn_quant_matmul_v3.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_QUANT_MATMUL_V3_
#define OP_API_INC_QUANT_MATMUL_V3_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * quantBatchMatmulV3
 * @brief aclnnQuantMatmulV3workspace
 * @domain aclnn_ops_infer
 * @param [in] x1: matmulint8, int4, int32
 * @param [in] x2: matmulint8, int4, int32
 * @param [in] scale: uint64_t, float32, int64_t, bfloat16
 * @param [in] offset: float32
 * @param [in] bias: int32_t, bfloat16, float32
 * @param [in] transposeX1: afalse
 * @param [in] transposeX2: bfalse
 * @param [out] out: half, int8, bfloat16
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulV3GetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                         const aclTensor* scale, const aclTensor* offset,
                                                         const aclTensor* bias, bool transposeX1, bool transposeX2,
                                                         const aclTensor* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnQuantMatmulV3
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnQuantMatmulV3GetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulV3(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QUANT_MATMUL_V3_// End content from: aclnn_quant_matmul_v3.h

// Begin content from: aclnn_sum.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_SUM_H_
#define OP_API_INC_SUM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSumworkspace
 * @domain aclnn_math
 *
 * tensorstensor
 *
 * @param [in] tensors: npu deviceaclTensorListshapeoutbroadcast
 * TensorND
 * @param [in] out: npu deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSumGetWorkspaceSize(const aclTensorList* tensors, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnSum
 *
 * tensorstensor
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnSumGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SUM_H_
// End content from: aclnn_sum.h

// Begin content from: aclnn_foreach_addcmul_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADDCMUL_LIST_H_
#define ACLNN_FOREACH_ADDCMUL_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddcmulListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * x3 : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcmulListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *x3,
    const aclTensor *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddcmulList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcmulList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_addcmul_list.h

// Begin content from: aclnn_adaptive_avg_pool3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_AdaptiveAvgPool3dBackward_H_
#define OP_API_INC_AdaptiveAvgPool3dBackward_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAdaptiveAvgPool3dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * aclnnAdaptiveAvgPool3d
 *
 * 
 * api
 * ```mermaid
 * @param [in] gradOutput: npu deviceaclTensorBFLOAT16FLOAT16FLOAT32
 * selfTensorNCDHWCDHWself
 * @param [in] self: npu deviceaclTensorBFLOAT16FLOAT16FLOAT32,
 * TensorNCDHWCDHW
 * @param [out] out: npu deviceaclTensorBFLOAT16FLOAT16FLOAT32
 * gradOutputTensorNCDHWCDHWself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnAdaptiveAvgPool3dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                     aclTensor* out, uint64_t* workspaceSize,
                                                                     aclOpExecutor** executor);

/**
 * @brief aclnnAdaptiveAvgPool3dBackward
 *
 * aclnnAdaptiveAvgPool3d
 *
 * 
 * api
 * ```mermaid
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnAdaptiveAvgPool3dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAdaptiveAvgPool3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AdaptiveAvgPool3dBackward_H_// End content from: aclnn_adaptive_avg_pool3d_backward.h

// Begin content from: aclnn_foreach_abs.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ABS_H_
#define ACLNN_FOREACH_ABS_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAbsGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAbsGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAbs
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAbs(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_abs.h

// Begin content from: aclnn_glu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GLU_H_
#define OP_API_INC_GLU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGluworkspace
 * @domain aclnn_ops_infer
 * GLUdim
 * Sigmoid.
 *
 * $$
 * GLU(a,b)=a \otimes \sigma(b)
 * $$
 *
 * adimb
 *
 * 
 * 1selfdtypeoutdtype
 * ```mermaid
 * graph LR
 *    A[(self)] -->B([l0op::Contiguous])
 *    B -->D([l0op::SplitV])--a--> C3
 *    E((dim)) -->D--b-->D1([l0op::Sigmoid])-->C3([l0op::Mul])
 *    C3 -->F1([l0op::ViewCopy])--> J[(out)]
 * ```
 *
 * 2selfdtypeoutdtype
 * ```mermaid
 * graph LR
 *    A[(self)] -->B([l0op::Contiguous])
 *    B -->D([l0op::SplitV])--a--> C3
 *    E((dim)) -->D--b-->D1([l0op::Sigmoid])-->C3([l0op::Mul])
 *    C3 -->F0([l0op::Cast])-->F1([l0op::ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] self: DOUBLE,FLOAT,BFLOAT16,FLOAT16tensor0
 * shapedim2shape$(*_1,N,*_2)$$*$$N$dim
 * TensorND
 * @param [in] dim: selfINT64[-self.dimself.dim-1]
 * @param [out] out: DOUBLE,FLOAT,BFLOAT16,FLOAT16self cast
 * shape$(*_1,M,*_2)$$*$self$M = N /2$TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGluGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* out,
                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGlu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGlu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GLU_H_
// End content from: aclnn_glu.h

// Begin content from: aclnn_ceil.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_CEIL_H_
#define OP_API_INC_LEVEL2_ACLNN_CEIL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCeilworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * $$ out_{i} =ceil(self_{i}) $$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B{l0op::Contiguous}
 *     B -->C([l0op::ceil])
 *     C --> D{l0op::ViewCopy}
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: ceilnpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16NDout Tensor
 * @param [in] out: ceilnpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16NDself Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCeilGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnCeil
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnCeilGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCeil(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceCeilworkspace
 * @domain aclnn_math
 * @param [in] selfRef: ceilnpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16NDout Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCeilGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceCeil
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnCeilGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCeil(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_CEIL_H_// End content from: aclnn_ceil.h

// Begin content from: aclnn_addmv.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ADDMV_H_
#define OP_API_INC_ADDMV_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAddmvworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnAddmvGetWorkspaceSize(const aclTensor* self, const aclTensor* mat, const aclTensor* vec,
                                                 const aclScalar* alpha, const aclScalar* beta, aclTensor* out,
                                                 int8_t cubeMathType, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnAddmv
 */
ACLNN_API aclnnStatus aclnnAddmv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADD_H_
// End content from: aclnn_addmv.h

// Begin content from: aclnn_prompt_flash_attention_v3.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License. 
 */

#ifndef ACLNN_PROMPT_FLASH_ATTENTION_V3_H_
#define ACLNN_PROMPT_FLASH_ATTENTION_V3_H_
// #include "aclnn/acl_meta.h"
// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief The first interface of aclnnPromptFlashAttentionV3 is used to calculate the workspace size based on the specific calculation process.
 * @domain aclnn_ops_infer
*/
__attribute__ ((visibility("default"))) aclnnStatus aclnnPromptFlashAttentionV3GetWorkspaceSize(
    const aclTensor *query,
    const aclTensor *key,
    const aclTensor *value,
    const aclTensor *pseShift,
    const aclTensor *attenMask, // attenMask of V3
    const aclIntArray *actualSeqLengths,
    const aclIntArray *actualSeqLengthsKv,
    const aclTensor *deqScale1,
    const aclTensor *quantScale1,
    const aclTensor *deqScale2,
    const aclTensor *quantScale2,
    const aclTensor *quantOffset2,
    int64_t numHeads, // q_n of V3
    double scaleValue,
    int64_t preTokens,
    int64_t nextTokens,
    char *inputLayout,
    int64_t numKeyValueHeads,
    int64_t sparseMode, // sparse of V3
    int64_t innerPrecise,
    const aclTensor *attentionOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief The second interface of aclnnPromptFlashAttentionV3 is used to perform calculations.
*/
__attribute__ ((visibility("default"))) aclnnStatus aclnnPromptFlashAttentionV3(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_prompt_flash_attention_v3.h

// Begin content from: aclnn_weight_quant_batch_matmul_v3.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_WEIGHT_QUANT_BATCH_MATMUL_V3_H_
#define OP_API_INC_LEVEL2_ACLNN_WEIGHT_QUANT_BATCH_MATMUL_V3_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnWeightQuantBatchMatmulV3workspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnWeightQuantBatchMatmulV3GetWorkspaceSize(
    const aclTensor* x, const aclTensor* weight, const aclTensor* antiquantScale,
    const aclTensor* antiquantOffsetOptional, const aclTensor* quantScaleOptional, const aclTensor* quantOffsetOptional,
    const aclTensor* biasOptional, int antiquantGroupSize, int innerPrecise, const aclTensor* y, uint64_t* workspaceSize,
    aclOpExecutor** executor);

/**
 * @brief aclnnWeightQuantBatchMatmulV3
 */
ACLNN_API aclnnStatus aclnnWeightQuantBatchMatmulV3(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_WEIGHT_QUANT_BATCH_MATMUL_V3_H_// End content from: aclnn_weight_quant_batch_matmul_v3.h

// Begin content from: aclnn_lerp_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_LERP_SCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_LERP_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLerpsworkspace
 * @domain aclnn_math
 * TensorTensor

 *
 * 
 * graph LR
 * ```mermaid
 * A1[(self)] --> B1([l0op::Contiguous])
 * B1 --> C([l0op::Lerp])
 * A2[(end)] --> B2([l0op::Contiguous])
 * B2 --> C
 * A3((weight)) --> C
 * C --> D([l0op::Cast])
 * D --> E([l0op::ViewCopy]) --> F[(out)]
 * ```
 *
 * @param [in] self: startFLOAT16FLOATshapeendbroadcast
 * TensorND
 * @param [in] end: endFLOAT16FLOATselfshapeselfbroadcast
 * TensorND
 * @param [in] weight: weightFLOAT16FLOAT
 * @param [in] out: outFLOAT16FLOATselfshapeselfend
 * broadcastshapeTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLerpsGetWorkspaceSize(const aclTensor* self, const aclTensor* end, const aclScalar* weight,
                                                 aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLerps
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLerpsGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLerps(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                 const aclrtStream stream);

/**
 * @brief aclnnInplaceLerpsworkspace
 * @domain aclnn_math
 * TensorTensor

 *
 * @param [in] selfRef: startFLOAT16FLOATshapeendbroadcastbroadcastshapeselfRef
 * TensorND
 * @param [in] end: endFLOAT16FLOATselfshapeselfRefbroadcastbroadcastshapeselfRef
 * TensorND
 * @param [in] weight: weightFLOAT16FLOAT
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLerpsGetWorkspaceSize(aclTensor* selfRef, const aclTensor* end,
                                                        const aclScalar* weight, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLerps
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceLerpsGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLerps(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_LERP_SCALAR_H_// End content from: aclnn_lerp_scalar.h

// Begin content from: aclnn_fmod_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_FMOD_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_FMOD_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFmodTensorworkspace
 * @domain aclnn_math
 *
 * selfother
 * $$ out_{i} = self_{i} - (other_{i} *\left \lfloor (self_{i}/other_{i}) \right \rfloor) $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(selfRef)] -->B([l0op::Contiguous])
 * B -->C([l0op::Cast])
 * C -->D([l0op::Mod])
 * E[(other)]-->F([l0op::Contiguous])
 * F -->H([l0op::Cast])
 * H --> D
 * D--> G([l0op::Cast])
 * G --> I([l0op::ViewCopy])
 * I --> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensor
 * DOUBLEBFLOAT16FLOAT16FLOAT32INT32INT64INT8UNIT8
 * otherTensorND
 * @param [in] other: npu deviceaclTensor
 * DOUBLEBFLOAT16FLOAT16FLOAT32INT32INT64INT8UNIT8
 * selfTensorND
 * @param [in] out: npu deviceaclTensorDOUBLEBFLOAT16FLOAT16FLOAT32INT32INT64INT8UNIT8
 * shapeselfother broadcastshapeTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFmodTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnFmodTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnFmodTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFmodTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

/**
 * @brief aclnnInplaceFmodTensorworkspace
 * @domain aclnn_math
 *
 * selfRefother
 * $$ out_{i} = self_{i} - (other_{i} *\left \lfloor (self_{i}/other_{i}) \right \rfloor) $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(selfRef)] -->B([l0op::Contiguous])
 * B -->C([l0op::Cast])
 * C -->D([l0op::Mod])
 * E[(other)]-->F([l0op::Contiguous])
 * F -->H([l0op::Cast])
 * H --> D
 * D--> G([l0op::Cast])
 * G --> I([l0op::ViewCopy])
 * I --> J[(out)]
 * ```
 *
 * @param [in] selfRef: npu deviceaclTensor
 * DOUBLEFLOAT16FLOAT32INT32INT64INT8UNIT8
 * otherTensorND
 * @param [in] other: npu deviceaclTensor
 * DOUBLEFLOAT16FLOAT32INT32INT64INT8UNIT8
 * selfTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFmodTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceFmodTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnInplaceFmodTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFmodTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_FMOD_TENSOR_H_
// End content from: aclnn_fmod_tensor.h

// Begin content from: aclnn_pow_tensor_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_POW_TENSOR_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_POW_TENSOR_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnPowTensorTensorworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64
 * INT16INT8UINT8BOOLCOMPLEX64COMPLEX128othershapeotherbroadcast
 * TensorNDother
 * @param [in] exponent: npu deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32
 * INT64INT16INT8UINT8BOOLCOMPLEX64COMPLEX128selfshapeselfbroadcast
 * TensorNDself
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64
 * INT16INT8UINT8BOOLCOMPLEX64COMPLEX128selfother
 * shapeselfotherbroadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnPowTensorTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* exponent,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnInplacePowTensorTensorworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplacePowTensorTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* exponent,
                                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnPowTensorTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnPowTensorTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnPowTensorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

ACLNN_API aclnnStatus aclnnInplacePowTensorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_POW_TENSOR_TENSOR_H_
// End content from: aclnn_pow_tensor_tensor.h

// Begin content from: aclnn_dynamic_quant_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef ACLNN_DYNAMIC_QUANT_V2_H_
#define ACLNN_DYNAMIC_QUANT_V2_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnDynamicQuantV2GetWorkspaceSizeworkspace
 * @domain aclnn_ops_infer
 */
__attribute__((visibility("default"))) aclnnStatus aclnnDynamicQuantV2GetWorkspaceSize(
    const aclTensor* x, const aclTensor* smoothScalesOptional, const aclTensor* groupIndexOptional, int64_t dstType,
    const aclTensor* yOut, const aclTensor* scaleOut, const aclTensor* offsetOut, uint64_t* workspaceSize,
    aclOpExecutor** executor);

/**
 * @brief aclnnDynamicQuantV2
 */
__attribute__((visibility("default"))) aclnnStatus aclnnDynamicQuantV2(void* workspace, uint64_t workspaceSize,
                                                                       aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // ACLNN_DYNAMIC_QUANT_V2_H_// End content from: aclnn_dynamic_quant_v2.h

// Begin content from: aclnn_grouped_matmul_v4.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GROUPED_MATMUL_V4_H
#define OP_API_INC_GROUPED_MATMUL_V4_H
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

typedef enum {
    GMM_ACT_TYPE_NONE = 0LL,
    GMM_ACT_TYPE_RELU = 1LL,
    GMM_ACT_TYPE_GELU_TANH = 2LL,
    GMM_ACT_TYPE_GELU_ERR_FUNC = 3LL,
    GMM_ACT_TYPE_FAST_GELU = 4LL,
    GMM_ACT_TYPE_SILU = 5LL,
} GMMActType;

/**
 * @brief aclnnGroupedMatmulV4workspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: xFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [in] weight:
 * weightFLOAT16BFLOAT16INT8FLOAT32INT4ND128
 * @param [in] biasOptional:
 * biasFLOAT16FLOAT32INT32ND128
 * @param [in] scaleOptional: UINT64BFLOAT16FLOAT32ND128
 * @param [in] offsetOptional: FLOAT32ND128
 * @param [in] antiquantScaleOptional:
 * FLOAT16BFLOAT16ND128
 * @param [in] antiquantOffsetOptional:
 * FLOAT16BFLOAT16ND128
 * @param [in] perTokenScaleOptional:
 * per tokenFLOAT32ND1
 * @param [in] groupListOptional: INT64
 * 1024128
 * @param [in] activationInputOptional: 
 * @param [in] activationQuantScaleOptional: 
 * @param [in] activationQuantOffsetOptional: 
 * @param [in] splitItem:
 * tensor0/1tensor2/3tensor0
 * @param [in] groupType:
 * -10M1N2K
 * @param [in] groupListType:
 * 010groupListOptionalcumsum
 * 1groupListOptional
 * @param [in] actType:GMMActType
 * @param [out] out: outFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [out] activationFeatureOutOptional: 
 * @param [out] dynQuantScaleOutOptional: 
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatmulV4GetWorkspaceSize(
    const aclTensorList *x, const aclTensorList *weight, const aclTensorList *biasOptional,
    const aclTensorList *scaleOptional, const aclTensorList *offsetOptional,
    const aclTensorList *antiquantScaleOptional, const aclTensorList *antiquantOffsetOptional,
    const aclTensorList *perTokenScaleOptional, const aclTensor *groupListOptional,
    const aclTensorList *activationInputOptional, const aclTensorList *activationQuantScaleOptional,
    const aclTensorList *activationQuantOffsetOptional,  int64_t splitItem, int64_t groupType,
    int64_t groupListType, int64_t actType, aclTensorList *out, aclTensorList *activationFeatureOutOptional,
    aclTensorList *dynQuantScaleOutOptional, uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnGroupedMatmulV4
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatmulV4(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_grouped_matmul_v4.h

// Begin content from: aclnn_logical_and.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LogicalAnd_H_
#define OP_API_INC_LogicalAnd_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogicalAndworkspace
 * @domain aclnn_math
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A1[(self)] -->B1([Contiguous])-->C1([Cast])-->D([LogicalAnd])
 * A2[(other)]-->B2([Contiguous])-->C2([Cast])-->D([LogicalAnd])
 * D([LogicalAnd])-->E([Cast])-->F([ViewCopy])-->G[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8UINT8
 * BOOLCOMPLEX64COMPLEX128
 * shapeotherbroadcastTensorNDother
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8UINT8
 * BOOLCOMPLEX64COMPLEX128,
 * shapeselfbroadcastTensorNDself
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8UINT8
 * BOOLCOMPLEX64COMPLEX128
 * shapeselfotherbroadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogicalAndGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogicalAnd
 *
 * 
 *
 * :
 * api:
 * ```mermaid
 * graph LR
 * A1[(self)] -->B1([Contiguous])-->C1([Cast])-->D([LogicalAnd])
 * A2[(other)]-->B2([Contiguous])-->C2([Cast])-->D([LogicalAnd])
 * D([LogicalAnd])-->E([Cast])-->F([ViewCopy])-->G[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLogicalAndGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogicalAnd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

/**
 * @brief aclnnInplaceLogicalAndworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] selfRef: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8UINT8
 * BOOLCOMPLEX64COMPLEX128
 * shapeotherbroadcastTensorNDother
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8UINT8
 * BOOLCOMPLEX64COMPLEX128,
 * shapeselfRefbroadcastTensorNDselfRef
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLogicalAndGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLogicalAnd
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLogicalAndGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLogicalAnd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LogicalAnd_H_
// End content from: aclnn_logical_and.h

// Begin content from: aclnn_nll_loss.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_NLL_LOSS_H_
#define OP_API_INC_NLL_LOSS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNLLLossworkspace
 * @domain aclnn_ops_train
 *
 * 
 *
 * @param [in] self: npu deviceaclTensorshape(N,C)(C,)Nbatch
 * sizeCFLOATTensor, ND
 * @param [in] target: npu deviceaclTensorshape(N,) (1,)[0, C-1]
 * INT64UINT8 Tensor ND
 * TensorNDself
 * @param [in] weight: npu
 * deviceaclTensorshape(C,)FLOATTensorND
 * @param [in] reduction: hostint64_t 0('none') | 1('mean') | 2('sum')'none'
 * 'mean' 'sum' 
 * @param [in] ignoreIndex: hostint64_t
 * @param [in] out: npu deviceaclTensorshape(N,)(1,)ND
 * @param [in] totalWeightOut: npu deviceaclTensorshape(1,)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNLLLossGetWorkspaceSize(const aclTensor* self, const aclTensor* target,
                                                   const aclTensor* weight, int64_t reduction, int64_t ignoreIndex,
                                                   aclTensor* out, aclTensor* totalWeightOut, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnNLLLoss
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnNLLLossGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNLLLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADD_H_
// End content from: aclnn_nll_loss.h

// Begin content from: aclnn_upsample_nearest_3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_NEAREST_3D_BACKWARD_H_
#define OP_API_INC_UNAMPLE_NEAREST_3D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearest3dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest3dBackwardGetWorkspaceSize(
    const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, double scalesD,
    double scalesH, double scalesW, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleNearest3dBackward
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_3D_BACKWARD_H_
// End content from: aclnn_upsample_nearest_3d_backward.h

// Begin content from: aclnn_nonzero.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_NONZERO_H_
#define OP_API_INC_NONZERO_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNonzeroworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * TensorND
 * @param [in] out: npu deviceaclTensorINT64ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNonzeroGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnNonzero
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnNonzeroGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNonzero(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_NONZERO_H_
// End content from: aclnn_nonzero.h

// Begin content from: aclnn_prelu_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_PRELU_BACKWARD_H_
#define OP_API_INC_PRELU_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnPreluBackwardworkspace
 * @domain aclnn_ops_train
 *
 * PRelu
 *
 * @param [in] gradOutput
 * npu deviceaclTensorFLOAT16FLOAT32
 * @param [in] selfPRelu
 * npu deviceaclTensorFLOAT16FLOAT32
 * @param [in] weightPRelu
 * npu deviceaclTensorFLOAT16FLOAT32
 * @param [out] gradInputbackward
 * npu deviceaclTensorFLOAT16FLOAT32
 * @param [out] gradWeightbackwardweightweight
 * npu deviceaclTensorFLOAT16FLOAT32
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnPreluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                         const aclTensor* weight, aclTensor* gradInput,
                                                         aclTensor* gradWeight, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnPreluBackward
 */
ACLNN_API aclnnStatus aclnnPreluBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                         aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_PRELU_BACKWARD_H_
// End content from: aclnn_prelu_backward.h

// Begin content from: aclnn_mse_loss.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MSE_LOSS_H_
#define OP_API_INC_MSE_LOSS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMseLossworkspace
 * @domain aclnn_ops_train
 *
 * xy
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16shapetargetbroadcast
 * TensorND
 * @param [in] target: npu deviceaclTensorFLOATFLOAT16shapeselfbroadcast
 * TensorND
 * @param [in] reduction: hostint64 0('none') | 1('mean') | 2('sum')
 * 'none' 'mean' 'sum' 
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMseLossGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction,
                                                   aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMseLoss
 *
 * xy
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnMseLossGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMseLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MSE_LOSS_H_
// End content from: aclnn_mse_loss.h

// Begin content from: aclnn_index.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_INDEX_H_
#define OP_API_INC_INDEX_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIndex
 */
ACLNN_API aclnnStatus aclnnIndex(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                 const aclrtStream stream);

/**
 * @brief aclnnIndexworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnIndexGetWorkspaceSize(const aclTensor* self, const aclTensorList* indices, aclTensor* out,
                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

#ifdef __cplusplus
}
#endif
#endif  // OP_API_INC_INDEX_H_// End content from: aclnn_index.h

// Begin content from: aclnn_replication_pad3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REPLICATION_PAD3D_BACKWARD_H_
#define OP_API_INC_REPLICATION_PAD3D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReplicationPad3dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 * @param [in] gradOutput: npu deviceaclTensor, FLOAT16, FLOAT32, DOUBLE, COMPLEX64,
 * COMPLEX128ND
 * selfgradInputshapereplication_pad3doutput
 * @param [in] self: npu deviceaclTensor,
 * gradOutputNDgradOutput gradInputshapegradInput
 * @param [in] padding: npu deviceaclIntArray, INT646
 * @param [in] gradInput: npu deviceaclTensor, gradOutputshapeselfND
 * gradOutputself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad3dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                    const aclIntArray* padding, aclTensor* gradInput,
                                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnReplicationPad3dBackward
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnReplicationPad3dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REPLICATION_PAD3D_BACKWARD_H_// End content from: aclnn_replication_pad3d_backward.h

// Begin content from: aclnn_trans_convolution_weight.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TRANS_CONVOLUTION_WEIGHT_H
#define OP_API_INC_TRANS_CONVOLUTION_WEIGHT_H

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief
 * aclnnCalculateConvolutionWeightSizeaclnnconvolutionweighttensor
 *
 *
 * @param [in] tensorShape: ConvolutionweightShape
 * @param [in] transposed: Convolution 
 * @param [in] groups: Convolutiongroup
 * @param [in] dataType: WeightDatatype, Float16
 * @param [out] weightTensorSize: ConvolutionWeight
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCalculateConvolutionWeightSize(const aclIntArray* tensorShape, bool transposed,
                                                          int64_t groups, aclDataType dataType,
                                                          uint64_t* weightTensorSize);

/**
 * @brief aclnnTransConvolutionWeightworkspace
 * @domain aclnn_ops_infer
 *
 * tensordtype\format
 *
 * @param [in] weightIn: ConvolutionweightTensorNDFloat16/Float32
 * tensorweightTensor, castfloat16
 * @param [in] transposed: Convolution 
 * @param [in] groups: Convolutiongroup
 * @param [out] weightOut: weighttensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTransConvolutionWeightGetWorkspaceSize(const aclTensor* weightIn, bool transposed,
                                                                  const int64_t groups, aclTensor* weightOut,
                                                                  uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnTransConvolutionWeight
 *
 * tensordtype\format
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnTransConvolutionWeightGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTransConvolutionWeight(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TRANS_CONVOLUTION_WEIGHT_H_
// End content from: aclnn_trans_convolution_weight.h

// Begin content from: aclnn_ctc_loss.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_CTCLOSS_H_
#define OP_API_INC_CTCLOSS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCtcLossworkspace
 * @domain aclnn_ops_train
 * 
 *
 * $y_{k}^{t}$$t$$k$($y_{k}^{t}$softmax)
 * $L^{'}$$L^{'T}$$L^{'T}$$$$$(1)
 *
 * $$
 * p(|x)=\prod_{t=1}^{T}y^{t}_{_{t}} , \forall  \in L'^{T}. \tag{1}
 * $$
 *
 * (many to one)B: $L^{'T} \to L^{\leq T}$B$l \in L^{\leq T}$
 * $l$(2):
 *
 * $$
 * p(l|x)=\sum_{ \in B^{-1}(l)}p(|x).\tag{2}
 * $$
 *
 * $p(l|x)$$l$(3)
 *
 * $$
 * h(x)=^{arg \  max}_{l \in L^{ \leq T}} \ p(l|x).\tag{3}
 * $$
 *
 *
 * 
 * ```mermaid
 * graph LR
 * A[(logProbs)] -->B([l0op::Contiguous])-->D([l0op::CTCLossV2])
 * A1[(targets)] -->B1([l0op::Contiguous])-->D
 * A2[(targetLengths)] -->B2([ConvertToTensor])-->D
 * A3[(inputLengths)] -->B3([ConvertToTensor])-->D
 * A4((blank)) -->D
 * A6((zeroInfinity)) -->D
 * D--negLogLikelihood--> F1([l0op::ViewCopy])--> J[(negLogLikelihoodOut)]
 * D--logAlpha-->H([l0op::ViewCopy])-->J1[(logAlphaOut)]
 * ```
 *
 * @param [in] logProbs(aclTensor*): FLOAT,DOUBLEshape($T,N,C$)
 * $T$$N$$C$0Tensor
 * [Tensor](https://)ND
 * @param [in] targets(aclTensor*): INT64,INT32,BOOL,FLOAT,FLOAT16shape($N,S$)
 * $S$$targetLengths$shape(SUM($targetLengths$))$targets$1
 * [Tensor](https://)ND
 * @param [in] inputLengths(aclIntArray*)UINT8,INT8,INT16,INT32,INT64$N$
 * $T$
 * @param [in] targetLengths(aclIntArray*)UINT8,INT8,INT16,INT32,INT64$N$
 * targetsshape($N,S$)$S$
 * @param [in] blank(int)int0$C$0
 * @param [in] zeroInfinity(bool)bool$False$
 * @param [out] negLogLikelihoodOut(aclTensor*): FLOAT,DOUBLE
 * ($N$)Tensor[Tensor](https://)ND
 * @param [out] logAlphaOut(aclTensor*): FLOAT,DOUBLE(logProbs)
 * Tensor3[Tensor](https://)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCtcLossGetWorkspaceSize(const aclTensor* logProbs, const aclTensor* targets,
                                                   const aclIntArray* inputLengths, const aclIntArray* targetlengths,
                                                   int64_t blank, bool zeroInfinity, aclTensor* negLogLikelihoodOut,
                                                   aclTensor* logAlphaOut, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnCtcLoss 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCtcLossGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCtcLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CTCLOSS_H_
// End content from: aclnn_ctc_loss.h

// Begin content from: aclnn_foreach_tan.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_TAN_H_
#define ACLNN_FOREACH_TAN_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachTanGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachTanGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachTan
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachTan(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_tan.h

// Begin content from: aclnn_softmax_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_SOFTMAX_BACKWARD_H_
#define OP_API_INC_LEVEL2_ACLNN_SOFTMAX_BACKWARD_H_

#include <array>
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSoftmaxBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnSoftmaxBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* output,
                                                           int64_t dim, aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnSoftmaxBackward
 */
ACLNN_API aclnnStatus aclnnSoftmaxBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SOFTMAX_BACKWARD_H_
// End content from: aclnn_softmax_backward.h

// Begin content from: aclnn_moe_finalize_routing.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_FINALIZE_ROUTING_H_
#define ACLNN_MOE_FINALIZE_ROUTING_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeFinalizeRoutingGetWorkspaceSize
 * parameters :
 * expandedX : required
 * x1 : required
 * x2Optional : optional
 * bias : required
 * scales : required
 * expandedRowIdx : required
 * expandedExpertIdx : required
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeFinalizeRoutingGetWorkspaceSize(
    const aclTensor *expandedX,
    const aclTensor *x1,
    const aclTensor *x2Optional,
    const aclTensor *bias,
    const aclTensor *scales,
    const aclTensor *expandedRowIdx,
    const aclTensor *expandedExpertIdx,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeFinalizeRouting
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeFinalizeRouting(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_finalize_routing.h

// Begin content from: aclnn_log.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOG_H_
#define OP_API_INC_LOG_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output = log_e(self) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C -->D([Log])
 *     E[(Out)] -->F([Contiguous])
 *     F --> G([Cast])
 *     G -->D([Log])
 *     D --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128
 *                   TensorND
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128ND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnLog
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLogGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLog(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceLogworkspace
 * @domain aclnn_math
 *
 * inplace
 * 
 * $$ selfRef_i = log_e(selfRef_i) $$
 *
 * @param [in] selfRef:
 * `selfRef`FLOATFLOAT16DOUBLECOMPLEX64COMPLEX128TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLogGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLog
 *
 * inplace
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceAddGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLog(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOG_H_
// End content from: aclnn_log.h

// Begin content from: aclnn_im2col.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_IM2COL_H_
#define OP_API_INC_IM2COL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIm2colworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnIm2colGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize,
                                                  const aclIntArray* dilation, const aclIntArray* padding,
                                                  const aclIntArray* stride, const aclTensor* out,
                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnIm2col
 */
ACLNN_API aclnnStatus aclnnIm2col(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_im2col.h

// Begin content from: aclnn_quantize.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_QUANTIZE_H_
#define OP_API_INC_QUANTIZE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQuantizeworkspace
 * @domain aclnn_ops_infer
 * 
 * 
 * 
 * @param [in] x: Tensornpu deviceaclTensorFLOATFLOAT16BFLOAT16ND
 * @param [in] scales: npu deviceaclTensorFLOATFLOAT16BFLOAT16ND
 * @param [in] zeroPoints: npu deviceaclTensorINT32INT8UINT8BFLOAT16ND
 * @param [in] axis: Hostx
 * @param [in] dtype: aclDataTypeINT8UINT8INT32ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantizeGetWorkspaceSize(const aclTensor* x, const aclTensor* scales,
    const aclTensor* zeroPoints, aclDataType dtype, int32_t axis, aclTensor* out, uint64_t* workspaceSize,
    aclOpExecutor** executor);


/**
 * @brief aclnnQuantize
 *
 * Tensor
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTopkGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantize(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif // OP_API_INC_QUANTIZE_H_
// End content from: aclnn_quantize.h

// Begin content from: aclnn_prod.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_PROD_H_
#define OP_API_INC_PROD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnProdworkspace
 * @domain aclnn_ops_infer
 *
 * tensor
 *
 * @param [in] self: npu
 * deviceaclTensorFLOAT16FLOATDOUBLEINT8UINT8INT16INT32INT64BOOL
 * TensorND
 * @param [in] dtype: hostaclDataTypetensorout
 * @param [in] out: npu
 * deviceaclTensorFLOAT16FLOATDOUBLEINT8UINT8INT16INT32INT64BOOLCOMPLEX64
 * COMPLEX128dtypeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnProdGetWorkspaceSize(const aclTensor* self, const aclDataType dtype, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnProd
 *
 * tensor
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnProdGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnProd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnProdDimworkspace
 * @domain aclnn_math
 *
 * tensor
 *
 * @param [in] self: npu
 * deviceaclTensorFLOAT16FLOATDOUBLEINT8UINT8INT16INT32INT64BOOL
 * TensorND
 * @param [in] dim: hostint64
 * @param [in] keepDim: hostbooltensor
 * @param [in] dtype: hostaclDataTypetensorout
 * @param [in] out: npu
 * deviceaclTensorFLOAT16FLOATDOUBLEINT8UINT8INT16INT32INT64BOOLCOMPLEX64
 * COMPLEX128dtypeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnProdDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepDim,
                                                   const aclDataType dtype, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);
/**
 * @brief aclnnProdDim
 *
 * tensor
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnProdDimGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnProdDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_PROD_H_
// End content from: aclnn_prod.h

// Begin content from: aclnn_incre_flash_attention_v4.h
/**
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef ACLNN_INCRE_FLASH_ATTENTION_V4_H_
#define ACLNN_INCRE_FLASH_ATTENTION_V4_H_

// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIncreFlashAttentionV4GetWorkspaceSizeworkspace
 * @domain aclnn_ops_infer
 * @param [in] query : required
 * @param [in] key : dynamic
 * @param [in] value : dynamic
 * @param [in] pseShift : optional
 * @param [in] attenMask : optional
 * @param [in] actualSeqLengths : optional
 * @param [in] dequantScale1 : optional
 * @param [in] quantScale1 : optional
 * @param [in] dequantScale2 : optional
 * @param [in] quantScale2 : optional
 * @param [in] quantOffset2 : optional
 * @param [in] antiquantScale : optional
 * @param [in] antiquantOffset : optional
 * @param [in] blocktable : optional
 * @param [in] kvPaddingSize : optional
 * @param [in] numHeads : required
 * @param [in] scaleValue : optional
 * @param [in] inputLayout : optional
 * @param [in] numKeyValueHeads : optional
 * @param [in] blockSize : optional
 * @param [in] innerPrecise : optional
 * @param [out] attentionOut : required
 * @param [out] workspaceSize : size of workspace(output).
 * @param [out] executor : executor context(output).
 * @return aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnIncreFlashAttentionV4GetWorkspaceSize(
    const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShift,
    const aclTensor *attenMask, const aclIntArray *actualSeqLengths, const aclTensor *dequantScale1,
    const aclTensor *quantScale1, const aclTensor *dequantScale2, const aclTensor *quantScale2,
    const aclTensor *quantOffset2, const aclTensor *antiquantScale, const aclTensor *antiquantOffset,
    const aclTensor *blocktable, const aclTensor *kvPaddingSize, int64_t numHeads, double scaleValue, char *inputLayout,
    int64_t numKeyValueHeads, int64_t blockSize, int64_t innerPrecise, const aclTensor *attentionOut,
    uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * funtion: aclnnIncreFlashAttentionV4
 * @param [in] workspace : workspace memory addr(input).
 * @param [in] workspaceSize : size of workspace(input).
 * @param [in] executor : executor context(input).
 * @param [in] stream : acl stream.
 * @return aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnIncreFlashAttentionV4(void *workspace, uint64_t workspaceSize,
                                                                              aclOpExecutor *executor,
                                                                              const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_incre_flash_attention_v4.h

// Begin content from: aclnn_hardshrink_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_HARDSHRINK_BACKWARD_H_
#define OP_API_INC_HARDSHRINK_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHardshrinkBackwardworkspace
 * @domain aclnn_ops_train
 *
 *  TensorhardShrink backward
 * @param [in] gradOutput: , FLOATFLOAT16, ND, Tensor
 * @param [in] self: , FLOATFLOAT16, ND, Tensor
 * @param [in] lambd:, hardShrinkBackwardFLOAT
 * @param [in] gradInput:, FLOATFLOAT16, ND, Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus:  ACLNN_SUCCESS, 
 */
ACLNN_API aclnnStatus aclnnHardshrinkBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                              const aclScalar* lambd, aclTensor* gradInput,
                                                              uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnHardshrinkBackward
 *
 *  TensorhardShrink backward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnHardshrinkBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: ,ACLNN_SUCCESS, 
 */
ACLNN_API aclnnStatus aclnnHardshrinkBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_HARDSHRINK_BACKWARD_H_// End content from: aclnn_hardshrink_backward.h

// Begin content from: aclnn_tanh.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TANH_H_
#define OP_API_INC_TANH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTanhworkspace
 * @domain aclnn_math
 *
 * tanh
 * 
 * $$ output_i = (exp(x) - exp(-x)) / (exp(x) + exp(-x))
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Tanh])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16BOOLUINT8INT8INT16INT32INT64
 * BFLOAT16(ASCEND910BASCEND910_93), Tensor
 * TensorND
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16BOOLUINT8INT8INT16INT32INT64
 * BFLOAT16(ASCEND910BASCEND910_93), Tensor
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTanhGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnTanh
 * tanh
 * 
 * $$ output_i = (exp(x) - exp(-x)) / (exp(x) + exp(-x))
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Tanh])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTanhGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceTanhworkspace
 * @domain aclnn_math
 *
 * tanh
 * 
 * $$ output_i = (exp(x) - exp(-x)) / (exp(x) + exp(-x))
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Tanh])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16BOOLUINT8INT8INT16INT32INT64
 * BFLOAT16(ASCEND910BASCEND910_93),Tensor
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTanhGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceTanh
 * tanh
 * 
 * $$ output_i = (exp(x) - exp(-x)) / (exp(x) + exp(-x))
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Tanh])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceTanhGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TANH_H
// End content from: aclnn_tanh.h

// Begin content from: aclnn_scale.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_SCALE_H_
#define OP_API_INC_LEVEL2_SCALE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnScaleworkspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: Scalenpu deviceaclTensor
 * float16, bfloat16, float32, ND
 * Tensor
 * @param [in] scale: npu deviceaclTensor, float, bf16, float16
 * @param [in] bias: npu deviceaclTensorfloat, bf16, float16
 * @param [in] axis:  hostaclScalarint64_t
 * @param [in] numAxes:  hostaclScalarint64_t
 * @param [in] scaleFromBlob:  hostaclScalar, bool
 * @param [in] y: Scalenpu deviceaclTensor,
 * int8, ND,
 * Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScaleGetWorkspaceSize(const aclTensor* x, const aclTensor* scale, const aclTensor* bias,
                                                 int64_t axis, int64_t numAxes, bool scaleFromBlob,
                                                 aclTensor* y, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnScale
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnScaleGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScale(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_SCALE_H_
// End content from: aclnn_scale.h

// Begin content from: aclnn_max_unpool2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAX_UNPOOL2D_H_
#define OP_API_INC_MAX_UNPOOL2D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxUnpool2dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnMaxUnpool2dGetWorkspaceSize(const aclTensor* self, const aclTensor* indices,
                                                       const aclIntArray* outputSize, aclTensor* out,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMaxUnpool2d
 */
ACLNN_API aclnnStatus aclnnMaxUnpool2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAX_UNPOOL2D_H_
// End content from: aclnn_max_unpool2d.h

// Begin content from: aclnn_constant_pad_nd.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CONSTANT_PAD_ND_H_
#define OP_API_INC_CONSTANT_PAD_ND_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnConstantPadNdworkspace
 * @domain aclnn_ops_infer
 *
 * tensor
 * @param [in] self: FLOAT16, FLOAT32, DOUBLE, INT8, INT16, INT32, INT64, UINT8,
 * COMPLEX64, COMPLEX128TensorND
 * @param [in] pad: UINT8INT8INT16INT32INT64self
 * @param [in] out: selfTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnConstantPadNdGetWorkspaceSize(const aclTensor* self, const aclIntArray* pad,
                                                         const aclScalar* value, aclTensor* out,
                                                         uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnConstantPadNd
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnConstantPadNdGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnConstantPadNd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CONSTANT_PAD_ND_H_
// End content from: aclnn_constant_pad_nd.h

// Begin content from: aclnn_cosh.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_COSH_H_
#define OP_API_INC_COSH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCoshworkspace
 * @domain aclnn_math
 *
 * cosh
 * 
 * $$ out = cosh(self) (
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Cosh])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensor FLOATDOUBLEBFLOAT16FLOAT16INT8INT16
 * INT32INT64UINT8BOOLCOMPLEX64COMPLEX128, Tensor
 * TensorND
 * @param [in] out: npu
 * deviceaclTensor FLOATDOUBLEBFLOAT16FLOAT16COMPLEX64COMPLEX128, Tensor
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCoshGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnCosh
 * cosh
 * 
 * $$ out = cosh(self)
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Cosh])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCoshGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCosh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceCoshworkspace
 * @domain aclnn_math
 *
 * cosh
 * 
 * $$ out = cosh(self)
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Cosh])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensor FLOATDOUBLEFLOAT16INT8INT16
 * INT32INT64UINT8BOOLCOMPLEX64COMPLEX128,Tensor
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCoshGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceCosh
 * cosh
 * 
 * $$ out = cosh(self)
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Cosh])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceCoshGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCosh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_COSH_H
// End content from: aclnn_cosh.h

// Begin content from: aclnn_batch_norm_gather_stats_with_counts.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_SYNC_BATCH_NORM_GATHER_STATS_WITH_COUNTS_H
#define OP_API_INC_SYNC_BATCH_NORM_GATHER_STATS_WITH_COUNTS_H

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchNormGatherStatsWithCountsworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnBatchNormGatherStatsWithCountsGetWorkspaceSize(
    const aclTensor* input, const aclTensor* mean, const aclTensor* invstd, aclTensor* runningMean,
    aclTensor* runningVar, double momentum, double eps, const aclTensor* counts, aclTensor* meanAll,
    aclTensor* invstdAll, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnBatchNormGatherStatsWithCounts
 */
ACLNN_API aclnnStatus aclnnBatchNormGatherStatsWithCounts(void* workspace, uint64_t workspaceSize,
                                                          aclOpExecutor* executor, const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_batch_norm_gather_stats_with_counts.h

// Begin content from: aclnn_mm.h

/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MM_H_
#define OP_API_INC_MM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMmworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnMmGetWorkspaceSize(const aclTensor* self, const aclTensor* mat2, aclTensor* out,
                                              int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMm
 */
// only for dims(2x2) patten
ACLNN_API aclnnStatus aclnnMm(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MM_H_
// End content from: aclnn_mm.h

// Begin content from: aclnn_range.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_RANGE_H_
#define OP_API_INC_RANGE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRangeworkspace
 * @domain aclnn_math
 *
 * startendstep $ \lfloor \frac{end - start} {step} \rfloor + 1
 * $1step 
 *
 * $$ out_{i+1}=out_i+step $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(Start)]--> E([l0op::Arange])
 *     B[(End)]--> D[(Limit = End + Step)]
 *     C[(Step)]--> D
 *     D--> E
 *     C--> E
 *     E--> H([l0op::Cast])
 *     H--> M([l0op::ViewCopy])
 *     M--> N[(Out)]
 * ```
 *
 * 
 * @param [in]   start
 * hostaclScalarNDstep0startendstep0startend
 * @param [in]   end
 * hostaclScalarNDstep0startendstep0startend
 * @param [in]   step
 * hostaclScalarNDstep0
 * @param [in]   out              tensornpu
 * deviceaclTensorND
 * @param [out]  workspaceSize: npu deviceworkspace
 * @param [out]  executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRangeGetWorkspaceSize(const aclScalar* start, const aclScalar* end, const aclScalar* step,
                                                 aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnRange
 *
 *
 * startendstep $ \lfloor \frac{end - start} {step} \rfloor + 1
 * $1step 
 *
 * $$ out_{i+1}=out_i+step $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(Start)]--> E([l0op::Arange])
 *     B[(End)]--> D[(Limit = End + Step)]
 *     C[(Step)]--> D
 *     D--> E
 *     C--> E
 *     E--> H([l0op::Cast])
 *     H--> M([l0op::ViewCopy])
 *     M--> N[(Out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRangeGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRange(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_range.h

// Begin content from: aclnn_std_mean_correction.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_STD_MEAN_CORRECTION_H_
#define OP_API_INC_STD_MEAN_CORRECTION_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnStdMeanCorrectionworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnStdMeanCorrectionGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim,
                                                             int64_t correction, bool keepdim, aclTensor* stdOut,
                                                             aclTensor* meanOut, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnStdMeanCorrection
 */
ACLNN_API aclnnStatus aclnnStdMeanCorrection(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_STD_MEAN_CORRECTION_H_
// End content from: aclnn_std_mean_correction.h

// Begin content from: aclnn_elu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ELU_H_
#define OP_API_INC_LEVEL2_ACLNN_ELU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * selfxELUout
 * 
 * $$
 * ELU(x) =
 * \begin{cases}
 * scale \ast x, \quad x > 0\\
 * \alpha \ast scale \ast (exp(x \ast inputScale)-1), \quad x \leq 0
 * \end{cases}
 * $$
 *
 * 
 *
 * 
 *
 * ```mermaid
 * graph LR
 *     A[(Self)] --> B([l0op::Contiguous])
 *     B --> C([l0op::Elu])
 *     C --> D([l0op::Cast])
 *     D --> E([l0op::ViewCopy])
 *     E --> F[(out)]
 *     G((alpha)) --> C
 *     H((scale)) --> C
 *     I((inputScale)) --> C
 * ```
 */

/**
 * @brief aclnnEluworkspace
 * @domain aclnn_ops_infer
 * @param [in] self: ELUnpu
 * deviceaclTensorFLOATFLOAT16DOUBLEBFLOAT16
 * TensorND8
 * @param [in] alpha: ELUhostaclScalarFLOAT
 * @param [in] scaleELUhostaclScalarFLOAT
 * @param [in] inputScaleELUhostaclScalarFLOAT
 * @param [in] out: ELUnpu
 * deviceaclTensorselfshapeself
 * TensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEluGetWorkspaceSize(const aclTensor* self, const aclScalar* alpha, const aclScalar* scale,
                                               const aclScalar* inputScale, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnElu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnEluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnElu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceEluworkspace
 * @domain aclnn_ops_infer
 * @param [in] selfRef: ELUnpu
 * deviceaclTensorFLOATFLOAT16DOUBLEBFLOAT16
 * TensorND8
 * @param [in] alpha: ELUhostaclScalarFLOAT
 * @param [in] scaleELUhostaclScalarFLOAT
 * @param [in] inputScaleELUhostaclScalarFLOAT
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceEluGetWorkspaceSize(aclTensor* selfRef, const aclScalar* alpha,
                                                      const aclScalar* scale, const aclScalar* inputScale,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceElu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceEluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceElu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ELU_H_
// End content from: aclnn_elu.h

// Begin content from: aclnn_grid_sampler3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023 All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_GRID_SAMPLER3D_BACKWARD_H_
#define OP_API_INC_GRID_SAMPLER3D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGridSampler3DBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnGridSampler3DBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* input,
                                                                 const aclTensor* grid, int64_t interpolationMode,
                                                                 int64_t paddingMode, bool alignCorners,
                                                                 const aclBoolArray* outputMask, aclTensor* inputGrad,
                                                                 aclTensor* gridGrad, uint64_t* workspaceSize,
                                                                 aclOpExecutor** executor);

/**
 * @brief aclnnGridSampler3DBackward
 */
ACLNN_API aclnnStatus aclnnGridSampler3DBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GRID_SAMPLER3D_BACKWARD_H_
// End content from: aclnn_grid_sampler3d_backward.h

// Begin content from: aclnn_upsample_bicubic_2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_BICUBIC_H_
#define OP_API_INC_UNAMPLE_BICUBIC_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleBicubic2dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleBicubic2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                             const bool alignCorners, const double scalesH,
                                                             const double scalesW, aclTensor* out,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleBicubic2d
 */
ACLNN_API aclnnStatus aclnnUpsampleBicubic2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_BICUBIC_H_
// End content from: aclnn_upsample_bicubic_2d.h

// Begin content from: aclnn_weight_quant_matmul_all_reduce_add_rms_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_weight_quant_matmul_all_reduce_add_rms_norm.h
 * \brief
 */
#ifndef OP_API_INC_WEIGHT_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_
#define OP_API_INC_WEIGHT_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnWeightQuantMatmulAllReduceAddRmsNormworkspace
 * @domain aclnn_ops_infer
 * MatmulAllReduce+AddRmsNorm
 * @param [in] x1: matmulfloat16, bfloat16
 * @param [in] x2: matmulint8,int4
 * @param [in] bias: float16, bfloat16
 * @param [in] antiquantScale: x2float16, bfloat16
 * @param [in] antiquantOffset: x2float16, bfloat16
 * @param [in] residual: float16, bfloat16
 * @param [in] gamma: RmsNormfloat16, bfloat16
 * @param [in] epsilon: 0double
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [in] antiquantGroupSize: per_groupgroupSize
 * @param [out] y: MatmulAllReduce+Add(residual)
 * @param [out] normOut: MatmulAllReduce+AddRmsNorm
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnWeightQuantMatmulAllReduceAddRmsNormGetWorkspaceSize(
    const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const aclTensor* antiquantScale,
    const aclTensor* antiquantOffset, const aclTensor* residual, const aclTensor* gamma, double epsilon,
    const char* group, const char* reduceOp, int64_t commTurn, int64_t streamMode, int64_t antiquantGroupSize,
    const aclTensor* y, const aclTensor* normOut, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnWeightQuantMatmulAllReduceAddRmsNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspace
 *                             aclnnWeightQuantMatmulAllReduceAddRmsNormGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnWeightQuantMatmulAllReduceAddRmsNorm(void* workspace, uint64_t workspaceSize,
                                                                aclOpExecutor* executor, const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_WEIGHT_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_// End content from: aclnn_weight_quant_matmul_all_reduce_add_rms_norm.h

// Begin content from: aclnn_grid_sampler3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023 All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_GRID_SAMPLER3D_H_
#define OP_API_INC_GRID_SAMPLER3D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGridSampler3Dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnGridSampler3DGetWorkspaceSize(const aclTensor* input, const aclTensor* grid,
                                                         int64_t interpolationMode, int64_t paddingMode,
                                                         bool alignCorners, aclTensor* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnGridSampler3D
 */
ACLNN_API aclnnStatus aclnnGridSampler3D(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GRID_SAMPLER3D_H_
// End content from: aclnn_grid_sampler3d.h

// Begin content from: aclnn_isin_tensor_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ISIN__TENSOR_SCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_ISIN__TENSOR_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIsInTensorScalarworkspace
 * @domain aclnn_math
 * @param [in] element: npu deviceaclTensorTensorND
 * @param [in] testElement: npu deviceaclScalar
 * @param [in] assumeUnique
 * @param [in] out: npu deviceaclTensorselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsInTensorScalarGetWorkspaceSize(const aclTensor* element, const aclScalar* testElement,
                                                            bool assumeUnique, bool invert, aclTensor* out,
                                                            uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnIsInTensorScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnIsInTensorScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsInTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ISIN__TENSOR_SCALAR_H_// End content from: aclnn_isin_tensor_scalar.h

// Begin content from: aclnn_binary_cross_entropy_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_BINARY_CROSS_ENTROPY_BACKWARD_H_
#define OP_API_INC_LEVEL2_ACLNN_BINARY_CROSS_ENTROPY_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBinaryCrossEntropyBackwardGetWorkspaceSizeworkspace
 * @domain aclnn_ops_train
 * 
 */
ACLNN_API aclnnStatus aclnnBinaryCrossEntropyBackwardGetWorkspaceSize(
    const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, const aclTensor* weightOptional,
    int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/*
 * @brief aclnnBinaryCrossEntropyBackward
 */
ACLNN_API aclnnStatus aclnnBinaryCrossEntropyBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                      const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_BINARY_CROSS_ENTROPY_BACKWARD_H_
// End content from: aclnn_binary_cross_entropy_backward.h

// Begin content from: aclnn_tanh_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TANH_BACKWARD_H_
#define OP_API_INC_TANH_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTanhBackwardworkspace
 * @domain aclnn_ops_train
 *
 * tanh(x)
 *
 * api
 * 
 * ```mermaid
 * graph LR
 *         A[(gradOutput)] -->B([l0op::Contiguous]) --> C([l0op::TanhGrad])
 *         D[(output)] -->E([l0op::Contiguous]) --> C
 *         C --> F([l0op::ViewCopy])
 *         F --> G[(gradInput)]
 * ```
 *
 * @param [in] gradOutput: npu deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLE
 * output,shapeoutput[Tensor](#Tensor)ND
 * @param [in] output: npu deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLE
 * [Tensor](#Tensor)ND
 * @param [out] gradInput: npu deviceaclTensorFLOATBFLOAT16FLOAT16DOUBLE
 * [Tensor](#Tensor)ND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTanhBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* output,
                                                        aclTensor* gradInput, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnTanhBackward
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTanhBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTanhBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TANH_BACKWARD_H_
// End content from: aclnn_tanh_backward.h

// Begin content from: aclnn_foreach_add_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADD_SCALAR_H_
#define ACLNN_FOREACH_ADD_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddScalarGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddScalarGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_add_scalar.h

// Begin content from: aclnn_swish_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_SWISH_BACKWARD_H_
#define OP_API_INC_LEVEL2_ACLNN_SWISH_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSwishBackwardworkspace
 * @domain aclnn_ops_train
 * Swish
 * @param [in] gradOutput: DeviceaclTensorgradOutputTensorND
 * gradOutputselfgradInputshape
 * @param [in] self: DeviceaclTensorxTensorNDgradOutput
 * selfgradInputshape
 * @param [in] betaOptional: HostaclScalarbetaFLOAT
 * betaOptional1.0
 * @param [out] gradInput: DeviceaclTensorgradInputTensorND
 * gradOutputselfgradInputshape
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSwishBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, 
                                                     const aclScalar* betaOptional, aclTensor* gradInput, 
                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnSwishBackward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAcosGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSwishBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SWISH_BACKWARD_H_// End content from: aclnn_swish_backward.h

// Begin content from: aclnn_strided_slice_assign_v2.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_STRIDED_SLICE_ASSIGN_V2_H_
#define ACLNN_STRIDED_SLICE_ASSIGN_V2_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnStridedSliceAssignV2GetWorkspaceSize
 * parameters :
 * varRef : required
 * inputValue : required
 * begin : required
 * end : required
 * strides : required
 * axesOptional : optional
 * varRef : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnStridedSliceAssignV2GetWorkspaceSize(
    aclTensor *varRef,
    const aclTensor *inputValue,
    const aclIntArray *begin,
    const aclIntArray *end,
    const aclIntArray *strides,
    const aclIntArray *axesOptional,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnStridedSliceAssignV2
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnStridedSliceAssignV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_strided_slice_assign_v2.h

// Begin content from: aclnn_trans_quant_param_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TRANS_QUANT_PARAM_V2_H
#define OP_API_INC_TRANS_QUANT_PARAM_V2_H

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * transQuantParamV2
 * @brief aclnnTransQuantParamV2workspace
 * @domain aclnn_ops_infer
 * @param [in] scale:  float32
 * @param [in] offset: float32
 * @param [out] out: uint64_t
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnTransQuantParamV2GetWorkspaceSize(const aclTensor* scale, const aclTensor* offset,
                                                             const aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnTransQuantParamV2
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnTransQuantParamV2GetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTransQuantParamV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TRANS_QUANT_PARAM_V2_H// End content from: aclnn_trans_quant_param_v2.h

// Begin content from: aclnn_blend_images_custom.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_BLEND_IMAGES_CUSTOM_H_
#define ACLNN_BLEND_IMAGES_CUSTOM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnBlendImagesCustomGetWorkspaceSize
 * parameters :
 * rgb : required
 * alpha : required
 * frame : required
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnBlendImagesCustomGetWorkspaceSize(
    const aclTensor *rgb,
    const aclTensor *alpha,
    const aclTensor *frame,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnBlendImagesCustom
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnBlendImagesCustom(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_blend_images_custom.h

// Begin content from: aclnn_swin_attention_score_quant.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_SWIN_ATTENTION_SCORE_QUANT_H_
#define ACLNN_SWIN_ATTENTION_SCORE_QUANT_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnSwinAttentionScoreQuantGetWorkspaceSize
 * parameters :
 * query : required
 * key : required
 * value : required
 * scaleQuant : required
 * scaleDequant1 : required
 * scaleDequant2 : required
 * biasQuantOptional : optional
 * biasDequant1Optional : optional
 * biasDequant2Optional : optional
 * paddingMask1Optional : optional
 * paddingMask2Optional : optional
 * queryTranspose : optional
 * keyTranspose : optional
 * valueTranspose : optional
 * softmaxAxes : optional
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnSwinAttentionScoreQuantGetWorkspaceSize(
    const aclTensor *query,
    const aclTensor *key,
    const aclTensor *value,
    const aclTensor *scaleQuant,
    const aclTensor *scaleDequant1,
    const aclTensor *scaleDequant2,
    const aclTensor *biasQuantOptional,
    const aclTensor *biasDequant1Optional,
    const aclTensor *biasDequant2Optional,
    const aclTensor *paddingMask1Optional,
    const aclTensor *paddingMask2Optional,
    bool queryTranspose,
    bool keyTranspose,
    bool valueTranspose,
    int64_t softmaxAxes,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnSwinAttentionScoreQuant
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnSwinAttentionScoreQuant(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_swin_attention_score_quant.h

// Begin content from: aclnn_baddbmm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BADDBMM_H_
#define OP_API_INC_BADDBMM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBaddbmmworkspace
 * @domain aclnn_ops_infer
 *
 * 
 * batch1batch2self
 * $$ out = self+(batch1@batch2) $$
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16batch1@batch2shapebatch1@batch2broadcast
 * TensorND
 * @param [in] batch1: npu
 * deviceaclTensorFLOATFLOAT16batch2shapebatch2bmm
 * TensorND
 * @param [in] batch2: npu
 * deviceaclTensorFLOATFLOAT16batch1shapebatch1bmm
 * TensorND
 * @param [in] beta: hostaclScalar1
 * @param [in] alpha: hostaclScalar1
 * @param [in] cubeMathType:
 * INT8CubeHFLOAT32
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16FLOATFLOAT16dtypeformatselfbatch1@batch2
 * TensorNDshapeshapeselfbatch1@batch2shape
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBaddbmmGetWorkspaceSize(const aclTensor* self, const aclTensor* batch1,
                                                   const aclTensor* batch2, const aclScalar* beta,
                                                   const aclScalar* alpha, aclTensor* out, int8_t cubeMathType,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnBaddbmm
 *
 * 
 * batch1batch2self
 * $$ out = self+(batch1@batch2) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnBaddbmmGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBaddbmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

/**
 * @brief aclnnInplaceBaddbmmworkspace
 * @domain aclnn_ops_infer
 *
 * 
 * batch1batch2self
 * $$ out = self+(batch1@batch2) $$
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16batch1@batch2shapebatch1@batch2broadcast
 * TensorND
 * @param [in] batch1: npu
 * deviceaclTensorFLOATFLOAT16batch2shapebatch2bmm
 * TensorND
 * @param [in] batch2: npu
 * deviceaclTensorFLOATFLOAT16batch1shapebatch1bmm
 * TensorND
 * @param [in] beta: hostaclScalar1
 * @param [in] alpha: hostaclScalar1
 * @param [in] cubeMathType:
 * INT8CubeHFLOAT32
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBaddbmmGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* batch1,
                                                          const aclTensor* batch2, const aclScalar* beta,
                                                          const aclScalar* alpha, int8_t cubeMathType,
                                                          uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBaddbmm
 *
 * 
 * batch1batch2self
 * $$ out = self+(batch1@batch2) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceBaddbmmGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBaddbmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BADDBMM_H_
// End content from: aclnn_baddbmm.h

// Begin content from: aclnn_masked_fill_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MASKEF_FILL_SCALAR_H_
#define OP_API_INC_MASKEF_FILL_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceMaskedFillScalarworkspace
 * @domain aclnn_ops_infer
 *
 * valueselfRefmasktrue
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *  A[(selfRef)] -->B([Contiguous])
 *  B  -->C([Unsqueeze])
 *  C  -->D([MaskedFill])
 *  D  -->I([Squeeze])
 *  I   --> J([ViewCopy])
 *  J   --> K[(out)]
 *
 *  A1[(mask)] -->B1([Contiguous])
 *  B1  -->C1([Cast])
 *  C1  -->D
 *
 *  A2[(value)]-->B2[(Cast)]
 *  B2-->D
 * ```
 *
 * @param [in] selfRef: npu deviceaclTensorBOOLUINT8INT8INT16INT32INT64FLOAT
 *                      FLOAT16BFLOAT16DOUBLECOMPLEX64COMPLEX128
 *                      TensorND
 * @param [in] mask: npu deviceaclTensorBOOLshapeselfRefbroadcastND
 * @param [in] value: hostaclScalarselfRef
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMaskedFillScalarGetWorkspaceSize(aclTensor* selfRef, const aclTensor* mask,
                                                                   const aclScalar* value, uint64_t* workspaceSize,
                                                                   aclOpExecutor** executor);
/**
 * @brief aclnnInplaceMaskedFillScalar
 *
 * valueselfRefmasktrue
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *  A[(selfRef)] -->B([Contiguous])
 *  B  -->C([Unsqueeze])
 *  C  -->D([MaskedFill])
 *  D  -->I([Squeeze])
 *  I   --> J([ViewCopy])
 *  J   --> K[(out)]
 *
 *  A1[(mask)] -->B1([Contiguous])
 *  B1  -->C1([Cast])
 *  C1  -->D
 *
 *  A2[(value)]-->B2[(Cast)]
 *  B2-->D
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnInplaceMaskedFillScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceMaskedFillScalar(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MASKEF_FILL_SCALAR_H_// End content from: aclnn_masked_fill_scalar.h

// Begin content from: aclnn_weight_quant_batch_matmul.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_WEIGHT_QUANT_MM_H_
#define OP_API_INC_WEIGHT_QUANT_MM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnWeightQuantBatchMatmulworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnWeightQuantBatchMatmulGetWorkspaceSize(
    const aclTensor* x1, const aclTensor* x2, const aclTensor* diagonalMatrix, const aclTensor* deqOffset,
    const aclTensor* deqScale, const aclTensor* addOffset, const aclTensor* mulScale, const aclTensor* bias,
    bool transposeX1, bool transposeX2, float antiquantScale, float antiquantOffset, aclTensor* out,
    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnWeightQuantBatchMatmul
 */
ACLNN_API aclnnStatus aclnnWeightQuantBatchMatmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_WEIGHT_QUANT_MM_H_
// End content from: aclnn_weight_quant_batch_matmul.h

// Begin content from: aclnn_trans_quant_param.h

/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_TRANS_QUANT_PARAM_H_
#define OP_API_INC_LEVEL2_ACLNN_TRANS_QUANT_PARAM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * scalefloatuint64_t
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnTransQuantParam(const float* scaleArray, uint64_t scaleSize, const float* offsetArray,
                                           uint64_t offsetSize, uint64_t** quantParam, uint64_t* quantParamSize);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_TRANS_QUANT_PARAM_H_
// End content from: aclnn_trans_quant_param.h

// Begin content from: aclnn_min_dim.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MIN_DIM_H_
#define OP_API_INC_MIN_DIM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMinDimworkspace
 * @domain aclnn_math
 *
 * 
 *
 * api
 * ```mermaid
 *  graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> C([l0op::ArgMinWithValue])
 *  C --> F([l0op::Cast])
 *  D([dim]) --> C
 *  F -.-> E([l0op::ViewCopy])
 *  E --> O[(Out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16NDTensor
 * @param [in] dim: hostint64
 * @param [in] keepdim: host
 * @param [in] indices: npu deviceaclTensorINT32INT64NDTensor
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16NDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMinDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepdim,
                                                  aclTensor* out, aclTensor* indices, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnArgMaxworkspace
 *
 * 
 *
 * api
 * ```mermaid
 *  graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> C([l0op::ArgMinWithValue])
 *  C --> F([l0op::Cast])
 *  D([dim]) --> C
 *  F -.-> E([l0op::ViewCopy])
 *  E --> O[(Out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnArgMaxGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMinDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MIN_DIM_H_// End content from: aclnn_min_dim.h

// Begin content from: aclnn_shrink.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SHRINK_H_
#define OP_API_INC_SHRINK_H_

// #include "aclnn/aclnn_base.h"
// #include"aclnn_util.h"

#ifdef __cplusplus
extern "C"{
#endif

/**
 * @brief aclnnShrinkworkspace
 * @domain aclnn_ops_inferaclnn_ops_train
 * selflambdbias
 * 
 * $$
 * out=
 * \begin{cases}
 * x-bias, if x > lambd \\
 * x+bias, if x < -lambd \\
 * 0, otherwise \\
 * \end{cases}
 * $$
 * 
 * @param [in]   self
 * TensorFLOATFLOAT16TensorND
 * @param [in]   lambd
 * ScalarFLOAT
 * @param [in]   bias
 * ScalarFLOAT
 * @param [in]   out
 * TensorFLOATFLOAT16TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnShrinkGetWorkspaceSize(const aclTensor* self, const aclScalar* lambd, const aclScalar* bias, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnShrink
 * selflambdbias
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnShrinkGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnShrink(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif //OP_API_INC_SHRINK_H_// End content from: aclnn_shrink.h

// Begin content from: aclnn_max_unpool3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAX_UNPOOL3D_H_
#define OP_API_INC_MAX_UNPOOL3D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxUnpool3dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnMaxUnpool3dGetWorkspaceSize(const aclTensor* self, const aclTensor* indices,
                                                       const aclIntArray* outputSize, const aclIntArray* stride,
                                                       const aclIntArray* padding, aclTensor* outRef,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMaxUnpool3d
 */
ACLNN_API aclnnStatus aclnnMaxUnpool3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAX_UNPOOL3D_H_
// End content from: aclnn_max_unpool3d.h

// Begin content from: aclnn_apply_rotary_pos_emb.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_APPLY_ROTARY_POS_EMB_H_
#define ACLNN_APPLY_ROTARY_POS_EMB_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnApplyRotaryPosEmbGetWorkspaceSize
 * parameters :
 * queryRef : required
 * keyRef : required
 * cos : required
 * sin : required
 * layout : optional
 * queryRef : required
 * keyRef : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnApplyRotaryPosEmbGetWorkspaceSize(
    aclTensor *queryRef,
    aclTensor *keyRef,
    const aclTensor *cos,
    const aclTensor *sin,
    int64_t layout,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnApplyRotaryPosEmb
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnApplyRotaryPosEmb(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_apply_rotary_pos_emb.h

// Begin content from: aclnn_foreach_sub_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_SUB_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_SUB_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachSubScalarV2workspace
 * scalar
 * 
 * out_{i}=x_{i}-scalar
 * @domain aclnnop_math
 * 
 * @param [in]   x
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   scalar
 * ScalarFLOATFLOAT16INT32ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachSubScalarV2GetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachSubScalarV2
 * scalar
 * 
 * out_{i}=x_{i}-scalar
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachSubScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachSubScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sub_scalar_v2.h

// Begin content from: aclnn_deep_norm.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_DEEP_NORM_H_
#define ACLNN_DEEP_NORM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnDeepNormGetWorkspaceSize
 * parameters :
 * x : required
 * gx : required
 * beta : required
 * gamma : required
 * alpha : optional
 * epsilon : optional
 * meanOut : required
 * rstdOut : required
 * yOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnDeepNormGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *gx,
    const aclTensor *beta,
    const aclTensor *gamma,
    double alpha,
    double epsilon,
    const aclTensor *meanOut,
    const aclTensor *rstdOut,
    const aclTensor *yOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnDeepNorm
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnDeepNorm(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_deep_norm.h

// Begin content from: aclnn_foreach_add_list_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_ADD_LIST_V2_H_
#define OP_API_INC_ACLNN_FOREACH_ADD_LIST_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachAddListV2workspace
 * TensorTensoralpha
 * 
 * out_{i}=x1_{i}+x2_{i}*alpha
 * @domain aclnnop_math
 * 
 * @param [in]   x1
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   x2
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   alpha
 * ScalarFLOATFLOAT16INT32ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachAddListV2GetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclScalar *alpha,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachAddListV2
 * TensorTensoralpha
 * 
 * out_{i}=x1_{i}+x2_{i}*alpha
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachAddListV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachAddListV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_add_list_v2.h

// Begin content from: aclnn_kl_div.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_KL_DIV_H_
#define OP_API_INC_KL_DIV_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnKlDivworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnKlDivGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction,
                                                 bool logTarget, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnKlDiv
 */
ACLNN_API aclnnStatus aclnnKlDiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_KL_DIV_H_
// End content from: aclnn_kl_div.h

// Begin content from: aclnn_foreach_lerp_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_LERP_SCALAR_H_
#define ACLNN_FOREACH_LERP_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachLerpScalarGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * weight : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLerpScalarGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclScalar *weight,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachLerpScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLerpScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_lerp_scalar.h

// Begin content from: aclnn_amax.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_AMAX_H_
#define OP_API_INC_AMAX_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAmaxworkspace
 * @domain aclnn_math
 *
 * 
 *
 *
 * @param [in] self:
 * deviceaclTensorFLOATFLOAT16DOUBLEINT8INT16INT32INT64UINT8BOOLND
 * Tensor
 * @param [in] dim: hostaclIntArray INT32INT64
 * @param [in] keepDim: host
 * @param [in] out: deviceaclTensorselfNDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAmaxGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim,
                                                aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAmax
 *
 * 
 *
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAmaxGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AMAX_H_// End content from: aclnn_amax.h

// Begin content from: aclnn_im2col_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_IM2COL_BACKWARD_H_
#define OP_API_INC_IM2COL_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIm2colBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnIm2colBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclIntArray* inputSize,
                                                          const aclIntArray* kernelSize, const aclIntArray* dilation,
                                                          const aclIntArray* padding, const aclIntArray* stride,
                                                          aclTensor* out, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

/**
 * @brief aclnnIm2colBackward
 */
ACLNN_API aclnnStatus aclnnIm2colBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_im2col_backward.h

// Begin content from: aclnn_kthvalue.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_KTHVALUE_H_
#define OP_API_INC_KTHVALUE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnKthvalueworkspace
 * @domain aclnn_math
 *
 * k
 *
 * @param [in] self: npu
 * npu deviceaclTensorINT32FLOAT16FLOAT32
 * TensorND
 * @param [in] k:
 * int64_t
 * @param [in] dim:
 * int64_t
 * @param [in] keepdim:
 * boolTrueself
 * Falsediminput1
 * @param [in] valuesOut:
 * dnpu deviceaclTensorINT32FLOAT16FLOAT32self
 * TensorND
 * @param [in] indicesOut:
 * npu deviceaclTensorINT64TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnKthvalueGetWorkspaceSize(const aclTensor* self, int64_t k, int64_t dim, bool keepdim,
                                                    aclTensor* valuesOut, aclTensor* indicesOut,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnKthvalue
 *
 * k
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnKthvalueGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnKthvalue(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_KTHVALUE_H_
// End content from: aclnn_kthvalue.h

// Begin content from: aclnn_avgpool2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_AVGPOOL2D_BACKWARD_H_
#define OP_API_INC_AVGPOOL2D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAvgPool2dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnAvgPool2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                             const aclIntArray* kernelSize, const aclIntArray* stride,
                                                             const aclIntArray* padding, bool ceilMode,
                                                             bool countIncludePad, int64_t divisorOverride,
                                                             int8_t cubeMathType, aclTensor* gradInput,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAvgPool2dBackward
 */
ACLNN_API aclnnStatus aclnnAvgPool2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AVGPOOL2D_BACKWARD_H_// End content from: aclnn_avgpool2d_backward.h

// Begin content from: aclnn_ffn.h
/**
 * Copyright (c) 2023-2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

/*!
 * \file aclnn_ffn.h
 * \brief
 */

#ifndef OP_API_INC_FFN_H
#define OP_API_INC_FFN_H
// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFFNworkspace
 * FFNMoeFFNFFN
 * y=activation(xW1+b1)W2+b2
 * @domain aclnn_ops_infer
 * @param [in]
 * xDeviceaclTensorxFLOAT16BFLOAT16INT8ND2[M,
 * K1]8
 * @param [in]
 * weight1DeviceaclTensorW1FLOAT16BFLOAT16INT8INT4ND/[E,
 * K1, N1]/[K1, N1]
 * @param [in]
 * weight2DeviceaclTensorW2FLOAT16BFLOAT16INT8INT4ND/[E,
 * K2, N2]/[K2, N2]
 * @param [in]
 * expertTokensHostaclIntArraytokenINT64ND256
 * @param [in]
 * bias1DeviceaclTensorb1FLOAT16FLOAT32INT32ND/[E,
 * N1]/[N1]
 * @param [in]
 * bias2DeviceaclTensorb2FLOAT16FLOAT32INT32ND/[E,
 * N2]/[N2]
 * @param [in]
 * scaleDeviceaclTensorFLOAT32NDper-tensor//[E]/[1]per-channel///[E,
 * N1]/[N1]
 * @param [in]
 * offsetDeviceaclTensorFLOAT32ND/[E]/[1]
 * @param [in]
 * deqScale1DeviceaclTensormatmulUINT64INT64FLOAT32BFLOAT16ND/[E,
 * N1]/[N1]
 * @param [in]
 * deqScale2DeviceaclTensormatmulUINT64INT64FLOAT32BFLOAT16ND/[E,
 * N2]/[N2]
 * @param [in]
 * antiquantScale1DeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N1]/[N1]per-in-group/[E, G, N1]/[G, N1]
 * @param [in]
 * antiquantScale2DeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N2]/[N2]per-in-group/[E, G, N2]/[G, N2]
 * @param [in]
 * antiquantOffset1DeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N1]/[N1]per-in-group/[E, G, N1]/[G, N1]
 * @param [in]
 * antiquantOffset2DeviceaclTensormatmulFLOAT16BFLOAT16NDper-channel/[E,
 * N2]/[N2]per-in-group/[E, G, N2]/[G, N2]
 * @param [in]
 * activationHostactivationfastgelu/gelu/relu/silugeglu/swiglu/reglu
 * @param [in]
 * innerPreciseHostintINT64FLOAT16BFLOAT16INT8
 * @param [out] yTensoryFLOAT16BFLOAT16NDx
 * @param [out] workspaceSizeDeviceworkspace
 * @param [out] executorop
 * @return      aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus
aclnnFFNGetWorkspaceSize(const aclTensor *x, const aclTensor *weight1, const aclTensor *weight2,
                         const aclIntArray *expertTokens, const aclTensor *bias1, const aclTensor *bias2,
                         const aclTensor *scale, const aclTensor *offset, const aclTensor *deqScale1,
                         const aclTensor *deqScale2, const aclTensor *antiquantScale1, const aclTensor *antiquantScale2,
                         const aclTensor *antiquantOffset1, const aclTensor *antiquantOffset2, const char *activation,
                         int64_t innerPrecise, const aclTensor *y, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnFFN
 * @param [in] workspace: Deviceworkspace
 * @param [in] workspaceSize: DeviceworkspaceaclnnFFNGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: AscendCL stream
 * @return     aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFFN(void *workspace, uint64_t workspaceSize,
                                                            aclOpExecutor *executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif // OP_API_INC_FFN_H// End content from: aclnn_ffn.h

// Begin content from: aclnn_grid_sampler2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GRID_SAMPLER2D_H_
#define OP_API_INC_GRID_SAMPLER2D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGridSampler2Dworkspace
 * @domain aclnn_ops_infer
 *
 * tensorflow-fieldgrid
 * input
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(input)] --> B([l0op::Contiguous]) --> C([l0op::GridSampler2D])
 *     D[(grid)] --> E([l0op::Contiguous]) --> C
 *     F((interpolationMode)) --> C
 *     G((paddingMode)) --> C
 *     H((alignCorners)) --> C
 *     C --> I([l0op::ViewCopy]) --> Out[(out)]
 * ```
 *
 * @param [in] input: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [in] grid: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [in] interpolationModehostint64_t 0bilinear1nearest
 * 2bicubic
 * @param [in] paddingModehostint64_tx,y
 * 0zeros1border2reflection
 * @param [in] alignCornershostbooltrue
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16DOUBLETensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGridSampler2DGetWorkspaceSize(const aclTensor* input, const aclTensor* grid,
                                                         int64_t interpolationMode, int64_t paddingMode,
                                                         bool alignCorners, aclTensor* out, uint64_t* workspaceSize,
                                                         aclOpExecutor** executor);

/**
 * @brief aclnnGridSampler2D
 *
 * tensorflow-fieldgrid
 * input
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(input)] --> B([l0op::Contiguous]) --> C([l0op::GridSampler2D])
 *     D[(grid)] --> E([l0op::Contiguous]) --> C
 *     F((interpolationMode)) --> C
 *     G((paddingMode)) --> C
 *     H((alignCorners)) --> C
 *     C --> I([l0op::ViewCopy]) --> Out[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGridSampler2DGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGridSampler2D(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GRID_SAMPLER2D_H_// End content from: aclnn_grid_sampler2d.h

// Begin content from: aclnn_matmul_all_reduce_add_rms_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_matmul_all_reduce_add_rms_norm.h
 * \brief
 */
#ifndef OP_API_INC_MATMUL_ALL_REDUCE_ADD_RMS_NORM_
#define OP_API_INC_MATMUL_ALL_REDUCE_ADD_RMS_NORM_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMatmulAllReduceAddRmsNormworkspace
 * @domain aclnn_ops_infer
 * MatmulAllReduce+AddRmsNorm
 * @param [in] x1: matmulfloat16, bfloat16
 * @param [in] x2: matmulfloat16, bfloat16
 * @param [in] bias: float16, bfloat16
 * @param [in] residual: float16, bfloat16
 * @param [in] gamma: RmsNormfloat16, bfloat16
 * @param [in] epsilon: 0double
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [out] y: MatmulAllReduce+Add(residual)
 * @param [out] normOut: MatmulAllReduce+AddRmsNorm
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMatmulAllReduceAddRmsNormGetWorkspaceSize(
    const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const aclTensor* residual, const aclTensor* gamma,
    double epsilon, const char* group, const char* reduceOp, int64_t commTurn, int64_t streamMode, const aclTensor* y,
    const aclTensor* normOut, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMatmulAllReduceAddRmsNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnMatmulAllReduceAddRmsNormGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMatmulAllReduceAddRmsNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                     const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MATMUL_ALL_REDUCE_ADD_EMS_NORM_// End content from: aclnn_matmul_all_reduce_add_rms_norm.h

// Begin content from: aclnn_foreach_pow_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_POW_LIST_H_
#define ACLNN_FOREACH_POW_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachPowListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachPowListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachPowList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachPowList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_pow_list.h

// Begin content from: aclnn_maximum.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAXIMUM_H_
#define OP_API_INC_MAXIMUM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnmaximumworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * othershapeotherbroadcastTensorND
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * othershapeotherbroadcastTensorND
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * selfothershapeselfother
 * broadcastshapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaximumGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMaximum
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMaximumGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaximum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAXIMUM_H_
// End content from: aclnn_maximum.h

// Begin content from: aclnn_group_norm_swish.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_GROUP_NORM_SWISH_H_
#define ACLNN_GROUP_NORM_SWISH_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnGroupNormSwishGetWorkspaceSize
 * parameters :
 * x : required
 * gamma : required
 * beta : required
 * numGroups : required
 * dataFormatOptional : optional
 * eps : optional
 * activateSwish : optional
 * swishScale : optional
 * yOut : required
 * meanOut : required
 * rstdOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnGroupNormSwishGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *gamma,
    const aclTensor *beta,
    int64_t numGroups,
    char *dataFormatOptional,
    double eps,
    bool activateSwish,
    double swishScale,
    const aclTensor *yOut,
    const aclTensor *meanOut,
    const aclTensor *rstdOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnGroupNormSwish
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnGroupNormSwish(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_group_norm_swish.h

// Begin content from: aclnn_foreach_cosh.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_COSH_H_
#define ACLNN_FOREACH_COSH_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachCoshGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachCoshGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachCosh
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachCosh(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_cosh.h

// Begin content from: aclnn_log1p.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOG1P_H_
#define OP_API_INC_LOG1P_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLog1pworkspace
 * @domain aclnn_math
 *
 *  Tensorsin
 * @param [in] self: npu deviceaclTensor, INT8INT16INT32, INT64, UINT8BOOLFLOATFLOAT16
 *  DOUBLEBFLOAT16shapeTensorND
 * @param [in] out: npu deviceaclTensor, FLOATBFLOAT16FLOAT16DOUBLE, shapeself
 *  ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLog1pGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief: aclnnLog1p
 *
 *  Tensorsin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLog1pGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLog1p(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceLog1pworkspace
 * @domain aclnn_math
 *
 *  Tensorsin
 * @param [in] selfRef: npu deviceaclTensor,
 * FLOATFLOAT16BFLOAT16DOUBLEshapeTensor ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLog1pGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size,
                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceLog1p
 *
 *  Tensorsin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLog1pGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLog1p(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOG1P_H_// End content from: aclnn_log1p.h

// Begin content from: aclnn_triu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_TRIU_H_
#define OP_API_INC_LEVEL2_ACLNN_TRIU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTriuworkspace
 * @domain aclnn_math
 * selfshapediagonal
 * 
 * iijj
 * ddiagonal(i, j)i+d==j
 * $$
 * i+d<=j, out_{i,j} = self_{i,j}\\
 * i+d>j,out_{i,j} = 0
 * $$
 *
 * 
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0::Contiguous]) --> C([l0op::Triu])
 *   C --> D([l0op::ViewCopy]) --> E[(out)]
 * ```
 *
 * @param [in] self: triunpu deviceaclTensor
 * DOUBLE,FLOAT,FLOAT16,BFLOAT16(910B),INT16,INT32,INT64,INT8,UINT16,UINT32,UINT64,UINT8,BOOL
 * TensorND
 * @param [in] diagonal: INT
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTriuGetWorkspaceSize(const aclTensor* self, int64_t diagonal, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnTriu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAllGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTriu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceTriuworkspace
 * @domain aclnn_math
 * @param [in] selfRef: npu deviceaclTensor
 * DOUBLE,FLOAT,FLOAT16,BFLOAT16(910B),INT16,INT32,INT64,INT8,UINT16,UINT32,UINT64,UINT8,BOOL
 * TensorND
 * @param [in] diagonal: INT
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTriuGetWorkspaceSize(aclTensor* selfRef, int64_t diagonal, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceTriu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceTriuGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceTriu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_TRIU_H_
// End content from: aclnn_triu.h

// Begin content from: aclnn_fake_quant_per_tensor_affine_cachemask.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_fake_quant_per_tensor_affine_cachemask.h
 * \brief
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_FAKE_QUANT_PER_TENSOR_AFFINE_CACHEMASK_TENSOR_QPARAMS_H_
#define OP_API_INC_LEVEL2_ACLNN_FAKE_QUANT_PER_TENSOR_AFFINE_CACHEMASK_TENSOR_QPARAMS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFakeQuantPerTensorAffineCachemaskworkspace
 * @domain aclnn_ops_train
 *
 * 
 *   1fake_quant_enabled >= 1: selfscalezero_pointself
 * quant_minquant_maxoutmask
 *   2) fake_quant_enabled < 1: outself.clone(maskTrue
 *
 * 
 * fake_quant_enabled1ViewCopyoutFillmask
 * ```mermaid
 * graph LR
 *   A1[(self)] -->B1(l0op::Contiguous)-->C1(l0op::ViewCopy)-->D1[(out)]
 *   A1[(self)] -->B1(l0op::Contiguous)-->D(l0op::Fill)-->C2(l0op::ViewCopy)-->D2[(mask)]
 * ```
 *
 * fake_quant_enabled1scalezero_pointsize1broadcastFakeQuantPerChannelAffineCachemask
 * ```mermaid
 * graph LR
 *   A1[(self)] -->B1(l0op::Contiguous)-->C(l0op::FakeQuantPerChannelAffineCachemask)
 *   A2[(scale)] -->B2(l0op::Contiguous)-->F1(l0op::BroadcastTo)-->C(l0op::FakeQuantPerChannelAffineCachemask)
 *   A3[(zeroPoint)]-->B3(l0op::Contiguous)-->F2(l0op::BroadcastTo)-->C(l0op::FakeQuantPerChannelAffineCachemask)
 *   A4((quantMin)) --> C(l0op::FakeQuantPerChannelAffineCachemask)
 *   A5((quantMax)) --> C(l0op::FakeQuantPerChannelAffineCachemask)
 *   C(l0op::FakeQuantPerChannelAffineCachemask)-->D1(l0op::ViewCopy)-->E1[(out)]
 *   C(l0op::FakeQuantPerChannelAffineCachemask)-->D2(l0op::ViewCopy)-->E2[(mask)]
 * ```
 *
 * @param [in] self:
 * DeviceaclTensorFLOAT16FLOAT32Tensor[](common/.md)ND
 * @param [in] scale: DeviceaclTensorFLOAT16FLOAT32size1
 * @param [in] zeroPoint: DeviceaclTensorINT32size1
 * @param [in] fake_quant_enabled: HostFLOAT
 * @param [in] quantMin: HostINT
 * @param [in] quantMax: HostINT
 * @param [out] out:
 * DeviceaclTensorLOAT16FLOAT32Tensor[](common/.md)ND
 * @param [out] mask: DeviceaclTensorBOOLTensor[](common/.md)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFakeQuantPerTensorAffineCachemaskGetWorkspaceSize(
    const aclTensor* self, const aclTensor* scale, const aclTensor* zeroPoint, float fakeQuantEnbled, int64_t quantMin,
    int64_t quantMax, aclTensor* out, aclTensor* mask, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnFakeQuantPerTensorAffineCachemask
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnFakeQuantPerTensorAffineCachemask
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFakeQuantPerTensorAffineCachemask(void* workspace, uint64_t workspaceSize,
                                                             aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_FAKE_QUANT_PER_TENSOR_AFFINE_CACHEMASK_TENSOR_QPARAMS_H_
// End content from: aclnn_fake_quant_per_tensor_affine_cachemask.h

// Begin content from: aclnn_foreach_tanh.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_TANH_H_
#define ACLNN_FOREACH_TANH_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachTanhGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachTanhGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachTanh
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachTanh(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_tanh.h

// Begin content from: aclnn_ne_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_NE_SCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_NE_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNeScalarworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,UINT64,INT32,INT8,UINT8,BOOL,UINT32,BFLOAT16,INT16NDTensor
 * @param [in] other:
 * hostaclScalarFLOAT16,FLOAT,INT64,UINT64,INT32,INT8,UINT8,BOOL,UINT32,BFLOAT16,INT16,
 * self
 * @param [in] out: npu deviceaclTensorboolshapeselfshapeND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNeScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnNeScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnNeScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    const aclrtStream stream);

/**
 * @brief aclnnInplaceNeScalarworkspace
 * @domain aclnn_math
 * @param [in] selfRef: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,UINT64,INT32,INT8,UINT8,BOOL,UINT32,BFLOAT16,INT16
 * shapeotherbroadcastTensorNDselfRef
 * @param [in] other: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,UINT64,INT32,INT8,UINT8,BOOL,UINT32,BFLOAT16,INT16
 * shapeotherbroadcastTensorND
 * @param [in] out: npu deviceaclTensorBOOLTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNeScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceNeScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceNeScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_NE_SCALAR_H_// End content from: aclnn_ne_scalar.h

// Begin content from: aclnn_gather_nd.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GATHER_ND_H_
#define OP_API_INC_LEVEL2_ACLNN_GATHER_ND_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * **r1**`self`**q1**`indices`**(q-1) + (r -
 * indices_shape[-1])**
 * outindices**q****q-1******(******indices_shape[-1]**
 * ******self**)
 *  1) **indices_shape[-1]** > **r**
 *  2) **indices_shape[-1]** = **r**out**q-1**outshape **[indices_shape[0:q-2]]**
 *     outself****1
 *  3) **indices_shape[-1]** < **r**out **(q-1) + (r -
 * indices_shape[-1])****c**=**r**-**indices_shape[-1]** outshape
 * **[indices_shape[0:q-2],self_shape[r-c:r-1]]**`out``self`****2,3,4
 * **r****q****indices_shape[-1]** 
 *  1) **r**1**q**1
 *  2) **indices_shape[-1]**1()**r**()
 *  3) `indices`[-**s**, **s-1**](**s****self_shape**)
 *     -**self_shape[i]**indices[...,i]**self_shape[i]**-1
 * 
 *  1
 *   self: [[0, 1],[2, 3]]       # self_shape=[2, 2], r=2
 *   indices: [[0, 0], [1, 1]]   # indices_shape=[2, 2], q=2, indices_shape[-1]=2
 *   out: [0, 3]                 # out_shape=[2]
 *  2
 *   self: [[0, 1],[2, 3]]       # self_shape=[2, 2], r=2
 *   indices: [[1], [0]]         # indices_shape=[2, 1], q=2, indices_shape[-1]=1
 *   out: [[2, 3], [0, 1]]       # out_shape=[2, 2]
 *  3
 *   self: [[[0, 1],[2, 3]], [[4, 5],[6, 7]]]   # self_shape=[2, 2, 2], r=3
 *   indices: [[0, 1], [1, 0]]                  # indices_shape=[2, 2], q=2, indices_shape[-1]=2
 *   out: [[2, 3], [4, 5]]                      # out_shape=[2, 2]
 *  4
 *   self: [[[0, 1],[2, 3]], [[4, 5],[6, 7]]]   # self_shape=[2, 2, 2], r=3
 *   indices: [[[0, 1]], [[1, 0]]]              # indices_shape=[2, 1, 2], q=3, indices_shape[-1]=2
 *   out: [[[2, 3]], [[4, 5]]]                  # out_shape=[2, 1, 2]
 *
 * 
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   C[(indices)] --> D([l0op::Contiguous])
 *   B --> E([l0op::GatherNd])
 *   D --> E
 *   E --> F([l0op::ViewCopy])
 *   F --> G[(out)]
 * ```
 */

/**
 * @brief aclnnGatherNdworkspace
 * @domain aclnn_ops_infer
 *
 * @param [in] self: npu deviceaclTensorINT64INT32INT8UINT8BOOLFLOATFLOAT16BFLOAT16
 * TensorND8
 * @param [in] index: npu
 * deviceaclTensorINT64INT32TensorND 8
 * @param [in] negativeIndexSupport: bool
 * @param [in] out: npu deviceaclTensorINT64INT32INT8UINT8BOOLFLOATFLOAT16BFLOAT16
 * selfND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGatherNdGetWorkspaceSize(const aclTensor* self, const aclTensor* indices,
                                                    bool negativeIndexSupport, aclTensor* out, uint64_t* workspaceSize,
                                                    aclOpExecutor** executor);

/**
 * @brief aclnnGatherNd
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGatherNdGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGatherNd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GATHER_ND_H_
// End content from: aclnn_gather_nd.h

// Begin content from: aclnn_incre_flash_attention.h
/**
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef ACLNN_INCRE_FLASH_ATTENTION_H_
#define ACLNN_INCRE_FLASH_ATTENTION_H_

// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIncreFlashAttentionworkspace
 * @domain aclnn_ops_infer
 * funtion: aclnnIncreFlashAttentionGetWorkspaceSize
 * param [in] query : required
 * param [in] key : dynamic
 * param [in] value : dynamic
 * param [in] pseShift : optional
 * param [in] attenMask : optional
 * param [in] actualSeqLengths : optional
 * param [in] numHeads : required
 * param [in] scaleValue : optional
 * param [in] inputLayout : optional
 * param [in] numKeyValueHeads : optional
 * @param [out] attentionOut : required
 * @param [out] workspaceSize : size of workspace(output).
 * @param [out] executor : executor context(output).
 * @return aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnIncreFlashAttentionGetWorkspaceSize(
    const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShift,
    const aclTensor *attenMask, const aclIntArray *actualSeqLengths, int64_t numHeads, double scaleValue,
    char *inputLayout, int64_t numKeyValueHeads, const aclTensor *attentionOut, uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * funtion: aclnnIncreFlashAttention
 * param [in] workspace : workspace memory addr(input).
 * param [in] workspaceSize : size of workspace(input).
 * param [in] executor : executor context(input).
 * param [in] stream : acl stream.
 * @return aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnIncreFlashAttention(void *workspace, uint64_t workspaceSize,
                                                                            aclOpExecutor *executor,
                                                                            const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_incre_flash_attention.h

// Begin content from: aclnn_dot.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_DOT_H_
#define OP_API_INC_LEVEL2_ACLNN_DOT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * 
 * 
 * $$
 * self = [x_{1}, x_{2}, ..., x_{n}]
 * $$
 *
 * $$
 * tensor = [y_{1}, y_{2}, ..., y_{n}]
 * $$
 *
 * $$
 * out = x_{1}*y_{1} + x_{2}*y_{2} + ... + x_{n}*y_{n}
 * $$
 *
 * 
 * apiselftensorTensor
 * ```mermaid
 * graph LR
 *     A[(self)] --> B([l0op::Contiguous])
 *     B --> C([l0op::Dot])
 *     D[(tensor)] --> E([l0op::Contiguous])
 *     E --> C
 *     C --> F([l0op::ViewCopy])
 *     F --> G[(out)]
 * ```
 *
 * apiselftensorTensor
 * ```mermaid
 * graph LR
 *     A[(self)] --> B([l0op::Fill])
 *     C[(tensor)] --> B
 *     B --> D([l0op::ViewCopy])
 *     D --> E[(out)]
 * ```
 */

/**
 * @brief aclnnDotworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorFLOATBFLOAT16FLOAT16tensor
 * TensorND1shapetensor
 * @param [in] tensor: npu deviceaclTensorFLOATBFLOAT16FLOAT16self
 * TensorND1shapeself
 * @param [in] out: npu deviceaclTensorFLOATBFLOAT16FLOAT16selftensor
 * ND0
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDotGetWorkspaceSize(const aclTensor* self, const aclTensor* tensor, aclTensor* out,
                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnDot
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnDotGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_DOT_H_
// End content from: aclnn_dot.h

// Begin content from: aclnn_foreach_div_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_DIV_LIST_H_
#define ACLNN_FOREACH_DIV_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachDivListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachDivListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachDivList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachDivList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_div_list.h

// Begin content from: aclnn_max.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAX_H_
#define OP_API_INC_MAX_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorTensorND
 * @param [in] out: npu deviceaclTensorselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaxGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnMax
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMaxGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAX_H_// End content from: aclnn_max.h

// Begin content from: aclnn_upsample_bilinear2d_aa_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef ACLNN_UPSAMPLE_BILINEAR2D_AABACKWARD_H_
#define ACLNN_UPSAMPLE_BILINEAR2D_AABACKWARD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleBilinear2dAABackwardworkspace
 * @domain aclnn_ops_infer
 *
 * aclnnUpsampleBilinear2dAA
 *
 * @param [in] gradOutput: DeviceaclTensorFLOATFLOAT16BFLOAT16
 * TensorNCHWshapeTensorout
 * @param [in] outputSize: HostaclIntArrayINT64size2gradOutputHW
 * @param [in] inputSize: HostaclIntArrayINT64size4outNCHW
 * @param [in] scalesH: Hostoutheight
 * @param [in] scalesW: Hostoutwidth
 * @param [out] out: DeviceaclTensorFLOATFLOAT16BFLOAT16
 * TensorNCHWshapeTensorgradOutput
 * @param [out] workspaceSize: Deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
__attribute__((visibility("default")))
aclnnStatus aclnnUpsampleBilinear2dAABackwardGetWorkspaceSize(
    const aclTensor *gradOutput, const aclIntArray *outputSize, const aclIntArray *inputSize, bool alignCorners, 
    double scalesH, double scalesW, aclTensor *out, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnUpsampleBilinear2dAABackward
 * 
 * aclnnUpsampleBilinear2dAA
 *
 * @param [in] workspace: Deviceworkspace
 * @param [in] workspaceSize: Deviceworkspace
 * aclnnUpsampleBilinear2dAABackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: AscendCL Stream
 * @return aclnnStatus: 
 */
__attribute__((visibility("default")))
aclnnStatus aclnnUpsampleBilinear2dAABackward(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                              aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_upsample_bilinear2d_aa_backward.h

// Begin content from: aclnn_upsample_nearest_exact1d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_NEAREST_EXACT1D_H_
#define OP_API_INC_UNAMPLE_NEAREST_EXACT1D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearestExact1dworkspace
 * 
 * 
 * out(N, C, l) = self(N, C, min(floor((l + 0.5) * scales),  L- 1))
 * @domain aclnn_ops_train
 * 
 * @param [in]   self
 * TensorFLOATFLOAT16BFLOAT16TensorNDNCL
 * @param [in]   outputSize
 * sizeINT32INT64
 * @param [in]   scales
 * DOUBLE
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16TensorNDNCL
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnUpsampleNearestExact1dGetWorkspaceSize(const aclTensor *self, const aclIntArray *outputSize,
                                                        double scales, aclTensor *out, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnUpsampleNearestExact1d
 * 
 * 
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnUpsampleNearestExact1dGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus:  
*/
ACLNN_API aclnnStatus aclnnUpsampleNearestExact1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_EXACT1D_H_
// End content from: aclnn_upsample_nearest_exact1d.h

// Begin content from: aclnn_matmul.h

/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MATMUL_H_
#define OP_API_INC_MATMUL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMatmulworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnMatmulGetWorkspaceSize(const aclTensor* self, const aclTensor* mat2, aclTensor* out,
                                                  int8_t cubeMathType, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnMatmul
 */
// for any shape mat multiply
ACLNN_API aclnnStatus aclnnMatmul(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MATMUL_H_
// End content from: aclnn_matmul.h

// Begin content from: aclnn_repeat.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_REPEAT_H_
#define OP_API_INC_LEVEL2_ACLNN_REPEAT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRepeatworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnRepeatGetWorkspaceSize(const aclTensor* self, const aclIntArray* repeats, aclTensor* out,
                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnRepeat
 */
ACLNN_API aclnnStatus aclnnRepeat(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_repeat.h

// Begin content from: aclnn_unique_consecutive.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNIQUE_CONSECUTIVE_H_
#define OP_API_INC_UNIQUE_CONSECUTIVE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUniqueConsecutiveworkspace
 * @domain aclnn_math
 *
 * 
 *
 * 
 * api
 * ```mermaid
 *  graph LR
 *      A[(self)] ---> B([l0op::Contiguous])
 *      B ---> F([l0op::UniqueConsecutive])
 *      C((returnInverse)) --->F
 *      D((returnCounts)) --->F
 *      E((dim)) --->F
 *      F --> G[(valueOut)]
 *      F --> H[(inverseOut)]
 *      F --> I[(countsOut)]
 * ```
 * @param [in] selfFLOATFLOAT16DOUBLEINT8INT16INT32INT64UINT8UINT16UINT32
 *                   UINT64COMPLEX64COMPLEX128BOOLND
 * @param [in] returnInverse: selfvalueOutTrueFalse
 * @param [in] returnCounts: valueOutselfTrueFalse
 * @param [in] dim: 
 * @param [in] valueOut: FLOATFLOAT16DOUBLEINT8INT16
 *                       INT32INT64UINT8UINT16UINT32UINT64COMPLEX64COMPLEX128BOOLND
 * @param [in] inverseOut:
 * returnInverseTrueselfvalueOut
 *                         INT64ND
 * @param [in] countsOut: returnCountsTruevalueOutself
 *                        INT64ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUniqueConsecutiveGetWorkspaceSize(const aclTensor* self, bool returnInverse,
                                                             bool returnCounts, int64_t dim, aclTensor* valueOut,
                                                             aclTensor* inverseOut, aclTensor* countsOut,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnUniqueConsecutive
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnUniqueConsecutiveGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUniqueConsecutive(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNIQUE_CONSECUTIVE_H_// End content from: aclnn_unique_consecutive.h

// Begin content from: aclnn_diag_flat.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_DIAG_FLAT_H_
#define OP_API_INC_DIAG_FLAT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnDiagFlatworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * deviceaclTensorTensorNDout
 * @param [in] diagonal: host,INT64
 * @param [out] out: npu deviceaclTensor, Tensor, ND,
 * 
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDiagFlatGetWorkspaceSize(const aclTensor* self, int64_t diagonal, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnDiagFlat
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnDiagFlatGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDiagFlat(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_DIAG_FLAT_H_
// End content from: aclnn_diag_flat.h

// Begin content from: aclnn_circular_pad3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CIRCULAR_PAD_H_
#define OP_API_INC_CIRCULAR_PAD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCircularPad3dworkspace
 * @domain aclnn_ops_infer
 * @domain aclnn_ops_train
 *
 * tensor
 * @param [in] self: npu deviceaclTensor, BFLOAT16,FLOAT16, FLOAT32,INT8, INT32,ND
 * @param [in] padding: npu deviceaclIntArray, INT646
 * selfselfself
 * @param [in] out: npu deviceaclTensor,
 * selfself
 * paddingself
 * paddingselfpadding
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCircularPad3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief: aclnnCircularPad3d
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCircularPad3dGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCircularPad3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CIRCULAR_PAD_H_// End content from: aclnn_circular_pad3d.h

// Begin content from: aclnn_equal.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TENSOREQUAL_H_
#define OP_API_INC_TENSOREQUAL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnEqualworkspace
 * @domain aclnn_math
 * TensorBool
 *
 * $$ out = (self == other)  ?  True : False $$
 *
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([l0op::Contiguous])
 *     B -->D([l0op::TensorEqual])
 *     E[(other)] -->F([l0op::Contiguous])
 *     F -->D --> F1([l0op::ViewCopy])
 *     F1 --> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensor
 * FLOAT16,FLOAT,INT32,INT8,UINT8,BOOL,DOUBLE,INT64,INT16,UINT16,UINT32,UINT64
 * selfotherTensorND
 * @param [in] other: npu deviceaclTensor
 * FLOAT16,FLOAT,INT32,INT8,UINT8,BOOL,DOUBLE,INT64,INT16,UINT16,UINT32,UINT64
 * selfotherTensorND
 * @param [in] out: BOOLTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEqualGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnEqual
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnEqualGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEqual(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TENSOREQUAL_H_
// End content from: aclnn_equal.h

// Begin content from: aclnn_reflection_pad3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REFLECTION_PAD3D_BACKWARD_H_
#define OP_API_INC_REFLECTION_PAD3D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReflectionPad3dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 * @param [in] gradOutput: npu deviceaclTensor, FLOAT16, FLOAT32, DOUBLE, COMPLEX64,
 * COMPLEX128ND
 * selfgradInputshapereflection_pad3doutput
 * @param [in] self: npu deviceaclTensor,
 * gradOutputNDgradOutput gradInputshapegradInput
 * @param [in] padding: npu deviceaclIntArray, INT646
 * selfself,
 * self,
 * @param [in] gradInput: npu deviceaclTensor, gradOutputshapeselfND
 * gradOutputself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad3dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                   const aclIntArray* padding, aclTensor* gradInput,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnReflectionPad3dBackward
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnReflectionPad3dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REFLECTION_PAD3D_BACKWARD_H_// End content from: aclnn_reflection_pad3d_backward.h

// Begin content from: aclnn_scatter_add.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SCATTER_OUT_H_
#define OP_API_INC_SCATTER_OUT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnScatterAddworkspace
 * @domain aclnn_ops_infer
 *
 *  tensorindex tensortensor
 * srcself
 * @param [in] self: npu deviceaclTensor, FLOAT16, FLOAT32, INT32, INT8, UINT8,
 * TensorND,
 * @param [in] dim: hostnum, INT64
 * @param [in] index: npu deviceaclTensorINT32, int64dimsrc
 * TensorND
 * @param [in] src: npu deviceaclTensorFLOAT16, FLOAT32, INT32, INT8,
 * UINT8dimsrc TensorNDself
 * @param [in] out: npu deviceaclTensor, FLOAT16, FLOAT32, INT32, INT8, UINT8,
 * ,,tensor shapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScatterAddGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index,
                                                      const aclTensor* src, aclTensor* out, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief: aclnnScatterAdd
 *
 * : tensorindex tensortensor
 * srcself
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnScatterAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScatterAdd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SCATTER_OUT_H_// End content from: aclnn_scatter_add.h

// Begin content from: acl_rfft1d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACL_RFFT1D_H_
#define OP_API_INC_LEVEL2_ACL_RFFT1D_H_

// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclRfft1D First segment interface. Calculate the workspace size based on the specific calculation process.
 * Function description: Calculates the RFFT of the input tensor and outputs the result.
 * Calculation formula:
 * $$ out = Rfft(input) $$
 * Calculation chart:
 ```mermaid
 * graph LR
 * A[(self)]--->B([l0op::Rfft1D])
 * B--->C([l0op::ViewCopy])
 * C--->D[(out)]
 * ` ` `
 * @domain aclnn_ops_infer
 * Parameter description:
 * @param [in] Input
 * Input tensor. The type is FLOAT. The data format supports ND, but does not support discontinuous tensors.
 * @param [in] out
 * Output tensor. The type is FLOAT. The data format supports ND, but does not support discontinuous tensors.
 * @param [out] workspace_size: Returns the workspace size that a user needs to apply for on the NPU device.
 * @param [out] executor: Return the op executor, including the operator calculation process.
 * @return aclnnStatus: Return the status code.
 */
 
aclnnStatus aclRfft1DGetWorkspaceSize(const aclTensor* self, int64_t n, int64_t dim, int64_t norm, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief A second interface of aclRfft1D, used to perform calculation.
 * @param [in] workspace: start address of the workspace memory allocated on the NPU device.
 * @param [in] workspace_size: size of the workspace applied on the NPU device, which is obtained by calling the first segment interface aclRfft1DGetWorkspaceSize.
 * @param [in] exector: op executor, including the operator calculation process.
 * @param [in] stream: acl stream.
 * @return aclnnStatus: returned status code
 */
                                    
aclnnStatus aclRfft1D(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACL_RFFT1D_H_
// End content from: acl_rfft1d.h

// Begin content from: aclnn_flash_attention_score_grad.h
/**
 * Copyright (c) 2023-2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef OP_API_INC_FLASH_ATTENTION_SCORE_GRAD_H_
#define OP_API_INC_FLASH_ATTENTION_SCORE_GRAD_H_

// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFlashAttentionScoreGradworkspace
 * @domain aclnn_ops_train
 */
aclnnStatus aclnnFlashAttentionScoreGradGetWorkspaceSize(
    const aclTensor *query, const aclTensor *keyIn, const aclTensor *value, const aclTensor *dy,
    const aclTensor *pseShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional,
    const aclTensor *attenMaskOptional, const aclTensor *softmaxMaxOptional, const aclTensor *softmaxSumOptional,
    const aclTensor *softmaxInOptional, const aclTensor *attentionInOptional, const aclIntArray *prefixOptional,
    double scaleValue, double keepProb, int64_t preTokens, int64_t nextTokens,
    int64_t headNum, char *inputLayout, int64_t innerPrecise, int64_t sparseMode,
    const aclTensor *dqOut, const aclTensor *dkOut, const aclTensor *dvOut, const aclTensor *dpseOut,
    uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnFlashAttentionScoreGrad
 */
aclnnStatus aclnnFlashAttentionScoreGrad(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                         const aclrtStream stream);

/**
 * @brief aclnnFlashAttentionUnpaddingScoreGradworkspace
 * @domain aclnn_ops_train
 */
aclnnStatus aclnnFlashAttentionUnpaddingScoreGradGetWorkspaceSize(
    const aclTensor *query, const aclTensor *keyIn, const aclTensor *value, const aclTensor *dy,
    const aclTensor *pseShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional,
    const aclTensor *attenMaskOptional, const aclTensor *softmaxMaxOptional, const aclTensor *softmaxSumOptional,
    const aclTensor *softmaxInOptional, const aclTensor *attentionInOptional, const aclIntArray *prefixOptional,
    const aclIntArray *actualSeqQLenOptional, const aclIntArray *actualSeqKvLenOptional, double scaleValue,
    double keepProb, int64_t preTokens, int64_t nextTokens, int64_t headNum,
    char *inputLayout, int64_t innerPrecise, int64_t sparseMode, const aclTensor *dqOut,
    const aclTensor *dkOut, const aclTensor *dvOut, const aclTensor *dpseOut, uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnFlashAttentionUnpaddingScoreGrad
 */
aclnnStatus aclnnFlashAttentionUnpaddingScoreGrad(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                                  const aclrtStream stream);


/**
 * @brief aclnnFlashAttentionScoreGradV2workspace
 * @domain aclnn_ops_train
*/
aclnnStatus aclnnFlashAttentionScoreGradV2GetWorkspaceSize(
    const aclTensor *query, const aclTensor *keyIn, const aclTensor *value, const aclTensor *dy,
    const aclTensor *pseShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional,
    const aclTensor *attenMaskOptional, const aclTensor *softmaxMaxOptional, const aclTensor *softmaxSumOptional,
    const aclTensor *softmaxInOptional, const aclTensor *attentionInOptional, const aclIntArray *prefixOptional,
    const aclIntArray *qStartIdxOptional, const aclIntArray *kvStartIdxOptional, double scaleValue,
    double keepProb, int64_t preTokens, int64_t nextTokens,
    int64_t headNum, char *inputLayout, int64_t innerPrecise, int64_t sparseMode,
    int64_t pseType, const aclTensor *dqOut, const aclTensor *dkOut, const aclTensor *dvOut,
    const aclTensor *dpseOut, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnFlashAttentionScoreGradV2
*/
aclnnStatus aclnnFlashAttentionScoreGradV2(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                           const aclrtStream stream);

/**
 * @brief aclnnFlashAttentionUnpaddingScoreGradV2workspace
 * @domain aclnn_ops_train
*/
aclnnStatus aclnnFlashAttentionUnpaddingScoreGradV2GetWorkspaceSize(
    const aclTensor *query, const aclTensor *keyIn, const aclTensor *value, const aclTensor *dy,
    const aclTensor *pseShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional,
    const aclTensor *attenMaskOptional, const aclTensor *softmaxMaxOptional, const aclTensor *softmaxSumOptional,
    const aclTensor *softmaxInOptional, const aclTensor *attentionInOptional, const aclIntArray *prefixOptional,
    const aclIntArray *actualSeqQLenOptional, const aclIntArray *actualSeqKvLenOptional,
    const aclIntArray *qStartIdxOptional, const aclIntArray *kvStartIdxOptional, double scaleValue,
    double keepProb, int64_t preTokens, int64_t nextTokens, int64_t headNum,
    char *inputLayout, int64_t innerPrecise, int64_t sparseMode, int64_t pseType,
    const aclTensor *dqOut, const aclTensor *dkOut, const aclTensor *dvOut, const aclTensor *dpseOut,
    uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnFlashAttentionUnpaddingScoreGradV2
*/
aclnnStatus aclnnFlashAttentionUnpaddingScoreGradV2(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                                    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif // OP_API_INC_FLASH_ATTENTION_SCORE_GRAD_H_
// End content from: aclnn_flash_attention_score_grad.h

// Begin content from: aclnn_bitwise_and_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BITWISE_AND_TENSOR_H_
#define OP_API_INC_BITWISE_AND_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBitwiseAndTensorworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output_i = self_i\&other_i $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([LogicalAnd])
 *     D[(other)] -->E([Contiguous])
 *     E --> F([Cast])
 *     F --> G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 * 
 * selfotherINTl0::BitwiseAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([BitwiseAnd])
 *     D[(other)] -->E([Contiguous])
 *     E --> F([Cast])
 *     F --> G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorINT16,UINT16,INT32,INT64,INT8,UINT8,BOOLother
 * shapeotherbroadcastTensorND
 * @param [in] other: npu
 * deviceaclTensorINT16,UINT16,INT32,INT64,INT8,UINT8,BOOLself
 * shapeselfbroadcastTensorND
 * @param [in] out: npu
 * deviceaclTensorINT16,UINT16,INT32,INT64,INT8,UINT8,BOOLselfother
 * shapeselfotherbroadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseAndTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief aclnnBitwiseAndTensor
 *
 * 
 * 
 * $$ output_i = self_i\&other_i $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([LogicalAnd])
 *     D[(other)] -->E([Contiguous])
 *     E --> F([Cast])
 *     F --> G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 * 
 * selfotherINTl0::BitwiseAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([BitwiseAnd])
 *     D[(other)] -->E([Contiguous])
 *     E --> F([Cast])
 *     F --> G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnBitwiseAndTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBitwiseAndTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

/**
 * @brief aclnnInplaceBitwiseAndTensorworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output_i = self_i\&other_i $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([LogicalAnd])
 *     D[(other)] -->E([Contiguous])
 *     E --> F([Cast])
 *     F --> G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 * 
 * selfotherINTl0::BitwiseAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([BitwiseAnd])
 *     D[(other)] -->E([Contiguous])
 *     E --> F([Cast])
 *     F --> G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorINT16,UINT16,INT32,INT64,INT8,UINT8,BOOLother
 * shapeotherbroadcastTensorND
 * @param [in] other: npu
 * deviceaclTensorINT16,UINT16,INT32,INT64,INT8,UINT8,BOOLself
 * shapeselfbroadcastTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseAndTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceBitwiseAndTenosr
 *
 * 
 * 
 * $$ output_i = self_i\&other_i $$
 *
 * 
 * 
 * selfotherBOOLl0::LogicalAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([LogicalAnd])
 *     D[(other)] -->E([Contiguous])
 *     E --> F([Cast])
 *     F --> G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 * 
 * selfotherINTl0::BitwiseAnd
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C --> G([BitwiseAnd])
 *     D[(other)] -->E([Contiguous])
 *     E --> F([Cast])
 *     F --> G
 *     G --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceBitwiseAndTensorOutGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceBitwiseAndTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BITWISE_AND_TENSOR_H_
// End content from: aclnn_bitwise_and_tensor.h

// Begin content from: aclnn_softshrink.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SOFTSHRINK_H_
#define OP_API_INC_SOFTSHRINK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSoftshrinkworkspace
 * @domain aclnn_ops_infer
 * 
 * 
 * $$
 * Softshrink(x)=
 * \begin{cases}
 * x-, if x >  \\
 * x+, if x < - \\
 * 0, otherwise \\
 * \end{cases}
 * $$
 * 
 * @param [in]   self
 * TensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in]   lambd
 * ScalarFLOAT
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnSoftshrinkGetWorkspaceSize(const aclTensor* self, const aclScalar* lambd, aclTensor* out,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnSoftshrink
 * 
 * 
 * $$
 * Softshrink(x)=
 * \begin{cases}
 * x-, if x >  \\
 * x+, if x < - \\
 * 0, otherwise \\
 * \end{cases}
 * $$
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B -->C([l0op::SoftShrink])
    C -->D([l0op::Cast])
    D -->E([l0op::ViewCopy])
    E -->F[(Out)]

    G((lambd)) -->C
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSoftshrinkGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftshrink(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SOFTSHRINK_H_
// End content from: aclnn_softshrink.h

// Begin content from: aclnn_upsample_nearest_exact2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef ACLNN_UPSAMPLE_NEAREST_EXACT2D_BACKWARD_H_
#define ACLNN_UPSAMPLE_NEAREST_EXACT2D_BACKWARD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearesrExact2dBackwardworkspace
 * @domain aclnn_ops_train
 * aclnnUpsampleNearesrExact2d
 *
 * @param [in] gradOutput: DeviceaclTensorFLOATFLOAT16BFLOAT16
 * TensorNCHWshapeTensorout
 * @param [in] outputSize: HostaclIntArrayINT64size2gradOutputHW
 * @param [in] inputSize: HostaclIntArrayINT64size4outNCHW
 * @param [in] scalesH: Hostoutheight
 * @param [in] scalesW: Hostoutwidth
 * @param [out] out: DeviceaclTensorFLOATFLOAT16BFLOAT16
 * TensorNCHWshapeTensorgradOutput
 * @param [out] workspaceSize: Deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
__attribute__((visibility("default")))
aclnnStatus aclnnUpsampleNearestExact2dBackwardGetWorkspaceSize(
    const aclTensor *gradOutput, const aclIntArray *outputSize, const aclIntArray *inputSize,  
    double scalesH, double scalesW, aclTensor *out, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnUpsampleNearestExact2dBackward
 * 
 * aclnnUpsampleNearestExact2d
 *
 * @param [in] workspace: Deviceworkspace
 * @param [in] workspaceSize: Deviceworkspace
 * aclnnUpsampleNearestExact2dBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: AscendCL Stream
 * @return aclnnStatus: 
 */
__attribute__((visibility("default")))
aclnnStatus aclnnUpsampleNearestExact2dBackward(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                              aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_upsample_nearest_exact2d_backward.h

// Begin content from: aclnn_ones.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ONES_H_
#define OP_API_INC_ONES_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnOneHotworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceOneGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnOneHot
 */
ACLNN_API aclnnStatus aclnnInplaceOne(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ONES_H_
// End content from: aclnn_ones.h

// Begin content from: aclnn_background_replace.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_BACKGROUND_REPLACE_H_
#define ACLNN_BACKGROUND_REPLACE_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnBackgroundReplaceGetWorkspaceSize
 * parameters :
 * bkg : required
 * src : required
 * mask : required
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnBackgroundReplaceGetWorkspaceSize(
    const aclTensor *bkg,
    const aclTensor *src,
    const aclTensor *mask,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnBackgroundReplace
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnBackgroundReplace(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_background_replace.h

// Begin content from: aclnn_clamp.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_CLAMP_H_
#define OP_API_INC_LEVEL2_ACLNN_CLAMP_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnClampworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnClampGetWorkspaceSize(const aclTensor* self, const aclScalar* clipValueMin,
                                                 const aclScalar* clipValueMax, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnClamp
 */
ACLNN_API aclnnStatus aclnnClamp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                 const aclrtStream stream);

/**
 * @brief aclnnClampMinworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnClampMinGetWorkspaceSize(const aclTensor* self, const aclScalar* clipValueMin,
                                                    aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnClampMin
 */
ACLNN_API aclnnStatus aclnnClampMin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    const aclrtStream stream);

/**
 * @brief aclnnClampTensorworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnClampTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* clipValueMin,
                                                       const aclTensor* clipValueMax, aclTensor* out,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnClampMinTensorworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnClampMinTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* clipValueMin,
                                                          aclTensor* out, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

/**
 * @brief aclnnClampMinTensor
 */
ACLNN_API aclnnStatus aclnnClampMinTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          const aclrtStream stream);

/**
 * @brief aclnnInplaceClampMinTensorworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceClampMinTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* clipValueMin,
                                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceClampMinTensor
 */
ACLNN_API aclnnStatus aclnnInplaceClampMinTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 const aclrtStream stream);

/**
 * @brief aclnnClampTensor
 */
ACLNN_API aclnnStatus aclnnClampTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

/**
 * @brief aclnnClampMaxworkspace
 * @domain aclnn_math
 *
 * [-inf,max]
 * 
 * $$ {y}_{i} = min({{x}_{i}},max) $$
 *
 * @param [in] self: tensorFLOAT16FLOATFLOAT64INT8UINT8INT16INT32INT64
 * [Tensor](#)ND[](#)
 * @param [in] clipValueMax: self
 * @param [in] out: FLOAT16FLOATFLOAT64INT8UINT8INT16INT32INT64
 * selfshapeselfND[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnClampMaxGetWorkspaceSize(const aclTensor* self, const aclScalar* clipValueMax,
                                                    aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnClampMax
 *
 * [-inf,max]
 * 
 * $$ {y}_{i} = min({{x}_{i}},max) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnClampMaxGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnClampMax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceClampMaxworkspace
 * @domain aclnn_math
 *
 * [-inf,max]
 * 
 * $$ {y}_{i} = min({{x}_{i}},max) $$
 *
 * @param [in] selfRef: tensorFLOAT16FLOATFLOAT64INT8UINT8INT16INT32INT64
 * [Tensor](#)ND[](#)
 * @param [in] clipValueMax: self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceClampMaxGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* clipValueMax,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceClampMax
 *
 * [-inf,max]
 * 
 * $$ {y}_{i} = min({{x}_{i}},max) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceClampMaxGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceClampMax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

/**
 * @brief aclnnClampMaxTensorworkspace
 * @domain aclnn_math
 *
 * [-inf, max]
 *
 * @param [in] self: tensorFLOAT16FLOATDOUBLEINT8UINT8INT16INT32INT64
 * maxshapemaxbroadcastTensorND
 * @param [in] max: tensorFLOAT16FLOATDOUBLEINT8UINT8INT16INT32INT64
 * selfshapemaxbroadcastTensorND
 * @param [in] out: tensorFLOAT16FLOATDOUBLEINT8UINT8INT16INT32INT64
 * selfmaxshapeselfmax
 * broadcastshapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnClampMaxTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* max, aclTensor* out,
                                                          uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceClampMaxTensorworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceClampMaxTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* max,
                                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnClampMaxTensor
 *
 * [-inf, max]
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnClampMaxTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnClampMaxTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

ACLNN_API aclnnStatus aclnnInplaceClampMaxTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_CLAMP_H_// End content from: aclnn_clamp.h

// Begin content from: aclnn_foreach_expm1.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_EXPM1_H_
#define ACLNN_FOREACH_EXPM1_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachExpm1GetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachExpm1GetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachExpm1
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachExpm1(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_expm1.h

// Begin content from: aclnn_masked_softmax_with_rel_pos_bias.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MASKED_SOFTMAX_WITH_REL_POS_BIAS_H_
#define ACLNN_MASKED_SOFTMAX_WITH_REL_POS_BIAS_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMaskedSoftmaxWithRelPosBiasGetWorkspaceSize
 * parameters :
 * x : required
 * attenMaskOptional : optional
 * relativePosBias : required
 * scaleValue : optional
 * innerPrecisionMode : optional
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMaskedSoftmaxWithRelPosBiasGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *attenMaskOptional,
    const aclTensor *relativePosBias,
    double scaleValue,
    int64_t innerPrecisionMode,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMaskedSoftmaxWithRelPosBias
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMaskedSoftmaxWithRelPosBias(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_masked_softmax_with_rel_pos_bias.h

// Begin content from: aclnn_foreach_pow_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_POW_SCALAR_H_
#define ACLNN_FOREACH_POW_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachPowScalarGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachPowScalarGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachPowScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachPowScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_pow_scalar.h

// Begin content from: aclnn_affine_grid.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_AFFINE_GRID_H_
#define OP_API_INC_AFFINE_GRID_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAffineGridworkspace
 * @domain aclnn_ops_infer
 *
 * (theta)2D3D
 *
 * @param [in] theta: npu deviceaclTensor
 * FLOATFLOAT16shape(N, 2, 3)(N, 3, 4)TensorND
 * @param [in] size: hostaclIntArraysize4(N, C, H, W)5(N, C, D, H, W)
 * @param [in] alignCorners: hostbool
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16theta
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAffineGridGetWorkspaceSize(const aclTensor* theta, const aclIntArray* size,
                                                      bool alignCorners, aclTensor* out, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnAffineGrid
 *
 * (theta)2D3D
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAffineGridGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAffineGrid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AFFINE_GRID_H_
// End content from: aclnn_affine_grid.h

// Begin content from: aclnn_batch_matmul.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_ACLNN_BATCHMATMUL_H
#define OP_API_ACLNN_BATCHMATMUL_H

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchMatMulworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnBatchMatMulGetWorkspaceSize(const aclTensor* self, const aclTensor* mat2, aclTensor* out,
                                                       int8_t cubeMathType, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnBatchMatMul
 */
ACLNN_API aclnnStatus aclnnBatchMatMul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_ACLNN_BATCHMATMUL_H// End content from: aclnn_batch_matmul.h

// Begin content from: aclnn_foreach_sub_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_SUB_SCALAR_LIST_H_
#define ACLNN_FOREACH_SUB_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachSubScalarListGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSubScalarListGetWorkspaceSize(
    const aclTensorList *x,
    const aclScalarList *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachSubScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSubScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sub_scalar_list.h

// Begin content from: aclnn_erf.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ERF_H_
#define OP_API_INC_LEVEL2_ACLNN_ERF_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnErfworkspace
 * @domain aclnn_ops_infer
 * Tensor
 * 
 * $$ erf(x)=\frac{2}{\sqrt{\pi } } \int_{0}^{x} e^{-t^{2} } \mathrm{d}t $$
 *
 * 
 * ErfFLOAT32FLOAT16BFLOAT16FLOAT64Erf
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B([l0op::Contiguous])
 *     B -->C([l0op::Erf])
 *     C --> D([l0op::ViewCopy])
 *     D --> E[(out)]
 * ```
 *
 * 
 * selfBOOLselfCASTFLOAT32Erf
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B([l0op::Contiguous])
 *     B -->C([l0op::Cast])
 *     C -->D([l0op::Erf])
 *     D -->H([l0op::Cast])
 *     H --> E([l0op::ViewCopy])
 *     E --> F[(out)]
 * ```
 *
 * @param [in] self: erfnpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16BOOLINT64ND Tensor
 * @param [in] out: erfnpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16ND Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnErfGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnErf
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnErfGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnErf(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceErfworkspace
 * @domain aclnn_ops_infer
 * Tensor
 * 
 * $$ erf(x)=\frac{2}{\sqrt{\pi } } \int_{0}^{x} e^{-t^{2} } \mathrm{d}t $$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B{l0op::Contiguous}
 *     B -->C([l0op::Erf])
 *     C --> D{l0op::ViewCopy}
 *     D --> E[(out)]
 * ```
 *
 * @param [in] selfRef: erfnpu deviceaclTensor
 * FLOAT64FLOAT32FLOAT16BFLOAT16BOOLND Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceErfGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnInplaceErf
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnErfGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceErf(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ERF_H_// End content from: aclnn_erf.h

// Begin content from: aclnn_le_tensor.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_LE_TENSOR_H_
#define OP_API_INC_LEVEL2_ACLNN_LE_TENSOR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLeTensorworkspace
 * @domain aclnn_math
 * Tensorotherselfotherout
 * @param [in] self: npu deviceaclTensor
 * INT8,UINT8,INT16,UINT16,INT32,INT64,FLOAT16,FLOAT,DOUBLE
 * othershapeotherbroadcastTensorND
 * @param [in] other: npu deviceaclTensor
 * INT8,UINT8,INT16,UINT16,INT32,INT64,FLOAT16,FLOAT,DOUBLE
 * othershapeotherbroadcastTensorND
 * @param [in] out: npu deviceaclTensor
 * INT8,UINT8,INT16,UINT16,INT32,INT64,FLOAT16,FLOAT,DOUBLEND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLeTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLeTensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLeTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceLeTensorworkspace
 * @domain aclnn_math
 * Tensorother Tensor
 *  $$ selfRef_{i} = (selfRef_{i} <= other_{i}) ? True : False $$
 *
 * @param [in] selfRef: le,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BOOLBFLOAT16BFLOAT16NDTensor
 * @param [in] other: ge,aclTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLeTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLeTensor
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceLeTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_LE_TENSOR_H_
// End content from: aclnn_le_tensor.h

// Begin content from: aclnn_gelu_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GELU_BACKWARD_H_
#define OP_API_INC_GELU_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGeluBackwardworkspace
 * @domain aclnn_ops_train
 *
 * Gelu
 * GeluxTensor
 * $$
 * Gelu(x)=x \cdot \Phi(x)=x/2 \cdot [1+erf(x/\sqrt{2})]
 * $$
 * erf
 * $$
 * erf(x)=\frac{2}{\sqrt \pi}\sum^{\infty}_{n=0}{\frac{(-1)^n \cdot x^{2n+1}}{n! \cdot (2n+1)}}
 * $$
 * gradInputgradOutput
 * $$
 * gradInput = gradOutput \cdot (\frac{1}{2}+\frac{1}{2} \cdot \\
 * erf(\frac{x}{\sqrt2})+\frac{x}{\sqrt{2\pi}} \cdot e^{-\frac{x^2}{2}})
 * $$
 * Gelu
 * $$
 * Gelu(x)=0.5x(1+tanh(\sqrt{2/\pi}(x+0.044715x^3)))
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(gradOutput)] -->B([l0op::Contiguous])
 * B --> C([l0op::GeluGrad])
 * D[(self)] --> E([l0op::Contiguous])
 * H[(gradInput)] --> I([l0op::Contiguous])
 * E --> C
 * I --> C
 * C --> F([l0op::ViewCopy])
 * F --> G[(gradInput)]
 * ```
 *
 * @param [in] gradOutputshape
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * FRACTAL_NZNC1HWC0,NDTensor
 * @param [in] selfGelu
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * FRACTAL_NZNC1HWC0,NDTensor
 * @param [out] gradInputbackward
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * FRACTAL_NZNC1HWC0,ND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                        const aclTensor* gradInput, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnGeluBackward
 */
ACLNN_API aclnnStatus aclnnGeluBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                        const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GELU_BACKWARD_H_
// End content from: aclnn_gelu_backward.h

// Begin content from: aclnn_matmul_all_reduce.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023-2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_matmul_all_reduce.h
 * \brief
 */
#ifndef OP_API_INC_MATMUL_ALL_REDUCE_
#define OP_API_INC_MATMUL_ALL_REDUCE_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMatmulAllReduceworkspace
 * @domain aclnn_ops_infer
 * mm+AllReduce
 * @param [in] x1: matmulfloat16, bf16
 * @param [in] x2: matmulfloat16, bf16
 * @param [in] bias: float16, bf16
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl0/1
 * @param [out] output: +
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMatmulAllReduceGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                           const aclTensor* bias, const char* group,
                                                           const char* reduceOp, int64_t commTurn, int64_t streamMode,
                                                           const aclTensor* output, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnMatmulAllReduce
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnMatmulAllReduceGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMatmulAllReduce(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MATMUL_ALL_REDUCE_// End content from: aclnn_matmul_all_reduce.h

// Begin content from: aclnn_eq_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_EQ_SCALAR_H_
#define OP_API_INC_LEVEL2_ACLNN_EQ_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnEqScalarworkspace
 * @domain aclnn_math
 * selfotherselfotherout
 *
 * $$ out_i = (self_i == \mathit{other} )  ?  [True] : [False] $$
 *
 *
 * 
 * ```mermaid
 * graph LR
 * A[(Self)] -->B([l0op::Contiguous])
 * B -->C1([l0op::Cast])-->D([l0op::Equal])
 *     F((other)) -->D
 *     D -->F1([l0op::ViewCopy])--> J[(out)]
 * ```
 * @param [in] self: npu deviceaclTensor
 * FLOAT16, FLOAT, INT64, UINT64, INT32, INT8, UINT8, BOOL, UINT32, BFLOAT16, DOUBLE, INT16, COMPLEX64,
 * COMPLEX128NDTensor
 * @param [in] other: hostaclScalarFLOAT16, FLOAT, INT64, UINT64, INT32, INT8, UINT8, BOOL, UINT32,
 * BFLOAT16, DOUBLE, INT16, COMPLEX64, COMPLEX128
 * @param [in] out: npu deviceaclTensorboolshapeselfshapeND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEqScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnEqScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnEqScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEqScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    const aclrtStream stream);

/**
 * @brief aclnnInplaceEqScalarworkspace
 * @domain aclnn_math
 * selfotherselfotherself
 *
 * $$ self_i = (self_i == \mathit{other} )  ?  [True] : [False] $$
 *
 * 
*```mermaid
* graph LR
* A[(SelfRef)] -->B([l0op::Contiguous])
* B -->C1([l0op::Cast])-->D([l0op::Equal])
* F((other)) -->D
* D -->F1([l0op::ViewCopy])--> J[(selfRef)]
```
 * @param [in] selfRef: npu deviceaclTensor
 * FLOAT16, FLOAT, INT64, UINT64, INT32, INT8, UINT8, BOOL, UINT32, BFLOAT16, DOUBLE, INT16, COMPLEX64,
 * COMPLEX128NDTensor
 * @param [in] other: hostaclScalarFLOAT16, FLOAT, INT64, UINT64, INT32, INT8, UINT8, BOOL, UINT32,
 * BFLOAT16, DOUBLE, INT16, COMPLEX64, COMPLEX128
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceEqScalarGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceEqScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnEqScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceEqScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_EQ_SCALAR_H_// End content from: aclnn_eq_scalar.h

// Begin content from: aclnn_ascend_anti_quant.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ASCEND_ANTI_QUANT_H_
#define OP_API_INC_LEVEL2_ACLNN_ASCEND_ANTI_QUANT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAscendAntiQuantworkspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: AscendAntiQuantnpu deviceaclTensor
 * int8, ND
 * Tensor
 * @param [in] scale: npu deviceaclTensor, float, bf16
 * @param [in] offset: npu deviceaclTensorfloat, bf16
 * @param [in] dstType:  hostaclScalar, int
 * @param [in] sqrtMode:  hostaclScalarbool
 * @param [in] y: AscendAntiQuantnpu deviceaclTensor
 * float16, bf16, ND
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAscendAntiQuantGetWorkspaceSize(const aclTensor* x, const aclTensor* scale,
                                                           const aclTensor* offset, int64_t dstType, bool sqrtMode,
                                                           const aclTensor* y, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnAscendAntiQuant
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAscendAntiQuantGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAscendAntiQuant(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ASCEND_ANTI_QUANT_H_// End content from: aclnn_ascend_anti_quant.h

// Begin content from: aclnn_nonzero_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_NONZERO_V2_H_
#define OP_API_INC_NONZERO_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNonzeroV2workspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnNonzeroV2GetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnNonzeroV2
 */
ACLNN_API aclnnStatus aclnnNonzeroV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_nonzero_v2.h

// Begin content from: aclnn_cummin.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_CUMMIN_H_
#define OP_API_INC_LEVEL2_ACLNN_CUMMIN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * self
 * 
 * $self_{i}$selfdimdim
 * $$
 * valuesOut_{i} = min(self_{1}, self_{2}, self_{3}, ......, self_{i})
 * $$
 * $$
 * indicesOut_{i} = argmin(self_{1}, self_{2}, self_{3}, ......, self_{i})
 * $$
 */

/**
 * @brief aclnnCumminworkspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu deviceaclTensorFLOATDOUBLEUINT8INT8INT16INT32INT64
 * FLOAT16BFLOAT16BOOLoutTensorND8
 * @param [in] dim: hostINT64
 * @param [in] valuesOutnpu deviceaclTensorFLOATDOUBLEUINT8INT8INT16INT32INT64
 * FLOAT16BFLOAT16BOOLTensorND8, shapeself
 * @param [in] indicesOutnpu deviceaclTensorINT32INT64TensorND
 * 8, shapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCumminGetWorkspaceSize(const aclTensor* self, int64_t dim, aclTensor* valuesOut,
                                                  aclTensor* indicesOut, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnCummin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCumminGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCummin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_CUMMIN_H_
// End content from: aclnn_cummin.h

// Begin content from: aclnn_max_pool3d_with_argmax_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_MAX_POOL3D_GRAD_WITH_ARGMAX_H_
#define OP_API_INC_LEVEL2_ACLNN_MAX_POOL3D_GRAD_WITH_ARGMAX_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxPool3dWithArgmaxBackward First segment interface. Calculate the workspace size based on the specific calculation process.
 * Function description: Calculates MaxPool3DGradWithArgmax from the gradOutput and self, at the result gradInput
 * @domain aclnn_ops_train
 * @param [in] gradOutput: gradient Tensor, which is the same as the positive output shape. It is aclTensor on the NPU device side. The data type can be float32/float16/bfloat16. Data format: ND and discontinuous tensors are supported. Only 4- or 5-dimensional tensors are supported.
     *  If there are four dimensions, the value of N is considered as 1, and the value of each dimension must be greater than 0.
     *  If the value is five dimensions, all dimensions except dimension 0 must be greater than 0. When dimension 0 is 0, gradInput is empty.
 * @param [in] self: aclTensor on the NPU device side, positive operator input. The data type can be float32/float16/bfloat16. . Data format: ND and discontinuous tensors are supported. Only 4- or 5-dimensional tensors are supported.
 * @param [in] indices: aclTensor on the NPU device side, which is the output of the forward operator. The index data with the maximum value on the DHW plane is int64 and ND is supported. Supports discontinuous tensors. Only 4- or 5-dimensional tensors are supported.
 * @param [in] kernelSize: aclIntArray type, indicating the maxpooling window size.
 * @param [in] stride: aclIntArray type, the step size of the window movement.
 * @param [in] padding: aclIntArray type, number of padding layers for each edge. The value is negative infinity.
 * @param [in] dilation: aclIntArray type, controls the stride of elements in the window.
 * @param [in] ceilMode: bool type, when true, the output shape is calculated using round-up method. By default is rounding down.
 * @param [in] gradInput: It is the same as the positive input shape. It is the aclTensor on the NPU device side. The data type can be float16, float32, or bfloat16. Added the data format ND and discontinuous tensors.
 * @param [out] workspaceSize: Returns the workspace size that the user needs to apply for on the npu device side.
 * @param [out] executor: Return the op executor, including the operator calculation process.
 * @return aclnnStatus: Return the status code.
 */

ACLNN_API aclnnStatus aclnnMaxPool3dWithArgmaxBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                       const aclTensor* indices, const aclIntArray* kernelSize,
                                                                       const aclIntArray* stride, const aclIntArray* padding,
                                                                       const aclIntArray* dilation, bool ceilMode,
                                                                       aclTensor* gradInput, uint64_t* workspaceSize,
                                                                       aclOpExecutor** executor);
/**
 * @brief A second interface of aclnnMaxPool3dWithArgmaxBackward, used to perform calculation.
 * @param [in] workspace: start address of the workspace memory allocated on the NPU device.
 * @param [in] workspace_size: size of the workspace applied on the NPU device, which is obtained by calling the first segment interface aclnnMaxPool3dWithIndicesBackwardGetWorkspaceSize.
 * @param [in] exector: op executor, including the operator calculation process.
 * @param [in] stream: acl stream.
 * @return aclnnStatus: returned status code
 */

ACLNN_API aclnnStatus aclnnMaxPool3dWithArgmaxBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, 
                                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_MAX_POOL3D_GRAD_WITH_ARGMAX_H_// End content from: aclnn_max_pool3d_with_argmax_backward.h

// Begin content from: aclnn_moe_init_routing.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_INIT_ROUTING_H_
#define ACLNN_MOE_INIT_ROUTING_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeInitRoutingGetWorkspaceSize
 * parameters :
 * x : required
 * rowIdx : required
 * expertIdx : required
 * activeNum : required
 * expandedXOut : required
 * expandedRowIdxOut : required
 * expandedExpertIdxOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRoutingGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *rowIdx,
    const aclTensor *expertIdx,
    int64_t activeNum,
    const aclTensor *expandedXOut,
    const aclTensor *expandedRowIdxOut,
    const aclTensor *expandedExpertIdxOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeInitRouting
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeInitRouting(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_init_routing.h

// Begin content from: aclnn_argmin.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ARGMIN_H_
#define OP_API_INC_ARGMIN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnARGMINworkspace
 * @domain aclnn_ops_infer
 *
 * 
 *
 * 
 * api
 * ```mermaid
 *  graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> C([l0op::ArgMin])
 *  C --> F([l0op::Cast])
 *  D([dim]) --> C
 *  F -.-> E([l0op::ViewCopy])
 *  E --> O[(Out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorFLOATBFLOAT16FLOAT16FLOAT64INT8
 * INT16INT32INT64UINT8BFLOAT16NDTensor
 * @param [in] dim: hostint64
 * @param [in] keepdim: host
 * @param [in] out: npu deviceaclTensorINT64NDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnArgMinGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepdim,
                                                  aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnArgMinworkspace
 *
 * 
 *
 * 
 * api
 * ```mermaid
 *  graph LR
 *  A[(self)] -.->B([l0op::Contiguous])
 *  B --> C([l0op::ArgMin])
 *  C --> F([l0op::Cast])
 *  D([dim]) --> C
 *  F -.-> E([l0op::ViewCopy])
 *  E --> O[(Out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnArgMinGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnArgMin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ARGMIN_H_// End content from: aclnn_argmin.h

// Begin content from: aclnn_unique2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNIQUE2_H_
#define OP_API_INC_UNIQUE2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUnique2workspace
 * @domain aclnn_math
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B ---> F([UniqueWithCountsAndSorting])
 *     C[(sorted)] --->F
 *     D[(returnInverse)] --->F
 *     E[(returnCounts)] --->F
 *     F --> G([valueOut])
 *     F --> H([inverseOut])
 *     F --> I([countsOut])
 * ```
 *
 * @param [in] self: npu deviceaclTensorBOOL, FLOAT, FLOAT16, DOUBLE, UINT8, INT8, UINT16, INT16,
 * INT32, UINT32, UINT64, INT64TensorND
 * @param [in] sorted: False valueOut 
 * @param [in] returnInverse: False valueOut 
 * @param [in] returnCounts: False valueOut Tensor
 * @param [in] valueOut: npu deviceaclTensor, BOOL, FLOAT,
 * FLOAT16, DOUBLE, UINT8, INT8, UINT16, INT16, INT32, UINT32, UINT64, INT64ND
 * @param [in] inverseOut: npu
 * deviceaclTensorreturnInversieTrueselfvalueOut
 *                      INT64shapeself
 * @param [in] countsOut: npu
 * deviceaclTensorreturnCountsTruevalueOutself
 *                     INT64shapevalueOut
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUnique2GetWorkspaceSize(const aclTensor* self, bool sorted, bool returnInverse,
                                                   bool returnCounts, aclTensor* valueOut, aclTensor* inverseOut,
                                                   aclTensor* countsOut, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnUnique2
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnUnique2GetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUnique2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNIQUE2_H_// End content from: aclnn_unique2.h

// Begin content from: aclnn_inverse.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_INVERSE_H_
#define OP_API_INC_LEVEL2_ACLNN_INVERSE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * 
 * 
 * $$
 * {A}^{-1}A = A{A}^{-1} = {I}_{n}
 * $$
 * A${A}^{-1}$A${I}_{n}$n
 *
 * 
 * selfFLOAT16
 *
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   B --> C([l0op::MatrixInverse])
 *   C --> D([l0op::Cast])
 *   D --> E([l0op::ViewCopy])
 *   E --> F[(out)]
 * ```
 *
 * 
 * selfFLOAT16FLOAT16FLOAT32
 *
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   B --> C([l0op::Cast])
 *   C --> D([l0op::MatrixInverse])
 *   D --> E([l0op::Cast])
 *   E --> F([l0op::ViewCopy])
 *   F --> G[(out)]
 * ```
 */

/**
 * @brief aclnnInverseworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * deviceaclTensorFLOATDOUBLECOMPLEX64COMPLEX128FLOAT16shape2
 * TensorND8
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16DOUBLEBFLOAT16COMPLEX64COMPLEX128
 * selfshapeselfshapeTensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInverseGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnInverse
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInverseGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInverse(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_INVERSE_H_// End content from: aclnn_inverse.h

// Begin content from: aclnn_unique_dim.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNIQUE_DIM_H_
#define OP_API_INC_UNIQUE_DIM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUniqueDimworkspace
 * @domain aclnn_math
 *
 * dimself
 *
 * 
 * api
 * ```mermaid
 *  graph LR
 *   A[(self)] ---> B([l0op::Contiguous])
 *   B ---> F([l0op::UniqueDim])
 *   J((sorted)) ---> F
 *   C((returnInverse)) --->F
 *   E((dim)) --->F
 *   F --> G[(valueOut)] --> F
 *   F --> H[(inverseOut)] -->F
 *   F --> I[(countsOut)] --> F
 * ```
 * @param [in]
 * selfDeviceaclTensorFLOATFLOAT16UINT8INT8UINT16INT16UINT32INT32UINT64
 *                   INT64FLOAT64 TensorND
 * @param [in] sorted: valueOut
 * @param [in] returnInverse: selfdimvalueOutTrueFalse
 * @param [in] dim: HostINT64[-self.dim(), self.dim())
 * @param [in] valueOut:
 * DeviceaclTensorFLOATFLOAT16UINT8INT8UINT16
 *                       INT16UINT32INT32UINT64INT64FLOAT64TensorND
 * @param [in] inverseOut: selfdimvalueOutINT64
 * @param [in] countsOut: valueOutselfINT64
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUniqueDimGetWorkspaceSize(const aclTensor* self, bool sorted, bool returnInverse,
                                                     int64_t dim, aclTensor* valueOut, aclTensor* inverseOut,
                                                     aclTensor* countsOut, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnUniqueDim
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnUniqueDim
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUniqueDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNIQUE_DIM_H_// End content from: aclnn_unique_dim.h

// Begin content from: aclnn_group_norm_silu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GROUP_NORM_SILU_H_
#define OP_API_INC_GROUP_NORM_SILU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupNormSiluworkspace
 * @domain aclnn_ops_infer
 *
 * GroupNormSilu
 * 
 * y=((x-Ex) / (sqrt(Var(x)+x)))  + 
 * channelgroupgroup(C//G)HW
 *
 * Silu
 * f(x) = x * sigmoid(x)
 * x0,Silux,x0,Silux,
 * ```
 *
 * @param [in] selfshape2
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * NDTensor
 * @param [in] gammashape1c
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * NDTensor
 * @param [in] betashape1c
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * NDTensor
 * @param [in] grouphostINT64,
 * @param [in] esphostdouble,le-5
 * @param [out] outy
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * ND
 * @param [out] meanOut
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * ND
 * @param [out] rstdOut1/sqrt(Var(x)+x)
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupNormSiluGetWorkspaceSize(const aclTensor* self, const aclTensor* gamma,
                                                         const aclTensor* beta, int64_t group, double eps,
                                                         aclTensor* out, aclTensor* meanOut, aclTensor* rstdOut,
                                                         uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGroupNormSilu
 */
ACLNN_API aclnnStatus aclnnGroupNormSilu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         const aclrtStream stream);

/**
 * @brief aclnnGroupNormSiluV2workspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnGroupNormSiluV2GetWorkspaceSize(const aclTensor* self, const aclTensor* gamma,
                                                           const aclTensor* beta, int64_t group, double eps,
                                                           bool activateSilu, aclTensor* out, aclTensor* meanOut,
                                                           aclTensor* rstdOut, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnGroupNormSiluV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GROUP_NORM_SILU_H_
// End content from: aclnn_group_norm_silu.h

// Begin content from: aclnn_rms_norm.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_RMS_NORM_H_
#define ACLNN_RMS_NORM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnRmsNormGetWorkspaceSize
 * parameters :
 * x : required
 * gamma : required
 * epsilon : optional
 * yOut : required
 * rstdOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnRmsNormGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *gamma,
    double epsilon,
    const aclTensor *yOut,
    const aclTensor *rstdOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnRmsNorm
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnRmsNorm(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_rms_norm.h

// Begin content from: aclnn_add_rms_norm.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_ADD_RMS_NORM_H_
#define ACLNN_ADD_RMS_NORM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnAddRmsNormGetWorkspaceSize
 * parameters :
 * x1 : required
 * x2 : required
 * gamma : required
 * epsilon : optional
 * yOut : required
 * rstdOut : required
 * xOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnAddRmsNormGetWorkspaceSize(
    const aclTensor *x1,
    const aclTensor *x2,
    const aclTensor *gamma,
    double epsilon,
    const aclTensor *yOut,
    const aclTensor *rstdOut,
    const aclTensor *xOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnAddRmsNorm
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnAddRmsNorm(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_add_rms_norm.h

// Begin content from: aclnn_moe_token_unpermute.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_TOKEN_UNPERMUTE_H_
#define ACLNN_MOE_TOKEN_UNPERMUTE_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeTokenUnpermuteGetWorkspaceSize
 * parameters :
 * permutedTokens : required
 * sortedIndices : required
 * probsOptional : optional
 * paddedMode : optional
 * restoreShapeOptional : optional
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeTokenUnpermuteGetWorkspaceSize(
    const aclTensor *permutedTokens,
    const aclTensor *sortedIndices,
    const aclTensor *probsOptional,
    bool paddedMode,
    const aclIntArray *restoreShapeOptional,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeTokenUnpermute
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeTokenUnpermute(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_token_unpermute.h

// Begin content from: aclnn_upsample_trilinear_3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UPSAMPLE_TRILINEAR_3D_BACKWARD_H_
#define OP_API_INC_UPSAMPLE_TRILINEAR_3D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleTrilinear3dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnUpsampleTrilinear3dBackwardGetWorkspaceSize(const aclTensor* gradOut,
                                                                       const aclIntArray* outputSize,
                                                                       const aclIntArray* inputSize, bool alignCorners,
                                                                       double scalesD, double scalesH, double scalesW,
                                                                       aclTensor* gradInput, uint64_t* workspaceSize,
                                                                       aclOpExecutor** executor);

/**
 * @brief aaclnnUpsampleTrilinear3dBackward
 */
ACLNN_API aclnnStatus aclnnUpsampleTrilinear3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UPSAMPLE_TRILINEAR_3D_BACKWARD_H_// End content from: aclnn_upsample_trilinear_3d_backward.h

// Begin content from: aclnn_remainder.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_REMAINDER_H_
#define OP_API_INC_LEVEL2_ACLNN_REMAINDER_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

// tensor self, tensor other
/**
 * @brief aclnnRemainderTensorTensorworkspace
 * @domain aclnn_math
 *
 *  Tensorremainder
 * @param [in] self: npu
 * deviceaclTensorselfother[](#)
 * INT32INT64FLOAT16FLOATDOUBLEshapeother[broadcast](#)[Tensor](#)
 * ND([](#))
 * @param [in] other: npu
 * deviceaclTensorselfother[](#)
 * INT32INT64FLOAT16FLOATDOUBLEshapeself[broadcast](#)[Tensor]
 * (#)ND([](#))
 * @param [in] out: npu deviceaclTensorUINT8INT8INT16INT32INT64FLOAT16FLOATDOUBLE
 * COMPLEX64COMPLEX128selfother([](#))shapeselfother
 * broadcastshape[Tensor](#)ND[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRemainderTensorTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other,
                                                                 aclTensor* out, uint64_t* workspaceSize,
                                                                 aclOpExecutor** executor);

/**
 * @brief: aclnnRemainderTensorTensor
 *
 *  Tensorremainder
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnRemainderTensorTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRemainderTensorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);

// tensor self, scalar other
/**
 * @brief aclnnRemainderTensorScalarworkspace
 * @domain aclnn_math
 *
 *  Tensorremainder
 * @param [in] self: npu deviceaclTensorselfINT32INT64FLOAT16FLOATDOUBLE
 * [Tensor](#)ND([](#))
 * @param [in] other:
 * hostaclScalarselfother[](#)
 * INT32INT64FLOAT16FLOATDOUBLEshapeself[broadcast](#)[Tensor](#)
 * ND([](#))
 * @param [in] out: npu deviceaclTensorUINT8INT8INT16INT32INT64FLOAT16FLOATDOUBLE
 * COMPLEX64COMPLEX128self[](#)shapeself[Tensor](#)
 * ND[](#)
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRemainderTensorScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other,
                                                                 aclTensor* out, uint64_t* workspaceSize,
                                                                 aclOpExecutor** executor);

/**
 * @brief: aclnnRemainderTensorScalar
 *
 *  Tensorremainder
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnRemainderTensorScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRemainderTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);

// scalar self, tensor other
/**
 * @brief aclnnRemainderScalarTensorworkspace
 * @domain aclnn_math
 *
 *  Tensorremainder
 * @param [in] self: hostaclScalarselfother
 * @param [in] other: npu
 * deviceaclTensorotherINT32INT64FLOAT16FLOATDOUBLE
 * [Tensor](#)ND([](#))
 * @param [in] out: npu
 * deviceaclTensorINT32INT64FLOAT16FLOATDOUBLEother
 * [](#)shapeother[Tensor](#)ND([](#))
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRemainderScalarTensorGetWorkspaceSize(const aclScalar* self, const aclTensor* other,
                                                                 aclTensor* out, uint64_t* workspaceSize,
                                                                 aclOpExecutor** executor);

/**
 * @brief: aclnnRemainderScalarTensor
 *
 *  Tensorremainder
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnRemainderScalarTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRemainderScalarTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);

// inplace
// tensor self, tensor other
/**
 * @brief aclnnInplaceRemainderTensorTensorworkspace
 * @domain aclnn_math
 *
 *  Tensorremainder
 * @param [in] selfRef: npu
 * deviceaclTensorselfRefother[](#)
 * INT32INT64FLOAT16FLOATDOUBLE[](#)shape
 * other[broadcast](#)shapebroadcast[Tensor](#)ND([](#))
 * @param [in] other: npu
 * deviceaclTensorselfRefother[](#)
 * INT32INT64FLOAT16FLOATDOUBLEshapeselfRef[broadcast](#)
 * [Tensor](#)ND([](#))
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRemainderTensorTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                                        uint64_t* workspaceSize,
                                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceRemainderTensorTensor
 *
 *  Tensorremainder
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace
 * aclnnInplaceRemainderTensorTensorGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRemainderTensorTensor(void* workspace, uint64_t workspaceSize,
                                                        aclOpExecutor* executor, aclrtStream stream);

// tensor self, scalar other
/**
 * @brief aclnnInplaceRemainderTensorScalarworkspace
 * @domain aclnn_math
 *
 *  Tensorremainder
 * @param [in] selfRef: npu
 * deviceaclTensorselfRefother[](#)
 * INT32INT64FLOAT16FLOATDOUBLE[](#)
 * [Tensor](#)ND([](#))
 * @param [in] other: hostaclScalarotherselfRef[](#)
 * selfRef
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRemainderTensorScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                                        uint64_t* workspaceSize,
                                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceRemainderTensorScalar
 *
 *  Tensorremainder
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace
 * aclnnInplaceRemainderTensorScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRemainderTensorScalar(void* workspace, uint64_t workspaceSize,
                                                        aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_REMAINDER_H_// End content from: aclnn_remainder.h

// Begin content from: aclnn_foreach_sqrt.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_SQRT_H_
#define ACLNN_FOREACH_SQRT_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachSqrtGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSqrtGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachSqrt
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSqrt(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sqrt.h

// Begin content from: aclnn_log2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOG2_H_
#define OP_API_INC_LOG2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLog2workspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output = log_2(self) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(Self)] -->B([Contiguous])
 *     B --> C([Cast])
 *     C -->D([Log])
 *     E[(Out)] -->F([Contiguous])
 *     F --> G([Cast])
 *     G -->D([Log])
 *     D --> H([Cast])
 *     H --> I([ViewCopy])
 *     I --> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16TensorND
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16ND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLog2GetWorkspaceSize(const aclTensor* self, const aclTensor* out, uint64_t* workspace_size,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnLog2
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLog2GetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLog2(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceLog2workspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output_i=log_2(self_i) $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(selfRef)] -->B([l0op::Contiguous])
 *     B -->D([l0op::Log])
 *     D --> I([l0op::ViewCopy])
 *     I --> J[(selfRef)]
 * ```
 *
 * @param [in] selfRef(aclTensor*): FLOATFLOAT16BFLOAT16910B
 * [Tensor](https://)NDselfRef
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLog2GetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLog2
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceLog2GetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLog2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOG2_H_// End content from: aclnn_log2.h

// Begin content from: aclnn_x_log_y_scalar_self.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_X_LOG_Y_SCALAR_SELF_H_
#define OP_API_INC_X_LOG_Y_SCALAR_SELF_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnXLogYScalarSelfworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnXLogYScalarSelfGetWorkspaceSize(const aclScalar* self, const aclTensor* other,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnXLogYScalarSelf
 */
ACLNN_API aclnnStatus aclnnXLogYScalarSelf(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_X_LOG_Y_SCALAR_SELF_H_// End content from: aclnn_x_log_y_scalar_self.h

// Begin content from: acl_stft.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACL_STFT_H_
#define OP_API_INC_LEVEL2_ACL_STFT_H_

// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclStftworkspace
 * @domain aclnn_fft
 * TensorStft
 * 
 * $$ out = Stft(input) $$
 *
 * 
 * ```mermaid
 * graph LR
 *   A[(self)]--->B([l0op::Stft])
 *   B--->C([l0op::ViewCopy])
 *   C--->D[(out)]
 * ```
 *
 * @param [in] self: Stftnpu deviceaclTensor,
 * FLOATDOUBLECOMPLEX64COMPLEX128NDTensor
 * @param [in] out: absnpu deviceaclTensor,
 * FLOATDOUBLECOMPLEX64COMPLEX128NDND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
aclnnStatus aclStftGetWorkspaceSize(const aclTensor* self, const aclTensor* windowOptional, aclTensor* out, int64_t nFft,
                                    int64_t hopLength, int64_t winLength, bool normalized, bool onesided,
                                    bool returnComplex, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclStft
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAbsGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
aclnnStatus aclStft(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACL_STFT_H_// End content from: acl_stft.h

// Begin content from: aclnn_foreach_log1p.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_LOG1P_H_
#define ACLNN_FOREACH_LOG1P_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachLog1pGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLog1pGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachLog1p
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLog1p(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_log1p.h

// Begin content from: aclnn_isclose.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ISCLOSE_H_
#define OP_API_INC_LEVEL2_ISCLOSE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIsCloseworkspace
 * @domain aclnn_math
 *
 * selfotherepsilon
 * 
 * $$ \left | input-other\right | = atol + rtol\times \left | other \right | $$
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16INT32INT64INT16INT8UINT8BOOLDOUBLE
 * TensordtypeotherdtypeshapeotherbroadcastND
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16INT32INT64INT16INT8UINT8BOOLDOUBLE
 * TensordtypeselfdtypeshapeselfbroadcastND
 * @param [in] rtol: DOUBLE
 * @param [in] atol: DOUBLE
 * @param [in] equal_nan: NaNTrueNaNBOOL
 * @param [out] out: npu
 * deviceaclTensorBOOLTensorshapeselfother
 * broadcastshapeND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsCloseGetWorkspaceSize(const aclTensor* self, const aclTensor* other, double rtol,
                                                   double atol, bool equal_nan, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnIsClose
 *
 * selfotherepsilon
 * 
 * $$ \left | input-other\right | = atol + rtol\times \left | other \right | $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnIsCloseGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsClose(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ISCLOSE_H_
// End content from: aclnn_isclose.h

// Begin content from: aclnn_foreach_minimum_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MINIMUM_LIST_H_
#define ACLNN_FOREACH_MINIMUM_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMinimumListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMinimumListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMinimumList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMinimumList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_minimum_list.h

// Begin content from: aclnn_moe_token_permute_grad.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MOE_TOKEN_PERMUTE_GRAD_H_
#define ACLNN_MOE_TOKEN_PERMUTE_GRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMoeTokenPermuteGradGetWorkspaceSize
 * parameters :
 * permutedOutputGrad : required
 * sortedIndices : required
 * numTopk : required
 * paddedMode : optional
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeTokenPermuteGradGetWorkspaceSize(
    const aclTensor *permutedOutputGrad,
    const aclTensor *sortedIndices,
    int64_t numTopk,
    bool paddedMode,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMoeTokenPermuteGrad
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMoeTokenPermuteGrad(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_moe_token_permute_grad.h

// Begin content from: aclnn_replication_pad3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REPLICATION_PAD3D_H_
#define OP_API_INC_REPLICATION_PAD3D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReplicationPad3dworkspace
 * @domain aclnn_ops_infer
 *
 * 3D
 * @param [in] self: FLOAT16, FLOAT32, DOUBLE, INT8, INT16, INT32, INT64, UINT8,
 * COMPLEX64, COMPLEX128TensorNDpad
 * @param [in] padding: INT646
 * @param [in] out: selfself
 * paddingselfpadding
 * selfpaddingTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief: aclnnReplicationPad3d
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnReplicationPad3dGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REPLICATION_PAD3D_H_// End content from: aclnn_replication_pad3d.h

// Begin content from: aclnn_swish.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_SWISH_H_
#define OP_API_INC_LEVEL2_ACLNN_SWISH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSwishworkspace
 * @domain aclnn_ops_train
 * Swish
 * @param [in] self: DeviceaclTensorinputTensorNDselfoutshape
 * @param [in] betaOptional: HostaclScalarbetaFLOAT
 * betaOptional1.0
 * @param [out] out: DeviceaclTensoroutputTensorND
 * selfoutshape
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSwishGetWorkspaceSize(const aclTensor* self, const aclScalar* betaOptional, aclTensor* out, 
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnSwish
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAcosGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSwish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_swish.h

// Begin content from: aclnn_index_put_impl.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_INDEX_PUT_H_
#define OP_API_INC_INDEX_PUT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIndexPutImplworkspace
 * @domain aclnn_ops_infer
 * @param [in] selfRef: npu deviceaclTensor
 * FLOATFLOAT16INT64INT32INT16INT8UINT8BOOLDOUBLETensorND
 * @param [in] indices: npu deviceaclTensorList
 * @param [in] values: npu deviceaclTensor
 * @param [in] accumulate: bool  Truevalue, Falsevalue
 * @param [in] unsafe: bool 
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIndexPutImplGetWorkspaceSize(aclTensor* selfRef, const aclTensorList* indices,
                                                        const aclTensor* values, const bool accumulate,
                                                        const bool unsafe, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnIndexPutImpl
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaaclnnIndexPutImplGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIndexPutImpl(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADD_H_
// End content from: aclnn_index_put_impl.h

// Begin content from: aclnn_foreach_round_off_number_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_ROUND_OFF_NUMBER_V2_H_
#define OP_API_INC_ACLNN_FOREACH_ROUND_OFF_NUMBER_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachRoundOffNumberV2workspace
 * 
 * 
 * out_i = round(x_i, roundMode)
 * @domain aclnnop_math
 * 
 * @param [in]   input
 * TensorFLOATFLOAT16BFLOAT16ND
 * @param [in]   input
 * ScalarINT8ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachRoundOffNumberV2GetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *roundMode,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachRoundOffNumberV2
 * 
 * 
 * out_i = round(x_i, roundMode)
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachRoundOffNumberV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachRoundOffNumberV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_round_off_number_v2.h

// Begin content from: aclnn_add_layer_norm.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_ADD_LAYER_NORM_H_
#define ACLNN_ADD_LAYER_NORM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnAddLayerNormGetWorkspaceSize
 * parameters :
 * x1 : required
 * x2 : required
 * gamma : required
 * beta : required
 * biasOptional : optional
 * epsilon : optional
 * additionalOutput : optional
 * yOut : required
 * meanOut : required
 * rstdOut : required
 * xOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnAddLayerNormGetWorkspaceSize(
    const aclTensor *x1,
    const aclTensor *x2,
    const aclTensor *gamma,
    const aclTensor *beta,
    const aclTensor *biasOptional,
    double epsilon,
    bool additionalOutput,
    const aclTensor *yOut,
    const aclTensor *meanOut,
    const aclTensor *rstdOut,
    const aclTensor *xOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnAddLayerNorm
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnAddLayerNorm(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_add_layer_norm.h

// Begin content from: aclnn_incre_flash_attention_v3.h
/**
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef ACLNN_INCRE_FLASH_ATTENTION_V3_H_
#define ACLNN_INCRE_FLASH_ATTENTION_V3_H_

// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIncreFlashAttentionV3workspace
 * @domain aclnn_ops_infer
 * funtion: aclnnIncreFlashAttentionV3GetWorkspaceSize
 * @param [in] query : required
 * @param [in] key : dynamic
 * @param [in] value : dynamic
 * @param [in] pseShift : optional
 * @param [in] attenMask : optional
 * @param [in] actualSeqLengths : optional
 * @param [in] dequantScale1 : optional
 * @param [in] quantScale1 : optional
 * @param [in] dequantScale2 : optional
 * @param [in] quantScale2 : optional
 * @param [in] quantOffset2 : optional
 * @param [in] antiquantScale : optional
 * @param [in] antiquantOffset : optional
 * @param [in] blocktable : optional
 * @param [in] numHeads : required
 * @param [in] scaleValue : optional
 * @param [in] inputLayout : optional
 * @param [in] numKeyValueHeads : optional
 * @param [in] blockSize : optional
 * @param [in] innerPrecise : optional
 * @param [out] attentionOut : required
 * @param [out] workspaceSize : size of workspace(output).
 * @param [out] executor : executor context(output).
 * @return aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnIncreFlashAttentionV3GetWorkspaceSize(
    const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShift,
    const aclTensor *attenMask, const aclIntArray *actualSeqLengths, const aclTensor *dequantScale1,
    const aclTensor *quantScale1, const aclTensor *dequantScale2, const aclTensor *quantScale2,
    const aclTensor *quantOffset2, const aclTensor *antiquantScale, const aclTensor *antiquantOffset,
    const aclTensor *blocktable, int64_t numHeads, double scaleValue, char *inputLayout, int64_t numKeyValueHeads,
    int64_t blockSize, int64_t innerPrecise, const aclTensor *attentionOut, uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * funtion: aclnnIncreFlashAttentionV3
 * @param [in] workspace : workspace memory addr(input).
 * @param [in] workspaceSize : size of workspace(input).
 * @param [in] executor : executor context(input).
 * @param [in] stream : acl stream.
 * @return aclnnStatus: 
 */
__attribute__((visibility("default"))) aclnnStatus aclnnIncreFlashAttentionV3(void *workspace, uint64_t workspaceSize,
                                                                              aclOpExecutor *executor,
                                                                              const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_incre_flash_attention_v3.h

// Begin content from: aclnn_batch_matmul_reduce_scatter_all_to_all.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023-2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BATCH_MATMUL_REDUCE_SCATTER_ALL_TO_ALL_
#define OP_API_INC_BATCH_MATMUL_REDUCE_SCATTER_ALL_TO_ALL_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * bmm + reduceScatter + alltoall 
 * @brief aclnnBatchMatMulReduceScatterAlltoAllworkspace
 * @domain aclnn_ops_infer
 * @param [in] x: Tensorfloat16bfloat163BatchMatMul
 * @param [in] weight: Tensorfloat16, bfloat163xBatchMatMul
 * @param [in] biasOptional: Tensorfloat16, float32xfloat16biasfloat16xbfloat16biasfloat32BatchMatMulbias(ReduceScatterAdd)
 * @param [in] groupEp: strep
 * @param [in] groupTp: strtpTensor
 * @param [in] epWorldSize: intepsize2/4/8/16
 * @param [in] tpWorldSize: inttpsize2/4/8/16
 * @param [in] yShardType: int00Htp1Ctpshard_type1
 * @param [out] out: Tensorfloat16, bfloat163x
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 * BatchMatMulshapeep=epWorldSizetp=tpWorldSize HReduceScattershard_type0
 * x: (E/ep, ep * C, M/tp)
 * weight(E/ep, M/tp, H)
 * bias(E/ep, 1, H/tp) (E/ep, H/tp)
 * y(E, C, H/tp)
 * CReduceScattershard_type1
 * x: (E/ep, ep * tp * C/tp, M/tp)
 * weight(E/ep, M/tp, H)
 * bias(E/ep, 1, H) (E/ep, H)
 * y(E, C/tp, H)
 * 
 * x.size(0)E/tpy.size(0)Ey.size(0) = ep * x.size(0)y.size(0)ep
 * E[2, 512]Eep
 * H[1, 65535]
 * M/tp[1, 65535]
 * E/ep[1, 32]
 * eptp24816
 * groupEpgroupTp
 * C0device
 * epAlltoAlltpReduceScatter
 */
ACLNN_API aclnnStatus aclnnBatchMatMulReduceScatterAlltoAllGetWorkspaceSize(const aclTensor* x, const aclTensor* weight,
                                                                            const aclTensor* biasOptional,
                                                                            const char* groupEp, const char* groupTp,
                                                                            int64_t epWorldSize, int64_t tpWorldSize,
                                                                            int64_t yShardType, aclTensor* out,
                                                                            uint64_t* workspaceSize,
                                                                            aclOpExecutor** executor);

/**
 * @brief aclnnBatchMatMulReduceScatterAlltoAll
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnBatchMatMulReduceScatterAlltoAllGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnBatchMatMulReduceScatterAlltoAll(void* workspace, uint64_t workspaceSize,
                                                            aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BATCH_MATMUL_REDUCE_SCATTER_ALL_TO_ALL_// End content from: aclnn_batch_matmul_reduce_scatter_all_to_all.h

// Begin content from: aclnn_foreach_mul_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_MUL_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_MUL_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachMulScalarV2workspace
 * scalar
 * 
 * out_{i}=x_{i}*scalar
 * @domain aclnnop_math
 * 
 * @param [in]   x
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [in]   scalar
 * ScalarFLOATFLOAT16INT32ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachMulScalarV2GetWorkspaceSize(
    const aclTensorList *x,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachMulScalarV2
 * scalar
 * 
 * out_{i}=x_{i}*scalar
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachMulScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachMulScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_mul_scalar_v2.h

// Begin content from: aclnn_upsample_nearest_exact1d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef ACLNN_UPSAMPLE_NEAREST_EXACT1D_BACKWARD_H_
#define ACLNN_UPSAMPLE_NEAREST_EXACT1D_BACKWARD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearesrExact1dBackwardworkspace
 * @domain aclnn_ops_train
 * aclnnUpsampleNearesrExact1d
 *
 * @param [in] gradOutput: DeviceaclTensorFLOATFLOAT16BFLOAT16
 * TensorNCHWshapeTensorout
 * @param [in] outputSize: HostaclIntArrayINT64size2gradOutputHW
 * @param [in] inputSize: HostaclIntArrayINT64size4outNCHW
 * @param [in] scales: Hostout
 * @param [out] out: DeviceaclTensorFLOATFLOAT16BFLOAT16
 * TensorNCHWshapeTensorgradOutput
 * @param [out] workspaceSize: Deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
__attribute__((visibility("default")))
aclnnStatus aclnnUpsampleNearestExact1dBackwardGetWorkspaceSize(
    const aclTensor *gradOutput, const aclIntArray *outputSize, const aclIntArray *inputSize,  
    double scales, aclTensor *out, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnUpsampleNearestExact1dBackward
 * 
 * aclnnUpsampleNearestExact1d
 *
 * @param [in] workspace: Deviceworkspace
 * @param [in] workspaceSize: Deviceworkspace
 * aclnnUpsampleNearestExact1dBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: AscendCL Stream
 * @return aclnnStatus: 
 */
__attribute__((visibility("default")))
aclnnStatus aclnnUpsampleNearestExact1dBackward(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                              aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_upsample_nearest_exact1d_backward.h

// Begin content from: aclnn_avgpool3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_AVGPOOL3D_H_
#define OP_API_INC_AVGPOOL3D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAvgPool3dworkspace
 * @domain aclnn_ops_infer
 *
 * self
 *
 * @param [in] self: npu
 * deviceaclTensortensorFLOAT16BFLOAT16FLOAT45TensorND
 * @param [in] kernelSize: npu
 * deviceaclIntArray1(kD=kH=kW)3(kD,kH,kW)INT32INT640
 * @param [in] stride: npu
 * deviceaclIntArray0(kernelSize)1(sD=sH=sW)3(sD,sH,sW)
 * INT32INT640
 * @param [in] padding: npu
 * deviceaclIntArray1(padD=padH=padW)3(padD,padH,padW)DHWpadding0
 * INT32INT64[0, kernelSize/2]
 * @param [in] ceilMode: BOOLshapeFalse
 * @param [in] countIncludePad: BOOLTrue
 * @param [in] divisorOverride: INT640
 * @param [out] output: npu
 * deviceaclTensorTensorFLOAT16BFLOAT16FLOAT45TensorND
 * self
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAvgPool3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize,
                                                     const aclIntArray* stride, const aclIntArray* padding,
                                                     bool ceilMode, bool countIncludePad,
                                                     int64_t divisorOverride, aclTensor* out,
                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAvgPool3d
 *
 *  self
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAtan2GetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAvgPool3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AVGPOOL3D_H_
// End content from: aclnn_avgpool3d.h

// Begin content from: aclnn_cat.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CAT_H_
#define OP_API_INC_CAT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAdaptiveAvgPool2dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnCatGetWorkspaceSize(const aclTensorList* tensors, int64_t dim, aclTensor* out,
                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnCat
 */
ACLNN_API aclnnStatus aclnnCat(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                               const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CAT_H_
// End content from: aclnn_cat.h

// Begin content from: aclnn_asin.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ASIN_H_
#define OP_API_INC_ASIN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAsinworkspace
 * @domain aclnn_math
 * 
 * 
 * out_{i}=sin^{-1}(input_{i})
 * 
 * @param [in]   input
 * TensorINT8INT16INT32INT64UINT8BOOLFLOATBFLOAT16,
 * FLOAT16DOUBLETensorND
 * @param [in]   out
 * TensorFLOATBFLOAT16, FLOAT16DOUBLETensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnAsinGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnAsin
 * 
 * 
 * out_{i}=sin^{-1}(input_{i})
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B --> C([l0op::Asin])
    C --> G([l0op::Cast])
    G --> E([l0op::ViewCopy])
    E --> S[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAsinGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAsin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceAsinworkspace
 * @domain aclnn_math
 * 
 * 
 * out_{i}=sin^{-1}(input_{i})
 * 
 * @param [in]   input
 * TensorFLOATFLOAT16DOUBLETensorND
 * @param [in]   out
 * TensorFLOATFLOAT16DOUBLETensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceAsinGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size,
                                                       aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceAsin
 *
 *  Tensorasin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAsinGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAsin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_asin.h

// Begin content from: aclnn_fill_diagonal.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ADD_H_
#define OP_API_INC_ADD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceFillDiagonalworkspace
 * @domain aclnn_ops_infer
 *
 * fillValuetensor
 *
 * @param [in] selfRef: npu deviceaclTensorselfRefFLOATFLOAT16INT32INT64
 * [Tensor](#Tensor)ND[](#)
 * @param [in] fillValue:
 * hostaclScalarfillValueFLOATFLOAT16DOUBLEUINT8INT8INT16INT32 INT64BOOL
 * @param [in] wrap: wrapBOOL`min(col, row)`Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFillDiagonalGetWorkspaceSize(aclTensor* selfRef, const aclScalar* fillValue,
                                                               bool wrap, uint64_t* workspaceSize,
                                                               aclOpExecutor** executor);

/**
 * @brief aclnnInplaceFillDiagonal
 *
 * fillValuetensor
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceFillDiagonalGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFillDiagonal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADD_H_
// End content from: aclnn_fill_diagonal.h

// Begin content from: aclnn_exp.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_EXP_H_
#define OP_API_INC_LEVEL2_ACLNN_EXP_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * 
 * 
 * $$
 *     out_{i} = e^{self_{i}}
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([l0op::Contiguous])
 *     B --> C([l0op::Exp])
 *     C --> D([l0op::Cast])
 *     D --> E([l0op::ViewCopy])
 *     E --> F[(out)]
 * ```
 */

/**
 * @brief aclnnExpworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLECOMPLEX64COMPLEX128BOOL
 * TensorND8
 * @param [in] out: npu
 * deviceaclTensorselfshapeselfTensor
 * ND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnExpGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnExp
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnExpGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnExp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceExpworkspace
 * @domain aclnn_math
 * @param [in] selfRef: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLECOMPLEX64COMPLEX128
 * TensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceExpGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnInplaceExp
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceExpGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceExp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_EXP_H_
// End content from: aclnn_exp.h

// Begin content from: aclnn_multi_scale_deformable_attention_grad.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MULTI_SCALE_DEFORMABLE_ATTENTION_GRAD_H_
#define OP_API_INC_MULTI_SCALE_DEFORMABLE_ATTENTION_GRAD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMultiScaleDeformableAttentionGradworkspace
 * @domain aclnn_ops_train
 * @param [in] value:
 * DeviceaclTensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in] spatialShape:
 * DeviceaclTensorINT32INT64TensorND
 * @param [in] levelStartIndex:
 * DeviceaclTensorINT32INT64TensorND
 * @param [in] location:
 * DeviceaclTensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in] attnWeight:
 * DeviceaclTensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in] gradOutput:
 * DeviceaclTensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in] gradValue:
 * DeviceaclTensorvalueFLOATFLOAT16BFLOAT16TensorND
 * @param [in] gradLocation:
 * DeviceaclTensorlocationFLOATFLOAT16BFLOAT16TensorND
 * @param [in] gradAttnWeight:
 * DeviceaclTensorattnWeightFLOATFLOAT16BFLOAT16TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMultiScaleDeformableAttentionGradGetWorkspaceSize(
    const aclTensor* value, const aclTensor* spatialShape, const aclTensor* levelStartIndex, const aclTensor* location,
    const aclTensor* attnWeight, const aclTensor* gradOutput, aclTensor* gradValue, aclTensor* gradLocation,
    aclTensor* gradAttnWeight, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMultiScaleDeformableAttentionGrad
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceMishGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMultiScaleDeformableAttentionGrad(void* workspace, uint64_t workspaceSize,
                                                             aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MULTI_SCALE_DEFORMABLE_ATTENTION_GRAD_H_
// End content from: aclnn_multi_scale_deformable_attention_grad.h

// Begin content from: aclnn_upsample_trilinear_3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UPSAMPLE_TRILINEAR_3D_H_
#define OP_API_INC_UPSAMPLE_TRILINEAR_3D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleTrilinear3dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleTrilinear3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                               bool alignCorners, double scalesD, double scalesH,
                                                               double scalesW, aclTensor* out, uint64_t* workspaceSize,
                                                               aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleTrilinear3d
 */
ACLNN_API aclnnStatus aclnnUpsampleTrilinear3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UPSAMPLE_TRILINEAR_3D_H_// End content from: aclnn_upsample_trilinear_3d.h

// Begin content from: aclnn_masked_select.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MASKED_SELECT_H_
#define OP_API_INC_MASKED_SELECT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaskedSelectworkspace
 * @domain aclnn_ops_infer
 *
 * maskself,
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * shapemask[broadcast]()[Tensor]()ND.
 * @param [in] mask: npu
 * deviceaclTensorbooluint8uint801shapeself[broadcast]()
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaskedSelectGetWorkspaceSize(const aclTensor* self, const aclTensor* mask, aclTensor* out,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnMaskedSelect
 *
 *  Tensor self maskmask
 * Tensor  api
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMaskedSelect(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MASKED_SELECT_H_
// End content from: aclnn_masked_select.h

// Begin content from: aclnn_inplace_weight_quant_matmul_all_reduce_add_rms_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_inplace_weight_quant_matmul_all_reduce_add_rms_norm.h
 * \brief
 */
#ifndef OP_API_INC_INPLACE_WEIGHT_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_
#define OP_API_INC_INPLACE_WEIGHT_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceWeightQuantMatmulAllReduceAddRmsNormworkspace
 * @domain aclnn_ops_infer
 * MatmulAllReduce+AddRmsNorm
 * @param [in] x1: matmulfloat16, bfloat16
 * @param [in] x2: matmulint8,int4
 * @param [in] bias: float16, bfloat16
 * @param [in] antiquantScale: x2float16, bfloat16
 * @param [in] antiquantOffset: x2float16, bfloat16
 * @param [in] residual: float16, bf16MatmulAllReduce+Add(residual)
 * @param [in] gamma: RmsNormfloat16, bfloat16
 * @param [in] epsilon: 0double
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [in] antiquantGroupSize: per_groupgroupSize
 * @param [out] normOut: MatmulAllReduce+AddRmsNorm
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnInplaceWeightQuantMatmulAllReduceAddRmsNormGetWorkspaceSize(
    const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const aclTensor* antiquantScale,
    const aclTensor* antiquantOffset, const aclTensor* residual, const aclTensor* gamma, double epsilon,
    const char* group, const char* reduceOp, int64_t commTurn, int64_t streamMode, int64_t antiquantGroupSize,
    const aclTensor* normOut, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceWeightQuantMatmulAllReduceAddRmsNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspace
 *                             aclnnInplaceWeightQuantMatmulAllReduceAddRmsNormGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceWeightQuantMatmulAllReduceAddRmsNorm(void* workspace, uint64_t workspaceSize,
                                                                       aclOpExecutor* executor,
                                                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_INPLACE_WEIGHT_QUANT_MATMUL_ALL_REDUCE_ADD_RMS_NORM_// End content from: aclnn_inplace_weight_quant_matmul_all_reduce_add_rms_norm.h

// Begin content from: aclnn_foreach_add_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADD_SCALAR_LIST_H_
#define ACLNN_FOREACH_ADD_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddScalarListGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddScalarListGetWorkspaceSize(
    const aclTensorList *x,
    const aclScalarList *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_add_scalar_list.h

// Begin content from: aclnn_neg.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_NEG_H_
#define OP_API_INC_NEG_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNegworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ output=(-1) * self $$
 *
 * 
 * api
 * ```mermaid
 *  graph LR
 *      A[(self)] -->B([Contiguous])
 *      B -->D([Neg])
 *      D-->E([Cast])
 *      E-->F([ViewCopy])
 *      F-->G[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensorTensorND
 * @param [in] out: npu deviceaclTensorNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNegGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnInplaceNegworkspace
 * @domain aclnn_math
 *
 * 
 * 
 * $$ selfRef =(-1) * selfRef $$
 *
 * @param [in] selfRef: npu deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNegGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnNeg
 *
 * 
 * 
 * $$ output_i = self_i+alpha*other_i $$
 *
 * 
 * api
 * ```mermaid
 *  graph LR
 *      A[(self)] -->B([Contiguous])
 *      B -->D([Neg])
 *      D-->E([Cast])
 *      E-->F([ViewCopy])
 *      F-->G[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnNegGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnNeg(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                               const aclrtStream stream);

/**
 * @brief aclnnInplaceNeg
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceNegGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceNeg(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif /* OP_API_INC_NEG_H_ */// End content from: aclnn_neg.h

// Begin content from: aclnn_s_where.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SWHERE_H_
#define OP_API_INC_SWHERE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSWhereworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnSWhereGetWorkspaceSize(const aclTensor* condition, const aclTensor* self,
                                                  const aclTensor* other, aclTensor* out, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnSWhere
 */
ACLNN_API aclnnStatus aclnnSWhere(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SWHERE_H_
// End content from: aclnn_s_where.h

// Begin content from: aclnn_cos.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_COS_H_
#define OP_API_INC_COS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCosworkspace
 * @domain aclnn_math
 * 
 * 
 * out_{i}=cos(input_{i})
 * 
 * @param [in]   input
 * TensorFLOATFLOAT16DOUBLE, COMPLEX64, COMPLEX128TensorND
 * @param [in]   out
 * TensorFLOATFLOAT16DOUBLE, COMPLEX64, COMPLEX128TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnCosGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);
/**
 * @brief aclnnCos
 * 
 * 
 * out_{i}=cos(input_{i})
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B --> C([l0op::Cos])
    C --> G([l0op::Cast])
    G --> E([l0op::ViewCopy])
    E --> S[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCos(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                               const aclrtStream stream);

/**
 * @brief aclnnInplaceCosworkspace
 * @domain aclnn_math
 * 
 * 
 * out_{i}=tan^{-1}(input_{i})
 * 
 * @param [in]   input
 * TensorINT8INT16INT32INT64UINT8BOOLFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128TensorND
 * @param [in]   out
 * TensorFLOATFLOAT16DOUBLETensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceCosGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceCos
 *
 *  Tensorcos
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCosGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceCos(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_cos.h

// Begin content from: aclnn_foreach_addcdiv_scalar_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACLNN_FOREACH_ADDCDIV_SCALAR_V2_H_
#define OP_API_INC_ACLNN_FOREACH_ADDCDIV_SCALAR_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnForeachAddcdivScalarV2workspace
 * 
 * 
 * out_i = {x}_{1i}+ \frac{{x}_{2i}}{{x}_{3i}}\times{scalar}
 * @domain aclnnop_math
 * 
 * @param [in]   input
 * TensorFLOATFLOAT16BFLOAT16ND
  * @param [in]   input
 * TensorFLOATFLOAT16BFLOAT16ND
  * @param [in]   input
 * TensorFLOATFLOAT16BFLOAT16ND
  * @param [in]  input
 * ScalarFLOATFLOAT16ND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16INT32ND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnForeachAddcdivScalarV2GetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *x3,
    const aclScalar *scalar,
    aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnForeachAddcdivScalarV2
 * 
 * 
 * out_i = {x}_{1i}+ \frac{{x}_{2i}}{{x}_{3i}}\times{scalar}
 * @domain aclnnop_math
 * 
 * param [in] workspace: npu deviceworkspace
 * param [in] workspaceSize: npu deviceworkspaceaclnnForeachAddcdivScalarV2GetWorkspaceSize
 * param [in] stream: acl stream
 * param [in] executor: op
 * return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnForeachAddcdivScalarV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_addcdiv_scalar_v2.h

// Begin content from: aclnn_gemm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GEMM_H_
#define OP_API_INC_GEMM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGemmworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnGemmGetWorkspaceSize(const aclTensor* A, const aclTensor* B, const aclTensor* C, float alpha,
                                                float beta, int64_t transA, int64_t transB, aclTensor* out,
                                                int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGemm
 */
ACLNN_API aclnnStatus aclnnGemm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GEMM_H_
// End content from: aclnn_gemm.h

// Begin content from: aclnn_reflection_pad3d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REFLECTION_PAD3D_H_
#define OP_API_INC_REFLECTION_PAD3D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReflectionPad3dworkspace
 * @domain aclnn_ops_infer
 *
 * 3D
 * @param [in] self: BFLOAT16,FLOAT16, FLOAT32, DOUBLE, INT8, INT16, INT32, INT64, UINT8, BOOL
 * TensorNDpad
 * @param [in] padding:
 * INT646self
 * selfself
 * @param [in] out:
 * selfoutselfpadding
 * outselfpaddingoutselfpadding
 * Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief: aclnnReflectionPad3d
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnReflectionPad3dGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REFLECTION_PAD3D_H_// End content from: aclnn_reflection_pad3d.h

// Begin content from: aclnn_matmul_all_reduce_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MATMUL_ALL_REDUCE_V2_
#define OP_API_INC_MATMUL_ALL_REDUCE_V2_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMatmulAllReduceV2workspace
 * @domain aclnn_ops_infer
 * mm+AllReduce
 * @param [in] x1: matmulfloat16, bf16
 * @param [in] x2: matmulint8
 * @param [in] bias: float16, bf16
 * @param [in] x3: addfloat16, bf16
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl0/1
 * @param [out] output: +
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMatmulAllReduceV2GetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                             const aclTensor* bias, const aclTensor* x3,
                                                             const char* group, const char* reduceOp, int64_t commTurn,
                                                             int64_t streamMode, const aclTensor* output,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMatmulAllReduceV2
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnMatmulAllReduceV2GetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMatmulAllReduceV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MATMUL_ALL_REDUCE_V2_// End content from: aclnn_matmul_all_reduce_v2.h

// Begin content from: aclnn_mse_loss_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MSE_LOSS_BACKWARD_H_
#define OP_API_INC_MSE_LOSS_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMseLossBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 *
 * @param [in] gradOutputnpu
 * deviceaclTensorFLOATBFLOAT16FLOAT16selfshapeselftarget
 * broadcastTensorND
 * @param [in] selfnpu deviceaclTensorFLOATBFLOAT16FLOAT16shapegradOutputtarget
 * broadcastTensorND
 * @param [in] targetnpu
 * deviceaclTensorFLOATBFLOAT16FLOAT16selfshapegradOutputself
 * broadcastTensorND
 * @param [in] reductionhostint64 0('none') | 1('mean') | 2('sum')'none'
 *  'mean' 'sum' 
 * @param [in] outnpu deviceaclTensorFLOATBFLOAT16FLOAT16shapetargetselfgradOutput
 * broadcastshape TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMseLossBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                           const aclTensor* target, int64_t reduction, aclTensor* out,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMseLossBackward
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnMseLossBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMseLossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MSE_LOSS_BACKWARD_H_
// End content from: aclnn_mse_loss_backward.h

// Begin content from: aclnn_expand.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_EXPAND_H_
#define OP_API_INC_EXPAND_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnExpandworkspace
 * @domain aclnn_ops_infer
 *
 * selfsize
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] --> B([l0op::Contiguous]) --> C([l0op::Expand])
 *     D((size)) --> E([sizeTensor]) --> C
 *     C --> F([l0op::ViewCopy]) --> Out[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorBFLOAT16FLOAT16FLOATUINT8INT8INT32INT64BOOLTensorND
 * @param [in] size: aclIntArrayINT
 * @param [in] out: npu
 * deviceaclTensorBFLOAT16FLOAT16FLOATUINT8INT8INT32INT64BOOLself
 * [Tensor](#)ND[](#)shapeselfshapsize
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnExpandGetWorkspaceSize(const aclTensor* self, const aclIntArray* size, aclTensor* out,
                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnExpand
 *
 * selfsize
 *
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] --> B([l0op::Contiguous]) --> C([l0op::Expand])
 *     D((size)) --> E([sizeTensor]) --> C
 *     C --> F([l0op::ViewCopy]) --> Out[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnExpandGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnExpand(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_EXPAND_H_// End content from: aclnn_expand.h

// Begin content from: aclnn_bidirection_lstmv2.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_BIDIRECTION_LSTMV2_H_
#define ACLNN_BIDIRECTION_LSTMV2_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnBidirectionLSTMV2GetWorkspaceSize
 * parameters :
 * x : required
 * initH : required
 * initC : required
 * wIh : required
 * wHh : required
 * bIhOptional : optional
 * bHhOptional : optional
 * wIhReverseOptional : optional
 * wHhReverseOptional : optional
 * bIhReverseOptional : optional
 * bHhReverseOptional : optional
 * batchSizeOptional : optional
 * numLayers : optional
 * isbias : optional
 * batchFirst : optional
 * bidirection : optional
 * packed : optional
 * yOut : required
 * outputHOut : required
 * outputCOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnBidirectionLSTMV2GetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *initH,
    const aclTensor *initC,
    const aclTensor *wIh,
    const aclTensor *wHh,
    const aclTensor *bIhOptional,
    const aclTensor *bHhOptional,
    const aclTensor *wIhReverseOptional,
    const aclTensor *wHhReverseOptional,
    const aclTensor *bIhReverseOptional,
    const aclTensor *bHhReverseOptional,
    const aclTensor *batchSizeOptional,
    int64_t numLayers,
    bool isbias,
    bool batchFirst,
    bool bidirection,
    bool packed,
    const aclTensor *yOut,
    const aclTensor *outputHOut,
    const aclTensor *outputCOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnBidirectionLSTMV2
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnBidirectionLSTMV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_bidirection_lstmv2.h

// Begin content from: aclnn_foreach_round_off_number.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ROUND_OFF_NUMBER_H_
#define ACLNN_FOREACH_ROUND_OFF_NUMBER_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachRoundOffNumberGetWorkspaceSize
 * parameters :
 * x : dynamic
 * roundMode : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachRoundOffNumberGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensor *roundMode,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachRoundOffNumber
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachRoundOffNumber(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_round_off_number.h

// Begin content from: aclnn_embedding_renorm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_EMBEDDING_RENORM_H_
#define OP_API_INC_EMBEDDING_RENORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnEmbeddingRenormworkspace
 * @domain aclnn_ops_infer
 *
 * max_normnorm_typetensorindices
 *
 * 
 * nnorm_type
 * $$ ||X||_{p}=\sqrt[p]{\sum_{i=1}^nx_{i}^p} $$
 * $$ X = (x_{1},x_{2}, ... , x_{n}) $$
 * max_normindices0
 * $$ scaler = \frac{max\_norm}{current\_norm + 1e^{-7}} $$
 *
 * 
 * api
 *```mermaid
 * graph LR
 * A[(selfRef)]  --> B([l0op::contiguous])
 * B --> C([l0op::GatherV2])
 * D((axis=0)) --> C
 * E[(Indices)] --> F([l0op::contiguous])
 * F --> R([l0op::Reshape])
 * R --> C
 * C --> G([l0op::Renorm])
 * H((maxNorm)) --> G
 * I((normType)) --> G
 * J((dim=0)) --> G
 * U[(indicesGatherV2)] --> V([l0op::Contiguous])
 * V --> K([l0op::GatherV2])
 * L((axis=0)) --> K
 * G --> K
 * C --> M([l0op::Mul])
 * K --> M
 * B --> N([l0op::ScatterUpdate])
 * M --> N
 * R --> N
 * N --> O([l0op::ViewCopy])
 * O --> P[(selfRef)]
 * ```
 *
 * @param [in] selfRef: npu
 * deviceaclTensorBFLOAT16FLOAT16FLOAT32
 * TensorNDdimension2
 * @param [in] indices: npu
 * deviceaclTensorINT64
 * TensorND
 * @param [in] maxNorm: doublefloat
 * @param [in] normType: doublefloat
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEmbeddingRenormGetWorkspaceSize(aclTensor* selfRef, const aclTensor* indices, double maxNorm,
                                                           double normType, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnEmbeddingRenorm
 *
 * max_normnorm_typetensorindices
 *
 * 
 * nnorm_type
 * $$ ||X||_{p}=\sqrt[p]{\sum_{i=1}^nx_{i}^p} $$
 * $$ X = (x_{1},x_{2}, ... , x_{n}) $$
 * max_normindices0
 * $$ scaler = \frac{max\_norm}{current\_norm + 1e^{-7}} $$
 *
 * 
 * api
 *```mermaid
 * graph LR
 * A[(selfRef)]  --> B([l0op::contiguous])
 * B --> C([l0op::GatherV2])
 * D[(axis=0)] --> C
 * E[(Indices)] --> F([l0op::contiguous])
 * F --> C
 * C --> G([l0op::Renorm])
 * H((maxNorm)) --> G
 * I((normType)) --> G
 * J((dim=0)) --> G
 * F --> K([l0op::GatherV2])
 * L[(axis=0)] --> K
 * G --> K
 * C --> M([l0op::Mul])
 * K --> M
 * B --> N([l0op::ScatterUpdate])
 * M --> N
 * F --> N
 * N --> O([l0op::ViewCopy])
 * O --> P[(selfRef)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEmbeddingRenorm(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                           const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_EMBEDDING_RENORM_H_
// End content from: aclnn_embedding_renorm.h

// Begin content from: aclnn_slogdet.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SLOGDET_H_
#define OP_API_INC_SLOGDET_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSlogdetworkspace.
 * @domain aclnn_math
 *
 *  Tensor
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(self)]-->B([Contiguous])-->C([LogMatrixDeterminant])
 * D1([Cast])-->E1([ViewCopy])-->F1([signOut])
 * D2([Cast])-->E2([ViewCopy])-->F2([logOut])
 * ```
 *
 * @param [in] self: npu deviceaclTensor, FLOATDOUBLECOMPLEX64COMPLEX128. shape(*, n, n),
 * `*`0batch. Tensor. ND.
 * @param [in] signOut: npu deviceaclTensor, FLOATDOUBLECOMPLEX64COMPLEX128.
 * shapeselfbatch. Tensor. ND.
 * @param [in] logOut: npu deviceaclTensor, FLOATDOUBLECOMPLEX64COMPLEX128.
 * shapeselfbatch. Tensor. ND.
 * @param [out] workspaceSize: npu deviceworkspace.
 * @param [out] executor: op.
 * @return aclnnStatus:  ACLNN_SUCCESS, .
 */
ACLNN_API aclnnStatus aclnnSlogdetGetWorkspaceSize(const aclTensor* self, aclTensor* signOut, aclTensor* logOut,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnSlogdet.
 *
 * 
 * @param [in] workspace: npu deviceworkspace.
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSlogdetGetWorkspaceSize.
 * @param [in] executor: op.
 * @param [in] stream: acl stream.
 * @return aclnnStatus: .
 */
ACLNN_API aclnnStatus aclnnSlogdet(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SLOGDET_H_
// End content from: aclnn_slogdet.h

// Begin content from: aclnn_gelu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GELU_H_
#define OP_API_INC_LEVEL2_ACLNN_GELU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGeluworkspace
 * @domain aclnn_ops_infer
 * 
 * 
 * $$ out_{i}=Gelu(self_{i})=self_{i}(self_{i}) $$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(Self)]  --> B{l0op::Contiguous}
 *     B -->C([l0op::Gelu])
 *     C --> D{l0op::ViewCopy}
 *     D --> E[(out)]
 * ```
 *
 * @param [in] self: gelunpu deviceaclTensor
 * FLOAT16FLOAT32BFLOAT16outNDshapeoutTensor
 * @param [in] out: gelu
 * npu
 * deviceaclTensorFLOAT16FLOAT32BFLOAT16selfNDshapeself
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeluGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnGelu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGeluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GELU_H_// End content from: aclnn_gelu.h

// Begin content from: aclnn_quant_matmul_v4.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_QUANT_MATMUL_V4
#define OP_API_INC_QUANT_MATMUL_V4

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQuantMatmulV4workspace
 * @domain aclnn_ops_infer
 * aclnnQuantBatchMatmulV3, pertokenScaleOptional
 * @param [in] x1: matmulint8, int4, int32
 * @param [in] x2: matmulint8, int4, int32
 * @param [in] scale: uint64_t, float32, bfloat16, int64_t
 * @param [in] offset: float32
 * @param [in] pertokenScaleOptional: float32
 * @param [in] bias: int32_t, bfloat16, float16, float32
 * @param [in] transposeX1: afalse
 * @param [in] transposeX2: bfalse
 * @param [out] out: half, int8, bfloat16
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulV4GetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                         const aclTensor* scale, const aclTensor* offset,
                                                         const aclTensor* pertokenScaleOptional, const aclTensor* bias,
                                                         bool transposeX1, bool transposeX2, const aclTensor* out,
                                                         uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnQuantMatmulV4
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnQuantMatmulV4GetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulV4(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QUANT_MATMUL_V4// End content from: aclnn_quant_matmul_v4.h

// Begin content from: aclnn_sin.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SIN_H_
#define OP_API_INC_SIN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSinworkspace
 * @domain aclnn_math
 *
 *  Tensorsin
 * @param [in] selfRef: npu deviceaclTensor, INT8INT16INT32, INT64, UINT8BOOLFLOATFLOAT16
 *  DOUBLECOMPLEX64COMPLEX128shapeTensorND
 * @param [in] out: npu deviceaclTensor, FLOATFLOAT16DOUBLECOMPLEX64COMPLEX128, shapeself
 *  ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSinGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief: aclnnSin
 *
 *  Tensorsin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSinGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceSinworkspace
 * @domain aclnn_math
 *
 *  Tensorsin
 * @param [in] selfRef: npu deviceaclTensor, INT8INT16INT32, INT64, UINT8BOOLFLOAT
 *  FLOAT16DOUBLECOMPLEX64COMPLEX128shapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSinGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size,
                                                      aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceSin
 *
 *  Tensorsin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSinGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SIN_H_// End content from: aclnn_sin.h

// Begin content from: aclnn_acos.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ACOS_H_
#define OP_API_INC_ACOS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAcosworkspace
 * @domain aclnn_math
 * 
 * 
 * out_{i}=cos^{-1}(input_{i})
 * 
 * @param [in]   input
 * TensorINT8INT16INT32INT64UINT8BOOLFLOATFLOAT16BFLOAT16DOUBLETensorND
 * @param [in]   out
 * TensorFLOATFLOAT16BFLOAT16DOUBLETensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnAcosGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnAcos
 * 
 * 
 * out_{i}=cos^{-1}(input_{i})
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B --> C([l0op::Acos])
    C --> G([l0op::Cast])
    G --> E([l0op::ViewCopy])
    E --> S[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAcos(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceAcosworkspace
 * @domain aclnn_math
 * 
 * 
 * out_{i}=cos^{-1}(input_{i})
 * 
 * @param [in]   input
 * TensorINT8INT16INT32INT64UINT8BOOLFLOATFLOAT16DOUBLETensorND
 * @param [in]   out
 * TensorFLOATFLOAT16DOUBLETensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceAcosGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceAcos
 *
 *  Tensoracos
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAcosGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAcos(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_acos.h

// Begin content from: aclnn_prelu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_PRELU_H_
#define OP_API_INC_PRELU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnPreluworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnPreluGetWorkspaceSize(const aclTensor* self, const aclTensor* weight, aclTensor* out,
                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnPrelu
 */
ACLNN_API aclnnStatus aclnnPrelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_prelu.h

// Begin content from: aclnn_ascend_quant_v3.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ASCEND_QUANT_V3_H_
#define OP_API_INC_LEVEL2_ACLNN_ASCEND_QUANT_V3_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAscendQuantV3workspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: AscendQuantV3npu deviceaclTensor
 * float16, bfloat16, float32, ND
 * Tensor
 * @param [in] scale: npu deviceaclTensor, float, bf16, float16
 * @param [in] offset: npu deviceaclTensorfloat, bf16, float16
 * @param [in] sqrtMode:  hostaclScalarbool
 * @param [in] roundMode:  hostaclScalarstring
 * @param [in] dstType:  hostaclScalar, int
 * @param [in] axis:  hostaclScalar, int
 * @param [in] y: AscendQuantV3npu deviceaclTensor
 * int8, ND
 * Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAscendQuantV3GetWorkspaceSize(const aclTensor* x, const aclTensor* scale,
                                                         const aclTensor* offset, bool sqrtMode, const char* roundMode,
                                                         int32_t dstType, int32_t axis, const aclTensor* y,
                                                         uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAscendQuantV3
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAscendAntiQuantGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAscendQuantV3(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ASCEND_QUANT_V3_H_// End content from: aclnn_ascend_quant_v3.h

// Begin content from: aclnn_round.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ROUND_H_
#define OP_API_INC_ROUND_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRoundworkspace
 * @domain aclnn_math
 *
 * 
 * @param [in] self: npu deviceaclTensorBFLOAT16,FLOAT16, FLOAT32, DOUBLE, INT32, INT64
 * NDshape9D
 * @param [in] out: npu deviceaclTensorshapeselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRoundGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief: aclnnRound
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRoundGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRound(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                 const aclrtStream stream);

/**
 * @brief aclnnInplaceRoundworkspace
 * @domain aclnn_math
 *
 * 
 * @param [in] selfRef: npu deviceaclTensorFLOAT16, FLOAT32, DOUBLE, INT32, INT64
 * NDshape9D
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRoundGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceRound
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSinGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRound(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        const aclrtStream stream);

/**
 * @brief aclnnRoundDecimalsworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * @param [in]   self
 * TensorFLOATBFLOAT16,FLOAT16DOUBLEINT32INT64TensorND
 * @param [in]   decimals: INT
 * @param [in]   out
 * TensorFLOATFLOAT16DOUBLEINT32INT64TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnRoundDecimalsGetWorkspaceSize(const aclTensor* self, int64_t decimals, aclTensor* out,
                                                         uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnRoundDecimals
 * Tensor
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B --> D([l0op::Round])

    C((decimals)) --> D([l0op::Cast])
    D --> E([l0op::ViewCopy])
    E --> F[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRoundDecimalsGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRoundDecimals(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

/**
 * @brief aclnnInplaceRoundDecimalsworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * @param [in]   selfRef
 * TensorFLOATFLOAT16DOUBLEINT32INT64TensorND
 * @param [in]   decimals: INT
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceRoundDecimalsGetWorkspaceSize(aclTensor* selfRef, int64_t decimals,
                                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceRoundDecimals
 *  Tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceRoundDecimalsGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRoundDecimals(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ROUND_H_// End content from: aclnn_round.h

// Begin content from: aclnn_minn.h
/*
 * Copyright (c) 2023 Huawei Technologies Co., Ltd.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * <p>
 * http://www.apache.org/licenses/LICENSE-2.0
 * <p>
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MINN_H_
#define OP_API_INC_MINN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMinNworkspace
 * @domain aclnn_math
 *
 * tensorstensormin
 *
 * @param [in] tensors: npu deviceaclTensorListshapeoutbroadcast
 * TensorND
 * @param [in] out: npu deviceaclTensorTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMinNGetWorkspaceSize(const aclTensorList* tensors, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnMinN
 *
 * tensorstensormin
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnSumGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMinN(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MINN_H_
// End content from: aclnn_minn.h

// Begin content from: aclnn_multi_scale_deformable_attn_function.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MULTI_SCALE_DEFORMABLE_ATTN_FUNCTION_H_
#define OP_API_INC_MULTI_SCALE_DEFORMABLE_ATTN_FUNCTION_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMultiScaleDeformableAttnFunctionworkspace
 * @domain aclnn_ops_infer
 * @param [in] value:
 * DeviceaclTensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in] spatialShape:
 * DeviceaclTensorINT32INT64TensorND
 * @param [in] levelStartIndex:
 * DeviceaclTensorINT32INT64TensorND
 * @param [in] location:
 * DeviceaclTensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in] attnWeight:
 * DeviceaclTensorFLOATFLOAT16BFLOAT16TensorND
 * @param [in] output:
 * DeviceaclTensorMultiScaleDeformableAttnFunctionFLOATFLOAT16BFLOAT16TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMultiScaleDeformableAttnFunctionGetWorkspaceSize(
    const aclTensor* value, const aclTensor* spatialShape, const aclTensor* levelStartIndex, const aclTensor* location,
    const aclTensor* attnWeight, aclTensor* output, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMultiScaleDeformableAttnFunction
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceMishGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMultiScaleDeformableAttnFunction(void* workspace, uint64_t workspaceSize,
                                                             aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MULTI_SCALE_DEFORMABLE_ATTN_FUNCTION_H_
// End content from: aclnn_multi_scale_deformable_attn_function.h

// Begin content from: aclnn_flip.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_FLIP_H_
#define OP_API_INC_LEVEL2_ACLNN_FLIP_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFlipworkspace
 * @domain aclnn_ops_infer
 * ndims
 *
 * $$
 * \operatorname{out}(i_0, i_1,
 * \ldots, i_{n-1}) = \operatorname{input}(j_0, j_1, \ldots, j_{n-1})
 * $$
 *
 * $n$$ j_k$ = $\operatorname{dimSize}(k)$ -1 - $i_k$$\operatorname{dimSize}(k)$
 * $k$
 *
 * 
 * ```mermaid
 * graph LR
 * 	A[(Self)] -->B([l0op::Contiguous])
 *     B -->D([l0op::Flip])
 *     G((dims)) --> D([l0op::ReverseV2])
 *     D -->R([l0op::ViewCopy])
 *     R --> J[(out)]
 * ```
 * @param [in] self: flipnpu deviceaclTensor
 * float16,float,int32,int16,int64,bool, int8, uint8,float64complex64, complex128, ND
 * Tensor
 * @param [in] dims: 
 * @param [in] out: flipnpu deviceaclTensor
 * float16,float,int32,int16,int64,bool, int8, uint8,float64, complex64, complex128ND
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFlipGetWorkspaceSize(const aclTensor* self, const aclIntArray* dims, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnFlip
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnFlipGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFlip(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_FLIP_H_// End content from: aclnn_flip.h

// Begin content from: aclnn_expm1.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_EXPM1_H_
#define OP_API_INC_EXPM1_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnExpm1workspace
 * @domain aclnn_math
 * selfe1self
 * $$ out_i = {e}^{self_i} - 1 $$
 * -
 *
 * ```mermaid
 * graph LR
 *  A[(self)] -->B([l0op::Contiguous])
 *  B --> D([l0op::Expm1])
 *  D --> H([l0op::Cast])
 *  H --> I([l0op::ViewCopy])
 *  I --> J[(out)]
 * ```
 *
 * @param [in] self`self`,INT64BOOLFLOATBFLOAT16FLOAT16shapeout
 * [Tensor](#)ND[](#)
 * @param [out] out`out`,FLOATBFLOAT16FLOAT16shapeself
 * [Tensor](#)ND[](#)
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnExpm1GetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnExpm1
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnExpm1GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnExpm1(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                 const aclrtStream stream);

/**
 * @brief aclnnInplaceExpm1workspace
 * @domain aclnn_math
 * selfe1self
 * $$ out_i = {e}^{self_i} - 1 $$
 * -
 *
 * ```mermaid
 * graph LR
 *  A[(selfRef)] -->B([l0op::Contiguous])
 *  B --> D([l0op::Expm1])
 *  D --> H([l0op::Cast])
 *  H --> I([l0op::ViewCopy])
 *  I --> J[(selfRef)]
 * ```
 *
 * @param [in] selfRef`selfRef`,FLOATFLOAT16
 * [Tensor](#)ND[](#)
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceExpm1GetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief aclnnInplaceExpm1
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceExpm1GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceExpm1(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                        const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_EXPM1_H_
// End content from: aclnn_expm1.h

// Begin content from: aclnn_linalg_vector_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LINALG_VECTOR_NORM_H_
#define OP_API_INC_LINALG_VECTOR_NORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLinalgVectorNorm workspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu deviceaclTensor, 
 * @param [in] ord: hostaclScalar, 
 * @param [in] dims: npu deviceaclIntArray, Axis
 * @param [in] keepDims: hostbool, dim
 * @param [in] dtype: selfselfdtypeFLOATFLOAT16
 * @param [in] out: tensor
 * @param [in] workspaceSize: npu deviceworkspace
 * @param [in] executor: op
 * @return aclnnStatus: 
 * */
ACLNN_API aclnnStatus aclnnLinalgVectorNormGetWorkspaceSize(const aclTensor* self, const aclScalar* ord,
                                                            const aclIntArray* dims, bool keepDims,
                                                            const aclDataType dtype, aclTensor* out,
                                                            uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * aclnnLinalgVectorNorm
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace
 * aclnnLinalgVectorNormGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLinalgVectorNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LINALG_VECTOR_NORM_H_// End content from: aclnn_linalg_vector_norm.h

// Begin content from: aclnn_logsumexp.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOGSUMEXP_H_
#define OP_API_INC_LOGSUMEXP_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogSumExpworkspace
 * @domain aclnn_math
 * @param [in] self: npu
 * npu deviceaclTensorFLOAT16BFLOAT16FLOAT32
 * TensorNDNCHWNHWCHWCNNDHWCNCDHW
 * @param [in] dim: logsumexpINT64
 * @param [in] keepDim: 
 * @param [in] out: npu
 * npu deviceaclTensorFLOAT16BFLOAT16FLOAT32NDNCHWNHWCHWCNNDHWCNCDHW
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnLogSumExpGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim,
                                                     aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogSumExp
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLogSoftmaxGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogSumExp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOGSUMEXP_H_
// End content from: aclnn_logsumexp.h

// Begin content from: aclnn_fake_quant_per_channel_affine_cachemask.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_fake_quant_per_channel_affine_cachemask.h
 * \brief
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_FAKE_QUANT_PER_CHANNEL_AFFINE_CACHEMASK_H_
#define OP_API_INC_LEVEL2_ACLNN_FAKE_QUANT_PER_CHANNEL_AFFINE_CACHEMASK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFakeQuantPerChannelAffineCachemaskworkspace
 * @domain aclnn_ops_train
 *
 * 
 *   selfscalezero_pointselfaxisquant_minquant_max
 * outmask
 *
 * 
 * ```mermaid
 * graph LR
 *   A1[(self)] -->B1(l0op::Contiguous)-->C1(l0op::Transpose)-->D(l0op::FakeQuantPerChannelAffineCachemask)
 *   A2[(scale)] -->B2(l0op::Contiguous)-->D(l0op::FakeQuantPerChannelAffineCachemask)
 *   A3[(zeroPoint)]-->B3(l0op::Contiguous)-->D(l0op::FakeQuantPerChannelAffineCachemask)
 *   A4((quantMin)) --> D(l0op::FakeQuantPerChannelAffineCachemask)
 *   A5((quantMax)) --> D(l0op::FakeQuantPerChannelAffineCachemask)
 *   A6((axis))-->C1(l0op::Transpose)
 *   D(l0op::FakeQuantPerChannelAffineCachemask)-->C2(l0op::Transpose)-->E1(l0op::ViewCopy)-->F1[(out)]
 *   D(l0op::FakeQuantPerChannelAffineCachemask)-->C3(l0op::Transpose)-->EF2(l0op::ViewCopy)-->F2[(mask)]
 * ```
 * @param [in] self:
 * DeviceaclTensorFLOAT16FLOAT32Tensor[](common/.md)ND
 * @param [in] scale: DeviceaclTensorFLOAT16FLOAT32size1
 * @param [in] zeroPoint: DeviceaclTensorINT32size1
 * @param [in] axis: HostINT
 * @param [in] quantMin: HostINT
 * @param [in] quantMax: HostINT
 * @param [out] out:
 * DeviceaclTensorLOAT16FLOAT32Tensor[](common/.md)ND
 * @param [out] mask: DeviceaclTensorBOOLTensor[](common/.md)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFakeQuantPerChannelAffineCachemaskGetWorkspaceSize(
    const aclTensor* self, const aclTensor* scale, const aclTensor* zeroPoint, int64_t axis, int64_t quantMin,
    int64_t quantMax, aclTensor* out, aclTensor* mask, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnFakeQuantPerChannelAffineCachemask
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnFakeQuantPerChannelAffineCachemask
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFakeQuantPerChannelAffineCachemask(void* workspace, uint64_t workspaceSize,
                                                              aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_FAKE_QUANT_PER_CHANNEL_AFFINE_CACHEMASK_H_
// End content from: aclnn_fake_quant_per_channel_affine_cachemask.h

// Begin content from: aclnn_nll_loss2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_NLLLOSS2DFORWARD_H_
#define OP_API_INC_NLLLOSS2DFORWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNLLLoss2dworkspace
 * @domain aclnn_ops_train
 * @param [in] self: npu deviceaclTensor
 * TensorNDNCHWNHWCHWCNNDHWCNCDHW
 * @param [in] target: npu deviceaclTensor
 * TensorNDNCHWNHWCHWCNNDHWCNCDHW
 * @param [in] weight: npu deviceaclTensor
 * @param [in] reduction: npu deviceworkspace
 * @param [in] ignoreIndex: op
 * @param [out] out: 
 * @param [out] totalWeightOut: 
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnNLLLoss2dGetWorkspaceSize(const aclTensor* self, const aclTensor* target,
                                                     const aclTensor* weight, int64_t reduction, int64_t ignoreIndex,
                                                     aclTensor* out, aclTensor* totalWeightOut, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);
/**
 * @brief aclnnNLLLoss2d
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnNLLLoss2dGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNLLLoss2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_NLLLOSS2DFORWARD_H_
// End content from: aclnn_nll_loss2d.h

// Begin content from: aclnn_foreach_pow_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_POW_SCALAR_LIST_H_
#define ACLNN_FOREACH_POW_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachPowScalarListGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachPowScalarListGetWorkspaceSize(
    const aclTensorList *x,
    const aclScalarList *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachPowScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachPowScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_pow_scalar_list.h

// Begin content from: aclnn_logsoftmax_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOGSOFTMAX_BACKWARD_H_
#define OP_API_INC_LOGSOFTMAX_BACKWARD_H_

#include <array>
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogSoftmaxBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnLogSoftmaxBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* output,
                                                              int64_t dim, aclTensor* out, uint64_t* workspaceSize,
                                                              aclOpExecutor** executor);

/**
 * @brief aclnnLogSoftmaxBackward
 */
ACLNN_API aclnnStatus aclnnLogSoftmaxBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                              aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOGSOFTMAX_BACKWARD_H_
// End content from: aclnn_logsoftmax_backward.h

// Begin content from: aclnn_ctc_loss_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_CTCLOSSBACKWARD_H_
#define OP_API_INC_CTCLOSSBACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCtcLossBackwardworkspace
 * @domain aclnn_ops_train
 * _ctc_loss
 *
 *
 * 
 * ```mermaid
 * graph LR
 * A[(logProbs)] -->B([l0op::Contiguous])-->D([l0op::CTCLossV2Grad])
 * A1[(targets)] -->B1([l0op::Contiguous])--> D
 * A6[(gradOut)] -->B6([l0op::Contiguous])-->D
 * A7[(negLogLikelihood)] -->B7([l0op::Contiguous])-->D
 * A8[(logAlpha)] -->B8([l0op::Contiguous])-->D
 * A2[(targetLengths)] -->B2([ConvertToTensor])-->D
 * A3[(inputLengths)] -->B3([ConvertToTensor])-->D
 * A4((blank)) -->D
 * A5((zeroInfinity)) -->D
 * D--> F1([l0op::ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] gradOut(aclTensor*): FLOAT,
 * DOUBLE(logProbs)Tensor1[Tensor](https://)ND
 * @param [in] logProbs(aclTensor*): FLOAT,DOUBLEshape($T,N,C$)
 * $T$$N$$C$0Tensor
 * [Tensor](https://)ND
 * @param [in] targets(aclTensor*): INT64,INT32,BOOL,FLOAT,FLOAT16shape($N,S$)
 * $S$$targetLengths$shape(SUM($targetLengths$))$targets$1
 * [Tensor](https://)ND
 * @param [in] inputLengths(aclIntArray*)UINT8,INT8,INT16,INT32,INT64$N$
 * $T$
 * @param [in] targetLengths(aclIntArray*)UINT8,INT8,INT16,INT32,INT64$N$
 * targetsshape($N,S$)$S$
 * @param [in] negLogLikelihood(aclTensor*)FLOAT,DOUBLE(logProbs)
 * Tensor1[Tensor](https://)ND
 * @param [in] logAlpha(aclTensor*)FLOAT,DOUBLE(logProbs)
 * Tensor3[Tensor](https://)ND
 * @param [in] blank(int)int0$C$0
 * @param [in] zeroInfinity(bool)bool$False$
 * @param [out] out(aclTensor*): CTCFLOAT,DOUBLEshape($T,N,C$)
 * [Tensor](https://)ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCtcLossBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* logProbs,
                                                           const aclTensor* targets, const aclIntArray* inputLengths,
                                                           const aclIntArray* targetLengths,
                                                           const aclTensor* negLogLikelihood, const aclTensor* logAlpha,
                                                           int64_t blank, bool zeroInfinity, aclTensor* out,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnCtcLossBackward 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnCtcLossBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCtcLossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CTCLOSSBACKWARD_H_
// End content from: aclnn_ctc_loss_backward.h

// Begin content from: aclnn_lt_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LTSCALAR_H_
#define OP_API_INC_LTSCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLtScalarGetWorkspaceSizeworkspace
 * @domain aclnn_math
 *
 * self Tensor(<)other
 * ScalarBoolTensorself<otherTrueFalse $$ out = (self < other)  ? [True]
 * : [False] $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(Self)] -->B([Contiguous])
 * B-->C1([Cast])-->D([Less])
 * E[(other)] -->F([Contiguous])
 * F --> C2([Cast])-->D
 * D -->F1([ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] self: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,INT32,UINT8,BOOL,UINT64,UINT32,DOUBLE,UINT16
 * shapeotherbroadcastTensorND
 * @param [in] other: hostaclScalarshapeotherbroadcast
 * @param [in] out: npu deviceaclTensorBOOLTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnLtScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLtScalar
 *
 * self Tensor(<)other
 * ScalarBoolTensorself<otherTrueFalse $$ out = (self < other)  ? [True]
 * : [False] $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(Self)] -->B([Contiguous])
 * B-->C1([Cast])-->D([Less])
 * E[(other)] -->F([Contiguous])
 * F --> C2([Cast])-->D
 * D -->F1([ViewCopy])--> J[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLtScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLtScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceLtScalarGetWorkspaceSizeworkspace
 * @domain aclnn_math
 *
 * selfRef Tensor(<)other
 * ScalarselfRefselfRef<otherTrueFalse $$ out = (selfRef < other)  ?
 * [True] : [False] $$
 *
 * api
 * ```mermaid
 * graph LR
 * A[(SelfRef)] --> B([l0op::Contiguous])
 * B-->C1([l0op::Cast])--> D([l0op::Less])
 * E((other)) --> C2([l0op::Cast])
 * C2 -->D
 * D --> C3([l0op::Cast])
 * C3 --> F1([l0op::ViewCopy])
 * F1 --> J[(selfRef)]
 * ```
 *
 * @param [in] selfRef: npu deviceaclTensor
 * FLOAT16,FLOAT,INT64,INT32,UINT8,BOOL,UINT64,UINT32,DOUBLE,UINT16
 * shapeotherbroadcastTensorND
 * @param [in] other: hostaclScalarshapeotherbroadcast
 * @param [in] out: npu deviceaclTensorBOOLTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnInplaceLtScalarGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLtScalar
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLtScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLtScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LTSCALAR_H_
// End content from: aclnn_lt_scalar.h

// Begin content from: aclnn_rms_norm_grad.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_RMS_NORM_GRAD_H_
#define ACLNN_RMS_NORM_GRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnRmsNormGradGetWorkspaceSize
 * parameters :
 * dy : required
 * x : required
 * rstd : required
 * gamma : required
 * dxOut : required
 * dgammaOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnRmsNormGradGetWorkspaceSize(
    const aclTensor *dy,
    const aclTensor *x,
    const aclTensor *rstd,
    const aclTensor *gamma,
    const aclTensor *dxOut,
    const aclTensor *dgammaOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnRmsNormGrad
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnRmsNormGrad(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_rms_norm_grad.h

// Begin content from: aclnn_relu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_RELU_H_
#define OP_API_INC_RELU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReluworkspace
 * @domain aclnn_ops_infer
 *
 * 
 * 
 * $$ output_i = xi if xi > 0 else 0
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Relu])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 * @param [in] self: npu
 * deviceaclTensor
 * FLOATFLOAT16INT8INT32UINT8BFLOAT16Ascend910
 * TensorND
 * @param [in] out: npu
 * deviceaclTensor
 * FLOATFLOAT16INT8INT32UINT8BFLOAT16Ascend910
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReluGetWorkspaceSize(const aclTensor* self, const aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief aclnnRelu
 * 
 * 
 * $$ output_i = xi if xi > 0 else 0
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Relu])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnReluGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

/**
 * @brief aclnnInplaceReluworkspace
 * @domain aclnn_ops_infer
 *
 * 
 * 
 * $$ output_i = xi if xi > 0 else 0
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Relu])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
```
 * @param [in] self: npu
 * deviceaclTensor
FLOATFLOAT16INT8INT32UINT8BFLOAT16Ascend910
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceReluGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnInplaceRelu
 * 
 * 
 * $$ output_i = xi if xi > 0 else 0
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([L0::Contiguous])
 *     B --> C([L0::Relu])
 *     C --> D([L0::ViewCopy])
 *     D --> E[(out)]
 * ```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceReluGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_RELU_H
// End content from: aclnn_relu.h

// Begin content from: aclnn_grouped_matmul_v3.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GROUPED_MATMUL_V3_H
#define OP_API_INC_GROUPED_MATMUL_V3_H
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupedMatmulV3workspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: xFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [in] weight:
 * weightFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [in] biasOptional:
 * biasFLOAT16FLOAT32INT32ND128
 * @param [in] scaleOptional: UINT64ND128
 * @param [in] offsetOptional: FLOAT32ND128
 * @param [in] antiquantScaleOptional:
 * FLOAT16BFLOAT16ND128
 * @param [in] antiquantOffsetOptional:
 * FLOAT16BFLOAT16ND128
 * @param [in] groupListOptional: INT64128
 * @param [in] splitItem:
 * tensor0/1tensor2/3tensor0
 * @param [in] groupType:
 * -10M1N2K
 * @param [out] y: outFLOAT16BFLOAT16INT8FLOAT32ND128
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatmulV3GetWorkspaceSize(
    const aclTensorList* x, const aclTensorList* weight, const aclTensorList* biasOptional,
    const aclTensorList* scaleOptional, const aclTensorList* offsetOptional,
    const aclTensorList* antiquantScaleOptional, const aclTensorList* antiquantOffsetOptional,
    const aclTensor* groupListOptional, int64_t splitItem, int64_t groupType, const aclTensorList* y,
    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGroupedMatmulV3
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnGtTensorGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGroupedMatmulV3(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_grouped_matmul_v3.h

// Begin content from: aclnn_convolution_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_CONVOLUTION_BACKWARD_H_
#define OP_API_INC_CONVOLUTION_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnConvolutionBackwardworkspace
 * @domain aclnn_ops_train
 *
 * @param [in] gradOutput: npu
 * deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * TensorNCLNCHW
 * @param [in] input: npu
 * deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * TensorNCLNCHW
 * @param [in] weight: npu, 
 * deviceaclTensorinput
 * Tensorinput
 * @param [in] biasSizes: npushape
 * aclIntArray, shape1
 * @param [in] stride: 
 * aclIntArray1input-2kernel size -12D2
 * @param [in] padding: 
 * aclIntArray1input-2kernel size
 * -1NCHW42Dpadding2
 * @param [in] dilation: kernel>1
 * aclIntArray1input-2kernel size -12Ddilation2
 * @param [in] transposed: 
 * boolTrue
 * @param [in] outputPadding
 * aclIntArray1input-2stridedilation2Ddilation2
 * @param [in] groups
 * int640inputoutput input = weight*groups
 * @param [in] outputMask, 
 * aclBoolArray, True
 * @param [in] cubeMathTypeCube
 * int8_t, Cube
 * @param [out] grad_input: npu deviceaclTensor
 * @param [out] grad_input: npu deviceaclTensor
 * @param [out] grad_bias: npu deviceaclTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnConvolutionBackwardGetWorkspaceSize(
    const aclTensor* gradOutput, const aclTensor* input, const aclTensor* weight, const aclIntArray* biasSizes,
    const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool transposed,
    const aclIntArray* outputPadding, int groups, const aclBoolArray* outputMask, int8_t cubeMathType,
    aclTensor* gradInput, aclTensor* gradWeight, aclTensor* gradBias, uint64_t* workspaceSize,
    aclOpExecutor** executor);

/**
 * @brief aclnnConvTbcBackwardworkspace
 * @domain aclnn_ops_train
 *
 * @param [in] self: npu
 * deviceaclTensorFLOAT16FLOAT32
 * TensorNDNCHW
 * @param [in] input: npu
 * deviceaclTensorFLOAT16FLOAT32
 * TensorNDNCHW
 * @param [in] weight: npu, 
 * deviceaclTensorinput
 * Tensorinput
 * @param [in] bias: npu
 * deviceaclTensorinput
 * @param [in] pad: 
 * int64_t,kernel size -12Dpadding2
 * @param [in] dilation: kernel>1
 * aclIntArrayinput-2kernel size -12Ddilation2
 * @param [out] grad_input: npu deviceaclTensor
 * @param [out] grad_input: npu deviceaclTensor
 * @param [out] grad_bias: npu deviceaclTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnConvTbcBackwardGetWorkspaceSize(const aclTensor* self, const aclTensor* input,
                                                           const aclTensor* weight, const aclTensor* bias,
                                                           int64_t pad, int8_t cubeMathType,
                                                           aclTensor* gradInput, aclTensor* gradWeight,
                                                           aclTensor* gradBias, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnConvolutionBackward
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnConvTbcBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnConvolutionBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               const aclrtStream stream);

/**
 * @brief aclnnConvTbcBackward
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnConvTbcbackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnConvTbcBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CONVOLUTION_BACKWARD_H_
// End content from: aclnn_convolution_backward.h

// Begin content from: aclnn_group_norm_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GROUP_NORM_BACKWARD_H_
#define OP_API_INC_GROUP_NORM_BACKWARD_H_

#include <array>
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupNormBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnGroupNormBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* input,
                                                             const aclTensor* mean, const aclTensor* rstd,
                                                             const aclTensor* gamma, int64_t N, int64_t C, int64_t HxW,
                                                             int64_t group, const aclBoolArray* outputMask,
                                                             aclTensor* gradInput, aclTensor* gradGammaOut,
                                                             aclTensor* gradBetaOut, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnGroupNormBackward
 */
ACLNN_API aclnnStatus aclnnGroupNormBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GROUP_NORM_BACKWARD_H_
// End content from: aclnn_group_norm_backward.h

// Begin content from: aclnn_slice.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_SLICE_H_
#define OP_API_INC_LEVEL2_ACLNN_SLICE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSliceworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnSliceGetWorkspaceSize(const aclTensor* self, int64_t dim, int64_t start, int64_t end,
                                                 int64_t step, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnSlice
 */
ACLNN_API aclnnStatus aclnnSlice(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SLICE_H_
// End content from: aclnn_slice.h

// Begin content from: aclnn_circular_pad2d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_CIRCULAR_PAD2D_BACKWARD_H_
#define OP_API_INC_CIRCULAR_PAD2D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnCircularPad2dBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 * @param [in] gradOutput: npu deviceaclTensor, FLOAT16, FLOAT32, BFLOAT16, ND
 * selfgradInputshapecircular_pad2doutput
 * @param [in] self: npu deviceaclTensor,
 * gradOutputNDgradOutput gradInputshapegradInput
 * @param [in] padding: npu deviceaclIntArray, INT644
 * selfself
 * @param [in] gradInput: npu deviceaclTensor, gradOutputshapeselfND
 * gradOutputself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCircularPad2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                                   const aclIntArray* padding, aclTensor* gradInput,
                                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnCircularPad2dBackward
 *
 * 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnCircularPad2dBackwardGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnCircularPad2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                 aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_CIRCULAR_PAD2D_BACKWARD_H_// End content from: aclnn_circular_pad2d_backward.h

// Begin content from: aclnn_multilabel_margin_loss.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MULTILABEL_MARGIN_LOSS_H_
#define OP_API_INC_MULTILABEL_MARGIN_LOSS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMultilabelMarginLossworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnMultilabelMarginLossGetWorkspaceSize(const aclTensor* self, const aclTensor* target,
                                                                int64_t reduction, aclTensor* out, aclTensor* isTarget,
                                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnMultilabelMarginLoss
 */
ACLNN_API aclnnStatus aclnnMultilabelMarginLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MULTILABEL_MARGIN_LOSS_H_
// End content from: aclnn_multilabel_margin_loss.h

// Begin content from: aclnn_upsample_bilinear2d_aa.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UPSAMPLE_BILINEAR2D_AA_H_
#define OP_API_INC_UPSAMPLE_BILINEAR2D_AA_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleBilinear2dAAworkspace
 * 2D
 * @domain aclnn_ops_infer
 * :
 * @Param [in] input TensorFLOATFLOAT16BFLOAT16TensorNCHWshape4Tensorout
 * @Param [in] outputSize INT64outHW
 * @Param [in] alignCorners truefalse
 * @Param [in] scalesH height
 * @Param [in] scalesW width
 * @Param [in] out FLOATFLOAT16BFLOAT16TensorNCHWshape4Tensorinput
 * @Param [out] workspaceSize npu deviceworkspace
 * @Param [out] executor op
 */
ACLNN_API aclnnStatus aclnnUpsampleBilinear2dAAGetWorkspaceSize(const aclTensor* input, const aclIntArray* outputSize,
                                                                bool alignCorners, double scalesH,
                                                                double scalesW, aclTensor* out,
                                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleBilinear2dAA
 * 2D
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleBilinear2dAA(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UPSAMPLE_BILINEAR2D_AA_H_// End content from: aclnn_upsample_bilinear2d_aa.h

// Begin content from: aclnn_weight_quant_matmul_all_reduce.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_weight_quant_matmul_all_reduce.h
 * \brief
 */
#ifndef OP_API_INC_WEIGHT_QUANT_MATMUL_ALL_REDUCE_
#define OP_API_INC_WEIGHT_QUANT_MATMUL_ALL_REDUCE_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnWeightQuantMatmulAllReduceworkspace
 * @domain aclnn_ops_infer
 * mm+AllReduce
 * @param [in] x1: matmulfloat16, bf16
 * @param [in] x2: matmulint8,int4
 * @param [in] bias: float16, bf16
 * @param [in] antiquantScale: x2float16, bf16
 * @param [in] antiquantOffset: x2float16, bf16
 * @param [in] x3: addfloat16, bf16
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [in] antiquantGroupSize: per_groupgroupSize
 * @param [out] output: +float16, bf16
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnWeightQuantMatmulAllReduceGetWorkspaceSize(
    const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const aclTensor* antiquantScale,
    const aclTensor* antiquantOffset, const aclTensor* x3, const char* group, const char* reduceOp, int64_t commTurn,
    int64_t streamMode, int64_t antiquantGroupSize, const aclTensor* output, uint64_t* workspaceSize,
    aclOpExecutor** executor);

/**
 * @brief aclnnWeightQuantMatmulAllReduce
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnWeightQuantMatmulAllReduceGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnWeightQuantMatmulAllReduce(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                      const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_WEIGHT_QUANT_MATMUL_ALL_REDUCE_// End content from: aclnn_weight_quant_matmul_all_reduce.h

// Begin content from: aclnn_isneginf.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_ISNEGINF_H_
#define OP_API_INC_ISNEGINF_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIsNegInfworkspace
 * @domain aclnn_math
 * 
 * -
 * 
 * 1
 * ```mermaid
 * graph LR
 *   A[(self)] -->B([l0op::Contiguous])
 *   B --> D([l0op::IsNegInf])
 *   D --> I([l0op::ViewCopy])
 *   I --> J[(out)]
 * ```
 * 2False
 * ```mermaid
 * graph LR
 *   A[(self)] -->B([l0op::Fill])
 *   B --> I([l0op::ViewCopy])
 *   I --> J[(out)]
 * ```
 *
 * @param [in] self`self`,FLOATFLOAT16BFLOAT16(Ascend910B),
 * INT32INT64INT16INT8UINT8BOOL[Tensor](#)ND[](#)
 * @param [out] out`out`,BOOLshapeself
 * [Tensor](#)ND[](#)
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsNegInfGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                    aclOpExecutor** executor);

/**
 * @brief aclnnIsNegInf
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnIsNegInfGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnIsNegInf(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                    const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ISNEGINF_H_
// End content from: aclnn_isneginf.h

// Begin content from: aclnn_logaddexp.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOG_ADD_EXP_H_
#define OP_API_INC_LOG_ADD_EXP_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogAddExpworkspace
 * @domain aclnn_math
 *
 * e
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEothershapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEselfshapeselfbroadcast
 * TensorNDself
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16DOUBLEselfothershapeselfother
 * broadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogAddExpGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                                     uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogAddExp
 *
 * e
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnLogAddExpGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogAddExp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOG_ADD_EXP_H_
// End content from: aclnn_logaddexp.h

// Begin content from: aclnn_pdist.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_PDIST_H_
#define OP_API_INC_PDIST_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnPdistworkspace
 * @domain aclnn_math
 *
 * p-
 *
 * @param [in] self: npu
 * deviceaclTensorTensorND
 * @param [in] p: FLOAT
 * @param [in] out: npu
 * deviceaclTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnPdistGetWorkspaceSize(const aclTensor* self, float p, aclTensor* out,
                                                 uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnPdist
 *
 * p-
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnPdistGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnPdist(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_PDIST_H_
// End content from: aclnn_pdist.h

// Begin content from: aclnn_fused_infer_attention_score_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef ACLNN_FUSED_INFER_ATTENTION_SCORE_V2_H_
#define ACLNN_FUSED_INFER_ATTENTION_SCORE_V2_H_
// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief The first interface of aclnnFusedInferAttentionScoreV2 calculates the workspace size based on the specific calculation process.
 * @domain aclnn_ops_infer
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFusedInferAttentionScoreV2GetWorkspaceSize(
    const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShiftOptional,
    const aclTensor *attenMaskOptional, const aclIntArray *actualSeqLengthsOptional,
    const aclIntArray *actualSeqLengthsKvOptional, const aclTensor *deqScale1Optional,
    const aclTensor *quantScale1Optional, const aclTensor *deqScale2Optional, const aclTensor *quantScale2Optional,
    const aclTensor *quantOffset2Optional, const aclTensor *antiquantScaleOptional,
    const aclTensor *antiquantOffsetOptional, const aclTensor *blockTableOptional,
    const aclTensor *queryPaddingSizeOptional, const aclTensor *kvPaddingSizeOptional,
    const aclTensor *keyAntiquantScaleOptional, const aclTensor *keyAntiquantOffsetOptional,
    const aclTensor *valueAntiquantScaleOptional, const aclTensor *valueAntiquantOffsetOptional,
    const aclTensor *keySharedPrefixOptional, const aclTensor *valueSharedPrefixOptional,
    const aclIntArray *actualSharedPrefixLenOptional, int64_t numHeads, double scaleValue, int64_t preTokens,
    int64_t nextTokens, char *inputLayout, int64_t numKeyValueHeads, int64_t sparseMode, int64_t innerPrecise,
    int64_t blockSize, int64_t antiquantMode, bool softmaxLseFlag, int64_t keyAntiquantMode, int64_t valueAntiquantMode,
    const aclTensor *attentionOut, const aclTensor *softmaxLse, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief The second interface of aclnnFusedInferAttentionScoreV2 is used to perform calculations.
 */
__attribute__((visibility("default"))) aclnnStatus aclnnFusedInferAttentionScoreV2(void *workspace,
                                                                                   uint64_t workspaceSize,
                                                                                   aclOpExecutor *executor,
                                                                                   const aclrtStream stream);


#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_fused_infer_attention_score_v2.h

// Begin content from: aclnn_gt_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GTSCALAR_H_
#define OP_API_INC_GTSCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGtworkspace
 * @domain aclnn_math
 * Tensorother
 * ScalarBoolTensorTensor  $$ out_{i}= (self_i >
 * other) ? True : False $$
 *
 * @param [in] self: gt,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BOOLBFLOAT16NDTensor
 * @param [in] other: gt,aclScalar
 * @param [in] out: npu deviceaclTensorBOOLTensorND
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGtScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGtScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGtScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGtScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceGtScalarworkspace
 * @domain aclnn_math
 * Tensorother Scalar
 *  $$ selfRef_{i} = (selfRef_{i} > other_{i}) ? True : False $$
 *
 * @param [in] selfRef: gt,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BOOLBFLOAT16NDTensor
 * @param [in] other: gt,aclScalar
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceGtScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceGtScalar
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceGtScalarGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceGtScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GTTENSOR_H_
// End content from: aclnn_gt_scalar.h

// Begin content from: aclnn_logdet.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOGDET_H_
#define OP_API_INC_LOGDET_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogdetworkspace.
 * @domain aclnn_math
 *
 *  Tensor
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(self)]-->B([Contiguous])-->C([LogMatrixDeterminant])
 * D([Cast])-->E([ViewCopy])-->F([out])
 * ```
 *
 * @param [in] self: npu deviceaclTensor, FLOATDOUBLECOMPLEX64COMPLEX128. shape(*, n, n),
 * `*`0batch. Tensor. ND.
 * @param [in] out: npu deviceaclTensor, FLOATDOUBLECOMPLEX64COMPLEX128. shapeselfbatch.
 * Tensor. ND.
 * @param [out] workspaceSize: npu deviceworkspace.
 * @param [out] executor: op.
 * @return aclnnStatus:  ACLNN_SUCCESS, .
 */
ACLNN_API aclnnStatus aclnnLogdetGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                  aclOpExecutor** executor);

/**
 * @brief aclnnLogdet.
 *
 * 
 * @param [in] workspace: npu deviceworkspace.
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLogdetGetWorkspaceSize.
 * @param [in] executor: op.
 * @param [in] stream: acl stream.
 * @return aclnnStatus: .
 */
ACLNN_API aclnnStatus aclnnLogdet(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOGDET_H_
// End content from: aclnn_logdet.h

// Begin content from: aclnn_any.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ANY_H_
#define OP_API_INC_LEVEL2_ACLNN_ANY_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAnyworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnAnyGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepdim,
                                               aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAny
 */
ACLNN_API aclnnStatus aclnnAny(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                               const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ANY_H_// End content from: aclnn_any.h

// Begin content from: aclnn_addmm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ADDMM_H_
#define OP_API_INC_ADDMM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAddmmworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnAddmmGetWorkspaceSize(const aclTensor* self, const aclTensor* mat1, const aclTensor* mat2,
                                                 const aclScalar* beta, const aclScalar* alpha, aclTensor* out,
                                                 int8_t cubeMathType, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @brief aclnnInplaceAddmmworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnInplaceAddmmGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* mat1,
                                                        const aclTensor* mat2, const aclScalar* beta,
                                                        const aclScalar* alpha, int8_t cubeMathType,
                                                        uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAddmm
 */
ACLNN_API aclnnStatus aclnnAddmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                 const aclrtStream stream);

/**
 * @brief aclnnInplaceAddmm
 */
ACLNN_API aclnnStatus aclnnInplaceAddmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADD_H_
// End content from: aclnn_addmm.h

// Begin content from: aclnn_selu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_SELU_H_
#define OP_API_INC_LEVEL2_ACLNN_SELU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSeluworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorselu
 * @param [in] self: npu deviceaclTensor, INT8INT32,
 * FLOATFLOAT16shapeTensorND
 * @param [in] out: npu deviceaclTensor, INT8INT32, FLOATFLOAT16, shapeself
 *  ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSeluGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief: aclnnSelu
 *
 *  Tensorselu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSeluGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceSeluworkspace
 * @domain aclnn_ops_infer
 *
 *  Tensorselu
 * @param [in] selfRef: npu deviceaclTensor, INT8INT32,
 * FLOATFLOAT16shapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSeluGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceSelu
 *
 *  Tensorselu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceSeluGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_selu.h

// Begin content from: aclnn_soft_margin_loss.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SOFT_MARGIN_LOSS_H_
#define OP_API_INC_SOFT_MARGIN_LOSS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSoftMarginLossworkspace
 * @domain aclnn_ops_train
 *
 * selftarget
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16shapetargetbroadcast
 * TensorND
 * @param [in] target: npu deviceaclTensorFLOATFLOAT16shapeselfbroadcast
 * TensorND
 * @param [in] reduction: hostint64 0('none') | 1('mean') | 2('sum')
 * 'none' 'mean' 'sum' 
 * @param [in] out: npu deviceaclTensorFLOATFLOAT16TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftMarginLossGetWorkspaceSize(const aclTensor* self, const aclTensor* target,
                                                          int64_t reduction, aclTensor* out, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

/**
 * @brief aclnnSoftMarginLoss
 *
 * selftarget
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnSoftMarginLossGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftMarginLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SOFT_MARGIN_LOSS_H_
// End content from: aclnn_soft_margin_loss.h

// Begin content from: aclnn_upsample_nearest_1d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_UNAMPLE_NEAREST_1D_H_
#define OP_API_INC_UNAMPLE_NEAREST_1D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleNearest1dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest1dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize,
                                                             aclTensor* out, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleNearest1d
 */
ACLNN_API aclnnStatus aclnnUpsampleNearest1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_NEAREST_1D_H_
// End content from: aclnn_upsample_nearest_1d.h

// Begin content from: aclnn_asinh.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_ASINH_H_
#define OP_API_INC_ASINH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAsinhworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * out_{i}=ln(input_{i} + \sqrt{input_{i}^2 + 1})
 * 
 * @param [in]   input
 * TensorFLOATBFLOAT16, FLOAT16DOUBLECOMPLEX64COMPLEX128TensorND
 * @param [in]   out
 * TensorFLOATBFLOAT16, FLOAT16DOUBLECOMPLEX64COMPLEX128TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnAsinhGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);
/**
 * @brief aclnnAsinh
 * Tensor
 * 
 * out_{i}=ln(input_{i} + \sqrt{input_{i}^2 + 1})
 * 
 * api
```mermaid
graph LR
    A[(Self)] -->B([l0op::Contiguous])
    B --> C([l0op::Asinh])
    C --> G([l0op::Cast])
    G --> E([l0op::ViewCopy])
    E --> S[(Out)]
```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAsinhGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAsinh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceAsinhworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * out_{i}=ln(input_{i} + \sqrt{input_{i}^2 + 1})
 * 
 * @param [in]   input
 * TensorINT8INT16INT32INT64UINT8BOOLFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128TensorND
 * @param [out]  workspaceSize   npu deviceworkspace
 * @param [out]  executor         op
 * @return       aclnnStatus      
 */
ACLNN_API aclnnStatus aclnnInplaceAsinhGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize,
                                                        aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceAsinh
 *
 *  Tensorasinh
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAsinhGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceAsinh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_asinh.h

// Begin content from: aclnn_flatten.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at **
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_FLATTEN_H_
#define OP_API_INC_FLATTEN_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFlattenworkspace
 * @domain aclnn_ops_infer
 * Tensoraxis2DTensor
 * selfshape(d_0,d_1,...,d_n)outshape(d_0 X d_1 ... X d_(axis-1), d_axis X d_(axis+1)... X d_n)
 * axis0outshape(1, d_0 X d_1 ... X d_n)
 * -
 *
 * ```mermaid
 * graph LR
 *   A[(self)] --> B([l0op::Contiguous])
 *   B --> C([l0op::Flatten])
 *   D[(axis)] --> C
 *   C --> I([l0op::ViewCopy])
 *   I --> J[(out)]
 * ```
 *
 * @param [in]
 * self`self`,INT8INT16INT32INT64UINT8BOOLBFLOAT16(Ascend910B)FLOATFLOAT16
 * [Tensor](#)ND[](#)
 * @param [in] axis`axis`int64_tflatten[-self.dim(),self.dim())
 * @param [out]
 * out`out`,INT8INT16INT32INT64UINT8BOOLBFLOAT16(Ascend910B)FLOATFLOAT16
 * shape2D[Tensor](#)ND[](#)
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFlattenGetWorkspaceSize(const aclTensor* self, int64_t axis, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnFlatten
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnFlattenGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnFlatten(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_FLATTEN_H_
// End content from: aclnn_flatten.h

// Begin content from: aclnn_binary_cross_entropy_with_logits.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_BINARY_CROSS_ENTROPY_WITH_LOGITS_H_
#define OP_API_INC_BINARY_CROSS_ENTROPY_WITH_LOGITS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBinaryCrossEntropyWithLogitsworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnBinaryCrossEntropyWithLogitsGetWorkspaceSize(
    const aclTensor* self, const aclTensor* target, const aclTensor* weightOptional, const aclTensor* posWeightOptional,
    int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/*
 * @brief aclnnBinaryCrossEntropyWithLogits
 */
ACLNN_API aclnnStatus aclnnBinaryCrossEntropyWithLogits(void* workspace, uint64_t workspaceSize,
                                                        aclOpExecutor* executor, const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_BINARY_CROSS_ENTROPY_WITH_LOGITS_H_
// End content from: aclnn_binary_cross_entropy_with_logits.h

// Begin content from: aclnn_quant_matmul_all_reduce_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_quant_matmul_all_reduce_v2.h
 * \brief
 */
#ifndef OP_API_INC_QUANT_MATMUL_ALL_REDUCE_V2_
#define OP_API_INC_QUANT_MATMUL_ALL_REDUCE_V2_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQuantMatmulAllReduceV2workspace
 * @domain aclnn_ops_infer
 * mm+AllReduce
 * @param [in] x1: matmulint8
 * @param [in] x2: matmulint8
 * @param [in] biasOptional: int32
 * @param [in] x3Optional: addfloat16,bfloat16
 * @param [in] dequantScale: int64,uint64,bfloat16,float32
 * @param [in] pertokenScaleOptional: per-tokenfloat32
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [out] output: +float16,bfloat16
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulAllReduceV2GetWorkspaceSize(const aclTensor *x1, const aclTensor *x2,
                                                                  const aclTensor *biasOptional,
                                                                  const aclTensor *x3Optional,
                                                                  const aclTensor *dequantScale,
                                                                  const aclTensor *pertokenScaleOptional,
                                                                  const char* group, const char *reduceOp,
                                                                  int64_t commTurn, int64_t streamMode,
                                                                  const aclTensor *output, uint64_t *workspaceSize,
                                                                  aclOpExecutor **executor);

/**
 * @brief aclnnQuantMatmulAllReduceV2
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnQuantMatmulAllReduceV2GetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulAllReduceV2(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                                  aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QUANT_MATMUL_ALL_REDUCE_V2_// End content from: aclnn_quant_matmul_all_reduce_v2.h

// Begin content from: aclnn_logsoftmax.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LOGSOFTMAX_H_
#define OP_API_INC_LOGSOFTMAX_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAddworkspace
 * @domain aclnn_ops_infer
 * @param [in] self: npu
 * npu deviceaclTensorDOUBLE, FLOAT16, FLOAT32
 * TensorNDNCHWNHWCHWCNNDHWCNCDHW
 * @param [in] dim: logsoftmaxINT64
 * @param [in] out: npu
 * npu deviceaclTensorDOUBLE, FLOAT16, FLOAT32NDNCHWNHWCHWCNNDHWCNCDHW
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogSoftmaxGetWorkspaceSize(const aclTensor* self, int64_t dim, aclTensor* out,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnLogSoftmax
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLogSoftmaxGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogSoftmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LOGSOFTMAX_H_
// End content from: aclnn_logsoftmax.h

// Begin content from: aclnn_max_unpool3d_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_MAX_UNPOOL3D_BACKWARD_H_
#define OP_API_INC_MAX_UNPOOL3D_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMaxUnpool3dBackwardworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnMaxUnpool3dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                               const aclTensor* indices, const aclIntArray* outputSize,
                                                               const aclIntArray* stride, const aclIntArray* padding,
                                                               aclTensor* out, uint64_t* workspaceSize,
                                                               aclOpExecutor** executor);

/**
 * @brief aclnnMaxUnpool3dBackward
 */
ACLNN_API aclnnStatus aclnnMaxUnpool3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                               aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_MAX_UNPOOL3D_BACKWARD_H_
// End content from: aclnn_max_unpool3d_backward.h

// Begin content from: aclnn_group_norm.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_GROUP_NORM_H_
#define OP_API_INC_GROUP_NORM_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGroupNormworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnGroupNormGetWorkspaceSize(const aclTensor* self, const aclTensor* gamma,
                                                     const aclTensor* beta, int64_t N, int64_t C, int64_t HxW,
                                                     int64_t group, double eps, aclTensor* out, aclTensor* meanOut,
                                                     aclTensor* rstdOut, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);

/**
 * @brief aclnnGroupNorm
 */
ACLNN_API aclnnStatus aclnnGroupNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GROUP_NORM_H_
// End content from: aclnn_group_norm.h

// Begin content from: aclnn_take.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_TAKE_H_
#define OP_API_INC_LEVEL2_ACLNN_TAKE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTakeworkspace
 * @domain aclnn_math
 * selfindexselfshapeindexTensor
 * i0index-1
 * $$ out_{i} = self_{index[i]}  $$
 *
 * 
 * ```mermaid
 * graph LR
 * A[(self)] --> B([l0op::Contiguous]) --> D([l0op::Gather])
 * I[(index)] --> IC([l0op::Contiguous]) --> D --> F1([l0op::ViewCopy]) --> J[(out)]
 * ```
 *
 * @param [in] self: takenpu deviceaclTensor,
 *     UINT64INT64UINT32INT32FLOAT32UINT16INT16FLOAT16INT8UINT8DOUBLECOMPLEX64COMPLEX128BOOL
 *     NDTensor8
 * @param [in] index: takenpu deviceaclTensorINT32INT64ND
 * @param [in] out: takenpu deviceaclTensorselfshapeindexND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTakeGetWorkspaceSize(const aclTensor* self, const aclTensor* index, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnTake
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTakeGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTake(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_TAKE_H_
// End content from: aclnn_take.h

// Begin content from: aclnn_gelu_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at **
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GELUV2_H_
#define OP_API_INC_LEVEL2_ACLNN_GELUV2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif
/**
 * @brief aclnnGeluV2workspace
 * @domain aclnn_ops_infer
 * 
 * 
 * $$ y_{i}=Gelu(x_{i})=x_{i}(x_{i}) $$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(x)]  --> B{l0op::Contiguous}
 *     B -->C([l0op::GeluV2])
 *     C --> D{l0op::ViewCopy}
 *     D --> E[(y)]
 *     F[approximate]-->G[getApproximateStr]-->C
 * ```
 *
 * @param [in] x: gelu_v2npu deviceaclTensor
 * FLOAT16FLOAT32BFLOAT16yNDshapeyTensor
 * @param [in] approximate: gelu_v200: "none", 1: "tanh" 
 * @param [in] y: gelu_v2
 * npu
 * deviceaclTensorFLOAT16FLOAT32BFLOAT16xNDshapex
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeluV2GetWorkspaceSize(const aclTensor* x, int64_t approximate, aclTensor* y,
                                                  uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnGeluV2
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGeluv2GetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeluV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                  const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GELUV2_H_// End content from: aclnn_gelu_v2.h

// Begin content from: aclnn_roll.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_ACLNN_ROLL_H
#define OP_API_ACLNN_ROLL_H

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRollworkspace
 * @domain aclnn_math
 *
 *  Tensorroll
 * @param [in] x: deviceaclTensorBFLOAT16,FLOAT16, FLOAT32, INT8, UINT8, INT32, UINT32BOOL
 * [Tensor](#)ND[](#)
 * @param [in] shifts: int64dims
 * @param [in] dims: int64shifts[-x.dim(), x.dim() -
 * 1]x4 [-4, 3]
 * @param [in] out: deviceaclTensorx
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRollGetWorkspaceSize(const aclTensor* x, const aclIntArray* shifts, const aclIntArray* dims,
                                                aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnRoll
 *
 *  Tensorroll
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnRollGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRoll(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_ACLNN_ROLL_H// End content from: aclnn_roll.h

// Begin content from: aclnn_foreach_acos.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ACOS_H_
#define ACLNN_FOREACH_ACOS_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAcosGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAcosGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAcos
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAcos(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_acos.h

// Begin content from: aclnn_foreach_addcdiv_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADDCDIV_SCALAR_H_
#define ACLNN_FOREACH_ADDCDIV_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddcdivScalarGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * x3 : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcdivScalarGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensorList *x3,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddcdivScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddcdivScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_addcdiv_scalar.h

// Begin content from: aclnn_foreach_maximum_scalar_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_MAXIMUM_SCALAR_LIST_H_
#define ACLNN_FOREACH_MAXIMUM_SCALAR_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachMaximumScalarListGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalars : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMaximumScalarListGetWorkspaceSize(
    const aclTensorList *x,
    const aclScalarList *scalars,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachMaximumScalarList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachMaximumScalarList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_maximum_scalar_list.h

// Begin content from: aclnn_foreach_sub_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_SUB_SCALAR_H_
#define ACLNN_FOREACH_SUB_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachSubScalarGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSubScalarGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachSubScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachSubScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_sub_scalar.h

// Begin content from: aclnn_pow.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_POW_TENSOR_SCALAR_H_
#define OP_API_INC_POW_TENSOR_SCALAR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnPowTensorScalarworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8
 * UINT8BOOLCOMPLEX64COMPLEX128BFLOAT16Ascend910
 * TensorND
 * @param [in] exponent: npu
 * deviceaclScalarFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8
 * UINT8BOOLCOMPLEX64COMPLEX128BFLOAT16Ascend910
 * @param [in] out:npu deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8
 * UINT8COMPLEX64COMPLEX128BFLOAT16Ascend910
 * shapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnPowTensorScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* exponent,
                                                           const aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);
/**
 * @brief aclnnPowTensorScalar
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnPowTensorScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnPowTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           const aclrtStream stream);

/**
 * @brief aclnnInplacePowTensorScalarworkspace
 * @domain aclnn_math
 *
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8
 * UINT8BOOLCOMPLEX64COMPLEX128BFLOAT16Ascend910
 * TensorND
 * @param [in] exponent: npu
 * deviceaclScalarFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8
 * UINT8COMPLEX64COMPLEX128BFLOAT16Ascend910
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplacePowTensorScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* exponent,
                                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplacePowTensorScalar
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace,
 * aclnnInplacePowTensorScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplacePowTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                  aclrtStream stream);

/**
 * @brief aclnnPowScalarTensorworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnPowScalarTensorGetWorkspaceSize(const aclScalar* self, const aclTensor* exponent,
                                                           const aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnPowScalarTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_POW_TENSOR_SCALAR_H_
// End content from: aclnn_pow.h

// Begin content from: aclnn_linspace.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LINSPACE_H_
#define OP_API_INC_LINSPACE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLinspaceworkspace
 * @domain aclnn_ops_infer
 *
 * steps1startend
 *
 * $$ out = (start, start + \frac{end - start}{steps - 1},...,
 *                    tart + (steps -2) * \frac{end - start}{steps - 1}, end) $$
 *
 * 
 * @param [in]   start
 * hostaclScalarND
 * @param [in]   end
 * hostaclScalarND
 * @param [in]   steps
 * hostaclScalarNDsteps0
 * @param [in]   out              tensornpu
 * deviceaclTensorND
 * @param [out]  workspaceSize: npu deviceworkspace
 * @param [out]  executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLinspaceGetWorkspaceSize(const aclScalar* start, const aclScalar* end, int64_t steps,
                                                    aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnLinspace
 *
 *
 * steps1startend
 *
 * $$ out = (start, start + \frac{end - start}{steps - 1},...,
 *                    start + (steps -2) * \frac{end - start}{steps - 1}, end) $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLinspaceGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLinspace(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_linspace.h

// Begin content from: aclnn_elu_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ELU_BACKWARD_H_
#define OP_API_INC_LEVEL2_ACLNN_ELU_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * ELUELU
 * 
 *
 * 
 *
 * 
 *
 * ```mermaid
 * graph LR
 *     A[(gradOutput)] --> B([l0op::Contiguous])
 *     B --> C([l0op::EluGradV2])
 *     C --> D([l0op::Cast])
 *     D --> E([l0op::ViewCopy])
 *     E --> F[(gradInput)]
 *     G((alpha)) --> C
 *     H((scale)) --> C
 *     I((inputScale)) --> C
 *     L((isResult)) --> C
 *     J((selfOrResult)) --> K([l0op::Contiguous])
 *     K --> C
 * ```
 */

/**
 * @brief aclnnEluBackwardworkspace
 * @domain aclnn_ops_train
 * @param [in] gradOutputELUnpu
 * deviceaclTensorFLOAT
 * FLOAT16BFLOAT16910BTensorND8
 * @param [in] alphaELUhostaclScalarFLOAT
 * @param [in] scaleELUhostaclScalarFLOAT
 * @param [in] inputScaleELUhostaclScalarFLOAT
 * @param [in] isResultELUELUBOOL
 * @param [in]
 * selfOrResultisResultTrueELUisResultFalseELU npu
 * deviceaclTensorFLOATFLOAT16gradOutputshapegradOutputshape
 * TensorND8
 * @param [in] gradInputELUnpu
 * deviceaclTensor
 * gradOutputshapegradOutputshapeTensorND8
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclScalar* alpha,
                                                       const aclScalar* scale, const aclScalar* inputScale,
                                                       bool isResult, const aclTensor* selfOrResult,
                                                       aclTensor* gradInput, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnEluBackward
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnEluBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ELU_BACKWARD_H_
// End content from: aclnn_elu_backward.h

// Begin content from: aclnn_silent_check.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_SILENT_CHECK_H_
#define OP_API_INC_LEVEL2_ACLNN_SILENT_CHECK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSilentCheckworkspace
 * @domain aclnn_ops_train
 *  val
 * , tensorflowpytorch
 * @param [in] val: npu deviceaclTensorFLOAT32, FLOAT16, BFLOAT16shape[1]
 * @param [in] inputGrad: npu deviceaclTensorFLOAT32, FLOAT16, BFLOAT16
 * @param [in] sfda: npu deviceaclTensorFLOAT32shape[3]
 * @param [in] step: npu deviceaclTensorINT64shape[1]
 * @param [in] cMinSteps: INT32
 * @param [in] cThreshL1: L1FLOAT
 * @param [in] cCoeffL1: L1FLOAT
 * @param [in] cThreshL2: L2FLOAT
 * @param [in] cCoeffL2: L2FLOAT
 * @param [in] npuAsdDetect: NPU_ASD_DETECTINT32
 * @param [in] result: aclTensorINT32
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSilentCheckGetWorkspaceSize(const aclTensor *val, aclTensor *inputGradRef,
                                                       aclTensor *sfdaRef, aclTensor *stepRef, const int32_t cMinSteps,
                                                       const float cThreshL1, const float cCoeffL1,
                                                       const float cThreshL2, const float cCoeffL2,
                                                       const int32_t npuAsdDetect, aclTensor* result,
                                                       uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief: aclnnSilentCheck
 * @domain aclnn_ops_train
 *  val
 * , tensorflowpytorch
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSilentCheckGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSilentCheck(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SILENT_CHECK_H_// End content from: aclnn_silent_check.h

// Begin content from: aclnn_bidirection_lstm.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_BIDIRECTION_LSTM_H_
#define ACLNN_BIDIRECTION_LSTM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnBidirectionLSTMGetWorkspaceSize
 * parameters :
 * x : required
 * initH : required
 * initC : required
 * wIh : required
 * wHh : required
 * bIhOptional : optional
 * bHhOptional : optional
 * wIhReverseOptional : optional
 * wHhReverseOptional : optional
 * bIhReverseOptional : optional
 * bHhReverseOptional : optional
 * numLayers : optional
 * isbias : optional
 * batchFirst : optional
 * bidirection : optional
 * yOut : required
 * outputHOut : required
 * outputCOut : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnBidirectionLSTMGetWorkspaceSize(
    const aclTensor *x,
    const aclTensor *initH,
    const aclTensor *initC,
    const aclTensor *wIh,
    const aclTensor *wHh,
    const aclTensor *bIhOptional,
    const aclTensor *bHhOptional,
    const aclTensor *wIhReverseOptional,
    const aclTensor *wHhReverseOptional,
    const aclTensor *bIhReverseOptional,
    const aclTensor *bHhReverseOptional,
    int64_t numLayers,
    bool isbias,
    bool batchFirst,
    bool bidirection,
    const aclTensor *yOut,
    const aclTensor *outputHOut,
    const aclTensor *outputCOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnBidirectionLSTM
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnBidirectionLSTM(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_bidirection_lstm.h

// Begin content from: aclnn_quant_matmul_all_reduce.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*!
 * \file aclnn_quant_matmul_all_reduce.h
 * \brief
 */
#ifndef OP_API_INC_QUANT_MATMUL_ALL_REDUCE_
#define OP_API_INC_QUANT_MATMUL_ALL_REDUCE_

#include <string>

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
// #include "hccl/hccl.h"
// #include "hccl/hccl_types.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQuantMatmulAllReduceworkspace
 * @domain aclnn_ops_infer
 * mm+AllReduce
 * @param [in] x1: matmulint8
 * @param [in] x2: matmulint8
 * @param [in] bias: int32
 * @param [in] x3: addfloat16,bfloat16
 * @param [in] dequantScale: int64,uint64,bfloat16
 * @param [in] group: 
 * @param [in] reduceOp: reducesum
 * @param [in] commTurn: /0
 * @param [in] streamMode: acl1
 * @param [out] output: +float16,bfloat16
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulAllReduceGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2,
                                                                const aclTensor* bias, const aclTensor* x3,
                                                                const aclTensor* dequantScale, const char* group,
                                                                const char* reduceOp, int64_t commTurn,
                                                                int64_t streamMode, const aclTensor* output,
                                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnQuantMatmulAllReduce
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu
 * deviceworkspaceaclnnQuantMatmulAllReduceGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQuantMatmulAllReduce(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                                const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QUANT_MATMUL_ALL_REDUCE_// End content from: aclnn_quant_matmul_all_reduce.h

// Begin content from: aclnn_foreach_add_list.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ADD_LIST_H_
#define ACLNN_FOREACH_ADD_LIST_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAddListGetWorkspaceSize
 * parameters :
 * x1 : dynamic
 * x2 : dynamic
 * alpha : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddListGetWorkspaceSize(
    const aclTensorList *x1,
    const aclTensorList *x2,
    const aclTensor *alpha,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAddList
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAddList(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_add_list.h

// Begin content from: aclnn_fill_scalar.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_FILL_H_
#define OP_API_INC_FILL_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnInplaceFillScalarworkspace
 * @domain aclnn_ops_infer
 *
 * tensor
 *
 *
 * @param [in] selfRefnpu deviceaclTensorFLOATFLOAT16UINT8INT8
 * INT16INT32INT64DOUBLECOMPLEX64COMPLEX128BOOLBFLOAT16Tensor
 * ND8
 * @param [in] value: hostaclScalarself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFillScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* value,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnInplaceFillScalar
 *
 * tensor
 *
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu
 * deviceworkspaceaclnnInplaceFillScalarGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceFillScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_FILL_H_
// End content from: aclnn_fill_scalar.h

// Begin content from: aclnn_mrgba_custom.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_MRGBA_CUSTOM_H_
#define ACLNN_MRGBA_CUSTOM_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnMrgbaCustomGetWorkspaceSize
 * parameters :
 * rgb : required
 * alpha : required
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMrgbaCustomGetWorkspaceSize(
    const aclTensor *rgb,
    const aclTensor *alpha,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnMrgbaCustom
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnMrgbaCustom(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_mrgba_custom.h

// Begin content from: aclnn_index_add.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_INDEX_ADD_H_
#define OP_API_INC_INDEX_ADD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnIndexAddworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnIndexAddGetWorkspaceSize(const aclTensor* self, const int64_t dim, const aclTensor* index,
                                                    const aclTensor* source, const aclScalar* alpha, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnIndexAdd
 */
ACLNN_API aclnnStatus aclnnIndexAdd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif// End content from: aclnn_index_add.h

// Begin content from: aclnn_rsqrt.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_RSQRT_H_
#define OP_API_INC_RSQRT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnRsqrtworkspace
 * @domain aclnn_math
 *
 *  Tensor
 * @param [in] self: npu deviceaclTensor,
 * shapeTensorND Tensor
 * @param [in] out: npu deviceaclTensor, , shapeselfND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRsqrtGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);
/**
 * @brief: aclnnRsqrt
 *
 *  Tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSigmoidGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnRsqrt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceRsqrtworkspace
 * @domain aclnn_math
 *
 *  Tensor
 * @param [in] self: npu deviceaclTensor, shapeTensorND
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceRsqrtGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size,
                                                        aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnInplaceRsqrt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                        aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_RSQRT_H_// End content from: aclnn_rsqrt.h

// Begin content from: aclnn_swi_glu.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_SWI_GLU_H_
#define ACLNN_SWI_GLU_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnSwiGluGetWorkspaceSize
 * parameters :
 * x : required
 * dim : optional
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnSwiGluGetWorkspaceSize(
    const aclTensor *x,
    int64_t dim,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnSwiGlu
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnSwiGlu(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_swi_glu.h

// Begin content from: aclnn_flash_attention_score.h
/**
 * Copyright (c) 2023-2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_FLASH_ATTENTION_SCORE_H_
#define OP_API_INC_LEVEL2_ACLNN_FLASH_ATTENTION_SCORE_H_

// #include "aclnn/aclnn_base.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnFlashAttentionScoreworkspace
 * @domain aclnn_ops_infer
 */
aclnnStatus aclnnFlashAttentionScoreGetWorkspaceSize(
    const aclTensor *query, const aclTensor *key, const aclTensor *value, const aclTensor *realShiftOptional,
    const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional,
    const aclIntArray *prefixOptional, double scaleValue, double keepProb, int64_t preTokens, int64_t nextTokens,
    int64_t headNum, char *inputLayout, int64_t innerPrecise, int64_t sparseMode, const aclTensor *softmaxMaxOut,
    const aclTensor *softmaxSumOut, const aclTensor *softmaxOutOut, const aclTensor *attentionOutOut,
    uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnFlashAttentionScore
 */
aclnnStatus aclnnFlashAttentionScore(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                     const aclrtStream stream);

/**
 * @brief aclnnFlashAttentionVarLenScoreworkspace
 * @domain aclnn_ops_infer
 */
aclnnStatus aclnnFlashAttentionVarLenScoreGetWorkspaceSize(
    const aclTensor *query, const aclTensor *key, const aclTensor *value, const aclTensor *realShiftOptional,
    const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional,
    const aclIntArray *prefixOptional, const aclIntArray *actualSeqQLenOptional,
    const aclIntArray *actualSeqKvLenOptional, double scaleValue, double keepProb, int64_t preTokens,
    int64_t nextTokens, int64_t headNum, char *inputLayout, int64_t innerPrecise, int64_t sparseMode,
    const aclTensor *softmaxMaxOut, const aclTensor *softmaxSumOut, const aclTensor *softmaxOutOut,
    const aclTensor *attentionOutOut, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnFlashAttentionVarLenScore
 */
aclnnStatus aclnnFlashAttentionVarLenScore(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                           const aclrtStream stream);


/**
 * @brief aclnnFlashAttentionScoreV2workspace
 * @domain aclnn_ops_infer
*/
aclnnStatus aclnnFlashAttentionScoreV2GetWorkspaceSize(
    const aclTensor *query,
    const aclTensor *key,
    const aclTensor *value,
    const aclTensor *realShiftOptional,
    const aclTensor *dropMaskOptional,
    const aclTensor *paddingMaskOptional,
    const aclTensor *attenMaskOptional,
    const aclIntArray *prefixOptional,
    const aclIntArray *qStartIdxOptional,
    const aclIntArray *kvStartIdxOptional,
    double scaleValue,
    double keepProb,
    int64_t preTokens,
    int64_t nextTokens,
    int64_t headNum,
    char *inputLayout,
    int64_t innerPrecise,
    int64_t sparseMode,
    int64_t pseType,
    const aclTensor *softmaxMaxOut,
    const aclTensor *softmaxSumOut,
    const aclTensor *softmaxOutOut,
    const aclTensor *attentionOutOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnFlashAttentionScoreV2
*/
aclnnStatus aclnnFlashAttentionScoreV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    const aclrtStream stream);

/**
 * @brief aclnnFlashAttentionVarLenScoreV2workspace
 * @domain aclnn_ops_infer
*/
aclnnStatus aclnnFlashAttentionVarLenScoreV2GetWorkspaceSize(
    const aclTensor *query,
    const aclTensor *key,
    const aclTensor *value,
    const aclTensor *realShiftOptional,
    const aclTensor *dropMaskOptional,
    const aclTensor *paddingMaskOptional,
    const aclTensor *attenMaskOptional,
    const aclIntArray *prefixOptional,
    const aclIntArray *actualSeqQLenOptional,
    const aclIntArray *actualSeqKvLenOptional,
    const aclIntArray *qStartIdxOptional,
    const aclIntArray *kvStartIdxOptional,
    double scaleValue,
    double keepProb,
    int64_t preTokens,
    int64_t nextTokens,
    int64_t headNum,
    char *inputLayout,
    int64_t innerPrecise,
    int64_t sparseMode,
    int64_t pseType,
    const aclTensor *softmaxMaxOut,
    const aclTensor *softmaxSumOut,
    const aclTensor *softmaxOutOut,
    const aclTensor *attentionOutOut,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/**
 * @brief aclnnFlashAttentionVarLenScoreV2
*/
aclnnStatus aclnnFlashAttentionVarLenScoreV2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif // OP_API_INC_LEVEL2_ACLNN_FLASH_ATTENTION_SCORE_H_
// End content from: aclnn_flash_attention_score.h

// Begin content from: aclnn_foreach_asin.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_ASIN_H_
#define ACLNN_FOREACH_ASIN_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachAsinGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAsinGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachAsin
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachAsin(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_asin.h

// Begin content from: aclnn_gelu_backward_v2.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_GELU_BACKWARD_V2_H_
#define OP_API_INC_GELU_BACKWARD_V2_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGeluBackwardV2workspace
 * @domain aclnn_ops_train
 * Gelu
 * @param [in] gradOutputshape
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * FRACTAL_NZNC1HWC0,NDTensor
 * @param [in] selfgelu
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * FRACTAL_NZNC1HWC0,NDTensor
 * @param [in] approximate: gelu_backward"none""tanh"
 * @param [out] gradInputgelu_backward
 * npu deviceaclTensorFLOAT16FLOAT32BFLOAT16
 * FRACTAL_NZNC1HWC0,NDTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeluBackwardV2GetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                          char *approximate, aclTensor* gradInput,
                                                          uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGeluBackwardV2
 */
ACLNN_API aclnnStatus aclnnGeluBackwardV2(void* workspace, uint64_t workspace_size, aclOpExecutor* executor,
                                          const aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_GELU_BACKWARD_V2_H_
// End content from: aclnn_gelu_backward_v2.h

// Begin content from: aclnn_softmax.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_OP_API_INC_LEVEL2_OP_ACLNN_SOFTMAX_H_
#define OP_API_OP_API_INC_LEVEL2_OP_ACLNN_SOFTMAX_H_
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"
#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSoftmaxworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnSoftmaxGetWorkspaceSize(const aclTensor* self, int64_t dim, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnSoftmax
 */
ACLNN_API aclnnStatus aclnnSoftmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif
#endif  // OP_API_OP_API_INC_LEVEL2_OP_ACLNN_SOFTMAX_H_
// End content from: aclnn_softmax.h

// Begin content from: aclnn_einsum.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_EINSUM_H_
#define OP_API_INC_EINSUM_H_

#include <string>
// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnEinsumworkspace
 * 
 * @domain aclnn_ops_infer
 * @param [in]   tensors:
 * TensorListFLOAT16FLOATINT16UINT16INT32UINT32INT64UINT64TensorND
 * @param [in]   equation: const char *
 * @param [out]  output:
 * TensorFLOAT16FLOATINT16UINT16INT32UINT32INT64UINT64TensorND
 * @param [out]  workspaceSizenpu deviceworkspace
 * @param [out]  executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEinsumGetWorkspaceSize(const aclTensorList* tensors, const char* equation, aclTensor* output,
                                                  uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnEinsum
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAddGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnEinsum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_EINSUM_H_// End content from: aclnn_einsum.h

// Begin content from: aclnn_softplus.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SOFTPLUS_H_
#define OP_API_INC_SOFTPLUS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSoftplusworkspace
 * @domain aclnn_ops_infer
 *
 * softplus
 * 
 * $$
 * Softplus(x) = \begin{cases}
 * \frac{1}{\beta} \log(1+\exp(\beta x)), \beta *x \le threshold \\
 * x, \beta *x > threshold
 * \end{cases}
 * $$
 *
 * @param [in] self: npu
 * deviceaclTensorTensorNDNCHWNHWCHWCNNDHWCNCDHW
 * @param [in] beta: hostaclScalarself
 * @param [in] thresholdhostaclScalarself
 * @param [in] out: npu
 * deviceaclTensorTensorNDNCHWNHWCHWCNNDHWCNCDHW
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftplusGetWorkspaceSize(const aclTensor* self, const aclScalar* beta,
                                                    const aclScalar* threshold, aclTensor* out, uint64_t* workspaceSize,
                                                    aclOpExecutor** executor);

/**
 * @brief aclnnSoftplus
 *
 * softplus
 * 
 * $$
 * Softplus(x) = \begin{cases}
 * \frac{1}{\beta} \log(1+\exp(\beta x)), \beta *x \le threshold \\
 * x, \beta *x > threshold
 * \end{cases}
 * $$
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSoftplusGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSoftplus(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SOFTPLUS_H_// End content from: aclnn_softplus.h

// Begin content from: aclnn_replication_pad2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REPLICATION_PAD2D_H_
#define OP_API_INC_REPLICATION_PAD2D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReplicationPad2dworkspace
 * @domain aclnn_ops_infer
 *
 * tensor
 * @param [in] self: FLOAT16, FLOAT32, DOUBLE, INT8, INT16, INT32, INT64, UINT8,
 * COMPLEX64, COMPLEX128TensorNDpad
 * @param [in] padding: INT644
 * @param [in] out: selfself
 * paddingselfpaddingTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding,
                                                            aclTensor* out, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);

/**
 * @brief: aclnnReplicationPad2d
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnReplicationPad2dGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReplicationPad2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REPLICATION_PAD2D_H_// End content from: aclnn_replication_pad2d.h

// Begin content from: aclnn_foreach_div_scalar.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_DIV_SCALAR_H_
#define ACLNN_FOREACH_DIV_SCALAR_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachDivScalarGetWorkspaceSize
 * parameters :
 * x : dynamic
 * scalar : required
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachDivScalarGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensor *scalar,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachDivScalar
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachDivScalar(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_div_scalar.h

// Begin content from: aclnn_signbit.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_SIGN_BIT_H_
#define OP_API_INC_LEVEL2_ACLNN_SIGN_BIT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSignbitworkspace
 * @domain aclnn_math
 * @param [in] self: npu deviceaclTensor
 * @param [in] out: npu deviceaclTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */

ACLNN_API aclnnStatus aclnnSignbitGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnSignbit
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSignbitGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSignbit(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_SIGN_BIT_H_// End content from: aclnn_signbit.h

// Begin content from: aclnn_sinc.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SINC_H_
#define OP_API_INC_SINC_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSincworkspace
 * @domain aclnn_math
 *
 *  Tensorsin
 * @param [in] selfRef: npu deviceaclTensor, INT8INT16INT32, INT64, UINT8BOOLFLOATFLOAT16
 *  DOUBLECOMPLEX64COMPLEX128shapeTensorND
 * @param [in] out: npu deviceaclTensor, FLOATFLOAT16DOUBLECOMPLEX64COMPLEX128, shapeself
 *  ND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSincGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** executor);

/**
 * @brief: aclnnSinc
 *
 *  Tensorsin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSincGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSinc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnInplaceSincworkspace
 * @domain aclnn_math
 *
 *  Tensorsin
 * @param [in] selfRef: npu deviceaclTensor, INT8INT16INT32, INT64, UINT8BOOLFLOAT
 *  FLOAT16DOUBLECOMPLEX64COMPLEX128shapeTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSincGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size,
                                                       aclOpExecutor** executor);

/**
 * @brief: aclnnInplaceSinc
 *
 *  Tensorsin
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceSincGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSinc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SINC_H_// End content from: aclnn_sinc.h

// Begin content from: aclnn_batch_norm_stats.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_BATCH_NORMAL_STATS_H_
#define OP_API_BATCH_NORMAL_STATS_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnBatchNormStatsworkspace
 * @domain aclnn_ops_train
 */
ACLNN_API aclnnStatus aclnnBatchNormStatsGetWorkspaceSize(const aclTensor* input, double eps, aclTensor* mean,
                                                          aclTensor* invstd, uint64_t* workspaceSize,
                                                          aclOpExecutor** executor);

/**
 * @brief aclnnBatchNormStats
 */
ACLNN_API aclnnStatus aclnnBatchNormStats(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_BATCH_NORMAL_STATS_H_
// End content from: aclnn_batch_norm_stats.h

// Begin content from: aclnn_geglu.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GEGLU_H_
#define OP_API_INC_LEVEL2_ACLNN_GEGLU_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGeGluworkspace
 * @domain aclnn_ops_infer
 * 
 * 
 * $$ out_{i}=GeGlu(self_{i}) = A \cdot Gelu(B) $$
 * $A$$self$$B$$self$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(self)] --> B([l0op::Contiguous])
 *     B --> C([l0op::GeGlu])
 *     C --> D([l0op::ViewCopy])
 *     D --> E[(out)]
 *     D --> F[(outGelu)]
 *
 *     G((dim)) --> C
 *     H((approximate)) --> C
```
 */

/**
 * @param [in] self: GeGlunpu
 * deviceaclTensorFLOAT32FLOAT16BFLOAT16910B
 * [Tensor](#)ND([](#))
 * @param [in] dimsliceINT64
 * @param [in] approximateGeGlu0`tanh`1`none`INT64
 * @param [in] out: GeGlunpu
 * deviceaclTensorself[Tensor](#)ND([](#))
 * @param [in] outGelu: Gelu(B)npu
 * deviceaclTensorself[Tensor](#)ND([](#))
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeGluGetWorkspaceSize(const aclTensor* self, int64_t dim, int64_t approximate,
                                                 aclTensor* out, aclTensor* outGelu, uint64_t* workspaceSize,
                                                 aclOpExecutor** executor);

/**
 * @param [in] self: GeGlunpu
 * @domain aclnn_ops_infer
 * deviceaclTensorFLOAT32FLOAT16BFLOAT16910B
 * [Tensor](#)ND([](#))
 * @param [in] dimsliceINT64
 * @param [in] approximateGeGlu0`tanh`1`none`INT64
 * @param [in] out: GeGlunpu
 * deviceaclTensorself[Tensor](#)ND([](#))
 * @param [in] activateLeft:
 * hostfalseactivate
 * @param [in] outGelu: Gelu(B)npu
 * deviceaclTensorself[Tensor](#)ND([](#))
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeGluV3GetWorkspaceSize(const aclTensor* self, int64_t dim, int64_t approximate,
                                                   bool activateLeft, aclTensor* out, aclTensor* outGelu,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGeGlu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGeGluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeGlu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

/**
 * @brief aclnnGeGlu
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGeGluGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGeGluV3(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GEGLU_H_
// End content from: aclnn_geglu.h

// Begin content from: aclnn_digamma.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/license/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_DIGAMMA_H_
#define OP_API_INC_LEVEL2_ACLNN_DIGAMMA_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

#define ACLNN_MAX_SHAPE_RANK 8

/**
 * @brief aclnnDigammaworkspace
 * @domain aclnn_math
 * Tensor
 * 
 * $$ out_{i} = digamma(self_{i}) $$
 * @param [in] self: digammanpu deviceaclTensor,
 * FLOATFLOAT16DOUBLENDTensor
 * @param [in] out: digammanpu deviceaclTensor,
 * FLOATFLOAT16DOUBLENDTensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDigammaGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                   aclOpExecutor** executor);

/**
 * @brief aclnnDigamma
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnDigammaGetWorkspaceSize
 * @param [in] exector: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDigamma(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_DIGAMMA_H_// End content from: aclnn_digamma.h

// Begin content from: aclnn_foreach_log2.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_LOG2_H_
#define ACLNN_FOREACH_LOG2_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachLog2GetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLog2GetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachLog2
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachLog2(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_log2.h

// Begin content from: aclnn_gather.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_GATHER_H_
#define OP_API_INC_LEVEL2_ACLNN_GATHER_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnGatherworkspace
 * @domain aclnn_ops_infer
 * tensor
 * $$ gather(X,index,d)_{i_0,i_1,\cdots,i_{d-1},i_{d+1},\cdots,i_{n-1}} =
 * X_{i_0,i_1,\cdots,i_{d-1},index_{i_d},i_{d+1},\cdots,i_{n-1}} $$
 *
 * @param [in] self: gather,npu deviceaclTensor
 * FLOAT16FLOAT32INT32INT64INT8UINT8DOUBLEUINT16UINT32UINT64BOOLND,
 * Tensor
 * @param [in] dim: hostint64
 * @param [in] index: gather,npu deviceaclTensor
 * INT32INT64ND,
 * Tensor
 * @param [in] out: gathernpu deviceaclTensor
 * selfND
 * Tensor
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGatherGetWorkspaceSize(const aclTensor* self, const int64_t dim, const aclTensor* index,
                                                  aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnGather
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnGatherGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnGather(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                  const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_GATHER_H_// End content from: aclnn_gather.h

// Begin content from: aclnn_avgpool2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_AVGPOOL2D_H_
#define OP_API_INC_AVGPOOL2D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAvgPool2dworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnAvgPool2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize,
                                                     const aclIntArray* strides, const aclIntArray* paddings,
                                                     const bool ceilMode, const bool countIncludePad,
                                                     const int64_t divisorOverride, const int8_t cubeMathType,
                                                     aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnAvgPool2d
 */
ACLNN_API aclnnStatus aclnnAvgPool2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_AVGPOOL2D_H_
// End content from: aclnn_avgpool2d.h

// Begin content from: aclnn_ascend_quant.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_ASCEND_QUANT_H_
#define OP_API_INC_LEVEL2_ACLNN_ASCEND_QUANT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnAscendQuantworkspace
 * @domain aclnn_ops_infer
 *
 * @param [in] x: AscendQuantnpu deviceaclTensor
 * float16, bfloat16, float32, ND
 * Tensor
 * @param [in] scale: npu deviceaclTensor, float, bf16, float16
 * @param [in] offset: npu deviceaclTensorfloat, bf16, float16
 * @param [in] sqrtMode:  hostaclScalarbool
 * @param [in] roundMode:  hostaclScalarstring
 * @param [in] dstType:  hostaclScalar, int
 * @param [in] y: AscendQuantnpu deviceaclTensor
 * int8, ND
 * Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAscendQuantGetWorkspaceSize(const aclTensor* x, const aclTensor* scale,
                                                       const aclTensor* offset, bool sqrtMode, const char* roundMode,
                                                       int32_t dstType, const aclTensor* y, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);

/**
 * @brief aclnnAscendQuant
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnAscendAntiQuantGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnAscendQuant(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_ASCEND_QUANT_H_// End content from: aclnn_ascend_quant.h

// Begin content from: aclnn_std.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_STD_H_
#define OP_API_INC_STD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnStdworkspace
 * @domain aclnn_math
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     D([dim]) --> C([l0op::ReduceMean])
 *     A[(self)] --> B([l0op::Contiguous])
 *     B --> C
 *     E([keepdim=true]) --> C
 *     C --> H([l0op::Expand])
 *     J([dim]) --> I
 *     K([correction]) --> I
 *     O[(self)] --> I
 *     P --> I([l0op::ReduceStdWithMean])
 *     L([keepdim]) --> I
 *     H --> P[(meanOut)]
 *     I --> M([l0op::ViewCopy])
 *     M --> N[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16NDTensor
 * @param [in] dim: hostaclIntArrayINT32INT64
 * @param [in] correction: host
 * @param [in] keepdim: host
 * @param [in] out: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16NDTensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnStdGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, const int64_t correction,
                                               bool keepdim, aclTensor* out, uint64_t* workspaceSize,
                                               aclOpExecutor** executor);

/**
 * @brief aclnnStd
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     D([dim]) --> C([l0op::ReduceMean])
 *     A[(self)] --> B([l0op::Contiguous])
 *     B --> C
 *     E([keepdim=true]) --> C
 *     C --> H([l0op::Expand])
 *     J([dim]) --> I
 *     K([correction]) --> I
 *     O[(self)] --> I
 *     P --> I([l0op::ReduceStdWithMean])
 *     L([keepdim]) --> I
 *     H --> P[(meanOut)]
 *     I --> M([l0op::ViewCopy])
 *     M --> N[(out)]
 * ```
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSubGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnStd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                               const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_STD_H_
// End content from: aclnn_std.h

// Begin content from: aclnn_swi_glu_grad.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_SWI_GLU_GRAD_H_
#define ACLNN_SWI_GLU_GRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnSwiGluGradGetWorkspaceSize
 * parameters :
 * yGrad : required
 * x : required
 * dim : optional
 * out : required
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnSwiGluGradGetWorkspaceSize(
    const aclTensor *yGrad,
    const aclTensor *x,
    int64_t dim,
    const aclTensor *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnSwiGluGrad
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnSwiGluGrad(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_swi_glu_grad.h

// Begin content from: aclnn_hardtanh.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LEVEL2_ACLNN_HARDTANH_H_
#define OP_API_INC_LEVEL2_ACLNN_HARDTANH_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnHardtanhworkspace
 * @domain aclnn_ops_infer
 * [clipValueMin,clipValueMax]maxmax
 * minminmin-1.0max1.0
 * 
 * $$
 * HardTanh(x) = \left\{\begin{matrix}
 * \begin{array}{l}
 * clipValueMax\ \ \ \ \ \ \ if \ \ x>clipValueMax \\
 * clipValueMin\ \ \ \ \ \ \ if\ \ x<clipValueMin \\
 * x\ \ \ \ \ \ \ \ \ \ \ otherwise \\
 * \end{array}
 * \end{matrix}\right.\begin{array}{l}
 * \end{array}
 * $$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([l0::Contiguous])
 *     B --> E([l0::ClipByValue])
 *     C((clipValueMin)) --> E
 *     D((clipValueMax)) --> E
 *     E --> G([l0::ViewCopy])
 *     G --> H[(out)]
 * ```
 *
 * @param [in] self: erfnpu
 * deviceaclTensorFLOATBFLOAT16FLOAT16INT32INT64INT16INT8
 * UINT8FLOAT64NDoutTensor
 * @param [in] out: erfnpu
 * deviceaclTensorFLOATBFLOAT16FLOAT16INT32INT64INT16INT8UINT8
 * FLOAT64NDself Tensor
 * @param [in] clipValueMin: hostaclScalarself
 * @param [in] clipValueMax: hostaclScalarself
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardtanhGetWorkspaceSize(const aclTensor* self, const aclScalar* clipValueMin,
                                                    const aclScalar* clipValueMax, aclTensor* out,
                                                    uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnHardtanh
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnHardtanhGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnHardtanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                    aclrtStream stream);

/**
 * @brief aclnnInplaceHardtanhworkspace
 * @domain aclnn_ops_infer
 * [clipValueMin,clipValueMax]maxmax
 * minminmin-1.0max1.0
 * 
 * $$
 * HardTanh(x) = \left\{\begin{matrix}
 * \begin{array}{l}
 * clipValueMax\ \ \ \ \ \ \ if \ \ x>clipValueMax \\
 * clipValueMin\ \ \ \ \ \ \ if\ \ x<clipValueMin \\
 * x\ \ \ \ \ \ \ \ \ \ \ otherwise \\
 * \end{array}
 * \end{matrix}\right.\begin{array}{l}
 * \end{array}
 * $$
 *
 * 
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([l0::Contiguous])
 *     B --> E([l0::ClipByValue])
 *     C((clipValueMin)) --> E
 *     D((clipValueMax)) --> E
 *     E --> G([l0::ViewCopy])
 *     G --> H[(out)]
 * ```
 *
 * @param [in] selfRef: erfnpu
 * deviceaclTensorFLOATFLOAT16INT32INT64INT16INT8
 * UINT8FLOAT64NDout Tensor
 * @param [in] clipValueMin: hostaclScalarself
 * @param [in] clipValueMax: hostaclScalarself
 * @param [out] workspace_size: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceHardtanhGetWorkspaceSize(aclTensor* selfRef, const aclScalar* clipValueMin,
                                                           const aclScalar* clipValueMax, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief aclnnInplaceHardtanh
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnInplaceHardtanhGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceHardtanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_HARDTANH_H_// End content from: aclnn_hardtanh.h

// Begin content from: aclnn_upsample_bicubic2d_aa_grad.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef ACLNN_UPSAMPLE_BICUBIC2D_AAGRAD_H_
#define ACLNN_UPSAMPLE_BICUBIC2D_AAGRAD_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleBicubic2dAAGradworkspace
 *
 * aclnnUpsampleBicubic2dAA
 *
 * @param [in] gradOutput: DeviceaclTensorFLOATFLOAT16BFLOAT16
 * TensorNCHWshapeTensorout
 * @param [in] outputSize: HostaclIntArrayINT64size2gradOutputHW
 * @param [in] inputSize: HostaclIntArrayINT64size4outNCHW
 * @param [in] scalesH: Hostoutheight
 * @param [in] scalesW: Hostoutwidth
 * @param [out] out: DeviceaclTensorFLOATFLOAT16BFLOAT16
 * TensorNCHWshapeTensorgradOutput
 * @param [out] workspaceSize: Deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
__attribute__((visibility("default")))
aclnnStatus aclnnUpsampleBicubic2dAAGradGetWorkspaceSize(
    const aclTensor *gradOutput, const aclIntArray *outputSize, const aclIntArray *inputSize, bool alignCorners, 
    double scalesH, double scalesW, aclTensor *out, uint64_t *workspaceSize, aclOpExecutor **executor);

/**
 * @brief aclnnUpsampleBicubic2dAAGrad
 * 
 * aclnnUpsampleBicubic2dAA
 *
 * @param [in] workspace: Deviceworkspace
 * @param [in] workspaceSize: Deviceworkspace
 * aclnnUpsampleBicubic2dAAGradGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: AscendCL Stream
 * @return aclnnStatus: 
 */
__attribute__((visibility("default")))
aclnnStatus aclnnUpsampleBicubic2dAAGrad(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor,
                                              aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_upsample_bicubic2d_aa_grad.h

// Begin content from: aclnn_sqrt.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SQRT_H_
#define OP_API_INC_SQRT_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnSqrtworkspace
 * @domain aclnn_math
 * nan
 * $$
 * sqrt(x)=\begin{cases}
 * \sqrt x, & x\ge 0 \\
 * nan, &  x\lt 0
 * \end{cases}
 * $$
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(self)] -->B([L0::Contiguous])
 * B --> C([L0::Sqrt])
 * C --> D([L0::ViewCopy])
 * D --> E[(out)]
 * ```
 * @param [in] self: npu
 * deviceaclTensorFLOAT16FLOAT32FLOAT64COMPLEX64COMPLEX128
 * INT32INT64INT16INT8BOOLBF16Tensor
 * TensorND
 * @param [in] out: npu
 * deviceaclTensorFLOAT16FLOAT32FLOAT64COMPLEX64COMPLEX128
 * INT32INT64INT16INT8BOOLBF16Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] opExecutor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSqrtGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                aclOpExecutor** opExecutor);
/**
 * @brief aclnnSqrt
 * nan
 * $$
 * sqrt(x)=\begin{cases}
 * \sqrt x, & x\ge 0 \\
 * nan, &  x\lt 0
 * \end{cases}
 * $$
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(self)] -->B([L0::Contiguous])
 * B --> C([L0::Sqrt])
 * C --> D([L0::ViewCopy])
 * D --> E[(out)]
 * ```
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnSqrtGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] opExecutor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnSqrt(void* workspace, uint64_t workspaceSize, aclOpExecutor* opExecutor, aclrtStream stream);
/**
 * @brief aclnnInplaceSqrtworkspace
 * @domain aclnn_math
 * nan
 * $$
 * sqrt(x)=\begin{cases}
 * \sqrt x, & x\ge 0 \\
 * nan, &  x\lt 0
 * \end{cases}
 * $$
 *
 * 
 * api
 * ```mermaid
 * graph LR
 * A[(self)] -->B([L0::Contiguous])
 * B --> C([L0::Sqrt])
 * C --> D([L0::ViewCopy])
 * D --> E[(out)]
 * ```
 * @param [in] self: npu
 * deviceaclTensorFLOAT16FLOAT32FLOAT64COMPLEX64COMPLEX128
 * INT32INT64INT16INT8BOOLBF16Tensor
 * TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSqrtGetWorkspaceSize(aclTensor* self, uint64_t* workspaceSize,
                                                       aclOpExecutor** executor);
/**
 * @brief aclnnInplaceSqrt
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceReluGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceSqrt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);
#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SQRT_H_
// End content from: aclnn_sqrt.h

// Begin content from: aclnn_permute.h

/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_PERMUTE_H_
#define OP_API_INC_PERMUTE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnPermuteworkspace
 * @domain aclnn_ops_infer
 */
ACLNN_API aclnnStatus aclnnPermuteGetWorkspaceSize(const aclTensor* self, const aclIntArray* dims, aclTensor* out,
                                                   uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnPermute
 */
ACLNN_API aclnnStatus aclnnPermute(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_PERMUTE_H_
// End content from: aclnn_permute.h

// Begin content from: aclnn_reflection_pad2d.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_REFLECTION_PAD2D_H_
#define OP_API_INC_REFLECTION_PAD2D_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnReflectionPad2dworkspace
 * @domain aclnn_ops_infer
 *
 * tensor
 * @param [in] self: npu deviceaclTensor, BFLOAT16,FLOAT16, FLOAT32, DOUBLE, INT8, INT16,
 * INT32, INT64, UINT8, BOOLND
 * @param [in] padding: npu deviceaclIntArray, INT644
 * selfself
 * @param [in] out: npu deviceaclTensor,
 * selfself
 * paddingselfpadding
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding,
                                                           aclTensor* out, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief: aclnnReflectionPad2d
 *
 *  tensor
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnReflectionPad2dGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnReflectionPad2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_REFLECTION_PAD2D_H_// End content from: aclnn_reflection_pad2d.h

// Begin content from: aclnn_logical_not.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_LogicalNot_H_
#define OP_API_INC_LogicalNot_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnLogicalNotworkspace
 * @domain aclnn_math
 *
 * 
 *
 * 
 * api
 * ```mermaid
 * graph LR
 *     A[(self)] -->B([l0op::Contiguous])
 *     B --> L([l0op::Cast])
 *     L --> E([l0op::LogicalNot])
 *     E --> E1([l0op::Cast])
 *     E1 --> G([l0op::ViewCopy])
 *     G --> H[(out)]
 * ```
 *
 * @param [in] self: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * TensorND
 * @param [in] out: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * shapeselfNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogicalNotGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize,
                                                      aclOpExecutor** executor);

/**
 * @brief aclnnLogicalNot
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLogicalNotGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnLogicalNot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

/**
 * @brief aclnnInplaceLogicalNotworkspace
 * @domain aclnn_math
 *
 * 
 *
 * @param [in] selfRef: npu
 * deviceaclTensorFLOATFLOAT16BFLOAT16DOUBLEINT32INT64INT16INT8UINT8BOOL
 * sTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLogicalNotGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize,
                                                             aclOpExecutor** executor);

/**
 * @brief aclnnInplaceLogicalNot
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnLogicalNotGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceLogicalNot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LogicalNot_H_
// End content from: aclnn_logical_not.h

// Begin content from: aclnn_non_max_suppression.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2024. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_NON_MAX_SUPPRESSION_H_
#define OP_API_INC_NON_MAX_SUPPRESSION_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

ACLNN_API aclnnStatus aclnnNonMaxSuppressionGetWorkspaceSize(const aclTensor* boxes, const aclTensor* scores,
                                                             aclIntArray* maxOutputBoxesPerClass,
                                                             aclFloatArray* iouThreshold, aclFloatArray* scoreThreshold,
                                                             int32_t centerPointBox, aclTensor* selectedIndices,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

ACLNN_API aclnnStatus aclnnNonMaxSuppression(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_NON_MAX_SUPPRESSION_H_// End content from: aclnn_non_max_suppression.h

// Begin content from: aclnn_topk.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_TOPK_H_
#define OP_API_INC_TOPK_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnTopkworkspace
 * @domain aclnn_ops_train
 *
 * k
 *
 * @param [in] self: npu
 * npu deviceaclTensorINT8UINT8INT16INT32INT64FLOAT16FLOAT32DOUBLE
 * TensorND
 * @param [in] k:
 * int64_t[0, self.size(dim)]
 * @param [in] dim:
 * int64_t[-self.dim(), self.dim())
 * @param [in] largest:
 * boolTrueFalse
 * @param [in] sorted:
 * boolTruelargestTruelargestFalse
 * False
 * @param [in] valuesOut:
 * dnpu deviceaclTensorINT8UINT8INT16INT32INT64FLOAT16FLOAT32DOUBLE
 * selfTensorND
 * @param [in] indicesOut:
 * npu deviceaclTensorINT64TensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTopkGetWorkspaceSize(const aclTensor* self, int64_t k, int64_t dim, bool largest,
                                                bool sorted, aclTensor* valuesOut, aclTensor* indicesOut,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);
/**
 * @brief aclnnTopk
 *
 * k
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnTopkGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnTopk(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                const aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_TOPK_H_
// End content from: aclnn_topk.h

// Begin content from: aclnn_div.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_DIV_H_
#define OP_API_INC_DIV_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnDivworkspace
 * @domain aclnn_math
 *
 * @param [in] self: npu
 * deviceaclTensorothershapeotherbroadcast
 * TensorNDother
 * @param [in] other: npu
 * deviceaclTensorselfshapeselfbroadcast
 * TensorNDself
 * @param [in]
 * mode0-1-2-
 * @param [in] out: npu
 * deviceaclTensorselfothershapeselfother
 * broadcastshapeNDself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDivGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out,
                                               uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnDivsworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnDivsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out,
                                                uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnDivModworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnDivModGetWorkspaceSize(const aclTensor* self, const aclTensor* other, int mode,
                                                  aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnDivModsworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnDivModsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, int mode,
                                                   aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceDivworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceDivGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other,
                                                      uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceDivsworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceDivsGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other,
                                                       uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceDivModworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceDivModGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, int mode,
                                                         uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnInplaceDivModsworkspace
 * @domain aclnn_math
 */
ACLNN_API aclnnStatus aclnnInplaceDivModsGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, int mode,
                                                          uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnDiv
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnDivGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnDiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

ACLNN_API aclnnStatus aclnnDivs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

ACLNN_API aclnnStatus aclnnDivMod(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

ACLNN_API aclnnStatus aclnnDivMods(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                   aclrtStream stream);

ACLNN_API aclnnStatus aclnnInplaceDiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                      aclrtStream stream);

ACLNN_API aclnnStatus aclnnInplaceDivs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                       aclrtStream stream);

ACLNN_API aclnnStatus aclnnInplaceDivMod(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                         aclrtStream stream);

ACLNN_API aclnnStatus aclnnInplaceDivMods(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                          aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_DIV_H_
// End content from: aclnn_div.h

// Begin content from: aclnn_mv.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_LEVEL2_ACLNN_MV_H_
#define OP_API_INC_LEVEL2_ACLNN_MV_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnMvworkspace
 * @domain aclnn_ops_infer
 *
 *  inputvec
 * @param [in] self: npu deviceaclTensorFLOAT16FLOATDOUBLECOMPLEX64COMPLEX128
 * [Tensor](#)shapen*mND([](#))
 * @param [in] vec: npu deviceaclTensorFLOAT16FLOATDOUBLECOMPLEX64COMPLEX128
 * self[Tensor](#)shapemND([](#))
 * @param [in] out: npu
 * deviceaclTensorFLOAT16FLOATDOUBLECOMPLEX64COMPLEX128self
 * [Tensor](#)shapenND([](#))
 * @param [in] cubeMathType(INT8,
 * )INT8Cube0KEEP_DTYPE, 
 * FP32Ascend91001ALLOW_FP32_DOWN_PRECISION
 * FP32Ascend910FP16Ascend910BHF16
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMvGetWorkspaceSize(const aclTensor* self, const aclTensor* vec, aclTensor* out,
                                              int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnMv
 *
 *  inputvec
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnMvGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnMv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_LEVEL2_ACLNN_MV_H_// End content from: aclnn_mv.h

// Begin content from: aclnn_qr.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_QR_H_
#define OP_API_INC_QR_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnQrworkspace
 * @domain aclnn_math
 *
 *  TensorQR
 * @param [in] self: , FLOATFLOAT16DOUBLECOMPLEX64COMPLEX128, ND,
 * Tensor
 * @param [in] some: , tensor shapecomplete, BOOL
 * @param [out] Q: ,
 * QrFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128self ND,
 * Tensor
 * @param [out] R: ,
 * QrFLOATFLOAT16DOUBLECOMPLEX64COMPLEX128self ND,
 * Tensor
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQrGetWorkspaceSize(const aclTensor* self, bool some, aclTensor* Q, aclTensor* R,
                                              uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief: aclnnQr
 *
 *  TensorQr 
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnQrGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnQr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_QR_H_// End content from: aclnn_qr.h

// Begin content from: aclnn_scatter_nd_update.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_SCATTER_ND_UPDATE_H_
#define OP_API_INC_SCATTER_ND_UPDATE_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnScatterNdUpdateworkspace
 * @domain aclnnop_ops_infer
 * @domain aclnnop_ops_train
 *  tensor updatesindicestensor var
 * @param [in] varRef: npu deviceaclTensor, FLOAT16, FLOAT32, BOOL
 * INT64BFLOAT16TensorND
 * @param [in] indices: npu deviceaclTensorINT32, INT64TensorND
 * @param [in] updates: npu deviceaclTensorFLOAT16, FLOAT32, BOOL
 * INT64BFLOAT16TensorND,
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScatterNdUpdateGetWorkspaceSize(aclTensor* varRef, const aclTensor* indices,
                                                           const aclTensor* updates, uint64_t* workspaceSize,
                                                           aclOpExecutor** executor);

/**
 * @brief: aclnnScatterNdUpdate
 * @domain aclnnop_ops_infer
 * @domain aclnnop_ops_train
 *  tensor updatesindicestensor var
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnScatterNdUpdateGetWorkspaceSize
 * @param [in] stream: acl stream
 * @param [in] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnScatterNdUpdate(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_SCATTER_ND_UPDATE_H_// End content from: aclnn_scatter_nd_update.h

// Begin content from: aclnn_nll_loss_backward.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_NLL_LOSS_BACKWARD_H_
#define OP_API_INC_NLL_LOSS_BACKWARD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnNLLLossBackwardworkspace
 * @domain aclnn_ops_train
 *
 * 
 *
 * @param [in] gradOutput: npu
 * deviceaclTensorshape(N,)(1,)FLOATTensorND
 * @param [in] self: npu deviceaclTensorshape(N,C)(C,)Nbatch
 * sizeCFLOATTensor, ND
 * @param [in] target: npu deviceaclTensorshape(N,) (1,)[0, C - 1]
 * INT64UINT8 Tensor ND
 * @param [in] weight: npu
 * deviceaclTensorshape(C,)FLOATTensorND
 * @param [in] reduction: hostint64_t 0('none') | 1('mean') | 2('sum')
 * 'none' 'mean' 'sum' 
 * @param [in] ignoreIndex: hostint64_t
 * @param [in] totalWeight: npu
 * deviceaclTensorshape(1,)FLOATweightND
 * @param [in] out: npu deviceaclTensorshapeselfTensorND
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNLLLossBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self,
                                                           const aclTensor* target, const aclTensor* weight,
                                                           int64_t reduction, int64_t ignoreIndex,
                                                           const aclTensor* totalWeight, aclTensor* out,
                                                           uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnNLLLossBackward
 *
 * 
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspace_size: npu deviceworkspaceaclnnNLLLossBackwardGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnNLLLossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                           aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_ADD_H_
// End content from: aclnn_nll_loss_backward.h

// Begin content from: aclnn_upsample_bicubic2d_aa.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef OP_API_INC_UNAMPLE_BICUBIC2D_AA_H_
#define OP_API_INC_UNAMPLE_BICUBIC2D_AA_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnUpsampleBicubic2dAAworkspace
 * @domain aclnn_ops_train
 * 
 * upsample_bicubic2d
 *
 * @param [in] x: npu deviceaclTensorFLOATBFLOAT16FLOAT16
 * [Tensor](#Tensor)NCHW
 * @param [in] outputSize: IntArraysize2outHW
 * @param [in] alignCorners: bool
 * @param [in] scalesH: doubleoutheight
 * @param [in] scalesW: doubleoutwidth
 * @param [out] out: npu
 * deviceaclTensorFLOATBFLOAT16FLOAT16x
 * [Tensor](#Tensor)NCHW
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUpsampleBicubic2dAAGetWorkspaceSize(const aclTensor* x, const aclIntArray* outputSize,
                                                             const bool alignCorners, const double scalesH,
                                                             const double scalesW, aclTensor* out,
                                                             uint64_t* workspaceSize, aclOpExecutor** executor);

/**
 * @brief aclnnUpsampleBicubic2dAA
 * 
 * upsample_bicubic2d
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspace
 * aclnnUpsampleBicubic2dAAGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnUpsampleBicubic2dAA(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                             aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_UNAMPLE_BICUBIC2D_AA_H_
// End content from: aclnn_upsample_bicubic2d_aa.h

// Begin content from: aclnn_threshold.h
/**
 * Copyright (c) Huawei Technologies Co., Ltd. 2023. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#ifndef OP_API_INC_THRESHOLD_H_
#define OP_API_INC_THRESHOLD_H_

// #include "aclnn/aclnn_base.h"
// #include "aclnn_util.h"

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief aclnnThresholdworkspace
 * @domain aclnn_math
 *
 * : selfselfthresholdvalue
 * @param [in] self: npu deviceaclTensorFLOATFLOAT16INT32INT8UINT8INT16INT64
 * [Tensor](),ND[](#)
 * @param [in] threshold: npu deviceaclScalarFLOATFLOAT16INT32INT8UINT8INT16INT64
 * self
 * @param [in] value: npu deviceaclScalarFLOATFLOAT16INT32INT8UINT8INT16INT64
 * self
 * @param [out] out: npu deviceaclTensorFLOATFLOAT16INT32INT8UINT8INT16INT64
 * Tensorshapeself
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnThresholdGetWorkspaceSize(const aclTensor* self, const aclScalar* threshold,
                                                     const aclScalar* value, aclTensor* out, uint64_t* workspaceSize,
                                                     aclOpExecutor** executor);
/**
 * @brief aclnnThreshold
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnThresholdGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnThreshold(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                     aclrtStream stream);

/**
 * @brief aclnnInplaceThresholdworkspace
 * @domain aclnn_math
 *
 * : selfselfthresholdvalue
 * @param [in] selfRef: npu deviceaclTensorFLOATFLOAT16INT32INT8UINT8INT16INT64
 * [Tensor](),ND[](#)
 * @param [in] threshold: npu deviceaclScalarFLOATFLOAT16INT32INT8UINT8INT16INT64
 * self
 * @param [in] value: npu deviceaclScalarFLOATFLOAT16INT32INT8UINT8INT16INT64
 * self
 * @param [out] workspaceSize: npu deviceworkspace
 * @param [out] executor: op
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceThresholdGetWorkspaceSize(aclTensor* selfRef, const aclScalar* threshold,
                                                            const aclScalar* value, uint64_t* workspaceSize,
                                                            aclOpExecutor** executor);
/**
 * @brief aclnnInplaceThreshold
 *
 * @param [in] workspace: npu deviceworkspace
 * @param [in] workspaceSize: npu deviceworkspaceaclnnInplaceThresholdGetWorkspaceSize
 * @param [in] executor: op
 * @param [in] stream: acl stream
 * @return aclnnStatus: 
 */
ACLNN_API aclnnStatus aclnnInplaceThreshold(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor,
                                            aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif  // OP_API_INC_THRESHOLD_H_
// End content from: aclnn_threshold.h

// Begin content from: aclnn_foreach_reciprocal.h

/*
 * calution: this file was generated automaticlly donot change it.
*/

#ifndef ACLNN_FOREACH_RECIPROCAL_H_
#define ACLNN_FOREACH_RECIPROCAL_H_

// #include "aclnn/acl_meta.h"

#ifdef __cplusplus
extern "C" {
#endif

/* funtion: aclnnForeachReciprocalGetWorkspaceSize
 * parameters :
 * x : dynamic
 * out : dynamic
 * workspaceSize : size of workspace(output).
 * executor : executor context(output).
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachReciprocalGetWorkspaceSize(
    const aclTensorList *x,
    const aclTensorList *out,
    uint64_t *workspaceSize,
    aclOpExecutor **executor);

/* funtion: aclnnForeachReciprocal
 * parameters :
 * workspace : workspace memory addr(input).
 * workspaceSize : size of workspace(input).
 * executor : executor context(input).
 * stream : acl stream.
 */
__attribute__((visibility("default")))
aclnnStatus aclnnForeachReciprocal(
    void *workspace,
    uint64_t workspaceSize,
    aclOpExecutor *executor,
    aclrtStream stream);

#ifdef __cplusplus
}
#endif

#endif
// End content from: aclnn_foreach_reciprocal.h

